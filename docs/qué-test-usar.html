<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lección 15 Qué test usar? | Bioestadística (Medicina UIB)</title>
  <meta name="description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Lección 15 Qué test usar? | Bioestadística (Medicina UIB)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="github-repo" content="AprendeR-UIB/INREMDN" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lección 15 Qué test usar? | Bioestadística (Medicina UIB)" />
  
  <meta name="twitter:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  

<meta name="author" content="Irene García, Francesc Rosselló" />


<meta name="date" content="2023-10-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="contrastes-de-hipótesis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">INREMDN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a></li>
<li class="part"><span><b>Tema I: Introducción a los estudios médicos y la estadística</b></span></li>
<li class="chapter" data-level="1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="estudios-médicos.html"><a href="estudios-médicos.html"><i class="fa fa-check"></i><b>2</b> Estudios médicos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:pasos"><i class="fa fa-check"></i><b>2.1</b> Pasos de un estudio médico</a></li>
<li class="chapter" data-level="2.2" data-path="estudios-médicos.html"><a href="estudios-médicos.html#algunos-calificativos-para-los-estudios-médicos"><i class="fa fa-check"></i><b>2.2</b> Algunos calificativos para los estudios médicos</a></li>
<li class="chapter" data-level="2.3" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-descriptivos"><i class="fa fa-check"></i><b>2.3</b> Estudios descriptivos</a></li>
<li class="chapter" data-level="2.4" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:cyc"><i class="fa fa-check"></i><b>2.4</b> Estudios de casos y controles</a></li>
<li class="chapter" data-level="2.5" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-de-cohorte"><i class="fa fa-check"></i><b>2.5</b> Estudios de cohorte</a></li>
<li class="chapter" data-level="2.6" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-transversales"><i class="fa fa-check"></i><b>2.6</b> Estudios transversales</a></li>
<li class="chapter" data-level="2.7" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:ecol"><i class="fa fa-check"></i><b>2.7</b> Estudios ecológicos</a></li>
<li class="chapter" data-level="2.8" data-path="estudios-médicos.html"><a href="estudios-médicos.html#ensayos-clínicos"><i class="fa fa-check"></i><b>2.8</b> Ensayos clínicos</a></li>
<li class="chapter" data-level="2.9" data-path="estudios-médicos.html"><a href="estudios-médicos.html#a-modo-de-resumen"><i class="fa fa-check"></i><b>2.9</b> A modo de resumen</a></li>
<li class="chapter" data-level="2.10" data-path="estudios-médicos.html"><a href="estudios-médicos.html#revisiones-sistemáticas-y-metaanálisis"><i class="fa fa-check"></i><b>2.10</b> Revisiones sistemáticas y metaanálisis</a></li>
<li class="chapter" data-level="2.11" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:causalidad"><i class="fa fa-check"></i><b>2.11</b> (Bonus track) Unos criterios de causalidad</a></li>
<li class="chapter" data-level="2.12" data-path="estudios-médicos.html"><a href="estudios-médicos.html#bonus-track-preguntas-clínicas-en-formato-pico"><i class="fa fa-check"></i><b>2.12</b> (Bonus track) Preguntas clínicas en formato PICO</a></li>
<li class="chapter" data-level="2.13" data-path="estudios-médicos.html"><a href="estudios-médicos.html#test"><i class="fa fa-check"></i><b>2.13</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html"><i class="fa fa-check"></i><b>3</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#unidad-de-observación"><i class="fa fa-check"></i><b>3.1</b> Unidad de observación</a></li>
<li class="chapter" data-level="3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#población-y-muestra"><i class="fa fa-check"></i><b>3.2</b> Población y muestra</a></li>
<li class="chapter" data-level="3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:muestreo"><i class="fa fa-check"></i><b>3.3</b> Tipos básicos de muestreo</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mas"><i class="fa fa-check"></i><b>3.3.1</b> Muestreo aleatorio con y sin reposición</a></li>
<li class="chapter" data-level="3.3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sist"><i class="fa fa-check"></i><b>3.3.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="3.3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:estr"><i class="fa fa-check"></i><b>3.3.3</b> Muestreo aleatorio estratificado</a></li>
<li class="chapter" data-level="3.3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mcluster"><i class="fa fa-check"></i><b>3.3.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="3.3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:oport"><i class="fa fa-check"></i><b>3.3.5</b> Muestreos no aleatorios</a></li>
<li class="chapter" data-level="3.3.6" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:poli"><i class="fa fa-check"></i><b>3.3.6</b> Muestreo polietápico</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sesgos"><i class="fa fa-check"></i><b>3.4</b> Sesgos</a></li>
<li class="chapter" data-level="3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#test-1"><i class="fa fa-check"></i><b>3.5</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema II: Probabilidades</b></span></li>
<li class="chapter" data-level="4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html"><i class="fa fa-check"></i><b>4</b> Probabilidades elementales: Las mates</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#álgebra-de-conjuntos"><i class="fa fa-check"></i><b>4.1</b> Álgebra de conjuntos</a></li>
<li class="chapter" data-level="4.2" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#algunas-fórmulas-básicas"><i class="fa fa-check"></i><b>4.2</b> Algunas fórmulas básicas</a></li>
<li class="chapter" data-level="4.3" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sec:odds"><i class="fa fa-check"></i><b>4.3</b> Odds</a></li>
<li class="chapter" data-level="4.4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>4.4</b> Probabilidad condicionada</a></li>
<li class="chapter" data-level="4.5" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sucesos-independientes"><i class="fa fa-check"></i><b>4.5</b> Sucesos independientes</a></li>
<li class="chapter" data-level="4.6" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#odds-condicionadas-y-odds-ratios-relativas"><i class="fa fa-check"></i><b>4.6</b> Odds condicionadas y odds ratios relativas</a></li>
<li class="chapter" data-level="4.7" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#el-teorema-de-la-probabilidad-total"><i class="fa fa-check"></i><b>4.7</b> El teorema de la probabilidad total</a></li>
<li class="chapter" data-level="4.8" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#la-fórmula-de-bayes"><i class="fa fa-check"></i><b>4.8</b> La fórmula de Bayes</a></li>
<li class="chapter" data-level="4.9" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#test-2"><i class="fa fa-check"></i><b>4.9</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html"><i class="fa fa-check"></i><b>5</b> Probabilidades elementales: Aplicaciones en medicina</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#pruebas-diagnósticas"><i class="fa fa-check"></i><b>5.1</b> Pruebas diagnósticas</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sensibilidad-especificidad-valores-predictivos-etc."><i class="fa fa-check"></i><b>5.1.1</b> Sensibilidad, especificidad, valores predictivos etc.</a></li>
<li class="chapter" data-level="5.1.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#curvas-roc"><i class="fa fa-check"></i><b>5.1.2</b> Curvas ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:probaplic2"><i class="fa fa-check"></i><b>5.2</b> Riesgos</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosRR"><i class="fa fa-check"></i><b>5.2.1</b> Riesgos relativos y absolutos</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosCyC"><i class="fa fa-check"></i><b>5.2.2</b> <em>Odds ratios</em></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#tratamientos"><i class="fa fa-check"></i><b>5.3</b> Tratamientos</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#test-3"><i class="fa fa-check"></i><b>5.4</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema III: Estadística descriptiva</b></span></li>
<li class="chapter" data-level="6" data-path="sec:tiposdatos.html"><a href="sec:tiposdatos.html"><i class="fa fa-check"></i><b>6</b> Tipos de datos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec:tiposdatos.html"><a href="sec:tiposdatos.html#test-4"><i class="fa fa-check"></i><b>6.1</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html"><i class="fa fa-check"></i><b>7</b> Descripción de datos cualitativos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:frecs"><i class="fa fa-check"></i><b>7.1</b> Frecuencias</a></li>
<li class="chapter" data-level="7.2" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#gráficos"><i class="fa fa-check"></i><b>7.2</b> Gráficos</a></li>
<li class="chapter" data-level="7.3" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#tablas-de-frecuencias-multidimensionales"><i class="fa fa-check"></i><b>7.3</b> Tablas de frecuencias multidimensionales</a></li>
<li class="chapter" data-level="7.4" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:barrasbidim"><i class="fa fa-check"></i><b>7.4</b> Diagramas de barras bidimensionales</a></li>
<li class="chapter" data-level="7.5" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#diagramas-de-mosaico"><i class="fa fa-check"></i><b>7.5</b> Diagramas de mosaico</a></li>
<li class="chapter" data-level="7.6" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#test-5"><i class="fa fa-check"></i><b>7.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html"><i class="fa fa-check"></i><b>8</b> Descripción de datos ordinales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#frecuencias-y-diagramas-de-barras"><i class="fa fa-check"></i><b>8.1</b> Frecuencias y diagramas de barras</a></li>
<li class="chapter" data-level="8.2" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#test-6"><i class="fa fa-check"></i><b>8.2</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html"><i class="fa fa-check"></i><b>9</b> Descripción de datos cuantitativos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#frecuencias"><i class="fa fa-check"></i><b>9.1</b> Frecuencias</a></li>
<li class="chapter" data-level="9.2" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-tendencia-central"><i class="fa fa-check"></i><b>9.2</b> Medidas de tendencia central</a></li>
<li class="chapter" data-level="9.3" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-posición"><i class="fa fa-check"></i><b>9.3</b> Medidas de posición</a></li>
<li class="chapter" data-level="9.4" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>9.4</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="9.5" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#diagramas-de-puntos-y-de-caja"><i class="fa fa-check"></i><b>9.5</b> Diagramas de puntos y de caja</a></li>
<li class="chapter" data-level="9.6" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#histogramas"><i class="fa fa-check"></i><b>9.6</b> Histogramas</a></li>
<li class="chapter" data-level="9.7" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#polígonos-de-frecuencias"><i class="fa fa-check"></i><b>9.7</b> Polígonos de frecuencias</a></li>
<li class="chapter" data-level="9.8" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#asimetría-y-curtosis"><i class="fa fa-check"></i><b>9.8</b> Asimetría y curtosis</a></li>
<li class="chapter" data-level="9.9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#estadísticos-y-gráficos-con-jamovi"><i class="fa fa-check"></i><b>9.9</b> Estadísticos y gráficos con JAMOVI</a></li>
<li class="chapter" data-level="9.10" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#sec:estagrup"><i class="fa fa-check"></i><b>9.10</b> Estadísticos sobre datos agrupados</a></li>
<li class="chapter" data-level="9.11" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#datos-cuantitativos-bivariantes"><i class="fa fa-check"></i><b>9.11</b> Datos cuantitativos bivariantes</a></li>
<li class="chapter" data-level="9.12" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#gráficos-en-escala-logarítmica"><i class="fa fa-check"></i><b>9.12</b> Gráficos en escala logarítmica</a></li>
<li class="chapter" data-level="9.13" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#test-7"><i class="fa fa-check"></i><b>9.13</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema IV: Variables aleatorias</b></span></li>
<li class="chapter" data-level="10" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html"><i class="fa fa-check"></i><b>10</b> Variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#densidad-y-distribución"><i class="fa fa-check"></i><b>10.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="10.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#esperanza"><i class="fa fa-check"></i><b>10.2</b> Esperanza</a></li>
<li class="chapter" data-level="10.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#varianza-y-desviación-típica"><i class="fa fa-check"></i><b>10.3</b> Varianza y desviación típica</a></li>
<li class="chapter" data-level="10.4" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#cuantiles"><i class="fa fa-check"></i><b>10.4</b> Cuantiles</a></li>
<li class="chapter" data-level="10.5" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#familias-importantes-de-variables-aleatorias-discretas"><i class="fa fa-check"></i><b>10.5</b> Familias importantes de variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-binomiales"><i class="fa fa-check"></i><b>10.5.1</b> Variables aleatorias binomiales</a></li>
<li class="chapter" data-level="10.5.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-hipergeométricas"><i class="fa fa-check"></i><b>10.5.2</b> Variables aleatorias hipergeométricas</a></li>
<li class="chapter" data-level="10.5.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-de-poisson"><i class="fa fa-check"></i><b>10.5.3</b> Variables aleatorias de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#test-8"><i class="fa fa-check"></i><b>10.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html"><i class="fa fa-check"></i><b>11</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#densidad-y-distribución-1"><i class="fa fa-check"></i><b>11.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="11.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#esperanza-varianza-cuantiles"><i class="fa fa-check"></i><b>11.2</b> Esperanza, varianza, cuantiles…</a></li>
<li class="chapter" data-level="11.3" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#sec:normal"><i class="fa fa-check"></i><b>11.3</b> Variables aleatorias normales</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#propiedades-básicas"><i class="fa fa-check"></i><b>11.3.1</b> Propiedades básicas</a></li>
<li class="chapter" data-level="11.3.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#intervalos-de-referencia"><i class="fa fa-check"></i><b>11.3.2</b> Intervalos de referencia</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#test-9"><i class="fa fa-check"></i><b>11.4</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema V: Estadística inferencial</b></span></li>
<li class="chapter" data-level="12" data-path="estimadores.html"><a href="estimadores.html"><i class="fa fa-check"></i><b>12</b> Estimadores</a>
<ul>
<li class="chapter" data-level="12.1" data-path="estimadores.html"><a href="estimadores.html#la-media-muestral"><i class="fa fa-check"></i><b>12.1</b> La media muestral</a></li>
<li class="chapter" data-level="12.2" data-path="estimadores.html"><a href="estimadores.html#la-proporción-muestral"><i class="fa fa-check"></i><b>12.2</b> La proporción muestral</a></li>
<li class="chapter" data-level="12.3" data-path="estimadores.html"><a href="estimadores.html#la-varianza-muestral"><i class="fa fa-check"></i><b>12.3</b> La varianza muestral</a></li>
<li class="chapter" data-level="12.4" data-path="estimadores.html"><a href="estimadores.html#la-distribución-t-de-student"><i class="fa fa-check"></i><b>12.4</b> La distribución t de Student</a></li>
<li class="chapter" data-level="12.5" data-path="estimadores.html"><a href="estimadores.html#test-10"><i class="fa fa-check"></i><b>12.5</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>13</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#sec:IC"><i class="fa fa-check"></i><b>13.1</b> Definiciones básicas</a></li>
<li class="chapter" data-level="13.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-ejemplo-ic-95-para-la-media-de-una-variable-aleatoria-normal"><i class="fa fa-check"></i><b>13.2</b> Un ejemplo: IC-95% para la media de una variable aleatoria normal</a></li>
<li class="chapter" data-level="13.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-basado-en-la-t-de-student"><i class="fa fa-check"></i><b>13.3</b> Intervalo de confianza para la media basado en la t de Student</a></li>
<li class="chapter" data-level="13.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-proporciones"><i class="fa fa-check"></i><b>13.4</b> Intervalos de confianza para proporciones</a></li>
<li class="chapter" data-level="13.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#bonus-track-otros-intervalos-de-confianza"><i class="fa fa-check"></i><b>13.5</b> (Bonus track) Otros intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-intervalo-de-confianza-para-la-diferencia-de-proporciones"><i class="fa fa-check"></i><b>13.5.1</b> Un intervalo de confianza para la diferencia de proporciones</a></li>
<li class="chapter" data-level="13.5.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-diferencias-de-medias"><i class="fa fa-check"></i><b>13.5.2</b> Intervalos de confianza para diferencias de medias</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#test-11"><i class="fa fa-check"></i><b>13.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>14</b> Contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="14.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#hipótesis-nula-y-alternativa"><i class="fa fa-check"></i><b>14.1</b> Hipótesis nula y alternativa</a></li>
<li class="chapter" data-level="14.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:moneda"><i class="fa fa-check"></i><b>14.2</b> Un ejemplo</a></li>
<li class="chapter" data-level="14.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:pval"><i class="fa fa-check"></i><b>14.3</b> El p-valor</a></li>
<li class="chapter" data-level="14.4" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#tipo-de-errores"><i class="fa fa-check"></i><b>14.4</b> Tipo de errores</a></li>
<li class="chapter" data-level="14.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:exttest"><i class="fa fa-check"></i><b>14.5</b> Ejemplo: El test t</a></li>
<li class="chapter" data-level="14.6" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#la-potencia-de-un-contraste"><i class="fa fa-check"></i><b>14.6</b> La potencia de un contraste</a></li>
<li class="chapter" data-level="14.7" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#intervalo-de-confianza-de-un-contraste"><i class="fa fa-check"></i><b>14.7</b> Intervalo de confianza de un contraste</a></li>
<li class="chapter" data-level="14.8" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#resultados-estadísticamente-significativos-versus-resultados-clínicamente-significativos"><i class="fa fa-check"></i><b>14.8</b> Resultados estadísticamente significativos <em>versus</em> resultados clínicamente significativos</a></li>
<li class="chapter" data-level="14.9" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#test-12"><i class="fa fa-check"></i><b>14.9</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="qué-test-usar.html"><a href="qué-test-usar.html"><i class="fa fa-check"></i><b>15</b> Qué test usar?</a>
<ul>
<li class="chapter" data-level="15.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-medias"><i class="fa fa-check"></i><b>15.1</b> Contrastes para medias</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-una-media"><i class="fa fa-check"></i><b>15.1.1</b> Contrastes para una media</a></li>
<li class="chapter" data-level="15.1.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#inciso-tests-de-normalidad"><i class="fa fa-check"></i><b>15.1.2</b> Inciso: tests de normalidad</a></li>
<li class="chapter" data-level="15.1.3" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-dos-medias"><i class="fa fa-check"></i><b>15.1.3</b> Contrastes para dos medias</a></li>
<li class="chapter" data-level="15.1.4" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-más-de-dos-medias"><i class="fa fa-check"></i><b>15.1.4</b> Contrastes para más de dos medias</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-varianzas"><i class="fa fa-check"></i><b>15.2</b> Contrastes para varianzas</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-bilaterales-para-dos-varianzas"><i class="fa fa-check"></i><b>15.2.1</b> Contrastes bilaterales para dos varianzas</a></li>
<li class="chapter" data-level="15.2.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-de-homogeneidad-para-más-de-dos-varianzas"><i class="fa fa-check"></i><b>15.2.2</b> Contrastes de homogeneidad para más de dos varianzas</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-proporciones"><i class="fa fa-check"></i><b>15.3</b> Contrastes para proporciones</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-una-proporción"><i class="fa fa-check"></i><b>15.3.1</b> Contrastes para una proporción</a></li>
<li class="chapter" data-level="15.3.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-dos-proporciones"><i class="fa fa-check"></i><b>15.3.2</b> Contrastes para dos proporciones</a></li>
<li class="chapter" data-level="15.3.3" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-más-de-dos-proporciones-y-contrastes-de-independencia"><i class="fa fa-check"></i><b>15.3.3</b> Contrastes para más de dos proporciones y contrastes de independencia</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bioestadística (Medicina UIB)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="qué-test-usar" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Lección 15</span> Qué test usar?<a href="qué-test-usar.html#qué-test-usar" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En esta lección estudiamos los contrastes de hipótesis más frecuentes sobre medias, varianzas, proporciones, etc. El objetivo principal es, para cada tipo de contraste, explicar qué tests se pueden usar. Para la mayoría de estos tests no vamos a explicar las fórmulas de los estadísticos de contraste o intervalos de confianza, solo qué test usar en cada situación, cómo efectuarlos con JAMOVI y cómo interpretar los resultados.</p>
<div id="contrastes-para-medias" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Contrastes para medias<a href="qué-test-usar.html#contrastes-para-medias" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-para-una-media" class="section level3 hasAnchor" number="15.1.1">
<h3><span class="header-section-number">15.1.1</span> Contrastes para una media<a href="qué-test-usar.html#contrastes-para-una-media" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria de media <span class="math inline">\(\mu\)</span>. Queremos realizar un contraste sobre <span class="math inline">\(\mu\)</span>, de la forma
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=\mu_0\\
H_{1}:\mu \neq\mu_0\text{ o }\mu &gt;\mu_0\text{ o }\mu&lt;\mu_0
\end{array}
\right.
\]</span>
Para ello, medimos <span class="math inline">\(X\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span>.</p>
<div id="test-t" class="section level4 hasAnchor" number="15.1.1.1">
<h4><span class="header-section-number">15.1.1.1</span> Test t<a href="qué-test-usar.html#test-t" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos que estamos en una de las dos situaciones siguientes:</p>
<ul>
<li><p><span class="math inline">\(X\)</span> es normal; o</p></li>
<li><p><span class="math inline">\(X\)</span> no es necesariamente normal pero el tamaño <span class="math inline">\(n\)</span> de la muestra que tomamos es grande (digamos, para fijar ideas, que <span class="math inline">\(n\geqslant 40\)</span>).</p></li>
</ul>
<p>En cualquiera de estas dos situaciones, podemos usar el <strong>test t</strong> que hemos explicado en la lección anterior para realizar el contraste. JAMOVI lo ofrece en la sección <strong>Prueba T en una muestra</strong> del módulo <strong>Pruebas T</strong> (lo que abreviaremos a partir de ahora como <strong>Pruebas T/Prueba T en una muestra</strong>) de su instalación básica.</p>
<div class="example">
<p><span id="exm:temp" class="example"><strong>Ejemplo 15.1  </strong></span>La temperatura media del cuerpo humano, ¿es el valor comúnmente aceptado de 37<sup>o</sup> C?</p>
</div>
<p>Para empezar, tenemos que traducir esta pregunta a un contraste de hipótesis:</p>
<ul>
<li><p><strong>Variable aleatoria poblacional</strong>: <span class="math inline">\(X\)</span>: temperatura del cuerpo humano en <sup>o</sup>C, de media <span class="math inline">\(\mu\)</span>.</p></li>
<li><p><strong>Contraste</strong>: Nos preguntamos si <span class="math inline">\(\mu=37^{\mathrm{o}}\)</span> o no, por lo que el contraste es bilateral:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=37\\
H_{1}:\mu\neq 37
\end{array}\right.
\]</span></p></li>
</ul>
<p>Para efectuar el contraste, necesitamos una muestra de temperaturas. Vamos a usar las recogidas por P. A. Mackowiak, S. S. Wasserman y M. M. Levine que ya usamos en el Ejemplo <a href="intervalos-de-confianza.html#exm:tempsIC">13.9</a>, y que tenemos guardadas en la variable <strong>Temperatura</strong> de la tabla de datos <strong>Temperaturas.txt</strong>.</p>
<p>Con JAMOVI, importamos el fichero <strong>Temperaturas.txt</strong> en una tabla de datos (con <strong>Importar especial</strong>). Dando una ojeada a la tabla de datos (con el menú <strong>Datos</strong>), o usando la casilla <em>N</em> de <strong>Exploración/Descriptivas</strong>, vemos que la muestra es de tamaño 230, más que suficiente para poder usar un test t.</p>
<p>Entonces, abrimos <strong>Pruebas T/Prueba T en una muestra</strong>; seleccionamos como variable dependiente la <code>Temperatura</code>; entramos 37 en la casilla <em>Valor de la prueba</em>; y marcamos las casillas que se muestran en la figura que sigue. Obtenemos la tabla de la derecha de la figura (observad que JAMOVI llama <span class="math inline">\(H_a\)</span> a nuestra hipótesis alternativa <span class="math inline">\(H_1\)</span>):</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El intervalo de confianza del 95% para la <span class="math inline">\(\mu\)</span> se obtiene sumando el valor que se contrasta (en nuestro caso 37) al “intervalo de confianza al 95%” obtenido, por lo tanto es [36.765, 36.886]. Sobre el p-valor, sólo nos dice que es menor que 0.001, no nos da su valor exacto. En resumen, hemos encontrado evidencia estadísticamente significativa de que la temperatura media del cuerpo humano no es de 37<sup>o</sup> C, y estimamos con un 95% de confianza que está entre 36.8<sup>o</sup> C y 36.9<sup>o</sup> C, o sea, entre una y dos décimas por debajo de 37<sup>o</sup> C. Si esto es clínicamente importante o no para definir “fiebre” ya no es un problema de estadística.</p>
<p>En este caso, si queremos saber qué vale el p-valor (que es lo que en el tema anterior os recomendábamos publicar), tendremos que usar la función <code>t.test</code> de <code>R</code>. Esta función <code>t.test</code> se aplica a un argumento formado por:</p>
<ul>
<li>el vector que contiene la muestra;</li>
<li>el parámetro <code>mu</code> igualado al valor que contrastamos;</li>
<li>el paràmetro <code>alternative</code> que indica el tipo de contraste, igualándolo a <code>"two.sided"</code> (para contrastes bilaterales, es decir, con <span class="math inline">\(\neq\)</span>), <code>"less"</code> (<span class="math inline">\(&lt;\)</span>) o <code>"greater"</code> (<span class="math inline">\(&gt;\)</span>); no os olvidéis de las comillas en los valores de este parámetro;</li>
<li>el parámetro <code>conf.level</code> que indica el nivel de confianza <span class="math inline">\(1-\alpha\)</span>, en nuestro caso 0.95, que corresponde a <span class="math inline">\(\alpha=0.05\)</span> (como este es el valor por defecto de este parámetro, no es necesario especificarlo).</li>
</ul>
<p>JAMOVI ha importado el fichero <strong>Temperaturas.txt</strong> en una tabla de datos que ha llamado <code>data</code>. El código siguiente, ejecutado en la ventana de <strong>R/Rj Editor</strong>, define un vector llamado <code>Temps</code> con la variable <code>Temperatura</code> de <code>data</code> y efectua el test t deseado:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.1.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El resultado contiene:</p>
<ul>
<li>El p-valor (<code>p-value</code>) del contraste: 3·10<sup>-8</sup></li>
<li>El intervalo de confianza del 95% (<code>95 percent confidence interval</code>): va de 36.77<sup>o</sup> C a 36.89<sup>o</sup> C</li>
<li>La media muestral (<code>mean of x</code>): 36.83</li>
</ul>
</div>
<div id="test-no-paramétrico" class="section level4 hasAnchor" number="15.1.1.2">
<h4><span class="header-section-number">15.1.1.2</span> Test no paramétrico<a href="qué-test-usar.html#test-no-paramétrico" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si no podemos suponer que la variable aleatoria de interés sea normal y la muestra es pequeña, no podemos usar un test t. Entonces, hay que usar algún <strong>test no paramétrico</strong> que no requiera de la normalidad de la variable poblacional. El recomendado en este caso es el <a href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test"><strong>Test de Wilcoxon</strong></a>, aunque conviene tener presente que, en el fondo, este test compara medianas y no medias. Con JAMOVI, hay que marcar la casilla <em>Rangos de Wilcoxon</em> en vez de <em>t de Student</em> en <strong>Pruebas T/Prueba T en una muestra</strong>:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Con <code>R</code> se usa la función <code>wilcox.test</code>, con la misma sintaxis que <code>t.test</code> salvo que, si eso, hay que indicar con <code>conf.int=TRUE</code> que queremos el intervalo de confianza para la temperatura media (en realidad, este intervalo, y el de JAMOVI, es para la <em>pseudomediana</em>: la mediana de las medias aritméticas de pares independientes de temperaturas, que coincide con la media si la distribución es simétrica), ya que por defecto no lo da:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2b.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="inciso-tests-de-normalidad" class="section level3 hasAnchor" number="15.1.2">
<h3><span class="header-section-number">15.1.2</span> Inciso: tests de normalidad<a href="qué-test-usar.html#inciso-tests-de-normalidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Muchos tests, como por ejemplo los tests t cuando las muestras son pequeñas, requieren que las variables poblacionales sea normales para que las conclusiones sean válidas. Para poder decidir si podemos aceptar o no que la variable poblacional es normal, se usa un <strong>contraste de normalidad</strong>, con hipótesis nula
<span class="math display">\[
H_0: \text{Esta muestra proviene de una variable aleatoria normal}
\]</span>
e hipótesis alternativa
<span class="math display">\[
H_1: \text{No es verdad que esta muestra provenga de una variable aleatoria normal}
\]</span></p>
<p>Hay <a href="https://en.wikipedia.org/wiki/Normality_test">muchos tests</a> que se pueden usar para efectuar este contraste. Por ejemplo, tras instalar el módulo <strong>moretests</strong> (que añade funcionalidades a los módulos básicos), cuando marcamos la casilla <em>Prueba de normalidad</em> al realizar algún test t, JAMOVI realiza tres tests de normalidad: el de <strong>Shapiro-Wilk</strong>, el de <strong>Kolmogorov-Smirnov</strong> y el de <strong>Anderson-Darling</strong>:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Os recomendamos que, en caso de disparidad de conclusiones según los p-valores (como pasa en nuestro ejemplo, donde el p-valor del test de Kolgomorov-Smirnov es mayor que 0.1 y los otros dos son 0.003) os quedéis con la conclusión del test de Shapiro-Wilk, que es el más fiable (el test de Kolmogorov-Smirnov es el más conocido, pero no es bueno detectando diferencias con la normal en las colas; el test de Anderson-Darling resuelve este problema, pero en muestras muy grandes tiende a dar muchos falsos positivos). El test de Shapiro-Wilk también está disponible en <strong>Exploración/Descriptivas</strong>. Con <code>R</code> se efectua con la función <code>shapiro.test</code> aplicado a la muestra.</p>
<p>Así pues, como vemos, en nuestro ejemplo podemos rechazar que la muestra de temperaturas provenga de una variable normal. Esto no afecta a la validez de la conclusión del test t, porque la muestra era muy grande.</p>
<p>La conclusión de un test de normalidad se puede ilustrar con algún gráfico que muestre si la muestra se ajusta o no a lo que sería de esperar si la distribución poblacional fuera normal. Por ejemplo, un histograma superponiendo la densidad de la normal de media y desviación típicas estimadas con la muestra. Otro de los gráficos más usados en este contexto son los q-q-plots.</p>
<p>Un <strong>q-q-plot</strong> de una muestra y una distribución teórica concreta (por ejemplo, una normal <span class="math inline">\(N(\mu,\sigma)\)</span>) es el gráfico de los llamados <strong>q-q-puntos</strong>: los puntos de la forma
<span class="math display">\[
(q\text{-cuantil de la distribución téorica},\ q\text{-cuantil de la muestra}),
\]</span>
para varios valores de <span class="math inline">\(q\)</span>. Si la muestra proviene de la distribución teórica, es de esperar que el q-cuantil de la muestra sea muy parecido al q-cuantil de la distribución y por lo tanto que estos q-q-puntos estén cerca de la diagonal principal <span class="math inline">\(y=x\)</span>.</p>
<p>JAMOVI dibuja un q-q-plot marcando la casilla <em>Gráfica Q-Q</em> en cualquier prueba t o en <strong>Exploración/Descriptivas</strong>.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>La función <code>qqPlot</code> del paquete <strong>car</strong> de <code>R</code>produce unos q-q-plots más adecuados, que además muestran una “región de confianza del 95%”, con el significado usual de nivel de confianza (para el 95% de las muestras de la distribución, los q-q-plot caen dentro de esta región; por lo tanto, si nuestro q-q-plot sale fuera de esta región, tenemos evidencia de que la muestra no proviene de la distribución teórica). La sintaxis para usarla es la que sigue (cambiad <code>Temps</code> por la muestra de la que queráis dibujar el q-q-plot)</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="qué-test-usar.html#cb78-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb78-2"><a href="qué-test-usar.html#cb78-2" tabindex="-1"></a><span class="fu">qqPlot</span>(Temps, <span class="at">distribution=</span><span class="st">&quot;norm&quot;</span>, <span class="at">mean=</span><span class="fu">mean</span>(Temps), <span class="at">sd=</span><span class="fu">sd</span>(Temps),</span>
<span id="cb78-3"><a href="qué-test-usar.html#cb78-3" tabindex="-1"></a>       <span class="at">ylab=</span><span class="st">&quot;Cuantiles de la muestra&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Cuantiles de normal&quot;</span>, </span>
<span id="cb78-4"><a href="qué-test-usar.html#cb78-4" tabindex="-1"></a>       <span class="at">pch=</span><span class="dv">20</span>, <span class="at">id=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-585-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>La existencia de muchos q-q-puntos fuera de la franja de confianza nos vuelve a aportar evidencia de que la muestra de temperaturas no se ajusta a una distribución normal.</p>
</div>
<div id="contrastes-para-dos-medias" class="section level3 hasAnchor" number="15.1.3">
<h3><span class="header-section-number">15.1.3</span> Contrastes para dos medias<a href="qué-test-usar.html#contrastes-para-dos-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias de medias <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span>, respectivamente. Queremos compararlas, mediante un contraste de la forma
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 &gt;\mu_2\text{ o }\mu_1&lt;\mu_2
\end{array}
\right.
\]</span>
Para ello, medimos <span class="math inline">\(X_1\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span>, y <span class="math inline">\(X_2\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span>.</p>
<div id="tests-t" class="section level4 hasAnchor" number="15.1.3.1">
<h4><span class="header-section-number">15.1.3.1</span> Tests t<a href="qué-test-usar.html#tests-t" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos que estamos en una de las dos situaciones siguientes:</p>
<ul>
<li><p><span class="math inline">\(X_1,X_2\)</span> son ambas normales; o</p></li>
<li><p><span class="math inline">\(X_1,X_2\)</span> no son necesariamente ambas normales pero los tamaños <span class="math inline">\(n_1,n_2\)</span> de las muestras son <strong>ambos</strong> grandes (digamos, para fijar ideas, que <span class="math inline">\(n_1,n_2\geqslant 40\)</span>).</p></li>
</ul>
<p>Si se cumple alguna de estas dos condiciones, podemos usar un <strong>test t</strong>, basado en un estadístico de contraste <span class="math inline">\(T\)</span> adecuado con distribución t de Student. Los estadísticos de contraste concretos y los grados de libertad de su distribución t de Student son los que dimos al hablar de intervalos de confianza para la diferencia de dos medias en el tema anterior, y dependen de las mismas condiciones que comentábamos allí:</p>
<ul>
<li><p>De si las dos muestras son:</p>
<ul>
<li><p><strong>independientes</strong>: hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre dos muestras aleatorias simples obtenidas de manera independiente la una de la otra; o</p></li>
<li><p><strong>emparejadas</strong>: hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre los individuos de una misma muestra aleatoria simple o hay un emparejamiento natural entre los sujetos de las dos muestras.</p></li>
</ul></li>
</ul>

<div class="rmdnote">
En el caso emparejado, podemos entender que tenemos una sola muestra, formada por los sujetos que medimos dos veces o por las parejas de sujetos. Entonces, podemos considerar la diferencia <span class="math inline">\(D=X_1-X_2\)</span>, que tendrá media poblacional <span class="math inline">\(\mu_D=\mu_1-\mu_2\)</span>, y traducir el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 &gt;\mu_2\text{ o }\mu_1&lt;\mu_2
\end{array}
\right.
\]</span>
en el contraste de una sola media
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_D=0\\
H_{1}:\mu_D \neq 0\text{ o }\mu_D &gt;0\text{ o }\mu_D&lt;0
\end{array}
\right.
\]</span>
Es decir, cuando las muestras son emparejadas, consideramos nuestro contraste de dos medias como un contraste de una sola media, usando como muestra las diferencias <span class="math inline">\(X_1-X_2\)</span> sobre nuestras parejas de sujetos.
</div>
<ul>
<li>Cuando las muestras son independientes, la prueba concreta a efectuar también depende de si las variables poblacionales <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> tienen la <strong>misma varianza</strong> o no, que en principio se ha de decidir con otro contraste.</li>
</ul>
<p>Todos estos tests t están implementados en la función <code>t.test</code> de <code>R</code> y en el módulo <strong>Pruebas T</strong> de JAMOVI.</p>
<div class="example">
<p><span id="exm:tempHD" class="example"><strong>Ejemplo 15.2  </strong></span>La temperatura media de las hombres, ¿es menor que la de las mujeres?</p>
</div>
<p>Traducimos esta pregunta en un contraste de hipótesis:</p>
<ul>
<li><p><strong>Variables aleatorias poblacionales</strong>:</p>
<ul>
<li><span class="math inline">\(X_m\)</span>: temperatura de un hombre (M) en <sup>o</sup>C, de media <span class="math inline">\(\mu_f\)</span></li>
<li><span class="math inline">\(X_f\)</span>: temperatura de una mujer (F) en <sup>o</sup>C, de media <span class="math inline">\(\mu_f\)</span></li>
</ul></li>
<li><p><strong>Contraste</strong>: Nos preguntamos si <span class="math inline">\(\mu_m\)</span> es menor que <span class="math inline">\(\mu_f\)</span>
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_m=\mu_f\\
H_{1}:\mu_m&lt; \mu_f
\end{array}\right.
\]</span></p></li>
</ul>
<p>Necesitamos una muestra de temperaturas de hombres y de mujeres. La tabla de datos <strong>Temperaturas.txt</strong> que hemos usado en los ejemplos anteriores contiene una variable <strong>Sexo</strong> con el sexo de los sujetos: M para hombres y F para mujeres. La muestra fue transversal, así que las muestras de hombres y mujeres son independientes (las que salieron en la muestra global).</p>
<p>Con JAMOVI, tras importar el fichero <strong>Temperaturas.txt</strong> en una tabla de datos, calculamos los tamaños de ambas muestras con la casilla <em>N</em> de <strong>Exploración/Descriptivas</strong>, seleccionando como variable dependiente la <code>Temperatura</code> y como variable de agrupación el <code>Sexo</code>. Aprovechamos para calcular los estadísticos básicos de cada muestra y dibujar sus boxplot:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Vemos que las temperaturas de las mujeres (F), y en particular su media y su mediana, son ligeramente mayores que las de los hombres (M). Como las muestras de mujeres y hombres son lo bastante grandes (116 y 114 sujetos, respectivamente), podemos usar un test t para realizar el contraste.
Para ello, usamos <strong>Pruebas T/Prueba T para muestras independientes</strong> y seleccionamos de nuevo como variable dependiente la <code>Temperatura</code> y como variable de agrupación el <code>Sexo</code>. Como en la variable <code>Sexo</code> las mujeres son F y los hombres M y JAMOVI los va a tomar ordenados alfabéticamente, la hipótesis alternativa tiene que ser <em>Grupo 1 &gt; Grupo 2</em>, es decir, con las notaciones que usamos, <span class="math inline">\(\mu_f&gt;\mu_m\)</span>.</p>
<p>En esta ventana, la casilla <em>t de Student</em> corresponde al test suponiendo varianzas poblacionales iguales y la casilla <em>t de Welch</em> al test suponiendo varianzas poblacionales diferentes. Vamos a efectuar los dos tests de golpe, y cruzaremos los dedos para que den la misma conclusión:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>En ambos casos el p-valor es (redondeado) 0.005, muy pequeño. Así, pues, hemos obtenido evidencia estadísticamente significativa de que los hombres tienen una temperatura corporal media inferior a la de las mujeres. Además, ambos intervalos de confianza del 95% para <span class="math inline">\(\mu_f-\mu_m\)</span> van de alrededor de 0.056 a <span class="math inline">\(\infty\)</span> (<em>Inf</em>), por lo que tenemos un 95% de confianza de que la temperatura corporal media es 6 centésimas de grado mayor en las mujeres que en los hombres. La diferencia de las medias muestrales <span class="math inline">\(\overline{X}_f-\overline{X}_m\)</span> ha sido 0.155<sup>o</sup> C, es decir, la media muestral de temperaturas de mujeres ha sido 0.16<sup>o</sup> C mayor que en los hombres.</p>
<p>¿Qué pasaría si los tests suponiendo varianzas iguales y diferentes hubieran dado resultados diferentes? En este caso tendríamos que decidir qué conclusion nos creemos, decidiendo si podemos aceptar o rechazar que las varianzas poblacionales sean iguales o no. Podéis contrastar la igualdad de varianzas en esta misma ventana marcando la casilla <em>Test de homogeneidad</em>, que efectua el contraste con hipótesis nula que las dos varianzas poblacionales son iguales e hipótesis alternativa que son diferentes. Con el módulo <strong>moretests</strong> instalado, da el resultado de dos tests: el de <strong>Levene</strong> y el <strong>test F</strong> (<em>Variance ratio</em>). Ya volveremos sobre ellos en la próxima sección. En todo caso, como su p-valor es grande, aquí aceptaríamos que las dos varianzas poblacionales son iguales.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.3.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Si preferís usar la función <code>t.test</code>, hay que entrar como argumentos:</p>
<ul>
<li><p>Los vectores que contienen la muestra de <span class="math inline">\(X_1\)</span> y la muestra de <span class="math inline">\(X_2\)</span>.</p></li>
<li><p>El tipo de contraste, que se especifica con el parámetro <code>alternative</code> como en el caso de una sola media.</p></li>
<li><p>El tipo de muestras, que se especifica igualando el parámetro <code>paired</code> a <code>FALSE</code> si son independientes o a <code>TRUE</code> si son emparejadas.</p></li>
<li><p>En caso de muestras independientes, si las varianzas son iguales o diferentes, que se especifica igualando el parámetro <code>var.equal</code> a <code>TRUE</code> o a <code>FALSE</code>, respectivamente.</p></li>
<li><p>El nivel de confianza, que se especifica con el parámetro <code>conf.level</code> como en el caso de una sola media y no hace falta si es 0.95.</p></li>
</ul>
<p>El código siguiente define vectores <code>TempsH</code> y <code>TempsM</code> con las temperaturas de los hombres y las mujeres de esta tabla, y efectua los tests t suponiendo que las varianzas son iguales y que son diferentes, respectivamente</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2.7.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="tests-no-paramétricos" class="section level4 hasAnchor" number="15.1.3.2">
<h4><span class="header-section-number">15.1.3.2</span> Tests no paramétricos<a href="qué-test-usar.html#tests-no-paramétricos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si no podemos suponer que las variables aleatorias de interés sean normales y si alguna muestra es pequeña, hay que usar algún <strong>test no paramétrico</strong>.
Para contrastes de dos medias, los recomendados son:</p>
<ul>
<li><p><strong>Test de Wilcoxon</strong> para muestras emparejadas (que, recordad, se traduce en un contraste sobre la media de las diferencias, y en los contrastes de una media ya recomendábamos el test de Wilcoxon).</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Mann–Whitney_U_test"><strong>Test de Mann-Whitney</strong></a> para muestras independientes.</p></li>
</ul>
<p>En JAMOVI se marcan las casillas <em>rangos de Wilcoxon</em> o <em>U de Mann-Whitney</em>, según corresponda.</p>

<div class="rmdimportant">
Usad tests paramétricos siempre que podáis, pero solo cuando podáis.
Los mejores tests no paramétricos suelen tener potencia inferior a los mejores tests paramétricos. Pero usar, por ejemplo, un test t cuando no toca, porque alguna variable no sea normal y alguna muestra sea pequeña, puede llevar a conclusiones equivocadas.
</div>
<p>Con R, ambos tests se calculan con la función <code>wilcox.test</code>, con una sintaxis idéntica a la de <code>t.test</code> para dos muestras excepto que no dispone del parámetro <code>var.equal</code> (ya que ahora no nos interesa lo más mínimo saber si las variables tienen varianzas iguales o diferentes en el caso de contrastes de dos medias con muestras independientes) y hay que usar el parámetro <code>conf.int=TRUE</code> si se quiere un intervalo de confianza (para la diferencia de las pseudomedianas de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>).</p>

<div class="rmdnote">
En el caso de dos muestras, para comprobar si ambas muestras se ajustan a variables normales con JAMOVI, no podemos hacerlo desde el módulo <strong>Pruebas T</strong> sino desde <strong>Exploración/Descriptivas</strong>. En nuestro ejemplo (véase la figura que sigue), tenemos que separar la variable <code>Temperatura</code> según el <code>Sexo</code>. Marcando la casilla <em>Shapiro-Wilk</em>, obtenemos los p-valores del test de Shapiro-Wilk tanto para F como para M. Ambos son menores que 0.05, así que podemos rechazar que las muestras provengan de distribuciones normales.
</div>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Veamos otro ejemplo.</p>
<div class="example">
<p><span id="exm:oatbran" class="example"><strong>Ejemplo 15.3  </strong></span>Desayunar salvado de avena (<em>oat bran</em>) en lugar de copos de maíz (<em>corn flakes</em>), ¿ayuda a reducir el nivel de colesterol?</p>
</div>
<p>Planteémoslo como un contraste de hipótesis. Las variables aleatorias poblacionales de interés son:</p>
<ul>
<li><span class="math inline">\(X_{ob}\)</span>: nivel de colesterol al consumir salvado de avena, de media <span class="math inline">\(\mu_{ob}\)</span></li>
<li><span class="math inline">\(X_{cf}\)</span>: nivel de colesterol al consumir copos de maíz, de media <span class="math inline">\(\mu_{cf}\)</span></li>
</ul>
<p>El contraste que queremos realizar es
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_{ob}=\mu_{cf}\\
H_{1}:\mu_{ob}&lt; \mu_{cf}
\end{array}\right.
\]</span></p>
<p>Para hacerlo, vamos a usar los datos obtenidos por J. Anderson <em>et al</em> en su estudio <a href="https://academic.oup.com/ajcn/article-abstract/52/3/495/4650821">“Oat-bran cereal lowers serum total and LDL cholesterol in hypercholesterolemic men”</a> (<em>The American Journal of Clinical Nutrition</em> 52 (1990), pp. 495-499). Se trata de un ensayo clínico cruzado sobre 14 individuos. A cada uno de ellos se le asignó uno de los dos desayunos de manera aleatoria y lo tomaron durante 15 días. Al final de este periodo, se les midió el nivel de colesterol en sangre. Pasado un mes de descanso, cada participante desayunó durante 15 días el otro producto, y al final se los volvió a medir el nivel de colesterol en sangre. Tenemos los niveles de colesterol que obtuvieron en la tabla de datos <strong>oatbran.txt</strong>, donde están medidos en milimoles por litro (mmol/l), así que esta será la unidad que tomamos en las variables poblacionales.</p>
<p>Con JAMOVI, importamos el fichero <strong>oatbran.txt</strong> en una tabla de datos. Como las muestras son pequeñas (de tamaño 14), si queremos aplicar un test t necesitamos poder aceptar que provienen de variables normales. Vamos a <strong>Exploración/Descriptivas</strong>, escogemos ambas variables, <code>CORNFLK</code> y <code>OATBRAN</code>, y marcamos el test de Shapiro-Wilk (y, ya que estamos, las gráficas Q-Q):</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Ambos p-valores son muy grandes, así que vamos a aceptar que ambas muestras provienen de variables normales y usaremos un test t de dos medias.</p>
<p>En este caso, como las muestras son emparejadas (hemos medido las dos variables aleatorias sobre los mismos individuos), hay que elegir <strong>Pruebas T/Prueba t para muestras emparejadas</strong>. Cuidado con la hipótesis alternativa: como JAMOVI toma como primera variable <code>CORNFLK</code> y segunda variable <code>OATBRAN</code> y nuestra hipótesis alternativa es que los <em>oat bran</em> reducen el nivel de colesterol respecto de los <em>corn flakes</em>, hemos de marcar “Medida 1 &gt; Medida 2”.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos un p-valor de 0.003. Por lo tanto, hemos encontrado evidencia estadísticamente significativa de que desayunar salvado reduce el nivel medio de colesterol respecto de desayunar copos de maíz. El intervalo de confianza del 95% para <span class="math inline">\(\mu_{cf}-\mu_{ob}\)</span> va de 0.163 a <span class="math inline">\(\infty\)</span>. Por lo tanto, tenemos un 95% de confianza en que desayunar salvado reduce en al menos 0.163 mmol/l el nivel medio de colesterol respecto de desayunar copos de maíz.</p>
<p>¿Y si no quisiéramos, o no pudiéramos, suponer que las muestras provienen de distribuciones normales? Entonces usaríamos un test de Wilcoxon:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor da 0.006, por lo que la conclusión es la misma.</p>

<div class="rmdexercici">
<p>Típica pregunta de MIR (esta, de 2017):</p>
<p>El grosor del pliegue subcutáneo de grasa a nivel del tríceps se utiliza a veces para evaluar la cantidad de grasa corporal. Esta variable no se distribuye normalmente en las poblaciones. Queremos comparar el valor medio de esta variable en dos poblaciones que suponemos presentan distinta condición nutricional. La prueba estadística más adecuada para contrastar la hipótesis es:</p>
<ul>
<li>La prueba de Mann-Whitney.<br />
</li>
<li>La prueba t de Student.<br />
</li>
<li>El cálculo del coeficiente de correlación de Pearson.</li>
<li>La prueba F de Snedecor.</li>
</ul>
</div>
</div>
</div>
<div id="contrastes-para-más-de-dos-medias" class="section level3 hasAnchor" number="15.1.4">
<h3><span class="header-section-number">15.1.4</span> Contrastes para más de dos medias<a href="qué-test-usar.html#contrastes-para-más-de-dos-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1,X_2,\ldots, X_k\)</span> <span class="math inline">\(k\)</span> variables aleatorias de medias <span class="math inline">\(\mu_1,\mu_2,\ldots,\mu_k\)</span> y desviaciones típicas <span class="math inline">\(\sigma_1,\sigma_2,\ldots,\sigma_k\)</span>, respectivamente. Normalmente, se tratará de una misma variable aleatoria definida sobre <span class="math inline">\(k\)</span> poblaciones diferentes.</p>
Nos preguntamos si es verdad o no que estas <span class="math inline">\(k\)</span> variables tienen la misma media. Es decir, planteamos el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2=\cdots=\mu_k\\
H_{1}:\text{No es verdad que } \mu_1=\mu_2=\cdots=\mu_k
\end{array}
\right.
\]</span>
Para ello, medimos cada <span class="math inline">\(X_i\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_i\)</span>.

<div class="rmdimportant">
Observad que <span class="math inline">\(H_1\)</span> en el contraste anterior es equivalente a
<span class="math display">\[
\text{Existen $i,j$ tales que } \mu_i \neq \mu_j
\]</span>
<strong>no</strong> a
<span class="math display">\[
\mu_i \neq \mu_j \text{ para todos los pares $i,j$ con $i\neq j$}
\]</span>
</div>
<div class="example">
<p><span id="exm:somriures" class="example"><strong>Ejemplo 15.4  </strong></span>En un estudio (publicado en <em>Personality and Social Psychology Bulletin</em> 21 (1995), pp. 207-214) se quiso determinar si la benevolencia con la se juzga a una persona depende de cómo sonríe.</p>
</div>
<p>Para ello se seleccionaron 136 personas, que se dividieron al azar en 4 grupos de 34. A las personas de cada grupo se les pasó un dosier donde se acusaba a un hombre de una falta grave (en un contexto universitario) y, tras estudiarlo, se les pusieron cinco preguntas sobre la culpabilidad del acusado y el castigo que se merecía. A partir de las respuestas de cada sujeto, se calculó un “índice de benevolencia” de cómo había juzgado al acusado.</p>
<p>Los dosieres eran idénticos, excepto la foto del acusado: mismo hombre, pero diferente tipo de sonrisa:</p>
<p><img src="INREMDN_files/figure-html/somriures.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Tenemos los índices obtenidos en el fichero <strong>smiles.txt</strong>. Veamos sus estadísticos básicos y un diagrama de caja.</p>
<p><img src="INREMDN_files/figure-html/somriuresJ1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Vemos que la sonrisa neutra ha generado una menor benevolencia y la falsa, mayor. Queremos determinar si las diferencias son lo bastante grandes para aportar evidencia que la benevolencia depende de la sonrisa.</p>
<p>En este caso tenemos una variable aleatoria, el índice de benevolencia con el que se juzga al acusado, definida sobre cuatro subpoblaciones definidas por el tipo de sonrisa en la foto. Llamemos <span class="math inline">\(\mu_s\)</span>, <span class="math inline">\(\mu_f\)</span>, <span class="math inline">\(\mu_c\)</span> y <span class="math inline">\(\mu_n\)</span> a sus medias: los índices de benevolencia medios con los que se juzga el dosier cuando la sonrisa es sincera, falsa, compungida o neutra, respectivamente.</p>
<p>Entonces, queremos realizar el contraste
<span class="math display">\[
\left\{
\begin{array}{l}
H_0 : \mu_s=\mu_{f}=\mu_{c}=\mu_{n} \\
H_1 : \mbox{Hay algún par de sonrisas }i,j\mbox{ tales que }  \mu_i \neq \mu_j
\end{array}
\right.
\]</span></p>
<p>Un posible modo de resolver este contraste sería realizar los seis contrastes de pares de medias <span class="math inline">\(\mu_i=\mu_j\)</span> contra <span class="math inline">\(\mu_i\neq \mu_j\)</span>, pero esto aumenta la probabilidad de error si no ajustamos los p-valores. Y tenemos que comparar todas las medias dos a dos, porque podría pasar, por ejemplo, que no pudiéramos rechazar que <span class="math inline">\(\mu_n= \mu_s\)</span> ni que <span class="math inline">\(\mu_s= \mu_f\)</span>, pero sí que pudiéramos rechazar que <span class="math inline">\(\mu_n= \mu_f\)</span>.</p>
<p>Lo que queremos es un test que nos diga en un solo paso si todas las medias son iguales o no. La técnica más usual es el <strong>Análisis de la Varianza</strong> (<strong>ANOVA</strong>, del inglés <em>ANalysis Of VAriance</em>). Esta técnica se puede aplicar bajo diferentes diseños experimentales: por ejemplo, según cuántos factores usemos para separar la población en subpoblaciones (uno o varios) o según cómo escojamos las muestras (independientes o emparejadas).</p>
<p>La idea básica del ANOVA es que tenemos evidencia de que no todas las medias poblacionales son iguales si la variabilidad de las medias poblacionales es muy grande en relacion a la variabilidad total de los datos obtenidos: de ahí la <strong>VA</strong>riancia en el nombre. Esta variabilidad relativa se mide mediante un estadístico de contraste adecuado que, si todas la medias poblacionales son iguales y se satisfacen las condiciones adecuadas, tiene una distribución conocida (llamada <strong>F de Fisher-Snedecor</strong>: es la distribución de un cociente de dos variables <span class="math inline">\(\chi^2\)</span> independientes, y sus parámetros son los grados de libertad de estas dos distribuciones <span class="math inline">\(\chi^2\)</span>). Por lo tanto podemos usar esta distribución para calcular un p-valor que nos dé lo improbablemente grande que es la variabilidad de las medias muestrales si las medias poblacionales fueran todas iguales.</p>
<div id="diseño-anova-de-un-factor" class="section level4 hasAnchor" number="15.1.4.1">
<h4><span class="header-section-number">15.1.4.1</span> Diseño ANOVA de un factor<a href="qué-test-usar.html#diseño-anova-de-un-factor" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En un estudio de diseño <strong>ANOVA de un factor</strong> (<em>One way ANOVA</em>):</p>
<ul>
<li><p>Usamos un solo factor para clasificar la población en subpoblaciones.</p></li>
<li><p>Tomamos una muestra aleatoria simple de la variable aleatoria sobre cada subpoblación, independientes unas de otras.</p></li>
</ul>
<p>El Ejemplo <a href="qué-test-usar.html#exm:somriures">15.4</a> es de tipo ANOVA de 1 factor: el factor que usamos para clasificar los índices de benevolencia es el tipo de sonrisa en la foto, y hemos tomado una muestra de índices de benevolencia para cada tipo de sonrisa, independientes las unas de las otras porque hemos asignado las fotos al azar a los participantes.</p>
<div id="anova-de-un-factor" class="section level5 unnumbered hasAnchor">
<h5>ANOVA de un factor<a href="qué-test-usar.html#anova-de-un-factor" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Supongamos que tenemos que realizar una comparación de medias en un estudio de diseño ANOVA de 1 vía. Si se cumple además que:</p>
<ul>
<li><p>Cada una de las <span class="math inline">\(k\)</span> variables aleatorias de las que hemos tomado muestras sigue una ley normal</p></li>
<li><p><strong>Homocedasticidad</strong> o <strong>homogeneidad</strong>: Todas estas variables tienen la misma varianza, <span class="math inline">\(\sigma^2\)</span>.</p></li>
</ul>
<p>Entonces podemos usar un test ANOVA. JAMOVI ofrece el ANOVA de 1 vía en <strong>ANOVA/ANOVA de Un Factor</strong>.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-591" class="example"><strong>Ejemplo 15.5  </strong></span>Sigamos con el Ejemplo <a href="qué-test-usar.html#exm:somriures">15.4</a>. Ya hemos cargado la tabla. Efectuamos los tests de Shapiro-Wilks (separando la variable <code>benevolencia</code> según el factor <code>sonrisa</code>) y obtenemos los 4 p-valores por encima de 0.05, así que vamos a aceptar que para los cuatro tipos de sonrisas los índices de benevolencia se ajustan a distribuciones normales.</p>
</div>
<p><img src="INREMDN_files/figure-html/somriuresJ2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Abriendo entonces <strong>ANOVA/ANOVA de Un Factor</strong>, separamos de nuevo la variable dependiente <code>benevolencia</code> según el factor <code>sonrisa</code>, marcamos la <em>Prueba de homogeneidad</em> para saber si podemos aceptar o no que las varianzas poblacionales son todas iguales, y como el p-valor de ambos tests es grande, marcamos la casilla <em>Asumir iguales (Fisher)</em>, que efectua el test ANOVA.</p>
<p><img src="INREMDN_files/figure-html/somriuresJ3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor es 0.018, por lo que obtenemos evidencia estadística de que al menos un par de medias son diferentes.</p>

<div class="rmdnote">
Un ANOVA de 1 factor aplicado a solo dos medias es equivalente a un test t para dos medias suponiendo varianzas iguales.
</div>
<p>También podéis usar <strong>ANOVA/ANOVA</strong> para efectuar un ANOVA de un factor, mucho más rico en opciones (pero para el nivel de este curso casi todas innecesarias).</p>
</div>
<div id="alternativas" class="section level5 unnumbered hasAnchor">
<h5>Alternativas<a href="qué-test-usar.html#alternativas" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>El test ANOVA de Fisher es bastante robusto a una ligera desviación de la normalidad de las muestras, pero deja estrepitosamente de ser válido si las varianzas poblacionales no son iguales.</p>
<p>Si las variables poblacionales son normales, pero no podemos aceptar que tengan todas la misma varianza, lo recomendado es usar una variante llamada <strong>ANOVA de Welch</strong>, y que en JAMOVI se ejecuta marcando <em>No asumir iguales (Welch)</em> en lugar de <em>Asumir iguales (Fisher)</em>.</p>
<p>Otra posibilidad es usar el test no paramétrico de Kruskal-Wallis, que extiende a más de dos medias el test de Mann-Whitney. JAMOVI lo ofrece en <strong>ANOVA/No paramétrico/ANOVA de Un Factor: Kruskall-Wallis</strong>.</p>
</div>
</div>
<div id="tests-post-hoc" class="section level4 unnumbered hasAnchor">
<h4>Tests <em>post hoc</em><a href="qué-test-usar.html#tests-post-hoc" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si hemos rechazado la hipótesis nula <span class="math inline">\(H_0:\mu_1=\cdots =\mu_k\)</span>, nos puede interesar estimar qué parejas de niveles tienen medias diferentes. La manera más popular es realizar los <span class="math inline">\(\binom{k}{2}\)</span> contrastes
<span class="math display">\[
\left\{
\begin{array}{ll}
H_0 &amp;: \mu_i=\mu_j \\
H_1 &amp;: \mu_i \neq \mu_j
\end{array}
\right.
\]</span>
usando un test t adecuado (si las muestras se ajustan a normalidad o son lo bastante grandes) o un test de Mann-Whitney (si no se puede usar un test t para todos los pares de medias). En caso de homogeneidad de varianzas, el test t no es exactamene el que hemos explicado para pares de medias y varianzas iguales porque usa todas las muestras, y no solo las dos involucradas, para estimar el error típico.</p>
<p>Pero hay que ir con cuidado con el nivel de significación global. Como vimos en el tema anterior, si efectuamos muchos contrastes de pares de medias, la probabilidad de cometer un error de tipo I <em>en alguno</em> aumenta, por lo que hay que reducir el nivel de significación con el que los efectuamos o, equivalentemente, ajustar los p-valores. En <strong>ANOVA/ANOVA de Un Factor</strong> JAMOVI efectua un ajuste por defecto que es más que suficiente para nuestros propósitos. Si queréis usar otros ajustes, por ejemplo el de Bonferroni que mencionábamos en el tema anterior (multiplicar los p-valores por el número de tests), los encontraréis en <strong>ANOVA/ANOVA/Pruebas Post Hoc</strong>. Normalmente no habrá grandes diferencias en las conclusiones de los tests según el método de ajuste usado.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-593" class="example"><strong>Ejemplo 15.6  </strong></span>Seguimos con nuestro ejemplo sobre la benevolencia que suscitan los diferentes tipos de sonrisa. Con un ANOVA de 1 factor hemos obtenido evidencia seignificativa de que hay al menos un par de sonrisas con índices de benevolencia medios diferentes. Vamos a investigar cuáles.</p>
</div>
<p>Antes de nada, un gráfico: en <strong>ANOVA/ANOVA de Un Factor</strong> pedimos que añada “Gráficas Descriptivas”:</p>
<p><img src="INREMDN_files/figure-html/somriuresJ6.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Nos da los intervalos de confianza del 95% para las cuatro medias. Observad que todos los pares de intervalos de confianza se solapan salvo dos: el de la sonrisa falsa y el de la sonrisa neutra. Este gráfico nos aporta evidencia de que estas dos medias no son iguales (cada una pertenece a su intervalo de confianza con una confianza del 95%, y estos dos intervalos son disjuntos) y nos indica que los otros pares de medias pueden ser iguales (sus intervalos de confianza no son disjuntos). Esto es solo una indicación gráfica del resultado que tenemos que esperar, pero no nos da el resultado del test con la confianza que deseamos: las conclusiones se basan en que <em>todos</em> los IC 95% aciertan, y la probabilidad de que eso ocurra es menor que 0.95.</p>
<p>Vamos ya a realizar las comparaciones posteriores por parejas.
Usamos para ello la ventana <strong>ANOVA/ANOVA de Un Factor/Pruebas Post-Hoc</strong>. Como hemos aceptado que las variables poblacionales son todas iguales, marcamos <em>Tukey (varianzas iguales)</em>:</p>
<p><img src="INREMDN_files/figure-html/somriuresJ4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>En la tabla obtenemos la diferencia de medias “fila menos columna” y el p-valor del test para cada par formado por las medias para el tipo de sonrisa de la fila y el de la columna. Los p-valores están ajustados por el mmétodo de Tukey, demasiado complicad para explicarlo aquí, así que tenemos que compararlos directamente con el nivel de significación elegido. Si este es 0.05, observamos que solo obtenemos evidencia de diferencia de medias para el par sonrisa falsa-sonrisa neutra. Para el resto de pares de medias no podemos rechazar que sean iguales. Era lo que esperábamos.</p>
<p>Si quisiéramos usar por ejemplo el ajuste de Bonferroni, tendríamos que efectuar el ANOVA con <strong>ANOVA/ANOVA</strong>:</p>
<p><img src="INREMDN_files/figure-html/somriuresJ5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Hemos marcado también la columna de p-valores sin ajustar (“p”) y la del ajuste de Tukey para que veáis que el ajuste de Bonferroni consiste en tomar el mínimo de 1 y el resultado de multiplicar el p-valor por 6 (el número total de contrastes de pares de medias) y podáis comparar los valores ajustados de Bonferroni con los de Tukey. La conclusión con los dos tipos de ajuste es la misma.</p>
<div id="continuará" class="section level5 hasAnchor" number="15.1.4.1.1">
<h5><span class="header-section-number">15.1.4.1.1</span> Continuará<a href="qué-test-usar.html#continuará" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
</div>
</div>
</div>
<div id="contrastes-para-varianzas" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Contrastes para varianzas<a href="qué-test-usar.html#contrastes-para-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-bilaterales-para-dos-varianzas" class="section level3 hasAnchor" number="15.2.1">
<h3><span class="header-section-number">15.2.1</span> Contrastes bilaterales para dos varianzas<a href="qué-test-usar.html#contrastes-bilaterales-para-dos-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias de desviaciones típicas <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span>. Queremos realizar el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1=\sigma_2\\
H_{1}:\sigma_1\neq \sigma_2
\end{array}
\right.
\]</span>
o, equivalentemente,
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1^2=\sigma_2^2\\
H_{1}:\sigma_1^2\neq \sigma_2^2
\end{array}
\right.
\]</span></p>
<p>Si <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son <strong>las dos normales</strong>, podemos usar el <strong>test F</strong>. Este test usa como estadístico de contraste el cociente de varianzas muestrales, <span class="math inline">\(\widetilde{S}^2_{X_1}/\widetilde{S}^2_{X_2}\)</span>, que, si <span class="math inline">\(\sigma_1=\sigma_2\)</span>, tiene distribución F de Fisher-Snedecor, de ahí el nombre del test.</p>
<p>Con JAMOVI, se realiza marcando la casilla <em>Test de homogeneidad</em> al llevar a cabo un test t de dos muestras independientes con el módulo <strong>moretests</strong> instalado: es el resultado de la fila “Variance ratio”. Con <code>R</code> se realiza con la función <code>var.test</code> aplicada a las dos muestras y además os da un intervalo de confianza para el cociente <span class="math inline">\(\sigma_1^2/\sigma_2^2\)</span>. La ventaja de <code>var.test</code> es que también permite efectuar contrastes unilaterales, especificando el parámetro <code>alternative</code>.</p>
<p>El test F no és válido a poco que las variables <span class="math inline">\(X_1\)</span> o <span class="math inline">\(X_2\)</span> difieran de normales, incluso aunque las muestras sean grandes. Si no podemos aceptar que <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sean normales, es necesario usar un test no paramétrico. JAMOVI usa el <a href="https://en.wikipedia.org/wiki/Levene%27s_test"><strong>test de Levene</strong></a>, que lleva a cabo marcando la mencionada casilla <em>Test de homogeneidad</em>.</p>
<p>Ya hemos visto un ejemplo de contraste bilateral de varianzas en el Ejemplo <a href="qué-test-usar.html#exm:tempHD">15.2</a>.</p>
</div>
<div id="contrastes-de-homogeneidad-para-más-de-dos-varianzas" class="section level3 hasAnchor" number="15.2.2">
<h3><span class="header-section-number">15.2.2</span> Contrastes de homogeneidad para más de dos varianzas<a href="qué-test-usar.html#contrastes-de-homogeneidad-para-más-de-dos-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1,X_2,\ldots,X_k\)</span> <span class="math inline">\(k\)</span> variables aleatorias, de desviaciones típicas <span class="math inline">\(\sigma_1,\sigma_2,\ldots,\sigma_k\)</span> respectivamente.. Queremos realizar el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1=\sigma_2=\cdots=\sigma_k\\
H_{1}: \text{Hay algún par }i,j\text{ tal que }\sigma_1\neq \sigma_2
\end{array}
\right.
\]</span>
o, equivalentemente,
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1^2=\sigma_2^2=\cdots=\sigma_k^2\\
H_{1}: \text{Hay algún par }i,j\text{ tal que }\sigma_1^2\neq \sigma_2^2
\end{array}
\right.
\]</span></p>
<p>Si todas las variables son normales, lo mejor es usar el <a href="https://en.wikipedia.org/wiki/Bartlett%27s_test"><strong>test de Bartlett</strong></a>, pero si alguna muestra no se ajusta a una variable normal, conviene usar algún test no paramétrico. JAMOVI ofrece el <strong>test de Levene</strong>, que también sirve para dos medias, ya está bien.</p>
<p>Como hemos visto en la sección anterior, ambos tests se pueden efectuar marcando la casilla <em>Prueba de homogeneidad</em> al hacer un ANOVA de un factor con <strong>ANOVA/ANOVA de Un Factor</strong> y el módulo <em>moretests</em> instalado.</p>
</div>
</div>
<div id="contrastes-para-proporciones" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Contrastes para proporciones<a href="qué-test-usar.html#contrastes-para-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-para-una-proporción" class="section level3 hasAnchor" number="15.3.1">
<h3><span class="header-section-number">15.3.1</span> Contrastes para una proporción<a href="qué-test-usar.html#contrastes-para-una-proporción" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria Bernoulli de parámetro <span class="math inline">\(p\)</span>. Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p=p_0\\
H_{1}:p\neq p_0\text{ o }p&gt; p_0\text{ o }p&lt; p_0
\end{array}
\right.
\]</span></p>
<p>Tomamos una muestra aleatoria simple de <span class="math inline">\(X\)</span> de tamaño <span class="math inline">\(n\)</span>.</p>
<div id="test-binomial" class="section level4 hasAnchor" number="15.3.1.1">
<h4><span class="header-section-number">15.3.1.1</span> Test binomial<a href="qué-test-usar.html#test-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como vimos en el tema anterior, siempre podemos usar el <strong>test binomial</strong>, que usa que si <span class="math inline">\(p=p_0\)</span>, el número de éxitos en una m.a.s. de tamaño <span class="math inline">\(n\)</span> tiene distribución <span class="math inline">\(B(n,p_0)\)</span>. Para llevarlo a cabo con JAMOVI, podemos usar <strong>Frecuencias/Prueba binomial</strong>.</p>
<div class="example">
<p><span id="exm:sexes" class="example"><strong>Ejemplo 15.7  </strong></span>La muestra de personas recogidas en la tabla de datos de temperaturas usada hasta ahora fue transversal, sin números prefijados de hombres y mujeres. Su composición en sexos, ¿aporta evidencia estadística de que la proporción de mujeres en la población es estrictamente mayor que la de hombres?</p>
</div>
<p>Sea <span class="math inline">\(p\)</span> la proporción de mujeres en la población. Podemos traducir la pregunta planteada en el contraste</p>
<p><span class="math display">\[
\left\{
\begin{array}{l}
H_0:p=0.5\\
H_1:p&gt;0.5
\end{array}
\right.
\]</span></p>
<p>La ventana del test binomial para este contraste con JAMOVI es:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>JAMOVI ha realizado el test binomial para las mujeres (F) y para los hombres (M): el que nos interesa es el primero. Con un p-valor 0.474 y un intervalo de confianza para <span class="math inline">\(p\)</span> de 0.448 a 1, no podemos rechazar que p sea 0.5.</p>
<p>Si no disponemos de la tabla de datos sino solo de las frecuencias, tenemos que entrarlas como una variable en una tabla de datos:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.2.png" width="40%" style="display: block; margin: auto;" /></p>
<p>y al cargar la variable en la ventana <strong>Frecuencias/Prueba binomial</strong>, marcar la casilla <em>Los valores son frecuencias</em>:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.3.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="test-aproximado" class="section level4 hasAnchor" number="15.3.1.2">
<h4><span class="header-section-number">15.3.1.2</span> Test aproximado<a href="qué-test-usar.html#test-aproximado" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si el tamaño <span class="math inline">\(n\)</span> de la muestra es grande (digamos <span class="math inline">\(\geqslant 40\)</span>), podemos usar el <strong>test aproximado</strong> basado en que, si <span class="math inline">\(H_0: p=p_0\)</span> es verdadera y <span class="math inline">\(n\)</span> es grande, por el Teorema Central del Límite
<span class="math display">\[
\frac{\widehat{p}_X-p_0}{\sqrt{\frac{\widehat{p}_X(1-\widehat{p}_X)}{n}}}\approx N(0,1)
\]</span></p>
<p>Este test es mucho más popular que el binomial, porque se puede efectuar “a mano” con una simple calculadora. Curiosamente, JAMOVI no lo implementa tal cual (solo un test equivalente y solo para el contraste bilateral, en <strong>Frecuencias/Prueba de proporciones (N resultados)</strong>; volveremos sobre él al hablar de contrastes para dos, o más, proporciones), pero podéis usar la función <code>prop.test</code> de <code>R</code>, aplicada a: el número de éxitos; el tamaño total de la muestra; el parámetro <code>p</code> igualado al valor a contrastar <span class="math inline">\(p_0\)</span>; el parámetro <code>alternative</code> igualado al tipo de contraste; y el parámetro <code>conf.level</code> igualado al nivel de confianza (si es 0.95, no hace falta especificarlo). En esta función <code>R</code> usa por defecto una corrección de continuidad que se suele usar al aproximar variables aleatorias discretas por medio de variables continuas y que suele mejorar los resultados del test. Podéis cancelar esta corrección de continuidad con el parámetro <code>correct=FALSE</code> pero os recomendamos que la mantengáis.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.4.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="contrastes-para-dos-proporciones" class="section level3 hasAnchor" number="15.3.2">
<h3><span class="header-section-number">15.3.2</span> Contrastes para dos proporciones<a href="qué-test-usar.html#contrastes-para-dos-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias Bernoulli de probabilidades poblacionales de éxito <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, respectivamente.</p>
<p>Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2\text{ o }p_1&gt; p_2\text{ o }p_1&lt; p_2
\end{array}
\right.
\]</span>
Para ello, tomamos una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span> de <span class="math inline">\(X_1\)</span> y una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span> de <span class="math inline">\(X_2\)</span>. Como en la comparación de dos medias, estas muestras pueden ser independientes o emparejadas.</p>
<div id="tests-para-dos-proporciones-con-muestras-independientes" class="section level4 hasAnchor" number="15.3.2.1">
<h4><span class="header-section-number">15.3.2.1</span> Tests para dos proporciones con muestras independientes<a href="qué-test-usar.html#tests-para-dos-proporciones-con-muestras-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="test-chi2" class="section level5 unnumbered hasAnchor">
<h5>Test <span class="math inline">\(\chi^2\)</span><a href="qué-test-usar.html#test-chi2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Cuando las dos muestras son grandes, digamos las dos de tamaño <span class="math inline">\(\geqslant 40\)</span>, podemos usar el llamado <strong>test <span class="math inline">\(\chi^2\)</span></strong>. Usa el estadístico de contraste que ya explicamos al hablar de intervalos de confianza para la diferencia de dos proporciones. Si <span class="math inline">\(p_1=p_2\)</span> y las muestras son lo bastante grandes, este estadístico de contraste sigue una ley aproximadamente normal estándar (por si os lía el nombre del test, recordad que el cuadrado de una normal estándar tiene distribución <span class="math inline">\(\chi_1^2\)</span> y esto es lo que realmente usa el test).</p>
<p>En JAMOVI lo encontramos en <strong>Frecuencias/Muestras independientes: Prueba de asociación de <span class="math inline">\(\chi^2\)</span></strong>. Os recomendamos usar la versión “con corrección de continuidad”, que aplica la corrección de continuidad que comentábamos al hablar de <code>prop.test</code>.</p>
<div class="example">
<p><span id="exm:bronquitis" class="example"><strong>Ejemplo 15.8  </strong></span>¿Hay asociación positiva entre bronquitis en la infancia y tos crónica en la adolescencia, en el sentido de que el riesgo de tos crónica es mayor entre los adolescentes que siendo niños tuvieron bronquitis?</p>
</div>
<p>Para responder esta cuestión, en un estudio transversal se tomaron 1319 niños de 14 años, se miró si en ese momento tenían tos crónica o no y si a los 5 años habían tenido bronquitis o no. El resultado fue la tabla siguiente:
<span class="math display">\[
\begin{array}{c}
\qquad\qquad\qquad\qquad\textbf{Bronquitis}\\
\qquad\qquad\qquad\qquad\textbf{a los 5 años}\\
\begin{array}{ll|cc}
&amp; &amp;  \quad\text{Sí}\quad  &amp;\quad  \text{No}\quad  \\ \hline
\textbf{Tos a los}   &amp; \text{Sí}  &amp; 26 &amp;     44 \\
\textbf{14 años} &amp; \text{No} &amp; 247 &amp;            1002
\end{array}
\end{array}
\]</span>
Tenemos los datos de los niños guardados en el fichero <strong>bronquitis.txt</strong>.</p>
<p>Las variables aleatorias de interés son:</p>
<ul>
<li><span class="math inline">\(X_1\)</span>: Que un niño que tuvo bronquitis a los 5 años, tenga tos crónica a los 14, de probabilidad poblacional de éxito <span class="math inline">\(p_1\)</span></li>
<li><span class="math inline">\(X_2\)</span>: Que un niño que no tuvo bronquitis a los 5 años, tenga tos crónica a los 14, de probabilidad poblacional de éxito <span class="math inline">\(p_2\)</span></li>
</ul>
<p>El contraste que queremos realizar es
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1&gt;p_2
\end{array}\right.
\]</span></p>
<p>Como las dos muestras son grandes, podemos usar el test <span class="math inline">\(\chi^2\)</span>. Para hacerlo con JAMOVI, importamos el fichero <strong>bronquitis.txt</strong> en una tabla de datos. A continuación, en <strong>Datos/Configuración</strong>, en la lista de “Niveles” ponemos el 1 encima del 0 (seleccionándolo y subíendolo con la flecha). Finalmente, vamos a <strong>Frecuencias/Muestras independientes</strong>, elegimos <code>bronquitis</code> como variable columna y <code>tos</code> como variable fila y marcamos que queremos comparar por “columnas” (la dimensión de las dos variables cuyas probabilidades de éxito queremos comparar). Observad que en este fichero los Síes son 1 y los Noes 0, y en la tabla de frecuencias la primera columna ahora es 1 y la segunda 0, por lo que la hipótesis alternativa ha de ser “Grupo 1 &gt; Grupo 2”. Mirad en la figura el resto de casillas marcadas.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor es menor que 0.001, por lo que obtenemos evidencia estadísticamente significativa de que la probabilidad de tos crónica en la adolescencia es mayor entre los que sufrieron bronquitis infantil. El RA estimado es de 0.174, con un IC 95% entre 0.077 y 1, y el RR estimado es de 1.88, con un IC 95% entre 1.36 y 2.60; es decir, con un 95% de confianza estimamos que:</p>
<ul>
<li>El riesgo de tos crónica en la adolescencia es al menos 7.7 puntos porcentuales mayor entre los adolescentes que tuvieron bronquitis infantil que entre los que no</li>
<li>El riesgo de tos crónica en la adolescencia es entre un 36% y un 160% mayor entre los adolescentes que tuvieron bronquitis infantil que entre los que no</li>
</ul>

<div class="rmdnote">
En los tests <span class="math inline">\(\chi^2\)</span> unilaterales para dos proporciones, el intervalo de confianza para el RR que calcula JAMOVI es el del test bilateral. Bueno, menos es nada.
</div>
<p>Si no hubiéramos dispuesto del fichero con los datos brutos y solo tuviéramos la tabla de frecuencias, las entraríamos en una tabla de datos como la que sigue:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.6.1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>y procederíamos como antes, solo que ahora declararíamos la variable con las frecuencias como “Frecuencias”:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.6.2.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="test-exacto-de-fisher" class="section level5 unnumbered hasAnchor">
<h5>Test exacto de Fisher<a href="qué-test-usar.html#test-exacto-de-fisher" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>En un contraste de dos proporciones siempre podemos usar el <a href="https://en.wikipedia.org/wiki/Fisher%27s_exact_test"><strong>test exacto de Fisher</strong></a>. Se basa en la idea de que si la hipótesis nula es verdadera (es decir, si <span class="math inline">\(p_1=p_2\)</span>) entonces sería como si las dos muestras se hubieran obtenido de la misma población. No entraremos en detalle. Lo importante, y lo que lo hace impopular en algunos ámbitos, es que en realidad no compara las proporciones poblacionales de éxito <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, sino sus <strong>odds</strong> y el intervalo de confianza que da es para el cociente de estas odds: es decir, para la <strong>odds ratio</strong>.</p>

<div class="rmdimportant">
En particular, si el estudio es de casos y controles con una muestra estratificada que no permita estimar riesgos, el test exacto de Fisher es el único test válido, ya que entonces no tiene sentido comparar las probabilidades del desenlace codicionadas a la exposición y la no exposición.
</div>
<p>Con JAMOVI se efectua marcando <em>Test exacto de Fisher</em> y <em>Razón de Odds</em> en <strong>Datos/Configuración</strong>, y el resto de casillas (y preparación) como para el test <span class="math inline">\(\chi^2\)</span>. Por ejemplo, para efectuarlo en la situación del Ejemplo <a href="qué-test-usar.html#exm:bronquitis">15.8</a> a partir del fichero de datos marcaríamos:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor es de nuevo menor que 0.001, por lo que obtenemos evidencia estadísticamente significativa de que <em>las odds, y por lo tanto el riesgo</em>
de tos crónica en la adolescencia aumenta en los adolescentes que tuvieron bronquitis infantil. La OR estimada de tos crónica relativa a la bronquitis infantil es de 2.4, con un IC 95% entre 1.45 y 3.97. Por lo tanto estimamos con un 95% de confianza las odds de tos crónica en la adolescencia son entre un 45% y un 297% mayores entre los que tuvieron bronquitis infantil. De nuevo, este IC es el del test bilateral, aunque hayamos efectuado un test unilateral.</p>
<p>Si queréis, o necesitáis, efectuar estos dos tests con <code>R</code>, por ejemplo para calcular el p-valor:</p>
<ul>
<li>El test <span class="math inline">\(\chi^2\)</span> también se hace con la función <code>prop.test</code>, ahora aplicada al vector con los números de éxitos y el vector con el tamaño de las muestras</li>
<li>El test exacto de Fisher se hace con la función <code>fisher.test</code> aplicada a la matriz con la tabla de contingencia.</li>
</ul>
<p>Observad la sintaxis para nuestro ejemplo en ambos casos en la figura siguiente:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor del test <span class="math inline">\(\chi^2\)</span> es 0.0004. El p-valor del test exacto de Fisher es 0.0008 y el IC 95% del contraste unilateral para la odds ratio va de 1.509 a <span class="math inline">\(\infty\)</span>, por lo que estimamos que las odds de tos crónica en la adolescencia si se ha tenido bronquitis en la infancia son al menos un 50.9% mayores que si no se ha tenido.</p>
</div>
</div>
<div id="tests-para-2-proporciones-con-muestras-emparejadas" class="section level4 hasAnchor" number="15.3.2.2">
<h4><span class="header-section-number">15.3.2.2</span> Tests para 2 proporciones con muestras emparejadas<a href="qué-test-usar.html#tests-para-2-proporciones-con-muestras-emparejadas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos ahora que tomamos las muestras emparejadas, ambas de tamaño <span class="math inline">\(n\)</span>. Para simplificar el lenguaje, supondremos que las dos muestras se obtienen midiendo las variables <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre los sujetos de una misma muestra aleatoria simple.</p>
<div id="test-de-mcnemar" class="section level5 unnumbered hasAnchor">
<h5>Test de McNemar<a href="qué-test-usar.html#test-de-mcnemar" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Si el contraste es <strong>bilateral</strong> y el número de <strong>casos discordantes</strong> (aquellos que son éxito para una variable y fracaso para la otra) es lo bastante grande (digamos que <span class="math inline">\(\geqslant 25\)</span>), el test recomendado es el <strong>test de McNemar</strong>. Si la tabla de contingencia es
<span class="math display">\[
\begin{array}{c}
\hphantom{Variable No}\quad\textbf{Variable $X_1$}\\
\begin{array}{ll|cc}
&amp; &amp; \quad \text{Sí}\quad &amp; \quad\text{No}\quad \\ \hline
\textbf{Variable} &amp; \text{Sí}  &amp; a &amp;     b \\
\textbf{$X_2$} &amp; \text{No} &amp; c &amp;     d
\end{array}
\end{array}
\]</span>
(y por lo tanto el número de casos discordantes, que ha de ser <span class="math inline">\(\geqslant 25\)</span>, es <span class="math inline">\(b+c\)</span>), este test usa que el estadístico
<span class="math display">\[
\frac{(b-c)^2}{b+c}
\]</span>
tiene una distribución aproximadamente <span class="math inline">\(\chi^2_1\)</span> si la hipótesis nula es cierta.</p>
<p>En JAMOVI lo encontramos en <strong>Frecuencias/Muestras apareadas: Prueba de McNemar</strong>.</p>
<div class="example">
<p><span id="exm:quimiopost" class="example"><strong>Ejemplo 15.9  </strong></span>Si en el tratamiento del cáncer de mama, a la quimioterapia perioperatoria y la mastectomía le añadimos quimioterapia postoperatoria durante 6 meses, ¿hay diferencia en la tasa de supervivencia a 5 años vista?</p>
</div>
<p>Para resolver esta cuestión, en un ensayo clínico se trató un grupo de 1244 pacientes, emparejadas según diferentes características. En cada pareja de pacientes se repartieron los dos tratamientos al azar: quimioterapia perioperatoria y mastectomía, o quimioterapia perioperatoria, mastectomía y quimioterapia postoperatoria durante 6 meses. Se anotó la supervivencia a los 5 años de las pacientes. Los datos obtenidos fueron:
<span class="math display">\[
\begin{array}{c}
\hphantom{postoperatoria No sobrevive}\qquad\textbf{No quimio postperatoria}\\
\begin{array}{ll|cc}
&amp; &amp; \quad\text{Sobrevive}\quad &amp; \quad\text{No sobrevive}\quad \\ \hline
\textbf{Sí quimio} &amp; \text{Sobrevive}  &amp; 510 &amp;     17 \\
\textbf{postoperatoria} &amp; \text{No sobrevive} &amp; 5 &amp;       90
\end{array}
\end{array}
\]</span></p>
<p>En este caso, las variables aleatorias de interés son:</p>
<ul>
<li><span class="math inline">\(X_1\)</span>: Que una paciente con cáncer de mama tratada con mastectomía y quimioterapia perioperatoria sobreviva 5 años, de probabilidad de éxito <span class="math inline">\(p_1\)</span></li>
<li><span class="math inline">\(X_2\)</span>: Que una paciente con cáncer de mama tratada con mastectomía, quimioterapia perioperatoria y quimioterapia postoperatoria sobreviva 5 años, de probabilidad de éxito <span class="math inline">\(p_2\)</span></li>
</ul>
<p>El contraste que nos interesa es si hay diferencia entre <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, no tenemos una hipótesis alternativa preconcebida sobre si un tratamiento es superior al otro:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2
\end{array}\right.
\]</span></p>
<p>El contraste es bilateral, tenemos dos muestras emparejadas y 22 casos discordantes (parejas de pacientes en las que una murió antes de los 5 años y la otra sobrevivió). En principio este número es algo justo para poder usar un test de McNemar, pero a falta de alternativa será el que emplearemos.</p>
<p>Entramos las frecuencias en una tabla de datos:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>A continuación, en la lista de “Niveles” de <strong>Datos/Configuración</strong> ponemos en cada variable el nivel correspondiente al Éxito (en nuestro caso, Sobrevive) encima del fracaso. Finalmente, vamos a <strong>Frecuencias/Muestras apareadas</strong>, entramos las variables, y marcamos <em>Test <span class="math inline">\(\chi^2\)</span> con corrección de continuidad</em> (recomendable sobre el <em>Test <span class="math inline">\(\chi^2\)</span></em> a secas).</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos un p-valor 0.019. Por lo tanto, con un nivel de significación del 5% concluimos que la probabilidad de supervivencia a 5 años bajo los dos tratamientos es diferente. Y entonces, como la supervivencia a 5 años ha sido más frecuente entre las que sí recibieron quimioterapia postoperatoria, concluímos que incluirla aumenta significativamente la probabilidad de supervivencia a 5 años.</p>
</div>
<div id="test-binomial-1" class="section level5 unnumbered hasAnchor">
<h5>Test binomial<a href="qué-test-usar.html#test-binomial-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Si no podéis usar el test de McNemar, siempre podéis usar un <strong>test binomial</strong> para efectuar un contraste de dos proporciones con dos muestras emparejadas. La idea es que si <span class="math inline">\(p_1=p_2\)</span>, las probabilidades poblacionales de los pares (Sí,No) y (No,Sí) entre los pares discordantes son la misma, ambas 0.5, mientras que si, por ejemplo, <span class="math inline">\(p_1&gt; p_2\)</span>, la probabilidad poblacional del par (Sí,No) entre los pares discordantes es mayor que la del par (No,Sí), y por lo tanto mayor que 0.5.
Entonces:</p>
<ul>
<li>tomamos la muestra solo de los casos discordantes, y</li>
<li>comparamos la probabilidad de (Sí,No) con 0.5 exactamente en el mismo sentido con el que comparábamos <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>.</li>
</ul>
<p>Fijaos que en este contraste solo nos interesará el p-valor, porque el intervalo de confianza va a ser para la proporción de los pares (Si,No) en la población de casos discordantes.</p>
<p>Imaginemos por ejemplo que ahora sí que nos preguntamos si añadir, en el tratamiento del cáncer de mama, quimioterapia postoperatoria durante 6 meses a la quimioterapia perioperatoria y la mastectomía aumenta la tasa de supervivencia a 5 años. Con las notaciones del ejemplo anterior, el contraste es ahora
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1&gt; p_2
\end{array}\right.
\]</span>
Como es un contraste unilateral, no podemos usar un test de McNemar, así que vamos a usar el test binomial. Entramos las frecuencias de los dos tipos de casos discordantes de nuestra muestra</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.8.1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>y efectuamos el test binomial correspondiente en <strong>Frecuencias/Prueba binomial</strong></p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.8.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos un p-valor 0.008. Por lo tanto, con un nivel de significación del 5% concluimos que la probabilidad de supervivencia a 5 años con quimioterapia postoperatoria es mayor que sin quimioterapia postoperatoria.</p>
</div>
</div>
</div>
<div id="contrastes-para-más-de-dos-proporciones-y-contrastes-de-independencia" class="section level3 hasAnchor" number="15.3.3">
<h3><span class="header-section-number">15.3.3</span> Contrastes para más de dos proporciones y contrastes de independencia<a href="qué-test-usar.html#contrastes-para-más-de-dos-proporciones-y-contrastes-de-independencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>

</div>
</div>
</div>






            </section>

          </div>
        </div>
      </div>
<a href="contrastes-de-hipótesis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
