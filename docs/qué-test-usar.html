<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lección 15 Qué test usar? | Bioestadística (Medicina UIB)</title>
  <meta name="description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Lección 15 Qué test usar? | Bioestadística (Medicina UIB)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="github-repo" content="AprendeR-UIB/INREMDN" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lección 15 Qué test usar? | Bioestadística (Medicina UIB)" />
  
  <meta name="twitter:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  

<meta name="author" content="Irene García, Francesc Rosselló" />


<meta name="date" content="2024-01-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="contrastes-de-hipótesis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">INREMDN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a></li>
<li class="part"><span><b>Tema I: Introducción a los estudios médicos y la estadística</b></span></li>
<li class="chapter" data-level="1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="estudios-médicos.html"><a href="estudios-médicos.html"><i class="fa fa-check"></i><b>2</b> Estudios médicos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:pasos"><i class="fa fa-check"></i><b>2.1</b> Pasos de un estudio médico</a></li>
<li class="chapter" data-level="2.2" data-path="estudios-médicos.html"><a href="estudios-médicos.html#algunos-calificativos-para-los-estudios-médicos"><i class="fa fa-check"></i><b>2.2</b> Algunos calificativos para los estudios médicos</a></li>
<li class="chapter" data-level="2.3" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-descriptivos"><i class="fa fa-check"></i><b>2.3</b> Estudios descriptivos</a></li>
<li class="chapter" data-level="2.4" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:cyc"><i class="fa fa-check"></i><b>2.4</b> Estudios de casos y controles</a></li>
<li class="chapter" data-level="2.5" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-de-cohorte"><i class="fa fa-check"></i><b>2.5</b> Estudios de cohorte</a></li>
<li class="chapter" data-level="2.6" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-transversales"><i class="fa fa-check"></i><b>2.6</b> Estudios transversales</a></li>
<li class="chapter" data-level="2.7" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:ecol"><i class="fa fa-check"></i><b>2.7</b> Estudios ecológicos</a></li>
<li class="chapter" data-level="2.8" data-path="estudios-médicos.html"><a href="estudios-médicos.html#ensayos-clínicos"><i class="fa fa-check"></i><b>2.8</b> Ensayos clínicos</a></li>
<li class="chapter" data-level="2.9" data-path="estudios-médicos.html"><a href="estudios-médicos.html#a-modo-de-resumen"><i class="fa fa-check"></i><b>2.9</b> A modo de resumen</a></li>
<li class="chapter" data-level="2.10" data-path="estudios-médicos.html"><a href="estudios-médicos.html#revisiones-sistemáticas-y-metaanálisis"><i class="fa fa-check"></i><b>2.10</b> Revisiones sistemáticas y metaanálisis</a></li>
<li class="chapter" data-level="2.11" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:causalidad"><i class="fa fa-check"></i><b>2.11</b> (Bonus track) Unos criterios de causalidad</a></li>
<li class="chapter" data-level="2.12" data-path="estudios-médicos.html"><a href="estudios-médicos.html#bonus-track-preguntas-clínicas-en-formato-pico"><i class="fa fa-check"></i><b>2.12</b> (Bonus track) Preguntas clínicas en formato PICO</a></li>
<li class="chapter" data-level="2.13" data-path="estudios-médicos.html"><a href="estudios-médicos.html#test"><i class="fa fa-check"></i><b>2.13</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html"><i class="fa fa-check"></i><b>3</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#unidad-de-observación"><i class="fa fa-check"></i><b>3.1</b> Unidad de observación</a></li>
<li class="chapter" data-level="3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#población-y-muestra"><i class="fa fa-check"></i><b>3.2</b> Población y muestra</a></li>
<li class="chapter" data-level="3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:muestreo"><i class="fa fa-check"></i><b>3.3</b> Tipos básicos de muestreo</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mas"><i class="fa fa-check"></i><b>3.3.1</b> Muestreo aleatorio con y sin reposición</a></li>
<li class="chapter" data-level="3.3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sist"><i class="fa fa-check"></i><b>3.3.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="3.3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:estr"><i class="fa fa-check"></i><b>3.3.3</b> Muestreo aleatorio estratificado</a></li>
<li class="chapter" data-level="3.3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mcluster"><i class="fa fa-check"></i><b>3.3.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="3.3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:oport"><i class="fa fa-check"></i><b>3.3.5</b> Muestreos no aleatorios</a></li>
<li class="chapter" data-level="3.3.6" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:poli"><i class="fa fa-check"></i><b>3.3.6</b> Muestreo polietápico</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sesgos"><i class="fa fa-check"></i><b>3.4</b> Sesgos</a></li>
<li class="chapter" data-level="3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#test-1"><i class="fa fa-check"></i><b>3.5</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema II: Probabilidades</b></span></li>
<li class="chapter" data-level="4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html"><i class="fa fa-check"></i><b>4</b> Probabilidades elementales: Las mates</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#álgebra-de-conjuntos"><i class="fa fa-check"></i><b>4.1</b> Álgebra de conjuntos</a></li>
<li class="chapter" data-level="4.2" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#algunas-fórmulas-básicas"><i class="fa fa-check"></i><b>4.2</b> Algunas fórmulas básicas</a></li>
<li class="chapter" data-level="4.3" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sec:odds"><i class="fa fa-check"></i><b>4.3</b> Odds</a></li>
<li class="chapter" data-level="4.4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>4.4</b> Probabilidad condicionada</a></li>
<li class="chapter" data-level="4.5" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sucesos-independientes"><i class="fa fa-check"></i><b>4.5</b> Sucesos independientes</a></li>
<li class="chapter" data-level="4.6" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#odds-condicionadas-y-odds-ratios-relativas"><i class="fa fa-check"></i><b>4.6</b> Odds condicionadas y odds ratios relativas</a></li>
<li class="chapter" data-level="4.7" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#el-teorema-de-la-probabilidad-total"><i class="fa fa-check"></i><b>4.7</b> El teorema de la probabilidad total</a></li>
<li class="chapter" data-level="4.8" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#la-fórmula-de-bayes"><i class="fa fa-check"></i><b>4.8</b> La fórmula de Bayes</a></li>
<li class="chapter" data-level="4.9" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#test-2"><i class="fa fa-check"></i><b>4.9</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html"><i class="fa fa-check"></i><b>5</b> Probabilidades elementales: Aplicaciones en medicina</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#pruebas-diagnósticas"><i class="fa fa-check"></i><b>5.1</b> Pruebas diagnósticas</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sensibilidad-especificidad-valores-predictivos-etc."><i class="fa fa-check"></i><b>5.1.1</b> Sensibilidad, especificidad, valores predictivos etc.</a></li>
<li class="chapter" data-level="5.1.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#curvas-roc"><i class="fa fa-check"></i><b>5.1.2</b> Curvas ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:probaplic2"><i class="fa fa-check"></i><b>5.2</b> Riesgos</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosRR"><i class="fa fa-check"></i><b>5.2.1</b> Riesgos relativos y absolutos</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosCyC"><i class="fa fa-check"></i><b>5.2.2</b> <em>Odds ratios</em></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#tratamientos"><i class="fa fa-check"></i><b>5.3</b> Tratamientos</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#test-3"><i class="fa fa-check"></i><b>5.4</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema III: Estadística descriptiva</b></span></li>
<li class="chapter" data-level="6" data-path="tipos-de-datos.html"><a href="tipos-de-datos.html"><i class="fa fa-check"></i><b>6</b> Tipos de datos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tipos-de-datos.html"><a href="tipos-de-datos.html#test-4"><i class="fa fa-check"></i><b>6.1</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html"><i class="fa fa-check"></i><b>7</b> Descripción de datos cualitativos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:frecs"><i class="fa fa-check"></i><b>7.1</b> Frecuencias</a></li>
<li class="chapter" data-level="7.2" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#gráficos"><i class="fa fa-check"></i><b>7.2</b> Gráficos</a></li>
<li class="chapter" data-level="7.3" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#tablas-de-frecuencias-multidimensionales"><i class="fa fa-check"></i><b>7.3</b> Tablas de frecuencias multidimensionales</a></li>
<li class="chapter" data-level="7.4" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:barrasbidim"><i class="fa fa-check"></i><b>7.4</b> Diagramas de barras bidimensionales</a></li>
<li class="chapter" data-level="7.5" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#diagramas-de-mosaico"><i class="fa fa-check"></i><b>7.5</b> Diagramas de mosaico</a></li>
<li class="chapter" data-level="7.6" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#test-5"><i class="fa fa-check"></i><b>7.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html"><i class="fa fa-check"></i><b>8</b> Descripción de datos ordinales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#frecuencias-y-diagramas-de-barras"><i class="fa fa-check"></i><b>8.1</b> Frecuencias y diagramas de barras</a></li>
<li class="chapter" data-level="8.2" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#test-6"><i class="fa fa-check"></i><b>8.2</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html"><i class="fa fa-check"></i><b>9</b> Descripción de datos cuantitativos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#frecuencias"><i class="fa fa-check"></i><b>9.1</b> Frecuencias</a></li>
<li class="chapter" data-level="9.2" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-tendencia-central"><i class="fa fa-check"></i><b>9.2</b> Medidas de tendencia central</a></li>
<li class="chapter" data-level="9.3" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-posición"><i class="fa fa-check"></i><b>9.3</b> Medidas de posición</a></li>
<li class="chapter" data-level="9.4" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>9.4</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="9.5" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#diagramas-de-puntos-y-de-caja"><i class="fa fa-check"></i><b>9.5</b> Diagramas de puntos y de caja</a></li>
<li class="chapter" data-level="9.6" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#histogramas"><i class="fa fa-check"></i><b>9.6</b> Histogramas</a></li>
<li class="chapter" data-level="9.7" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#polígonos-de-frecuencias"><i class="fa fa-check"></i><b>9.7</b> Polígonos de frecuencias</a></li>
<li class="chapter" data-level="9.8" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#asimetría-y-curtosis"><i class="fa fa-check"></i><b>9.8</b> Asimetría y curtosis</a></li>
<li class="chapter" data-level="9.9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#estadísticos-y-gráficos-con-jamovi"><i class="fa fa-check"></i><b>9.9</b> Estadísticos y gráficos con JAMOVI</a></li>
<li class="chapter" data-level="9.10" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#sec:estagrup"><i class="fa fa-check"></i><b>9.10</b> Estadísticos sobre datos agrupados</a></li>
<li class="chapter" data-level="9.11" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#datos-cuantitativos-bivariantes"><i class="fa fa-check"></i><b>9.11</b> Datos cuantitativos bivariantes</a></li>
<li class="chapter" data-level="9.12" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#gráficos-en-escala-logarítmica"><i class="fa fa-check"></i><b>9.12</b> Gráficos en escala logarítmica</a></li>
<li class="chapter" data-level="9.13" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#test-7"><i class="fa fa-check"></i><b>9.13</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema IV: Variables aleatorias</b></span></li>
<li class="chapter" data-level="10" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html"><i class="fa fa-check"></i><b>10</b> Variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#densidad-y-distribución"><i class="fa fa-check"></i><b>10.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="10.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#esperanza"><i class="fa fa-check"></i><b>10.2</b> Esperanza</a></li>
<li class="chapter" data-level="10.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#varianza-y-desviación-típica"><i class="fa fa-check"></i><b>10.3</b> Varianza y desviación típica</a></li>
<li class="chapter" data-level="10.4" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#cuantiles"><i class="fa fa-check"></i><b>10.4</b> Cuantiles</a></li>
<li class="chapter" data-level="10.5" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#familias-importantes-de-variables-aleatorias-discretas"><i class="fa fa-check"></i><b>10.5</b> Familias importantes de variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-binomiales"><i class="fa fa-check"></i><b>10.5.1</b> Variables aleatorias binomiales</a></li>
<li class="chapter" data-level="10.5.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-hipergeométricas"><i class="fa fa-check"></i><b>10.5.2</b> Variables aleatorias hipergeométricas</a></li>
<li class="chapter" data-level="10.5.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-de-poisson"><i class="fa fa-check"></i><b>10.5.3</b> Variables aleatorias de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#test-8"><i class="fa fa-check"></i><b>10.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html"><i class="fa fa-check"></i><b>11</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#densidad-y-distribución-1"><i class="fa fa-check"></i><b>11.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="11.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#esperanza-varianza-cuantiles"><i class="fa fa-check"></i><b>11.2</b> Esperanza, varianza, cuantiles…</a></li>
<li class="chapter" data-level="11.3" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#sec:normal"><i class="fa fa-check"></i><b>11.3</b> Variables aleatorias normales</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#propiedades-básicas"><i class="fa fa-check"></i><b>11.3.1</b> Propiedades básicas</a></li>
<li class="chapter" data-level="11.3.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#intervalos-de-referencia"><i class="fa fa-check"></i><b>11.3.2</b> Intervalos de referencia</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#test-9"><i class="fa fa-check"></i><b>11.4</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema V: Estadística inferencial</b></span></li>
<li class="chapter" data-level="12" data-path="estimadores.html"><a href="estimadores.html"><i class="fa fa-check"></i><b>12</b> Estimadores</a>
<ul>
<li class="chapter" data-level="12.1" data-path="estimadores.html"><a href="estimadores.html#la-media-muestral"><i class="fa fa-check"></i><b>12.1</b> La media muestral</a></li>
<li class="chapter" data-level="12.2" data-path="estimadores.html"><a href="estimadores.html#la-proporción-muestral"><i class="fa fa-check"></i><b>12.2</b> La proporción muestral</a></li>
<li class="chapter" data-level="12.3" data-path="estimadores.html"><a href="estimadores.html#la-varianza-muestral"><i class="fa fa-check"></i><b>12.3</b> La varianza muestral</a></li>
<li class="chapter" data-level="12.4" data-path="estimadores.html"><a href="estimadores.html#la-distribución-t-de-student"><i class="fa fa-check"></i><b>12.4</b> La distribución t de Student</a></li>
<li class="chapter" data-level="12.5" data-path="estimadores.html"><a href="estimadores.html#test-10"><i class="fa fa-check"></i><b>12.5</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>13</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#sec:IC"><i class="fa fa-check"></i><b>13.1</b> Definiciones básicas</a></li>
<li class="chapter" data-level="13.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-ejemplo-ic-95-para-la-media-de-una-variable-aleatoria-normal"><i class="fa fa-check"></i><b>13.2</b> Un ejemplo: IC-95% para la media de una variable aleatoria normal</a></li>
<li class="chapter" data-level="13.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-basado-en-la-t-de-student"><i class="fa fa-check"></i><b>13.3</b> Intervalo de confianza para la media basado en la t de Student</a></li>
<li class="chapter" data-level="13.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-proporciones"><i class="fa fa-check"></i><b>13.4</b> Intervalos de confianza para proporciones</a></li>
<li class="chapter" data-level="13.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#bonus-track-otros-intervalos-de-confianza"><i class="fa fa-check"></i><b>13.5</b> (Bonus track) Otros intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-intervalo-de-confianza-para-la-diferencia-de-proporciones"><i class="fa fa-check"></i><b>13.5.1</b> Un intervalo de confianza para la diferencia de proporciones</a></li>
<li class="chapter" data-level="13.5.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-diferencias-de-medias"><i class="fa fa-check"></i><b>13.5.2</b> Intervalos de confianza para diferencias de medias</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#test-11"><i class="fa fa-check"></i><b>13.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>14</b> Contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="14.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#hipótesis-nula-y-alternativa"><i class="fa fa-check"></i><b>14.1</b> Hipótesis nula y alternativa</a></li>
<li class="chapter" data-level="14.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:moneda"><i class="fa fa-check"></i><b>14.2</b> Un ejemplo</a></li>
<li class="chapter" data-level="14.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:pval"><i class="fa fa-check"></i><b>14.3</b> El p-valor</a></li>
<li class="chapter" data-level="14.4" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#tipo-de-errores"><i class="fa fa-check"></i><b>14.4</b> Tipo de errores</a></li>
<li class="chapter" data-level="14.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:exttest"><i class="fa fa-check"></i><b>14.5</b> Ejemplo: El test t</a></li>
<li class="chapter" data-level="14.6" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#la-potencia-de-un-contraste"><i class="fa fa-check"></i><b>14.6</b> La potencia de un contraste</a></li>
<li class="chapter" data-level="14.7" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#intervalo-de-confianza-de-un-contraste"><i class="fa fa-check"></i><b>14.7</b> Intervalo de confianza de un contraste</a></li>
<li class="chapter" data-level="14.8" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#resultados-estadísticamente-significativos-versus-resultados-clínicamente-significativos"><i class="fa fa-check"></i><b>14.8</b> Resultados estadísticamente significativos <em>versus</em> resultados clínicamente significativos</a></li>
<li class="chapter" data-level="14.9" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#test-12"><i class="fa fa-check"></i><b>14.9</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="qué-test-usar.html"><a href="qué-test-usar.html"><i class="fa fa-check"></i><b>15</b> Qué test usar?</a>
<ul>
<li class="chapter" data-level="15.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-medias"><i class="fa fa-check"></i><b>15.1</b> Contrastes para medias</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-una-media"><i class="fa fa-check"></i><b>15.1.1</b> Contrastes para una media</a></li>
<li class="chapter" data-level="15.1.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#inciso-tests-de-normalidad"><i class="fa fa-check"></i><b>15.1.2</b> Inciso: tests de normalidad</a></li>
<li class="chapter" data-level="15.1.3" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-dos-medias"><i class="fa fa-check"></i><b>15.1.3</b> Contrastes para dos medias</a></li>
<li class="chapter" data-level="15.1.4" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-más-de-dos-medias"><i class="fa fa-check"></i><b>15.1.4</b> Contrastes para más de dos medias</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-varianzas"><i class="fa fa-check"></i><b>15.2</b> Contrastes para varianzas</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-bilaterales-para-dos-varianzas"><i class="fa fa-check"></i><b>15.2.1</b> Contrastes bilaterales para dos varianzas</a></li>
<li class="chapter" data-level="15.2.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-de-homogeneidad-para-más-de-dos-varianzas"><i class="fa fa-check"></i><b>15.2.2</b> Contrastes de homogeneidad para más de dos varianzas</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-proporciones"><i class="fa fa-check"></i><b>15.3</b> Contrastes para proporciones</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-una-proporción"><i class="fa fa-check"></i><b>15.3.1</b> Contrastes para una proporción</a></li>
<li class="chapter" data-level="15.3.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-dos-proporciones"><i class="fa fa-check"></i><b>15.3.2</b> Contrastes para dos proporciones</a></li>
<li class="chapter" data-level="15.3.3" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-más-de-dos-proporciones"><i class="fa fa-check"></i><b>15.3.3</b> Contrastes para más de dos proporciones</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-para-distribuciones"><i class="fa fa-check"></i><b>15.4</b> Contrastes para distribuciones</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-de-bondad-de-ajuste-de-una-muestra-a-una-distribución"><i class="fa fa-check"></i><b>15.4.1</b> Contrastes de bondad de ajuste de una muestra a una distribución</a></li>
<li class="chapter" data-level="15.4.2" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-de-igualdad-de-dos-o-más-distribuciones"><i class="fa fa-check"></i><b>15.4.2</b> Contrastes de igualdad de dos o más distribuciones</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="qué-test-usar.html"><a href="qué-test-usar.html#contrastes-de-correlación"><i class="fa fa-check"></i><b>15.5</b> Contrastes de correlación</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bioestadística (Medicina UIB)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="qué-test-usar" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Lección 15</span> Qué test usar?<a href="qué-test-usar.html#qué-test-usar" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En esta lección estudiamos los contrastes de hipótesis más frecuentes sobre medias, varianzas, proporciones, etc. El objetivo principal es, para cada tipo de contraste, explicar qué tests se pueden usar. Para la mayoría de estos tests no vamos a explicar las fórmulas de los estadísticos de contraste o intervalos de confianza, solo qué test usar en cada situación, cómo efectuarlos con JAMOVI y cómo interpretar los resultados.</p>
<div id="contrastes-para-medias" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Contrastes para medias<a href="qué-test-usar.html#contrastes-para-medias" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-para-una-media" class="section level3 hasAnchor" number="15.1.1">
<h3><span class="header-section-number">15.1.1</span> Contrastes para una media<a href="qué-test-usar.html#contrastes-para-una-media" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria de media <span class="math inline">\(\mu\)</span>. Queremos realizar un contraste sobre <span class="math inline">\(\mu\)</span>, de la forma
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=\mu_0\\
H_{1}:\mu \neq\mu_0\text{ o }\mu &gt;\mu_0\text{ o }\mu&lt;\mu_0
\end{array}
\right.
\]</span>
Para ello, medimos <span class="math inline">\(X\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span>.</p>
<div id="test-t" class="section level4 hasAnchor" number="15.1.1.1">
<h4><span class="header-section-number">15.1.1.1</span> Test t<a href="qué-test-usar.html#test-t" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos que estamos en una de las dos situaciones siguientes:</p>
<ul>
<li><p><span class="math inline">\(X\)</span> es normal; o</p></li>
<li><p><span class="math inline">\(X\)</span> no es necesariamente normal pero el tamaño <span class="math inline">\(n\)</span> de la muestra que tomamos es grande (digamos, para fijar ideas, que <span class="math inline">\(n\geqslant 40\)</span>).</p></li>
</ul>
<p>En cualquiera de estas dos situaciones, podemos usar el <strong>test t</strong> que hemos explicado en la lección anterior para realizar el contraste. JAMOVI lo ofrece en la sección <strong>Prueba T en una muestra</strong> del módulo <strong>Pruebas T</strong> (lo que abreviaremos a partir de ahora como <strong>Pruebas T/Prueba T en una muestra</strong>) de su instalación básica.</p>
<div class="example">
<p><span id="exm:temp" class="example"><strong>Ejemplo 15.1  </strong></span>La temperatura media del cuerpo humano, ¿es el valor comúnmente aceptado de 37<sup>o</sup> C?</p>
</div>
<p>Para empezar, tenemos que traducir esta pregunta a un contraste de hipótesis:</p>
<ul>
<li><p><strong>Variable aleatoria poblacional</strong>: <span class="math inline">\(X\)</span>: temperatura del cuerpo humano en <sup>o</sup>C, de media <span class="math inline">\(\mu\)</span>.</p></li>
<li><p><strong>Contraste</strong>: Nos preguntamos si <span class="math inline">\(\mu=37^{\mathrm{o}}\)</span> o no, por lo que el contraste es bilateral:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=37\\
H_{1}:\mu\neq 37
\end{array}\right.
\]</span></p></li>
</ul>
<p>Para efectuar el contraste, necesitamos una muestra de temperaturas. Vamos a usar las recogidas por P. A. Mackowiak, S. S. Wasserman y M. M. Levine que ya usamos en el Ejemplo <a href="intervalos-de-confianza.html#exm:tempsIC">13.4</a>, y que tenemos guardadas en la variable <strong>Temperatura</strong> de la tabla de datos <strong>Temperaturas.txt</strong>.</p>
<p>Con JAMOVI, importamos el fichero <strong>Temperaturas.txt</strong> en una tabla de datos (con <strong>Importar especial</strong>). Dando una ojeada a la tabla de datos (con el menú <strong>Datos</strong>), o usando la casilla <em>N</em> de <strong>Exploración/Descriptivas</strong>, vemos que la muestra es de tamaño 230, más que suficiente para poder usar un test t.</p>
<p>Entonces, abrimos <strong>Pruebas T/Prueba T en una muestra</strong>; seleccionamos como variable dependiente la <code>Temperatura</code>; entramos 37 en la casilla <em>Valor de la prueba</em>; y marcamos las casillas que se muestran en la figura que sigue. Obtenemos la tabla de la derecha de la figura (observad que JAMOVI llama <span class="math inline">\(H_a\)</span> a nuestra hipótesis alternativa <span class="math inline">\(H_1\)</span>):</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El intervalo de confianza del 95% para la <span class="math inline">\(\mu\)</span> se obtiene sumando el valor que se contrasta (en nuestro caso 37) al “intervalo de confianza al 95%” obtenido, por lo tanto es [36.765, 36.886]. Sobre el p-valor, sólo nos dice que es menor que 0.001, no nos da su valor exacto. En resumen, hemos encontrado evidencia estadísticamente significativa de que la temperatura media del cuerpo humano no es de 37<sup>o</sup> C, y estimamos con un 95% de confianza que está entre 36.8<sup>o</sup> C y 36.9<sup>o</sup> C, o sea, entre una y dos décimas por debajo de 37<sup>o</sup> C. Si esto es clínicamente importante o no para definir “fiebre” ya no es un problema de estadística.</p>
<p>En este caso, si queremos saber qué vale el p-valor (que es lo que en el tema anterior os recomendábamos publicar), tendremos que usar la función <code>t.test</code> de <code>R</code>. Esta función <code>t.test</code> se aplica a un argumento formado por:</p>
<ul>
<li>el vector que contiene la muestra;</li>
<li>el parámetro <code>mu</code> igualado al valor que contrastamos;</li>
<li>el paràmetro <code>alternative</code> que indica el tipo de contraste, igualándolo a <code>"two.sided"</code> (para contrastes bilaterales, es decir, con <span class="math inline">\(\neq\)</span>), <code>"less"</code> (<span class="math inline">\(&lt;\)</span>) o <code>"greater"</code> (<span class="math inline">\(&gt;\)</span>); no os olvidéis de las comillas en los valores de este parámetro;</li>
<li>el parámetro <code>conf.level</code> que indica el nivel de confianza <span class="math inline">\(1-\alpha\)</span>, en nuestro caso 0.95, que corresponde a <span class="math inline">\(\alpha=0.05\)</span> (como este es el valor por defecto de este parámetro, no es necesario especificarlo).</li>
</ul>
<p>JAMOVI ha importado el fichero <strong>Temperaturas.txt</strong> en una tabla de datos que ha llamado <code>data</code>. El código siguiente, ejecutado en la ventana de <strong>R/Rj Editor</strong>, define un vector llamado <code>Temps</code> con la variable <code>Temperatura</code> de <code>data</code> y efectua el test t deseado:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.1.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El resultado contiene:</p>
<ul>
<li>El p-valor (<code>p-value</code>) del contraste: 3·10<sup>-8</sup></li>
<li>El intervalo de confianza del 95% (<code>95 percent confidence interval</code>): va de 36.77<sup>o</sup> C a 36.89<sup>o</sup> C</li>
<li>La media muestral (<code>mean of x</code>): 36.83</li>
</ul>
</div>
<div id="test-no-paramétrico" class="section level4 hasAnchor" number="15.1.1.2">
<h4><span class="header-section-number">15.1.1.2</span> Test no paramétrico<a href="qué-test-usar.html#test-no-paramétrico" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si no podemos suponer que la variable aleatoria de interés sea normal y la muestra es pequeña, no podemos usar un test t. Entonces, hay que usar algún <strong>test no paramétrico</strong> que no requiera de la normalidad de la variable poblacional. El recomendado en este caso es el <a href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test"><strong>Test de Wilcoxon</strong></a>, aunque conviene tener presente que, en el fondo, este test compara medianas y no medias. Con JAMOVI, hay que marcar la casilla <em>Rangos de Wilcoxon</em> en vez de <em>t de Student</em> en <strong>Pruebas T/Prueba T en una muestra</strong>:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Con <code>R</code> se usa la función <code>wilcox.test</code>, con la misma sintaxis que <code>t.test</code> salvo que, si eso, hay que indicar con <code>conf.int=TRUE</code> que queremos el intervalo de confianza para la temperatura media (en realidad, este intervalo, y el de JAMOVI, es para la <em>pseudomediana</em>: la mediana de las medias aritméticas de pares independientes de temperaturas, que coincide con la media si la distribución es simétrica), ya que por defecto no lo da:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2b.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="inciso-tests-de-normalidad" class="section level3 hasAnchor" number="15.1.2">
<h3><span class="header-section-number">15.1.2</span> Inciso: tests de normalidad<a href="qué-test-usar.html#inciso-tests-de-normalidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Muchos tests, como por ejemplo los tests t cuando las muestras son pequeñas, requieren que las variables poblacionales sea normales para que las conclusiones sean válidas. Para poder decidir si podemos aceptar o no que la variable poblacional es normal, se usa un <strong>contraste de normalidad</strong>, con hipótesis nula
<span class="math display">\[
H_0: \text{Esta muestra proviene de una variable aleatoria normal}
\]</span>
e hipótesis alternativa
<span class="math display">\[
H_1: \text{No es verdad que esta muestra provenga de una variable aleatoria normal}
\]</span></p>
<p>Hay <a href="https://en.wikipedia.org/wiki/Normality_test">muchos tests</a> que se pueden usar para efectuar este contraste. Por ejemplo, tras instalar el módulo <strong>moretests</strong> (que añade funcionalidades a los módulos básicos), cuando marcamos la casilla <em>Prueba de normalidad</em> al realizar algún test t, JAMOVI realiza tres tests de normalidad: el de <strong>Shapiro-Wilk</strong>, el de <strong>Kolmogorov-Smirnov</strong> y el de <strong>Anderson-Darling</strong>:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Os recomendamos que, en caso de disparidad de conclusiones según los p-valores (como pasa en nuestro ejemplo, donde el p-valor del test de Kolgomorov-Smirnov es mayor que 0.1 y los otros dos son 0.003) os quedéis con la conclusión del test de Shapiro-Wilk, que es el más fiable (el test de Kolmogorov-Smirnov es el más conocido, pero no es bueno detectando diferencias con la normal en las colas; el test de Anderson-Darling resuelve este problema, pero en muestras muy grandes tiende a dar muchos falsos positivos). El test de Shapiro-Wilk también está disponible en <strong>Exploración/Descriptivas</strong>. Con <code>R</code> se efectua con la función <code>shapiro.test</code> aplicado a la muestra.</p>
<p>Así pues, como vemos, en nuestro ejemplo podemos rechazar que la muestra de temperaturas provenga de una variable normal. Esto no afecta a la validez de la conclusión del test t, porque la muestra era muy grande.</p>
<p>La conclusión de un test de normalidad se puede ilustrar con algún gráfico que muestre si la muestra se ajusta o no a lo que sería de esperar si la distribución poblacional fuera normal. Por ejemplo, un histograma superponiendo la densidad de la normal de media y desviación típicas estimadas con la muestra. Otro de los gráficos más usados en este contexto son los q-q-plots.</p>
<p>Un <strong>q-q-plot</strong> de una muestra y una distribución teórica concreta (por ejemplo, una normal <span class="math inline">\(N(\mu,\sigma)\)</span>) es el gráfico de los llamados <strong>q-q-puntos</strong>: los puntos de la forma
<span class="math display">\[
(q\text{-cuantil de la distribución téorica},\ q\text{-cuantil de la muestra}),
\]</span>
para varios valores de <span class="math inline">\(q\)</span>. Si la muestra proviene de la distribución teórica, es de esperar que el q-cuantil de la muestra sea muy parecido al q-cuantil de la distribución y por lo tanto que estos q-q-puntos estén cerca de la diagonal principal <span class="math inline">\(y=x\)</span>.</p>
<p>JAMOVI dibuja un q-q-plot marcando la casilla <em>Gráfica Q-Q</em> en cualquier prueba t o en <strong>Exploración/Descriptivas</strong>.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>La función <code>qqPlot</code> del paquete <strong>car</strong> de <code>R</code>produce unos q-q-plots más adecuados, que además muestran una “región de confianza del 95%”, con el significado usual de nivel de confianza (para el 95% de las muestras de la distribución, los q-q-plot caen dentro de esta región; por lo tanto, si nuestro q-q-plot sale fuera de esta región, tenemos evidencia de que la muestra no proviene de la distribución teórica). La sintaxis para usarla es la que sigue (cambiad <code>Temps</code> por la muestra de la que queráis dibujar el q-q-plot)</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="qué-test-usar.html#cb75-1" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb75-2"><a href="qué-test-usar.html#cb75-2" tabindex="-1"></a><span class="fu">qqPlot</span>(Temps, <span class="at">distribution=</span><span class="st">&quot;norm&quot;</span>, <span class="at">mean=</span><span class="fu">mean</span>(Temps), <span class="at">sd=</span><span class="fu">sd</span>(Temps),</span>
<span id="cb75-3"><a href="qué-test-usar.html#cb75-3" tabindex="-1"></a>       <span class="at">ylab=</span><span class="st">&quot;Cuantiles de la muestra&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Cuantiles de normal&quot;</span>, </span>
<span id="cb75-4"><a href="qué-test-usar.html#cb75-4" tabindex="-1"></a>       <span class="at">pch=</span><span class="dv">20</span>, <span class="at">id=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-583-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>La existencia de muchos q-q-puntos fuera de la franja de confianza nos vuelve a aportar evidencia de que la muestra de temperaturas no se ajusta a una distribución normal.</p>
</div>
<div id="contrastes-para-dos-medias" class="section level3 hasAnchor" number="15.1.3">
<h3><span class="header-section-number">15.1.3</span> Contrastes para dos medias<a href="qué-test-usar.html#contrastes-para-dos-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias de medias <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span>, respectivamente. Queremos compararlas, mediante un contraste de la forma
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 &gt;\mu_2\text{ o }\mu_1&lt;\mu_2
\end{array}
\right.
\]</span>
Para ello, medimos <span class="math inline">\(X_1\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span>, y <span class="math inline">\(X_2\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span>.</p>
<div id="tests-t" class="section level4 hasAnchor" number="15.1.3.1">
<h4><span class="header-section-number">15.1.3.1</span> Tests t<a href="qué-test-usar.html#tests-t" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos que estamos en una de las dos situaciones siguientes:</p>
<ul>
<li><p><span class="math inline">\(X_1,X_2\)</span> son ambas normales; o</p></li>
<li><p><span class="math inline">\(X_1,X_2\)</span> no son necesariamente ambas normales pero los tamaños <span class="math inline">\(n_1,n_2\)</span> de las muestras son <strong>ambos</strong> grandes (digamos, para fijar ideas, que <span class="math inline">\(n_1,n_2\geqslant 40\)</span>).</p></li>
</ul>
<p>Si se cumple alguna de estas dos condiciones, podemos usar un <strong>test t</strong>, basado en un estadístico de contraste <span class="math inline">\(T\)</span> adecuado con distribución t de Student. Los estadísticos de contraste concretos y los grados de libertad de su distribución t de Student son los que dimos al hablar de intervalos de confianza para la diferencia de dos medias en el tema anterior, y dependen de las mismas condiciones que comentábamos allí:</p>
<ul>
<li><p>De si las dos muestras son:</p>
<ul>
<li><p><strong>independientes</strong>: hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre dos muestras aleatorias simples obtenidas de manera independiente la una de la otra; o</p></li>
<li><p><strong>emparejadas</strong>: hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre los individuos de una misma muestra aleatoria simple o hay un emparejamiento natural entre los sujetos de las dos muestras.</p></li>
</ul></li>
</ul>

<div class="rmdnote">
En el caso emparejado, podemos entender que tenemos una sola muestra, formada por los sujetos que medimos dos veces o por las parejas de sujetos. Entonces, podemos considerar la diferencia <span class="math inline">\(D=X_1-X_2\)</span>, que tendrá media poblacional <span class="math inline">\(\mu_D=\mu_1-\mu_2\)</span>, y traducir el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 &gt;\mu_2\text{ o }\mu_1&lt;\mu_2
\end{array}
\right.
\]</span>
en el contraste de una sola media
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_D=0\\
H_{1}:\mu_D \neq 0\text{ o }\mu_D &gt;0\text{ o }\mu_D&lt;0
\end{array}
\right.
\]</span>
Es decir, cuando las muestras son emparejadas, consideramos nuestro contraste de dos medias como un contraste de una sola media, usando como muestra las diferencias <span class="math inline">\(X_1-X_2\)</span> sobre nuestras parejas de sujetos.
</div>
<ul>
<li>Cuando las muestras son independientes, la prueba concreta a efectuar también depende de si las variables poblacionales <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> tienen la <strong>misma varianza</strong> o no, que en principio se ha de decidir con otro contraste.</li>
</ul>
<p>Todos estos tests t están implementados en la función <code>t.test</code> de <code>R</code> y en el módulo <strong>Pruebas T</strong> de JAMOVI.</p>
<div class="example">
<p><span id="exm:tempHD" class="example"><strong>Ejemplo 15.2  </strong></span>La temperatura media de las hombres, ¿es menor que la de las mujeres?</p>
</div>
<p>Traducimos esta pregunta en un contraste de hipótesis:</p>
<ul>
<li><p><strong>Variables aleatorias poblacionales</strong>:</p>
<ul>
<li><span class="math inline">\(X_m\)</span>: temperatura de un hombre (M) en <sup>o</sup>C, de media <span class="math inline">\(\mu_f\)</span></li>
<li><span class="math inline">\(X_f\)</span>: temperatura de una mujer (F) en <sup>o</sup>C, de media <span class="math inline">\(\mu_f\)</span></li>
</ul></li>
<li><p><strong>Contraste</strong>: Nos preguntamos si <span class="math inline">\(\mu_m\)</span> es menor que <span class="math inline">\(\mu_f\)</span>
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_m=\mu_f\\
H_{1}:\mu_m&lt; \mu_f
\end{array}\right.
\]</span></p></li>
</ul>
<p>Necesitamos una muestra de temperaturas de hombres y de mujeres. La tabla de datos <strong>Temperaturas.txt</strong> que hemos usado en los ejemplos anteriores contiene una variable <strong>Sexo</strong> con el sexo de los sujetos: M para hombres y F para mujeres. La muestra fue transversal, así que las muestras de hombres y mujeres son independientes (las que salieron en la muestra global).</p>
<p>Con JAMOVI, tras importar el fichero <strong>Temperaturas.txt</strong> en una tabla de datos, calculamos los tamaños de ambas muestras con la casilla <em>N</em> de <strong>Exploración/Descriptivas</strong>, seleccionando como variable dependiente la <code>Temperatura</code> y como variable de agrupación el <code>Sexo</code>. Aprovechamos para calcular los estadísticos básicos de cada muestra y dibujar sus boxplot:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Vemos que las temperaturas de las mujeres (F), y en particular su media y su mediana, son ligeramente mayores que las de los hombres (M). Como las muestras de mujeres y hombres son lo bastante grandes (116 y 114 sujetos, respectivamente), podemos usar un test t para realizar el contraste.
Para ello, usamos <strong>Pruebas T/Prueba T para muestras independientes</strong> y seleccionamos de nuevo como variable dependiente la <code>Temperatura</code> y como variable de agrupación el <code>Sexo</code>. Como en la variable <code>Sexo</code> las mujeres son F y los hombres M y JAMOVI los va a tomar ordenados alfabéticamente, la hipótesis alternativa tiene que ser <em>Grupo 1 &gt; Grupo 2</em>, es decir, con las notaciones que usamos, <span class="math inline">\(\mu_f&gt;\mu_m\)</span>.</p>
<p>En esta ventana, la casilla <em>t de Student</em> corresponde al test suponiendo varianzas poblacionales iguales y la casilla <em>t de Welch</em> al test suponiendo varianzas poblacionales diferentes. Vamos a efectuar los dos tests de golpe, y cruzaremos los dedos para que den la misma conclusión:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>En ambos casos el p-valor es (redondeado) 0.005, muy pequeño. Así, pues, hemos obtenido evidencia estadísticamente significativa de que los hombres tienen una temperatura corporal media inferior a la de las mujeres. Además, ambos intervalos de confianza del 95% para <span class="math inline">\(\mu_f-\mu_m\)</span> van de alrededor de 0.056 a <span class="math inline">\(\infty\)</span> (<em>Inf</em>), por lo que tenemos un 95% de confianza de que la temperatura corporal media es 6 centésimas de grado mayor en las mujeres que en los hombres. La diferencia de las medias muestrales <span class="math inline">\(\overline{X}_f-\overline{X}_m\)</span> ha sido 0.155<sup>o</sup> C, es decir, la media muestral de temperaturas de mujeres ha sido 0.16<sup>o</sup> C mayor que en los hombres.</p>
<p>¿Qué pasaría si los tests suponiendo varianzas iguales y diferentes hubieran dado resultados diferentes? En este caso tendríamos que decidir qué conclusion nos creemos, decidiendo si podemos aceptar o rechazar que las varianzas poblacionales sean iguales o no. Podéis contrastar la igualdad de varianzas en esta misma ventana marcando la casilla <em>Test de homogeneidad</em>, que efectua el contraste con hipótesis nula que las dos varianzas poblacionales son iguales e hipótesis alternativa que son diferentes. Con el módulo <strong>moretests</strong> instalado, da el resultado de dos tests: el de <strong>Levene</strong> y el <strong>test F</strong> (<em>Variance ratio</em>). Ya volveremos sobre ellos en la próxima sección. En todo caso, como su p-valor es grande, aquí aceptaríamos que las dos varianzas poblacionales son iguales.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.3.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Si preferís usar la función <code>t.test</code>, hay que entrar como argumentos:</p>
<ul>
<li><p>Los vectores que contienen la muestra de <span class="math inline">\(X_1\)</span> y la muestra de <span class="math inline">\(X_2\)</span>.</p></li>
<li><p>El tipo de contraste, que se especifica con el parámetro <code>alternative</code> como en el caso de una sola media.</p></li>
<li><p>El tipo de muestras, que se especifica igualando el parámetro <code>paired</code> a <code>FALSE</code> si son independientes o a <code>TRUE</code> si son emparejadas.</p></li>
<li><p>En caso de muestras independientes, si las varianzas son iguales o diferentes, que se especifica igualando el parámetro <code>var.equal</code> a <code>TRUE</code> o a <code>FALSE</code>, respectivamente.</p></li>
<li><p>El nivel de confianza, que se especifica con el parámetro <code>conf.level</code> como en el caso de una sola media y no hace falta si es 0.95.</p></li>
</ul>
<p>El código siguiente define vectores <code>TempsH</code> y <code>TempsM</code> con las temperaturas de los hombres y las mujeres de esta tabla, y efectua los tests t suponiendo que las varianzas son iguales y que son diferentes, respectivamente</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.2.7.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="tests-no-paramétricos" class="section level4 hasAnchor" number="15.1.3.2">
<h4><span class="header-section-number">15.1.3.2</span> Tests no paramétricos<a href="qué-test-usar.html#tests-no-paramétricos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si no podemos suponer que las variables aleatorias de interés sean normales y si alguna muestra es pequeña, hay que usar algún <strong>test no paramétrico</strong>.
Para contrastes de dos medias, los recomendados son:</p>
<ul>
<li><p><strong>Test de Wilcoxon</strong> para muestras emparejadas (que, recordad, se traduce en un contraste sobre la media de las diferencias, y en los contrastes de una media ya recomendábamos el test de Wilcoxon).</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Mann–Whitney_U_test"><strong>Test de Mann-Whitney</strong></a> para muestras independientes.</p></li>
</ul>
<p>En JAMOVI se marcan las casillas <em>rangos de Wilcoxon</em> o <em>U de Mann-Whitney</em>, según corresponda.</p>

<div class="rmdimportant">
Usad tests paramétricos siempre que podáis, pero solo cuando podáis.
Los mejores tests no paramétricos suelen tener potencia inferior a los mejores tests paramétricos. Pero usar, por ejemplo, un test t cuando no toca, porque alguna variable no sea normal y alguna muestra sea pequeña, puede llevar a conclusiones equivocadas.
</div>
<p>Con R, ambos tests se calculan con la función <code>wilcox.test</code>, con una sintaxis idéntica a la de <code>t.test</code> para dos muestras excepto que no dispone del parámetro <code>var.equal</code> (ya que ahora no nos interesa lo más mínimo saber si las variables tienen varianzas iguales o diferentes en el caso de contrastes de dos medias con muestras independientes) y hay que usar el parámetro <code>conf.int=TRUE</code> si se quiere un intervalo de confianza (para la diferencia de las pseudomedianas de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>).</p>

<div class="rmdnote">
En el caso de dos muestras, para comprobar si ambas muestras se ajustan a variables normales con JAMOVI, no podemos hacerlo desde el módulo <strong>Pruebas T</strong> sino desde <strong>Exploración/Descriptivas</strong>. En nuestro ejemplo (véase la figura que sigue), tenemos que separar la variable <code>Temperatura</code> según el <code>Sexo</code>. Marcando la casilla <em>Shapiro-Wilk</em>, obtenemos los p-valores del test de Shapiro-Wilk tanto para F como para M. Ambos son menores que 0.05, así que podemos rechazar que las muestras provengan de distribuciones normales.
</div>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Veamos otro ejemplo.</p>
<div class="example">
<p><span id="exm:oatbran" class="example"><strong>Ejemplo 15.3  </strong></span>Desayunar salvado de avena (<em>oat bran</em>) en lugar de copos de maíz (<em>corn flakes</em>), ¿ayuda a reducir el nivel de colesterol?</p>
</div>
<p>Planteémoslo como un contraste de hipótesis. Las variables aleatorias poblacionales de interés son:</p>
<ul>
<li><span class="math inline">\(X_{ob}\)</span>: nivel de colesterol al consumir salvado de avena, de media <span class="math inline">\(\mu_{ob}\)</span></li>
<li><span class="math inline">\(X_{cf}\)</span>: nivel de colesterol al consumir copos de maíz, de media <span class="math inline">\(\mu_{cf}\)</span></li>
</ul>
<p>El contraste que queremos realizar es
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_{ob}=\mu_{cf}\\
H_{1}:\mu_{ob}&lt; \mu_{cf}
\end{array}\right.
\]</span></p>
<p>Para hacerlo, vamos a usar los datos obtenidos por J. Anderson <em>et al</em> en su estudio <a href="https://academic.oup.com/ajcn/article-abstract/52/3/495/4650821">“Oat-bran cereal lowers serum total and LDL cholesterol in hypercholesterolemic men”</a> (<em>The American Journal of Clinical Nutrition</em> 52 (1990), pp. 495-499). Se trata de un ensayo clínico cruzado sobre 14 individuos. A cada uno de ellos se le asignó uno de los dos desayunos de manera aleatoria y lo tomaron durante 15 días. Al final de este periodo, se les midió el nivel de colesterol en sangre. Pasado un mes de descanso, cada participante desayunó durante 15 días el otro producto, y al final se los volvió a medir el nivel de colesterol en sangre. Tenemos los niveles de colesterol que obtuvieron en la tabla de datos <strong>oatbran.txt</strong>, donde están medidos en milimoles por litro (mmol/l), así que esta será la unidad que tomamos en las variables poblacionales.</p>
<p>Con JAMOVI, importamos el fichero <strong>oatbran.txt</strong> en una tabla de datos. Como las muestras son pequeñas (de tamaño 14), si queremos aplicar un test t necesitamos poder aceptar que provienen de variables normales. Vamos a <strong>Exploración/Descriptivas</strong>, escogemos ambas variables, <code>CORNFLK</code> y <code>OATBRAN</code>, y marcamos el test de Shapiro-Wilk (y, ya que estamos, las gráficas Q-Q):</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.N.4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Ambos p-valores son muy grandes, así que vamos a aceptar que ambas muestras provienen de variables normales y usaremos un test t de dos medias.</p>
<p>En este caso, como las muestras son emparejadas (hemos medido las dos variables aleatorias sobre los mismos individuos), hay que elegir <strong>Pruebas T/Prueba t para muestras emparejadas</strong>. Cuidado con la hipótesis alternativa: como JAMOVI toma como primera variable <code>CORNFLK</code> y segunda variable <code>OATBRAN</code> y nuestra hipótesis alternativa es que los <em>oat bran</em> reducen el nivel de colesterol respecto de los <em>corn flakes</em>, hemos de marcar “Medida 1 &gt; Medida 2”.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos un p-valor de 0.003. Por lo tanto, hemos encontrado evidencia estadísticamente significativa de que desayunar salvado reduce el nivel medio de colesterol respecto de desayunar copos de maíz. El intervalo de confianza del 95% para <span class="math inline">\(\mu_{cf}-\mu_{ob}\)</span> va de 0.163 a <span class="math inline">\(\infty\)</span>. Por lo tanto, tenemos un 95% de confianza en que desayunar salvado reduce en al menos 0.163 mmol/l el nivel medio de colesterol respecto de desayunar copos de maíz.</p>
<p>¿Y si no quisiéramos, o no pudiéramos, suponer que las muestras provienen de distribuciones normales? Entonces usaríamos un test de Wilcoxon:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.t.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor da 0.006, por lo que la conclusión es la misma.</p>

<div class="rmdexercici">
<p>Típica pregunta de MIR (esta, de 2017):</p>
<p>El grosor del pliegue subcutáneo de grasa a nivel del tríceps se utiliza a veces para evaluar la cantidad de grasa corporal. Esta variable no se distribuye normalmente en las poblaciones. Queremos comparar el valor medio de esta variable en dos poblaciones que suponemos presentan distinta condición nutricional. La prueba estadística más adecuada para contrastar la hipótesis es:</p>
<ul>
<li>La prueba de Mann-Whitney.<br />
</li>
<li>La prueba t de Student.<br />
</li>
<li>El cálculo del coeficiente de correlación de Pearson.</li>
<li>La prueba F de Snedecor.</li>
</ul>
</div>
</div>
</div>
<div id="contrastes-para-más-de-dos-medias" class="section level3 hasAnchor" number="15.1.4">
<h3><span class="header-section-number">15.1.4</span> Contrastes para más de dos medias<a href="qué-test-usar.html#contrastes-para-más-de-dos-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1,X_2,\ldots, X_k\)</span> <span class="math inline">\(k\)</span> variables aleatorias de medias <span class="math inline">\(\mu_1,\mu_2,\ldots,\mu_k\)</span> y desviaciones típicas <span class="math inline">\(\sigma_1,\sigma_2,\ldots,\sigma_k\)</span>, respectivamente. Normalmente, se tratará de una misma variable aleatoria definida sobre <span class="math inline">\(k\)</span> poblaciones diferentes.</p>
Nos preguntamos si es verdad o no que estas <span class="math inline">\(k\)</span> variables tienen la misma media. Es decir, planteamos el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2=\cdots=\mu_k\\
H_{1}:\text{No es verdad que } \mu_1=\mu_2=\cdots=\mu_k
\end{array}
\right.
\]</span>
Para ello, medimos cada <span class="math inline">\(X_i\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_i\)</span>.

<div class="rmdimportant">
Observad que <span class="math inline">\(H_1\)</span> en el contraste anterior es equivalente a
<span class="math display">\[
\text{Existen $i,j$ tales que } \mu_i \neq \mu_j
\]</span>
<strong>no</strong> a
<span class="math display">\[
\mu_i \neq \mu_j \text{ para todos los pares $i,j$ con $i\neq j$}
\]</span>
</div>
<div class="example">
<p><span id="exm:somriures" class="example"><strong>Ejemplo 15.4  </strong></span>En un estudio (publicado en <em>Personality and Social Psychology Bulletin</em> 21 (1995), pp. 207-214) se quiso determinar si la benevolencia con la se juzga a una persona depende de cómo sonríe.</p>
</div>
<p>Para ello se seleccionaron 136 personas, que se dividieron al azar en 4 grupos de 34. A las personas de cada grupo se les pasó un dosier donde se acusaba a un hombre de una falta grave (en un contexto universitario) y, tras estudiarlo, se les pusieron cinco preguntas sobre la culpabilidad del acusado y el castigo que se merecía. A partir de las respuestas de cada sujeto, se calculó un “índice de benevolencia” de cómo había juzgado al acusado.</p>
<p>Los dosieres eran idénticos, excepto la foto del acusado: mismo hombre, pero diferente tipo de sonrisa:</p>
<p><img src="INREMDN_files/figure-html/somriures.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Tenemos los índices obtenidos en el fichero <strong>smiles.txt</strong>. Veamos sus estadísticos básicos y un diagrama de caja.</p>
<p><img src="INREMDN_files/figure-html/somriuresJ1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Vemos que la sonrisa neutra ha generado una menor benevolencia y la falsa, mayor. Queremos determinar si las diferencias son lo bastante grandes para aportar evidencia que la benevolencia depende de la sonrisa.</p>
<p>En este caso tenemos una variable aleatoria, el índice de benevolencia con el que se juzga al acusado, definida sobre cuatro subpoblaciones definidas por el tipo de sonrisa en la foto. Llamemos <span class="math inline">\(\mu_s\)</span>, <span class="math inline">\(\mu_f\)</span>, <span class="math inline">\(\mu_c\)</span> y <span class="math inline">\(\mu_n\)</span> a sus medias: los índices de benevolencia medios con los que se juzga el dosier cuando la sonrisa es sincera, falsa, compungida o neutra, respectivamente.</p>
<p>Entonces, queremos realizar el contraste
<span class="math display">\[
\left\{
\begin{array}{l}
H_0 : \mu_s=\mu_{f}=\mu_{c}=\mu_{n} \\
H_1 : \mbox{Hay algún par de sonrisas }i,j\mbox{ tales que }  \mu_i \neq \mu_j
\end{array}
\right.
\]</span></p>
<p>Un posible modo de resolver este contraste sería realizar los seis contrastes de pares de medias <span class="math inline">\(\mu_i=\mu_j\)</span> contra <span class="math inline">\(\mu_i\neq \mu_j\)</span>, pero esto aumenta la probabilidad de error si no ajustamos los p-valores. Y tenemos que comparar todas las medias dos a dos, porque podría pasar, por ejemplo, que no pudiéramos rechazar que <span class="math inline">\(\mu_n= \mu_s\)</span> ni que <span class="math inline">\(\mu_s= \mu_f\)</span>, pero sí que pudiéramos rechazar que <span class="math inline">\(\mu_n= \mu_f\)</span>.</p>
<p>Lo que queremos es un test que nos diga en un solo paso si todas las medias son iguales o no. La técnica más usual es el <strong>Análisis de la Varianza</strong> (<strong>ANOVA</strong>, del inglés <em>ANalysis Of VAriance</em>). Esta técnica se puede aplicar bajo diferentes diseños experimentales: por ejemplo, según cuántos factores usemos para separar la población en subpoblaciones (uno o varios) o según cómo escojamos las muestras (independientes o emparejadas).</p>
<p>La idea básica del ANOVA es que tenemos evidencia de que no todas las medias poblacionales son iguales si la variabilidad de las medias poblacionales es muy grande en relacion a la variabilidad total de los datos obtenidos: de ahí la <strong>VA</strong>riancia en el nombre. Esta variabilidad relativa se mide mediante un estadístico de contraste adecuado que, si todas la medias poblacionales son iguales y se satisfacen las condiciones adecuadas, tiene una distribución conocida (llamada <strong>F de Fisher-Snedecor</strong>: es la distribución de un cociente de dos variables <span class="math inline">\(\chi^2\)</span> independientes, y sus parámetros son los grados de libertad de estas dos distribuciones <span class="math inline">\(\chi^2\)</span>). Por lo tanto podemos usar esta distribución para calcular un p-valor que nos dé lo improbablemente grande que es la variabilidad de las medias muestrales si las medias poblacionales fueran todas iguales.</p>
<div id="diseño-anova-de-un-factor" class="section level4 hasAnchor" number="15.1.4.1">
<h4><span class="header-section-number">15.1.4.1</span> Diseño ANOVA de un factor<a href="qué-test-usar.html#diseño-anova-de-un-factor" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En un estudio de diseño <strong>ANOVA de un factor</strong> (<em>One way ANOVA</em>):</p>
<ul>
<li><p>Usamos un solo factor para clasificar la población en subpoblaciones.</p></li>
<li><p>Tomamos una muestra aleatoria simple de la variable aleatoria sobre cada subpoblación, independientes unas de otras.</p></li>
</ul>
<p>El Ejemplo <a href="qué-test-usar.html#exm:somriures">15.4</a> es de tipo ANOVA de 1 factor: el factor que usamos para clasificar los índices de benevolencia es el tipo de sonrisa en la foto, y hemos tomado una muestra de índices de benevolencia para cada tipo de sonrisa, independientes las unas de las otras porque hemos asignado las fotos al azar a los participantes.</p>
<div id="anova-de-un-factor" class="section level5 unnumbered hasAnchor">
<h5>ANOVA de un factor<a href="qué-test-usar.html#anova-de-un-factor" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Supongamos que tenemos que realizar una comparación de medias en un estudio de diseño ANOVA de 1 vía. Si se cumple además que:</p>
<ul>
<li><p>Cada una de las <span class="math inline">\(k\)</span> variables aleatorias de las que hemos tomado muestras sigue una ley normal</p></li>
<li><p><strong>Homocedasticidad</strong> o <strong>homogeneidad</strong>: Todas estas variables tienen la misma varianza, <span class="math inline">\(\sigma^2\)</span>.</p></li>
</ul>
<p>Entonces podemos usar un test ANOVA. JAMOVI ofrece el ANOVA de 1 vía en <strong>ANOVA/ANOVA de Un Factor</strong>.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-589" class="example"><strong>Ejemplo 15.5  </strong></span>Sigamos con el Ejemplo <a href="qué-test-usar.html#exm:somriures">15.4</a>. Ya hemos cargado la tabla. Efectuamos los tests de Shapiro-Wilks (separando la variable <code>benevolencia</code> según el factor <code>sonrisa</code>) y obtenemos los 4 p-valores por encima de 0.05, así que vamos a aceptar que para los cuatro tipos de sonrisas los índices de benevolencia se ajustan a distribuciones normales.</p>
</div>
<p><img src="INREMDN_files/figure-html/somriuresJ2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Abriendo entonces <strong>ANOVA/ANOVA de Un Factor</strong>, separamos de nuevo la variable dependiente <code>benevolencia</code> según el factor <code>sonrisa</code>, marcamos la <em>Prueba de homogeneidad</em> para saber si podemos aceptar o no que las varianzas poblacionales son todas iguales, y como el p-valor de ambos tests es grande, marcamos la casilla <em>Asumir iguales (Fisher)</em>, que efectua el test ANOVA.</p>
<p><img src="INREMDN_files/figure-html/somriuresJ3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor es 0.018, por lo que obtenemos evidencia estadística de que al menos un par de medias son diferentes.</p>

<div class="rmdnote">
Un ANOVA de 1 factor aplicado a solo dos medias es equivalente a un test t para dos medias suponiendo varianzas iguales.
</div>
<p>También podéis usar <strong>ANOVA/ANOVA</strong> para efectuar un ANOVA de un factor, mucho más rico en opciones (pero para el nivel de este curso casi todas innecesarias).</p>
</div>
<div id="alternativas" class="section level5 unnumbered hasAnchor">
<h5>Alternativas<a href="qué-test-usar.html#alternativas" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>El test ANOVA de Fisher es bastante robusto a una ligera desviación de la normalidad de las muestras, pero deja estrepitosamente de ser válido si las varianzas poblacionales no son iguales.</p>
<p>Si las variables poblacionales son normales, pero no podemos aceptar que tengan todas la misma varianza, lo recomendado es usar una variante llamada <strong>ANOVA de Welch</strong>, y que en JAMOVI se ejecuta marcando <em>No asumir iguales (Welch)</em> en lugar de <em>Asumir iguales (Fisher)</em>.</p>
<p>Otra posibilidad es usar el test no paramétrico de Kruskal-Wallis, que extiende a más de dos medias el test de Mann-Whitney. JAMOVI lo ofrece en <strong>ANOVA/No paramétrico/ANOVA de Un Factor: Kruskall-Wallis</strong>.</p>
</div>
</div>
<div id="tests-post-hoc" class="section level4 unnumbered hasAnchor">
<h4>Tests <em>post hoc</em><a href="qué-test-usar.html#tests-post-hoc" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si hemos rechazado la hipótesis nula <span class="math inline">\(H_0:\mu_1=\cdots =\mu_k\)</span>, nos puede interesar estimar qué parejas de niveles tienen medias diferentes. La manera más popular es realizar los <span class="math inline">\(\binom{k}{2}\)</span> contrastes
<span class="math display">\[
\left\{
\begin{array}{ll}
H_0 &amp;: \mu_i=\mu_j \\
H_1 &amp;: \mu_i \neq \mu_j
\end{array}
\right.
\]</span>
usando un test t adecuado (si las muestras se ajustan a normalidad o son lo bastante grandes) o un test de Mann-Whitney (si no se puede usar un test t para todos los pares de medias). En caso de homogeneidad de varianzas, el test t no es exactamene el que hemos explicado para pares de medias y varianzas iguales porque usa todas las muestras, y no solo las dos involucradas, para estimar el error típico.</p>
<p>Pero hay que ir con cuidado con el nivel de significación global. Como vimos en el tema anterior, si efectuamos muchos contrastes de pares de medias, la probabilidad de cometer un error de tipo I <em>en alguno</em> aumenta, por lo que hay que reducir el nivel de significación con el que los efectuamos o, equivalentemente, ajustar los p-valores. En <strong>ANOVA/ANOVA de Un Factor</strong> JAMOVI efectua un ajuste por defecto que es más que suficiente para nuestros propósitos. Si queréis usar otros ajustes, por ejemplo el de Bonferroni que mencionábamos en el tema anterior (multiplicar los p-valores por el número de tests), los encontraréis en <strong>ANOVA/ANOVA/Pruebas Post Hoc</strong>. Normalmente no habrá grandes diferencias en las conclusiones de los tests según el método de ajuste usado.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-591" class="example"><strong>Ejemplo 15.6  </strong></span>Seguimos con nuestro ejemplo sobre la benevolencia que suscitan los diferentes tipos de sonrisa. Con un ANOVA de 1 factor hemos obtenido evidencia seignificativa de que hay al menos un par de sonrisas con índices de benevolencia medios diferentes. Vamos a investigar cuáles.</p>
</div>
<p>Antes de nada, un gráfico: en <strong>ANOVA/ANOVA de Un Factor</strong> pedimos que añada “Gráficas Descriptivas”:</p>
<p><img src="INREMDN_files/figure-html/somriuresJ6.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Nos da los intervalos de confianza del 95% para las cuatro medias. Observad que todos los pares de intervalos de confianza se solapan salvo dos: el de la sonrisa falsa y el de la sonrisa neutra. Este gráfico nos aporta evidencia de que estas dos medias no son iguales (cada una pertenece a su intervalo de confianza con una confianza del 95%, y estos dos intervalos son disjuntos) y nos indica que los otros pares de medias pueden ser iguales (sus intervalos de confianza no son disjuntos). Esto es solo una indicación gráfica del resultado que tenemos que esperar, pero no nos da el resultado del test con la confianza que deseamos: las conclusiones se basan en que <em>todos</em> los IC 95% aciertan, y la probabilidad de que eso ocurra es menor que 0.95.</p>
<p>Vamos ya a realizar las comparaciones posteriores por parejas.
Usamos para ello la ventana <strong>ANOVA/ANOVA de Un Factor/Pruebas Post-Hoc</strong>. Como hemos aceptado que las variables poblacionales son todas iguales, marcamos <em>Tukey (varianzas iguales)</em>:</p>
<p><img src="INREMDN_files/figure-html/somriuresJ4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>En la tabla obtenemos la diferencia de medias “fila menos columna” y el p-valor del test para cada par formado por las medias para el tipo de sonrisa de la fila y el de la columna. Los p-valores están ajustados por el mmétodo de Tukey, demasiado complicad para explicarlo aquí, así que tenemos que compararlos directamente con el nivel de significación elegido. Si este es 0.05, observamos que solo obtenemos evidencia de diferencia de medias para el par sonrisa falsa-sonrisa neutra. Para el resto de pares de medias no podemos rechazar que sean iguales. Era lo que esperábamos.</p>
<p>Si quisiéramos usar por ejemplo el ajuste de Bonferroni, tendríamos que efectuar el ANOVA con <strong>ANOVA/ANOVA</strong>:</p>
<p><img src="INREMDN_files/figure-html/somriuresJ5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Hemos marcado también la columna de p-valores sin ajustar (“p”) y la del ajuste de Tukey para que veáis que el ajuste de Bonferroni consiste en tomar el mínimo de 1 y el resultado de multiplicar el p-valor por 6 (el número total de contrastes de pares de medias) y podáis comparar los valores ajustados de Bonferroni con los de Tukey. La conclusión con los dos tipos de ajuste es la misma.</p>
</div>
<div id="diseño-anova-de-bloques" class="section level4 hasAnchor" number="15.1.4.2">
<h4><span class="header-section-number">15.1.4.2</span> Diseño ANOVA de bloques<a href="qué-test-usar.html#diseño-anova-de-bloques" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Así como el diseño de ANOVA de una vía generaliza a más de dos medias el contraste de igualdad de dos medias con muestras independientes, el ANOVA de bloques generaliza a más de dos medias el contraste de igualdad de dos medias <em>con muestras emparejadas</em>.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-592" class="example"><strong>Ejemplo 15.7  </strong></span>Hemos querido comparar los efectos de dos analgésicos y un placebo en el tratamiento de la cefalea. Para ello, hemos reclutado 10 enfermos de cefalea y a cada uno le hemos aplicado los tres tratamientos en diferentes episodios de cefalea. El orden de los tratamientos ha sido aleatorio. El efecto de los tratamientos lo cuantificamos mediante el tiempo (en minutos) que tarda en desaparecer una cefalea con el tratamiento.</p>
</div>
<p>Los resultados han sido los siguientes:
<span class="math display">\[
\begin{array}{c|ccc}
\text{Sujeto} &amp; \text{Placebo} &amp; \text{Analgésico A}&amp;\text{Analgésico B}\\\hline
        1 &amp; 35 &amp; 20 &amp; 22\\
        2 &amp; 40 &amp; 35 &amp; 42\\
        3 &amp; 60 &amp; 50 &amp; 30\\
        4 &amp; 50 &amp; 40 &amp; 35\\
        5 &amp; 50 &amp; 30 &amp; 22 \\
        6 &amp; 52 &amp; 30 &amp; 25\\
        7 &amp; 37 &amp; 22 &amp; 18\\
        8 &amp; 45 &amp; 30 &amp; 28\\
        9 &amp; 40 &amp; 45 &amp; 35\\
        10 &amp; 47 &amp; 40 &amp; 37
\end{array}
\]</span></p>
<p>Si llamamos</p>
<ul>
<li><p><span class="math inline">\(\mu_P\)</span>: Tiempo medio tomando el placebo</p></li>
<li><p><span class="math inline">\(\mu_A\)</span>: Tiempo medio tomando el analgésico A</p></li>
<li><p><span class="math inline">\(\mu_1\)</span>: Tiempo medio tomando el analgésico B</p></li>
</ul>
<p>queremos realizar el contraste:
<span class="math display">\[
  \left\{
    \begin{array}{l}
    H_0 : \mu_1 =\mu_2 =\mu_3 \\
    H_1 : \mu_1\neq \mu_2\mbox{ o }\mu_1\neq \mu_3\mbox{ o }\mu_2\neq \mu_3
    \end{array}
    \right.
\]</span></p>
<p>Aunque hemos usado un factor para clasificar la población (el tipo de tratamiento), no se trata de un diseño de ANOVA de 1 vía, porque las muestras de cada nivel no son independientes, sino emparejadas. Se trata de un <strong>diseño de ANOVA de bloques</strong>.</p>
<p>En un experimento con diseño de ANOVA de bloques</p>
<ul>
<li><p>Tenemos <span class="math inline">\(k\)</span> tratamientos que queremos comparar.</p></li>
<li><p>Escogemos <span class="math inline">\(b\)</span> : conjuntos de <span class="math inline">\(k\)</span> sujetos emparejados (por ejemplo, <span class="math inline">\(k\)</span> copias del mismo sujeto).</p></li>
<li><p>Dentro de cada bloque, asignamos aleatoriamente a cada sujeto un tratamiento, de manera que cada tratamiento se use exactamente una vez dentro de cada bloque.</p>
<p>Por ejemplo, si cada bloque corresponde a un único sujeto, le asignamos los tratamientos en diferentes momentos de tiempo en un orden aleatorio, como hemos hecho en nuestro ejemplo.</p></li>
</ul>
<p>El contraste que se quiere realizar es
<span class="math display">\[
      \left\{
        \begin{array}{l}
        H_0 : \mu_{1} =\mu_{2} =\cdots =\mu_{k} \\
        H_1 : \mbox{Hay $i,j$ tales que } \mu_{i}  \neq \mu_{j}
        \end{array}
        \right.
\]</span>
donde cada <span class="math inline">\(\mu_{i}\)</span> es la media del tratamiento <span class="math inline">\(i\)</span>-ésimo</p>
<p>La filosofía del contraste ANOVA es similar al de un factor: la variabilidad de los datos se descompone en la suma de</p>
<ul>
<li><p>la variabilidad de las medias muestrales de los tratamientos</p></li>
<li><p>la variabilidad de las medias de los bloques</p></li>
<li><p>la variabilidad residual debida al azar al escoger las muestras</p></li>
</ul>
<p>y se compara la variabilidad de las medias muestrales con la variabilidad residual</p>
<p>Para que las conclusiones de un ANOVA de bloques tengan sentido, ha de pasar que</p>
<ol style="list-style-type: lower-alpha">
<li><p>Las <span class="math inline">\(k\cdot b\)</span> observaciones sean muestras aleatorias (de tamaño 1) e independientes de las <span class="math inline">\(k\cdot b\)</span> poblaciones definidas por las medidas que se tomarían para cada combinación de sujeto y tratamiento</p></li>
<li><p>Estas <span class="math inline">\(k\cdot b\)</span> poblaciones son normales y con la misma varianza</p></li>
<li><p>No hay <strong>interacción</strong> entre los bloques y los tratamientos: Para cada par de tratamientos <span class="math inline">\(i,j\)</span> y para cada par de bloques <span class="math inline">\(s,t\)</span>, la diferencia entre las medias poblacionales de las mediciones para el tratamiento <span class="math inline">\(i\)</span> y el tratamiento <span class="math inline">\(j\)</span> en el bloque <span class="math inline">\(s\)</span> es la misma que en el bloque <span class="math inline">\(t\)</span>.</p></li>
</ol>
<p>Ninguna de estas condiciones se puede contrastar, por lo tanto el experimentador ha de decidir si se cumplen o no según su experiencia.
Si no se cree que se cumpla (b), puede ser conveniente efectuar un test no paramétrico. Si se cree que puede haber interacción entre los bloques y los tratamientos, es más recomendable usar un ANOVA de 2 factores (véase la siguiente sección).</p>
<p>Podemos efectuar un ANOVA de bloques con JAMOVI en la pestaña <strong>ANOVA/ANOVA de Medidas Repetidas</strong>. Para ello, tenemos que tener la tabla con los resultados de las mediciones en una tabla de datos con filas los bloques y columnas los tratamientos. Para el ejemplo anterior, la tenemos en el fichero <em>Analgesicos.csv</em>. Tras importarla, comprobad (o especificad) que las variables de los tratamientos son numéricas.</p>
<p><img src="INREMDN_files/figure-html/ANOVA.b.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>A continuación, en la ventana “Factores de Medidas Repetidas” de **ANOVA/ANOVA de Medidas Repetidas* tenemos que indicar cuántos tratamientos usamos. Como en nuestro ejemplo usamos tres tratamientos, hemos de añadir un “Nivel 3” a los dos que se especifican por defecto. Es una buena idea poner nombres tanto al factor que usamos para clasificar los tratamientos como a sus niveles (clicando encima y reescribiendo)</p>
<p><img src="INREMDN_files/figure-html/ANOVA.b.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>A continuación, arrastramos las variables de cada tratamiento a su nivel correspondiende en la ventana “Celdas de Medidas Repetidas”:</p>
<p><img src="INREMDN_files/figure-html/ANOVA.b.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor &lt;0.001 nos indica que hay evidencia estadística de diferencia en las eficacias medias de al menos dos tratamientos. Los contrastes <em>post hoc</em> por parejas se efectuan más abajo en la misma pestaña, seleccionando el factor. Se puede también elegir el método de corrección de p-valores.</p>
<p><img src="INREMDN_files/figure-html/ANOVA.b.4.png" width="100%" style="display: block; margin: auto;" />
Obtenemos evidencia significativa de diferencia entre ambos tratamientos y el placebo, pero no de diferencia entre los dos tratamientos.</p>
<p>El test no paramétrico que generaliza al diseño ANOVA de bloques el test de Wilcoxon es el test de Friedman que se encuentra en la pestaña <strong>ANOVA/No Paramétrico/ANOVA de Medidas Repetidas (Friedman)</strong>. En él solo hay que seleccionar las variables que contienen las mediciones de tratamientos. También se pueden efectuar los tests <strong>post hoc</strong> por parejas (y no os burléis del “no paramédico” por “no paramétrico” de la versión actual en español, ya lo arreglarán).</p>
<p><img src="INREMDN_files/figure-html/ANOVA.b.5.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="diseño-anova-multifactorial" class="section level4 hasAnchor" number="15.1.4.3">
<h4><span class="header-section-number">15.1.4.3</span> Diseño ANOVA multifactorial<a href="qué-test-usar.html#diseño-anova-multifactorial" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En un experimento de diseño de <strong>ANOVA factorial</strong> se usan las combinaciones de niveles de dos o más factores para definir las subpoblaciones para las que comparamos las medias de una variable aleatoria. El caso más sencillo, que es el único que trataremos aquí es el diseño de <strong>ANOVA de 2 vías</strong> o <strong>de 2 factores</strong>:</p>
<ul>
<li><p>Usamos las combinaciones de niveles de dos factores para definir las subpoblaciones</p></li>
<li><p>Para cada pareja de niveles, uno de cada factor, tomamos una muestra aleatoria simple de la subpoblación definida por la combinación de ambos niveles. Estas muestras han de ser independientes las unas de las otras y todas del mismo tamaño <span class="math inline">\(n\geq 2\)</span>.</p></li>
</ul>
<div class="example">
<p><span id="exm:unnamed-chunk-593" class="example"><strong>Ejemplo 15.8  </strong></span>Para contrastar si el nivel de colesterol depende del sexo o la complexión de las personas, se midió el nivel de colesterol (en mg/dL) de 30 personas de cada combinación de sexo (<em>male</em> o <em>female</em>) y complexión (<em>small</em>, <em>medium</em> o<em>large</em>). Tenemos los datos guardados en el tabla de datos <code>colesterol.csv</code>, con variables <em>chol</em> (el nivel de colesterol), <em>sex</em> (el sexo) y <em>frame</em> (la complexión).</p>
</div>
<p><img src="INREMDN_files/figure-html/ANOVA2w.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Como en los otros ANOVA, de nuevo se comparan variabilidades.</p>
<p>En un estudio como el de este ejemplo, en realidad nos podemos plantear cuatro preguntas:</p>
<ul>
<li><p>¿Hay diferencia en el nivel medio de colesterol según el sexo, teniendo en cuenta la posible influencia de la complexión en el nivel del colesterol?</p></li>
<li><p>¿Hay diferencia en el nivel medio de colesterol según la complexión, teniendo en cuenta la posible influencia del sexo en el nivel del colesterol?</p></li>
<li><p>¿Hay diferencia en el nivel medio de colesterol según la combinación sexo-complexión?</p></li>
<li><p>¿Hay interacción en el nivel medio de colesterol entre el sexo y la complexión (en el sentido de que el efecto de los niveles de un factor se magnifiquen en los del otro factor: por ejemplo, que la diferencia en el nivel medio de colesterol entre hombres y mujeres de complexión grande sea diferente que entre hombres y mujeres de complexión pequeña)?</p></li>
</ul>
<p>Formalmente, usamos dos factores <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> para clasificar la población sobre la que medimos una variable <span class="math inline">\(X\)</span>. El factor <span class="math inline">\(A\)</span> tiene <span class="math inline">\(k\)</span> niveles: <span class="math inline">\(a_1,\ldots,a_k\)</span>. El factor <span class="math inline">\(B\)</span> tiene <span class="math inline">\(l\)</span> niveles: <span class="math inline">\(b_1,\ldots,b_l\)</span>. Tomamos para cada par <span class="math inline">\((a_i,b_j)\)</span> una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span>, independientes las unas de las otras. Por lo tanto, el número total de observaciones es <span class="math inline">\(n\cdot k\cdot l\)</span>.</p>
<p>Llamemos:</p>
<ul>
<li><p><span class="math inline">\(\mu_{i\bullet}\)</span>: media poblacional de <span class="math inline">\(X\)</span> para los sujetos del nivel <span class="math inline">\(a_i\)</span> de <span class="math inline">\(A\)</span></p></li>
<li><p><span class="math inline">\(\mu_{\bullet j}\)</span>: media poblacional de <span class="math inline">\(X\)</span> para los sujetos del nivel <span class="math inline">\(b_j\)</span> de <span class="math inline">\(B\)</span></p></li>
<li><p><span class="math inline">\(\mu_{ij}\)</span>: media poblacional de <span class="math inline">\(X\)</span> para los sujetos que son simultáneamente del nivel <span class="math inline">\(a_i\)</span> de <span class="math inline">\(A\)</span> y del nivel <span class="math inline">\(b_j\)</span> de <span class="math inline">\(B\)</span></p></li>
</ul>
<p>Planteamos los cuatro contrastes siguientes:</p>
<ul>
<li><p><strong>Contraste de medias del factor <span class="math inline">\(A\)</span></strong>: Contrastamos si hay diferencias entre los niveles del factor <span class="math inline">\(A\)</span>:
<span class="math display">\[
\left\{
\begin{array}{l}
H_0 : \mu_{1\bullet}=\mu_{2\bullet}=\cdots
=\mu_{k\bullet} \\
H_1 : \mbox{Hay $i,i&#39;$ tales que  $\mu_{i\bullet}\neq \mu_{i&#39;\bullet}$}
\end{array}
\right.
\]</span></p></li>
<li><p><strong>Contraste de medias del factor <span class="math inline">\(B\)</span></strong>: Contrastamos si hay diferencias entre los niveles del factor <span class="math inline">\(B\)</span>:
<span class="math display">\[
\left\{
\begin{array}{l}
H_0 : \mu_{\bullet 1}=\mu_{\bullet 2}=\cdots =\mu_{\bullet l} \\
H_1 : \mbox{Hay $j,j&#39;&#39;$ tales que  $\mu_{\bullet j}\neq \mu_{\bullet j&#39;}$}
\end{array}
\right.
\]</span></p></li>
<li><p><strong>Contraste de medias de la combinación <span class="math inline">\(A\)</span>-<span class="math inline">\(B\)</span></strong>: Contrastamos si hay diferencias entre las parejas (nivel de <span class="math inline">\(A\)</span>, nivel de <span class="math inline">\(B\)</span>):
<span class="math display">\[
\left\{
\begin{array}{l}
H_0 : \mbox{Para todos $i,j,i&#39;,j&#39;$,  $\mu_{ij}=\mu_{i&#39;j&#39;}$} \\
H_1 : \mbox{Hay $i,j,i&#39;,j&#39;$ tales que  $\mu_{ij}\neq \mu_{i&#39;j&#39;}$}
\end{array}
\right.
\]</span></p></li>
<li><p><strong>Contraste de interacción</strong>: Contrastamos si hay interacción entre los niveles de <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span>
<span class="math display">\[
\left\{
\begin{array}{l}
H_0 : \mbox{No hay interacción entre ningún par de niveles} \\
H_1 : \mbox{Hay interacción entre algún par de niveles}
\end{array}
\right.
\]</span></p></li>
</ul>
<p>Para que las conclusiones del ANOVA de 2 vías tengan sentido, es necesario que:</p>
<ul>
<li><p>Las observaciones para cada combinación de niveles constituyan
muestras aleatorias simples independientes, cada una de tamaño <span class="math inline">\(n\)</span>, de las <span class="math inline">\(k\cdot l\)</span>
subpoblaciones definidas por las combinaciones de un nivel de <span class="math inline">\(A\)</span> y un nivel de <span class="math inline">\(B\)</span></p></li>
<li><p>La restricción de <span class="math inline">\(X\)</span> a cada una de estas <span class="math inline">\(k\cdot l\)</span> poblaciones es normal y todas tienen la misma varianza</p></li>
</ul>
<p>En JAMOVI, los ANOVA factoriales, y en particular el de 2 vías, se pueden efectuar en la pestaña <strong>ANOVA/ANOVA</strong>, seleccionando la variable que contiene los valores como “Variable dependiente” y las variables correspondientes a los factores como “Factores Fijos”, y marcando la casilla “Modelo Global”:</p>
<p><img src="INREMDN_files/figure-html/ANOVA2w.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>En esta tabla:</p>
<ul>
<li><p>La fila “frame” corresponde al contraste de medias del factor <em>frame</em>: como el p-valor es 0.066, con nivel de significación 0.05 no tenemos evidencia estadística de que el nivel medio de colesterol varíe con la complexión</p></li>
<li><p>La fila “sex” corresponde al contraste de medias del factor <em>sex</em>: como el p-valor es 0.332, no tenemos evidencia estadística de que el nivel medio de colesterol varíe con el sexo</p></li>
<li><p>La fila “Modelo Global” corresponde al contraste de medias de la combinación <em>sex</em>-<em>frame</em>: como el p-valor es 0.26, no tenemos evidencia estadística de que el nivel medio de colesterol varíe con la combinación de sexo y complexión</p></li>
<li><p>La fila “frame*sex” corresponde al contraste de interacción: como el p-valor es 0.958, no tenemos evidencia estadística de que haya interaccón entre la influencia del sexo y la complexión en el nivel medio de colesterol.</p></li>
</ul>
<p>Si hubiéramos encontrado evidencia de diferencias entre medias para algún factor, podríamos efectuar los contrastes post-hoc por parejas en la sección “Pruebas post-hoc”.</p>
<p><img src="INREMDN_files/figure-html/ANOVA2w.3.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="contrastes-para-varianzas" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Contrastes para varianzas<a href="qué-test-usar.html#contrastes-para-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-bilaterales-para-dos-varianzas" class="section level3 hasAnchor" number="15.2.1">
<h3><span class="header-section-number">15.2.1</span> Contrastes bilaterales para dos varianzas<a href="qué-test-usar.html#contrastes-bilaterales-para-dos-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias de desviaciones típicas <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span>. Queremos realizar el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1=\sigma_2\\
H_{1}:\sigma_1\neq \sigma_2
\end{array}
\right.
\]</span>
o, equivalentemente,
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1^2=\sigma_2^2\\
H_{1}:\sigma_1^2\neq \sigma_2^2
\end{array}
\right.
\]</span></p>
<p>Si <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son <strong>las dos normales</strong>, podemos usar el <strong>test F</strong>. Este test usa como estadístico de contraste el cociente de varianzas muestrales, <span class="math inline">\(\widetilde{S}^2_{X_1}/\widetilde{S}^2_{X_2}\)</span>, que, si <span class="math inline">\(\sigma_1=\sigma_2\)</span>, tiene distribución F de Fisher-Snedecor, de ahí el nombre del test.</p>
<p>Con JAMOVI, se realiza marcando la casilla <em>Test de homogeneidad</em> al llevar a cabo un test t de dos muestras independientes con el módulo <strong>moretests</strong> instalado: es el resultado de la fila “Variance ratio”. Con <code>R</code> se realiza con la función <code>var.test</code> aplicada a las dos muestras y además os da un intervalo de confianza para el cociente <span class="math inline">\(\sigma_1^2/\sigma_2^2\)</span>. La ventaja de <code>var.test</code> es que también permite efectuar contrastes unilaterales, especificando el parámetro <code>alternative</code>.</p>
<p>El test F no és válido a poco que las variables <span class="math inline">\(X_1\)</span> o <span class="math inline">\(X_2\)</span> difieran de normales, incluso aunque las muestras sean grandes. Si no podemos aceptar que <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sean normales, es necesario usar un test no paramétrico. JAMOVI usa el <a href="https://en.wikipedia.org/wiki/Levene%27s_test"><strong>test de Levene</strong></a>, que lleva a cabo marcando la mencionada casilla <em>Test de homogeneidad</em>.</p>
<p>Ya hemos visto un ejemplo de contraste bilateral de varianzas en el Ejemplo <a href="qué-test-usar.html#exm:tempHD">15.2</a>.</p>
</div>
<div id="contrastes-de-homogeneidad-para-más-de-dos-varianzas" class="section level3 hasAnchor" number="15.2.2">
<h3><span class="header-section-number">15.2.2</span> Contrastes de homogeneidad para más de dos varianzas<a href="qué-test-usar.html#contrastes-de-homogeneidad-para-más-de-dos-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1,X_2,\ldots,X_k\)</span> <span class="math inline">\(k\)</span> variables aleatorias, de desviaciones típicas <span class="math inline">\(\sigma_1,\sigma_2,\ldots,\sigma_k\)</span> respectivamente.. Queremos realizar el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1=\sigma_2=\cdots=\sigma_k\\
H_{1}: \text{Hay algún par }i,j\text{ tal que }\sigma_1\neq \sigma_2
\end{array}
\right.
\]</span>
o, equivalentemente,
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1^2=\sigma_2^2=\cdots=\sigma_k^2\\
H_{1}: \text{Hay algún par }i,j\text{ tal que }\sigma_1^2\neq \sigma_2^2
\end{array}
\right.
\]</span></p>
<p>Si todas las variables son normales, lo mejor es usar el <a href="https://en.wikipedia.org/wiki/Bartlett%27s_test"><strong>test de Bartlett</strong></a>, pero si alguna muestra no se ajusta a una variable normal, conviene usar algún test no paramétrico. JAMOVI ofrece el <strong>test de Levene</strong>, que también sirve para dos medias, ya está bien.</p>
<p>Como hemos visto en la sección anterior, ambos tests se pueden efectuar marcando la casilla <em>Prueba de homogeneidad</em> al hacer un ANOVA de un factor con <strong>ANOVA/ANOVA de Un Factor</strong> y el módulo <em>moretests</em> instalado.</p>
</div>
</div>
<div id="contrastes-para-proporciones" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Contrastes para proporciones<a href="qué-test-usar.html#contrastes-para-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-para-una-proporción" class="section level3 hasAnchor" number="15.3.1">
<h3><span class="header-section-number">15.3.1</span> Contrastes para una proporción<a href="qué-test-usar.html#contrastes-para-una-proporción" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria Bernoulli de parámetro <span class="math inline">\(p\)</span>. Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p=p_0\\
H_{1}:p\neq p_0\text{ o }p&gt; p_0\text{ o }p&lt; p_0
\end{array}
\right.
\]</span></p>
<p>Tomamos una muestra aleatoria simple de <span class="math inline">\(X\)</span> de tamaño <span class="math inline">\(n\)</span>.</p>
<div id="test-binomial" class="section level4 hasAnchor" number="15.3.1.1">
<h4><span class="header-section-number">15.3.1.1</span> Test binomial<a href="qué-test-usar.html#test-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como vimos en el tema anterior, siempre podemos usar el <strong>test binomial</strong>, que usa que si <span class="math inline">\(p=p_0\)</span>, el número de éxitos en una m.a.s. de tamaño <span class="math inline">\(n\)</span> tiene distribución <span class="math inline">\(B(n,p_0)\)</span>. Para llevarlo a cabo con JAMOVI, podemos usar <strong>Frecuencias/Prueba binomial</strong>.</p>
<div class="example">
<p><span id="exm:sexes" class="example"><strong>Ejemplo 15.9  </strong></span>La muestra de personas recogidas en la tabla de datos de temperaturas usada hasta ahora fue transversal, sin números prefijados de hombres y mujeres. Su composición en sexos, ¿aporta evidencia estadística de que la proporción de mujeres en la población es estrictamente mayor que la de hombres?</p>
</div>
<p>Sea <span class="math inline">\(p\)</span> la proporción de mujeres en la población. Podemos traducir la pregunta planteada en el contraste</p>
<p><span class="math display">\[
\left\{
\begin{array}{l}
H_0:p=0.5\\
H_1:p&gt;0.5
\end{array}
\right.
\]</span></p>
<p>La ventana del test binomial para este contraste con JAMOVI es:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>JAMOVI ha realizado el test binomial para las mujeres (F) y para los hombres (M): el que nos interesa es el primero. Con un p-valor 0.474 y un intervalo de confianza para <span class="math inline">\(p\)</span> de 0.448 a 1, no podemos rechazar que p sea 0.5.</p>
<p>Si no disponemos de la tabla de datos sino solo de las frecuencias, tenemos que entrarlas como una variable en una tabla de datos:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.2.png" width="40%" style="display: block; margin: auto;" /></p>
<p>y al cargar la variable en la ventana <strong>Frecuencias/Prueba binomial</strong>, marcar la casilla <em>Los valores son frecuencias</em>:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.3.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="test-aproximado" class="section level4 hasAnchor" number="15.3.1.2">
<h4><span class="header-section-number">15.3.1.2</span> Test aproximado<a href="qué-test-usar.html#test-aproximado" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si el tamaño <span class="math inline">\(n\)</span> de la muestra es grande (digamos <span class="math inline">\(\geqslant 40\)</span>), podemos usar el <strong>test aproximado</strong> basado en que, si <span class="math inline">\(H_0: p=p_0\)</span> es verdadera y <span class="math inline">\(n\)</span> es grande, por el Teorema Central del Límite
<span class="math display">\[
\frac{\widehat{p}_X-p_0}{\sqrt{\frac{\widehat{p}_X(1-\widehat{p}_X)}{n}}}\approx N(0,1)
\]</span></p>
<p>Este test es mucho más popular que el binomial, porque se puede efectuar “a mano” con una simple calculadora. Curiosamente, JAMOVI no lo implementa tal cual (solo un test equivalente y solo para el contraste bilateral, en <strong>Frecuencias/Prueba de proporciones (N resultados)</strong>; volveremos sobre él al hablar de contrastes para dos, o más, proporciones), pero podéis usar la función <code>prop.test</code> de <code>R</code>, aplicada a: el número de éxitos; el tamaño total de la muestra; el parámetro <code>p</code> igualado al valor a contrastar <span class="math inline">\(p_0\)</span>; el parámetro <code>alternative</code> igualado al tipo de contraste; y el parámetro <code>conf.level</code> igualado al nivel de confianza (si es 0.95, no hace falta especificarlo). En esta función <code>R</code> usa por defecto una corrección de continuidad que se suele usar al aproximar variables aleatorias discretas por medio de variables continuas y que suele mejorar los resultados del test. Podéis cancelar esta corrección de continuidad con el parámetro <code>correct=FALSE</code> pero os recomendamos que la mantengáis.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.1.4.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="contrastes-para-dos-proporciones" class="section level3 hasAnchor" number="15.3.2">
<h3><span class="header-section-number">15.3.2</span> Contrastes para dos proporciones<a href="qué-test-usar.html#contrastes-para-dos-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias Bernoulli de probabilidades poblacionales de éxito <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, respectivamente.</p>
<p>Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2\text{ o }p_1&gt; p_2\text{ o }p_1&lt; p_2
\end{array}
\right.
\]</span>
Para ello, tomamos una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span> de <span class="math inline">\(X_1\)</span> y una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span> de <span class="math inline">\(X_2\)</span>. Como en la comparación de dos medias, estas muestras pueden ser independientes o emparejadas.</p>
<div id="tests-para-dos-proporciones-con-muestras-independientes" class="section level4 hasAnchor" number="15.3.2.1">
<h4><span class="header-section-number">15.3.2.1</span> Tests para dos proporciones con muestras independientes<a href="qué-test-usar.html#tests-para-dos-proporciones-con-muestras-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="test-chi2" class="section level5 unnumbered hasAnchor">
<h5>Test <span class="math inline">\(\chi^2\)</span><a href="qué-test-usar.html#test-chi2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Cuando las dos muestras son grandes, digamos las dos de tamaño <span class="math inline">\(\geqslant 40\)</span>, podemos usar el llamado <strong>test <span class="math inline">\(\chi^2\)</span></strong>. Usa el estadístico de contraste que ya explicamos al hablar de intervalos de confianza para la diferencia de dos proporciones. Si <span class="math inline">\(p_1=p_2\)</span> y las muestras son lo bastante grandes, este estadístico de contraste sigue una ley aproximadamente normal estándar (por si os lía el nombre del test, recordad que el cuadrado de una normal estándar tiene distribución <span class="math inline">\(\chi_1^2\)</span> y esto es lo que realmente usa el test).</p>
<p>En JAMOVI lo encontramos en <strong>Frecuencias/Muestras independientes: Prueba de asociación de <span class="math inline">\(\chi^2\)</span></strong>. Os recomendamos usar la versión “con corrección de continuidad”, que aplica la corrección de continuidad que comentábamos al hablar de <code>prop.test</code>.</p>
<div class="example">
<p><span id="exm:bronquitis" class="example"><strong>Ejemplo 15.10  </strong></span>¿Hay asociación positiva entre bronquitis en la infancia y tos crónica en la adolescencia, en el sentido de que el riesgo de tos crónica es mayor entre los adolescentes que siendo niños tuvieron bronquitis?</p>
</div>
<p>Para responder esta cuestión, en un estudio transversal se tomaron 1319 niños de 14 años, se miró si en ese momento tenían tos crónica o no y si a los 5 años habían tenido bronquitis o no. El resultado fue la tabla siguiente:
<span class="math display">\[
\begin{array}{c}
\qquad\qquad\qquad\qquad\textbf{Bronquitis}\\
\qquad\qquad\qquad\qquad\textbf{a los 5 años}\\
\begin{array}{ll|cc}
&amp; &amp;  \quad\text{Sí}\quad  &amp;\quad  \text{No}\quad  \\ \hline
\textbf{Tos a los}   &amp; \text{Sí}  &amp; 26 &amp;     44 \\
\textbf{14 años} &amp; \text{No} &amp; 247 &amp;            1002
\end{array}
\end{array}
\]</span>
Tenemos los datos de los niños guardados en el fichero <strong>bronquitis.txt</strong>.</p>
<p>Las variables aleatorias de interés son:</p>
<ul>
<li><span class="math inline">\(X_1\)</span>: Que un niño que tuvo bronquitis a los 5 años, tenga tos crónica a los 14, de probabilidad poblacional de éxito <span class="math inline">\(p_1\)</span></li>
<li><span class="math inline">\(X_2\)</span>: Que un niño que no tuvo bronquitis a los 5 años, tenga tos crónica a los 14, de probabilidad poblacional de éxito <span class="math inline">\(p_2\)</span></li>
</ul>
<p>El contraste que queremos realizar es
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1&gt;p_2
\end{array}\right.
\]</span></p>
<p>Como las dos muestras son grandes, podemos usar el test <span class="math inline">\(\chi^2\)</span>. Para hacerlo con JAMOVI, importamos el fichero <strong>bronquitis.txt</strong> en una tabla de datos. A continuación, en <strong>Datos/Configuración</strong>, en la lista de “Niveles” ponemos el 1 encima del 0 (seleccionándolo y subíendolo con la flecha). Finalmente, vamos a <strong>Frecuencias/Muestras independientes</strong>, elegimos <code>bronquitis</code> como variable columna y <code>tos</code> como variable fila y marcamos que queremos comparar por “columnas” (la dimensión de las dos variables cuyas probabilidades de éxito queremos comparar). Observad que en este fichero los Síes son 1 y los Noes 0, y en la tabla de frecuencias la primera columna ahora es 1 y la segunda 0, por lo que la hipótesis alternativa ha de ser “Grupo 1 &gt; Grupo 2”. Mirad en la figura el resto de casillas marcadas.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor es menor que 0.001, por lo que obtenemos evidencia estadísticamente significativa de que la probabilidad de tos crónica en la adolescencia es mayor entre los que sufrieron bronquitis infantil. El RA estimado es de 0.174, con un IC 95% entre 0.077 y 1, y el RR estimado es de 1.88, con un IC 95% entre 1.36 y 2.60; es decir, con un 95% de confianza estimamos que:</p>
<ul>
<li>El riesgo de tos crónica en la adolescencia es al menos 7.7 puntos porcentuales mayor entre los adolescentes que tuvieron bronquitis infantil que entre los que no</li>
<li>El riesgo de tos crónica en la adolescencia es entre un 36% y un 160% mayor entre los adolescentes que tuvieron bronquitis infantil que entre los que no</li>
</ul>

<div class="rmdnote">
En los tests <span class="math inline">\(\chi^2\)</span> unilaterales para dos proporciones, el intervalo de confianza para el RR que calcula JAMOVI es el del test bilateral. Bueno, menos es nada.
</div>
<p>Si no hubiéramos dispuesto del fichero con los datos brutos y solo tuviéramos la tabla de frecuencias, las entraríamos en una tabla de datos como la que sigue:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.6.1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>y procederíamos como antes, solo que ahora declararíamos la variable con las frecuencias como “Frecuencias”:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.6.2.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="test-exacto-de-fisher" class="section level5 unnumbered hasAnchor">
<h5>Test exacto de Fisher<a href="qué-test-usar.html#test-exacto-de-fisher" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>En un contraste de dos proporciones siempre podemos usar el <a href="https://en.wikipedia.org/wiki/Fisher%27s_exact_test"><strong>test exacto de Fisher</strong></a>. Se basa en la idea de que si la hipótesis nula es verdadera (es decir, si <span class="math inline">\(p_1=p_2\)</span>) entonces sería como si las dos muestras se hubieran obtenido de la misma población. No entraremos en detalle. Lo importante, y lo que lo hace impopular en algunos ámbitos, es que en realidad no compara las proporciones poblacionales de éxito <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, sino sus <strong>odds</strong> y el intervalo de confianza que da es para el cociente de estas odds: es decir, para la <strong>odds ratio</strong>.</p>

<div class="rmdimportant">
En particular, si el estudio es de casos y controles con una muestra estratificada que no permita estimar riesgos, el test exacto de Fisher es el único test válido, ya que entonces no tiene sentido comparar las probabilidades del desenlace codicionadas a la exposición y la no exposición.
</div>
<p>Con JAMOVI se efectua marcando <em>Test exacto de Fisher</em> y <em>Razón de Odds</em> en <strong>Datos/Configuración</strong>, y el resto de casillas (y preparación) como para el test <span class="math inline">\(\chi^2\)</span>. Por ejemplo, para efectuarlo en la situación del Ejemplo <a href="qué-test-usar.html#exm:bronquitis">15.10</a> a partir del fichero de datos marcaríamos:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor es de nuevo menor que 0.001, por lo que obtenemos evidencia estadísticamente significativa de que <em>las odds, y por lo tanto el riesgo</em>
de tos crónica en la adolescencia aumenta en los adolescentes que tuvieron bronquitis infantil. La OR estimada de tos crónica relativa a la bronquitis infantil es de 2.4, con un IC 95% entre 1.45 y 3.97. Por lo tanto estimamos con un 95% de confianza las odds de tos crónica en la adolescencia son entre un 45% y un 297% mayores entre los que tuvieron bronquitis infantil. De nuevo, este IC es el del test bilateral, aunque hayamos efectuado un test unilateral.</p>
<p>Si queréis, o necesitáis, efectuar estos dos tests con <code>R</code>, por ejemplo para calcular el p-valor:</p>
<ul>
<li>El test <span class="math inline">\(\chi^2\)</span> también se hace con la función <code>prop.test</code>, ahora aplicada al vector con los números de éxitos y el vector con el tamaño de las muestras</li>
<li>El test exacto de Fisher se hace con la función <code>fisher.test</code> aplicada a la matriz con la tabla de contingencia.</li>
</ul>
<p>Observad la sintaxis para nuestro ejemplo en ambos casos en la figura siguiente:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor del test <span class="math inline">\(\chi^2\)</span> es 0.0004. El p-valor del test exacto de Fisher es 0.0008 y el IC 95% del contraste unilateral para la odds ratio va de 1.509 a <span class="math inline">\(\infty\)</span>, por lo que estimamos que las odds de tos crónica en la adolescencia si se ha tenido bronquitis en la infancia son al menos un 50.9% mayores que si no se ha tenido.</p>
</div>
</div>
<div id="tests-para-2-proporciones-con-muestras-emparejadas" class="section level4 hasAnchor" number="15.3.2.2">
<h4><span class="header-section-number">15.3.2.2</span> Tests para 2 proporciones con muestras emparejadas<a href="qué-test-usar.html#tests-para-2-proporciones-con-muestras-emparejadas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos ahora que tomamos las muestras emparejadas, ambas de tamaño <span class="math inline">\(n\)</span>. Para simplificar el lenguaje, supondremos que las dos muestras se obtienen midiendo las variables <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre los sujetos de una misma muestra aleatoria simple.</p>
<div id="test-de-mcnemar" class="section level5 unnumbered hasAnchor">
<h5>Test de McNemar<a href="qué-test-usar.html#test-de-mcnemar" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Si el contraste es <strong>bilateral</strong> y el número de <strong>casos discordantes</strong> (aquellos que son éxito para una variable y fracaso para la otra) es lo bastante grande (digamos que <span class="math inline">\(\geqslant 25\)</span>), el test recomendado es el <strong>test de McNemar</strong>. Si la tabla de contingencia es
<span class="math display">\[
\begin{array}{c}
\hphantom{Variable No}\quad\textbf{Variable $X_1$}\\
\begin{array}{ll|cc}
&amp; &amp; \quad \text{Sí}\quad &amp; \quad\text{No}\quad \\ \hline
\textbf{Variable} &amp; \text{Sí}  &amp; a &amp;     b \\
\textbf{$X_2$} &amp; \text{No} &amp; c &amp;     d
\end{array}
\end{array}
\]</span>
(y por lo tanto el número de casos discordantes, que ha de ser <span class="math inline">\(\geqslant 25\)</span>, es <span class="math inline">\(b+c\)</span>), este test usa que el estadístico
<span class="math display">\[
\frac{(b-c)^2}{b+c}
\]</span>
tiene una distribución aproximadamente <span class="math inline">\(\chi^2_1\)</span> si la hipótesis nula es cierta.</p>
<p>En JAMOVI lo encontramos en <strong>Frecuencias/Muestras apareadas: Prueba de McNemar</strong>.</p>
<div class="example">
<p><span id="exm:quimiopost" class="example"><strong>Ejemplo 15.11  </strong></span>Si en el tratamiento del cáncer de mama, a la quimioterapia perioperatoria y la mastectomía le añadimos quimioterapia postoperatoria durante 6 meses, ¿hay diferencia en la tasa de supervivencia a 5 años vista?</p>
</div>
<p>Para resolver esta cuestión, en un ensayo clínico se trató un grupo de 1244 pacientes, emparejadas según diferentes características. En cada pareja de pacientes se repartieron los dos tratamientos al azar: quimioterapia perioperatoria y mastectomía, o quimioterapia perioperatoria, mastectomía y quimioterapia postoperatoria durante 6 meses. Se anotó la supervivencia a los 5 años de las pacientes. Los datos obtenidos fueron:
<span class="math display">\[
\begin{array}{c}
\hphantom{postoperatoria No sobrevive}\qquad\textbf{No quimio postperatoria}\\
\begin{array}{ll|cc}
&amp; &amp; \quad\text{Sobrevive}\quad &amp; \quad\text{No sobrevive}\quad \\ \hline
\textbf{Sí quimio} &amp; \text{Sobrevive}  &amp; 510 &amp;     17 \\
\textbf{postoperatoria} &amp; \text{No sobrevive} &amp; 5 &amp;       90
\end{array}
\end{array}
\]</span></p>
<p>En este caso, las variables aleatorias de interés son:</p>
<ul>
<li><span class="math inline">\(X_1\)</span>: Que una paciente con cáncer de mama tratada con mastectomía y quimioterapia perioperatoria sobreviva 5 años, de probabilidad de éxito <span class="math inline">\(p_1\)</span></li>
<li><span class="math inline">\(X_2\)</span>: Que una paciente con cáncer de mama tratada con mastectomía, quimioterapia perioperatoria y quimioterapia postoperatoria sobreviva 5 años, de probabilidad de éxito <span class="math inline">\(p_2\)</span></li>
</ul>
<p>El contraste que nos interesa es si hay diferencia entre <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, no tenemos una hipótesis alternativa preconcebida sobre si un tratamiento es superior al otro:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2
\end{array}\right.
\]</span></p>
<p>El contraste es bilateral, tenemos dos muestras emparejadas y 22 casos discordantes (parejas de pacientes en las que una murió antes de los 5 años y la otra sobrevivió). En principio este número es algo justo para poder usar un test de McNemar, pero a falta de alternativa será el que emplearemos.</p>
<p>Entramos las frecuencias en una tabla de datos:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>A continuación, en la lista de “Niveles” de <strong>Datos/Configuración</strong> ponemos en cada variable el nivel correspondiente al Éxito (en nuestro caso, Sobrevive) encima del fracaso. Finalmente, vamos a <strong>Frecuencias/Muestras apareadas</strong>, entramos las variables, y marcamos <em>Test <span class="math inline">\(\chi^2\)</span> con corrección de continuidad</em> (recomendable sobre el <em>Test <span class="math inline">\(\chi^2\)</span></em> a secas).</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.7.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos un p-valor 0.019. Por lo tanto, con un nivel de significación del 5% concluimos que la probabilidad de supervivencia a 5 años bajo los dos tratamientos es diferente. Y entonces, como la supervivencia a 5 años ha sido más frecuente entre las que sí recibieron quimioterapia postoperatoria, concluímos que incluirla aumenta significativamente la probabilidad de supervivencia a 5 años.</p>
</div>
<div id="test-binomial-1" class="section level5 unnumbered hasAnchor">
<h5>Test binomial<a href="qué-test-usar.html#test-binomial-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Si no podéis usar el test de McNemar, siempre podéis usar un <strong>test binomial</strong> para efectuar un contraste de dos proporciones con dos muestras emparejadas. La idea es que si <span class="math inline">\(p_1=p_2\)</span>, las probabilidades poblacionales de los pares (Sí,No) y (No,Sí) entre los pares discordantes son la misma, ambas 0.5, mientras que si, por ejemplo, <span class="math inline">\(p_1&gt; p_2\)</span>, la probabilidad poblacional del par (Sí,No) entre los pares discordantes es mayor que la del par (No,Sí), y por lo tanto mayor que 0.5.
Entonces:</p>
<ul>
<li>tomamos la muestra solo de los casos discordantes, y</li>
<li>comparamos la probabilidad de (Sí,No) con 0.5 exactamente en el mismo sentido con el que comparábamos <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>.</li>
</ul>
<p>Fijaos que en este contraste solo nos interesará el p-valor, porque el intervalo de confianza va a ser para la proporción de los pares (Si,No) en la población de casos discordantes.</p>
<p>Imaginemos por ejemplo que ahora sí que nos preguntamos si añadir, en el tratamiento del cáncer de mama, quimioterapia postoperatoria durante 6 meses a la quimioterapia perioperatoria y la mastectomía aumenta la tasa de supervivencia a 5 años. Con las notaciones del ejemplo anterior, el contraste es ahora
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1&gt; p_2
\end{array}\right.
\]</span>
Como es un contraste unilateral, no podemos usar un test de McNemar, así que vamos a usar el test binomial. Entramos las frecuencias de los dos tipos de casos discordantes de nuestra muestra</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.8.1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>y efectuamos el test binomial correspondiente en <strong>Frecuencias/Prueba binomial</strong></p>
<p><img src="INREMDN_files/figure-html/JAMOVI.p.8.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos un p-valor 0.008. Por lo tanto, con un nivel de significación del 5% concluimos que la probabilidad de supervivencia a 5 años con quimioterapia postoperatoria es mayor que sin quimioterapia postoperatoria.</p>
</div>
</div>
</div>
<div id="contrastes-para-más-de-dos-proporciones" class="section level3 hasAnchor" number="15.3.3">
<h3><span class="header-section-number">15.3.3</span> Contrastes para más de dos proporciones<a href="qué-test-usar.html#contrastes-para-más-de-dos-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El contraste de igualdad o no de más dos o más proporciones es un caso particular de contraste de igualdad de dos o más distribuciones que estudiaremos en una próxima sección. Lo dejamos para entonces.</p>
</div>
</div>
<div id="contrastes-para-distribuciones" class="section level2 hasAnchor" number="15.4">
<h2><span class="header-section-number">15.4</span> Contrastes para distribuciones<a href="qué-test-usar.html#contrastes-para-distribuciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contrastes-de-bondad-de-ajuste-de-una-muestra-a-una-distribución" class="section level3 hasAnchor" number="15.4.1">
<h3><span class="header-section-number">15.4.1</span> Contrastes de bondad de ajuste de una muestra a una distribución<a href="qué-test-usar.html#contrastes-de-bondad-de-ajuste-de-una-muestra-a-una-distribución" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A menudo queremos contrastar si una muestra proviene o no de una distribución concreta. Por ejemplo:</p>
<ul>
<li><p>Lanzamos una moneda al aire varias veces, apuntamos los resultados, y de estos resultados queremos deducir si la moneda está equilibrada o trucada: es decir, si las caras siguen o no una distribución de Bernoulli con probabilidad de éxito 0.5.</p></li>
<li><p>Anotamos los casos diarios de ingresos por una enfermedad concreta en un hospital, y deseamos saber si se ajustan a una distribución de Poisson.</p></li>
<li><p>Hemos usado unas muestras pequeñas en un test t para comparar dos medias; para que nos podamos fiar del resultado del contraste, estas muestras tendrían que provenir de distribuciones aproximadamente normales.</p></li>
</ul>
<p>En todos estos casos, nos interesa un contraste cuya hipótesis nula es que la muestra sigue una cierta distribución: técnicamente, se dice que la muestra <strong>se ajusta</strong> a esa distribución. La hipótesis alternativa es que la muestra no sigue dicha distribución, es decir, que <strong>no se ajusta</strong> a la misma. Genéricamente, llamamos a este tipo de contrastes <strong>de bondad de ajuste</strong>.</p>
<p><span class="math display">\[
\left\{
\begin{array}{l}
H_0: \text{ la muestra se ajusta a una determinada distribución}\\
H_1: \text{ la muestra NO se ajusta a esa distribución}
\end{array}
\right.
\]</span></p>
<p>Como siempre, si obtenemos evidencia que nos permita rechazar la hipótesis nula, concluiremos que la muestra que la muestra no se ajusta a esa distribución la distribución que contrastamos. Esta evidencia se obtiene comparando de manera adecuada nuestra muestra con la “esperada” para la distribución que contrastamos: si son muy diferentes, lo tomamos como evidencia de que nuestra muestra no sigue dicha distribución, porque sería muy “rara” si la siguiera. Si nuestra muestra no es lo bastante diferente de la esperada como para hacernos dudar de que siga dicha distribución, no obtenemos evidencia que nos permita rechazar la hipótesis nula y aceptamos que la muestra se ajusta a la distribución que contrastamos.</p>
<div id="test-chi2-de-bondad-de-ajuste-para-distribuciones-discretas" class="section level4 hasAnchor" number="15.4.1.1">
<h4><span class="header-section-number">15.4.1.1</span> Test <span class="math inline">\(\chi^2\)</span> de bondad de ajuste para distribuciones discretas<a href="qué-test-usar.html#test-chi2-de-bondad-de-ajuste-para-distribuciones-discretas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El test más popular para contrastar si una muestra de una variable aleatoria cualitativa, ordinal o cuantitativa discreta se ajusta a una distribución dada es el <strong>test <span class="math inline">\(\chi^2\)</span> de Pearson</strong>. Este test compara las frecuencias de los posibles valores de la variable en la <em>muestra observada</em> con las esperadas en una muestra de la distribución contrastada del mismo tamaño mediante un estadístico que mide esta diferencia. Si el estadítsico toma un valor muy grande, es señal de que las <em>frecuencias observadas</em> son muy diferentes de las <em>frecuencias esperadas</em> y nos hace dudar de que la hipótesis nula sea verdadera.</p>
<p>Veamos un ejemplo que igual os es útil.</p>
<div class="example">
<p><span id="exm:loteria1" class="example"><strong>Ejemplo 15.12  </strong></span>La tabla que sigue muestra las frecuencias de aparición de las últimas cifras del Gordo de Navidad entre 1812 y 2023. En total, 213 sorteos contando la repetición de un sorteo durante la Guerra Civil.</p>
</div>
<p><span class="math display">\[
\begin{array}{l|cccccccccc}
\hline
\text{cifra} &amp; 0 &amp;  1 &amp;  2 &amp;  3 &amp;  4 &amp;  5 &amp;  6 &amp;  7 &amp;  8 &amp;  9 \\ \hline
\text{frecuencia} &amp; 23 &amp;  8 &amp; 13 &amp; 21 &amp; 26 &amp; 31 &amp; 27 &amp; 23 &amp; 25 &amp; 16 \\
\hline
\end{array}
\]</span>
Si estas últimas cifras tuvieran todas la misma probabilidad de salir, esta probabilidad sería 1/10. Entonces, esperaríamos de media unas 213/10=21.3 ocurrencias de cada cifra. El diagrama de barras inferior muestra que hay algunas desviaciones notables respecto de esta media, marcada con la línea roja discontinua. Las diferencias que observamos respecto de los valores esperados, ¿son los bastante grandes como para hacernos dudar de que todas las cifras salgan con la misma probabilidad, sin ningún tipo de sesgo? O, por el contrario, ¿son razonables dentro de lo que se puede achacar al azar?</p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-596-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Este ejemplo ilustra la situación general siguiente:</p>
<ul>
<li><p>Tenemos una muestra aleatoria simple de <em>n</em> observaciones que queremos contrastar si se ajusta o no a una <strong>distribución totalmente determinada</strong>. El contraste que queremos realizar es
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}: \mbox{ La muestra se ajusta a esta distribución}\\
H_{1}: \mbox{ La población no se ajusta a esta distribución}
\end{array}
\right.
\]</span></p>
<p>En el ejemplo anterior, queremos contrastar si las últimas cifras del Gordo se ajustan a una <strong>distribución uniforme</strong>: si todas tienen la misma probabilidad.</p></li>
<li><p>Agrupamos todos los elementos del dominio de la distribución teórica que contrastamos en un número finito <em>k</em> de <strong>clases</strong> que denotaremos por <span class="math inline">\(C_1,\ldots,C_k\)</span>. Cada clase puede corresponder a un solo elemento del dominio o a más de uno, pero todo elemento del dominio ha de pertenecer a una, y solo una, clase. Queremos recalcar que el número de clases ha de ser finito.</p>
<p>En nuestro ejemplo, hemos tomado 10 clases, una para cada elemento del dominio: la clase formada solo por el 0, la clase formada solo por el 1, etc.</p>
<p>El hecho de que la distribución que queremos contrastar esté totalmente determinada nos ha de permitir calcular la probabilidad de cada clase.</p></li>
<li><p>Para cada clase <span class="math inline">\(C_i\)</span>, sean</p>
<ul>
<li><p><span class="math inline">\(obs_i\)</span>: la frecuencia absoluta <em>observada</em> de esta clase en la muestra.</p>
<p>En nuestro ejemplo, son las frecuencias de cada última cifra que hemos dado en la tabla.</p></li>
<li><p><span class="math inline">\(p_i\)</span>: la probabilidad <em>teórica</em> de esta clase para la distribución de probabilidades que estamos contrastando.</p>
<p>En nuestro ejemplo, cada <span class="math inline">\(p_i\)</span> vale 1/10.</p></li>
<li><p><span class="math inline">\(esp_i\)</span>: la frecuencia absoluta <em>esperada</em> de esta clase si se hubiera obtenido con la distribución que estamos contrastando: <span class="math inline">\(esp_i=p_i\cdot n\)</span>.</p>
<p>En nuestro ejemplo, cada <span class="math inline">\(esp_i\)</span> vale 21.3.</p></li>
</ul></li>
<li><p>Se calcula entonces el estadístico de contraste
<span class="math display">\[
\chi^2=\sum_{i=1}^k \frac{(obs_{i}-esp_{i})^2}{esp_{i}}
\]</span></p>
<p>Fijaos en que <span class="math inline">\(\chi^2\)</span> mide, de una manera concreta, la diferencia entre las <span class="math inline">\(obs_i\)</span> y las <span class="math inline">\(esp_i\)</span>.</p></li>
</ul>
<p>Lo que necesitamos ahora es saber a partir de qué valor esta <span class="math inline">\(\chi^2\)</span> es tan grande que sería muy improbable si la muestra proviniera de la distribución contrastada, lo que nos permitiría concluir que es inverosímil que provenga de dicha distribución.</p>
<div class="theorem">
<p><span id="thm:unnamed-chunk-597" class="theorem"><strong>Teorema 15.1  </strong></span>Si</p>
<ul>
<li><p><span class="math inline">\(n\)</span> es grande (digamos que <span class="math inline">\(n\geqslant 30\)</span>)</p></li>
<li><p>Las <span class="math inline">\(k\)</span> clases elegidas forman una partición del dominio: <span class="math inline">\(p_1+\cdots+p_k=n\)</span></p></li>
<li><p>Las clases cumplen la <strong>regla de Cochran</strong>: <span class="math inline">\(esp_i\geqslant 5\)</span> para todo <span class="math inline">\(i=1,\ldots,k\)</span></p></li>
</ul>
<p>entonces el estadístico <span class="math inline">\(\chi^2\)</span> tiene distribución aproximadamente <span class="math inline">\(\chi_{k-1}^2\)</span> (<span class="math inline">\(\chi^2\)</span> con número de grados de libertad <strong>el número de clases menos 1</strong>).</p>
</div>
<p>Por lo tanto, si llamamos <span class="math inline">\(\chi_0\)</span> a lo que ha valido <span class="math inline">\(\chi^2\)</span> en nuestra muestra, el <strong>p-valor</strong> del contraste, que nos permite decidir si aceptamos o rechazamos la hipótesis nula de que la muestra proviene de la distribución contrastada, es
<span class="math display">\[
P(\chi_{k-1}^2\geqslant \chi_0).
\]</span></p>
<p>Siguiendo con nuestro ejemplo del Gordo de Navidad, si calculamos el valor de <span class="math inline">\(\chi^2\)</span>, da
<span class="math display">\[
\frac{(23-21.3)^2}{21.3}+\frac{(8-21.3)^2}{21.3}+\frac{(13-21.3)^2}{21.3}+\cdots+\frac{(16-21.3)^2}{21.3}=20.756
\]</span>
Como <span class="math inline">\(k=10\)</span>, el p-valor será <span class="math inline">\(P(\chi_9^2\geqslant 20.756)=0.014\)</span>.</p>
<p><img src="INREMDN_files/figure-html/estorat.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Naturalmente, puede ser un error de tipo I. Pero por si acaso, no juguéis a números que terminen en 1 o 2…</p>
<p>En JAMOVI, este test <span class="math inline">\(\chi^2\)</span> se encuentra disponible en la pestaña <strong>Recuento/N Resultados (<span class="math inline">\(\chi^2\)</span> de bondad de ajuste)</strong>. Se puede aplicar directamente a una muestra o a las frecuencias observadas.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-599" class="example"><strong>Ejemplo 15.13  </strong></span>Seguimos con el ejemplo de las terminaciones de los Gordos de Navidad. Tenemos estas terminaciones en la variable <em>ultimacifra</em> de la tabla de datos <em>loteria.csv</em>. Si, tras cargar la tabla de datos, en <strong>Recuento/N Resultados (<span class="math inline">\(\chi^2\)</span> de bondad de ajuste)</strong> elegimos esta variable, por defecto realiza el contraste de bondad de ajuste a la distribución uniforme, en la que todos los resultados presentes en dicha variable tienen la misma probabilidad y que es el que queremos efectuar en este ejemplo.</p>
</div>
<p>Hemos marcado además la casilla de “Frecuencias esperadas” para que nos dé las frecuencias esperadas de cada clase y así comprobar que se satisface la regla de Cochran:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos al final el valor del estadístico <span class="math inline">\(\chi^2\)</span>, el número <em>gl</em> de grados de libertad que ha usado para calcular el p-valor, y el valor <em>p</em> de este último.</p>
<p>Supongamos ahora que no disponemos de los datos originales, sino solo de las frecuencias observadas de las clases. Entonces, primero tenemos que definir una variable con las diferentes clases (en nuestro ejemplo las cifras de 0 a 9) y una variable con sus frecuencias observadas.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>A continuación, en <strong>Recuento/N Resultados (<span class="math inline">\(\chi^2\)</span> de bondad de ajuste)</strong> elegimos como “Variable” la que especifica las clases y como “Frecuencias (opcional)” la columna con las frecuencias:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El resultado es el mismo que antes.</p>
<p>En ambos casos, si en vez de contrastar si todas las últimas cifras aparecen con la misma probabilidad quisiéramos contrastar alguna otra hipótesis sobre los valores de estas probabilidades, las especificaríamos en la columna “Razón” de la tabla de “Proporciones esperadas”.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-600" class="example"><strong>Ejemplo 15.14  </strong></span>La distribución por edades de la población española es la siguiente:</p>
</div>
<p><span class="math display">\[
\begin{array}{c|ccccccccc}
\text{edad} &amp; 0\!-\!9 &amp; 10\!-\!19 &amp; 20\!-\!29 &amp; 30\!-\!39 &amp; 40\!-\!49 &amp; 50\!-\!59 &amp; 60\!-\!69 &amp; 70\!-\!79 &amp; 80\text{ o más}\\\hline
\text{%} &amp; 9.3 &amp; 10&amp; 10&amp;13.2&amp; 17&amp; 14.9&amp; 11&amp; 8.4&amp; 6.2
\end{array}
\]</span></p>
<p>En una muestra de 65 españoles diagnosticados de COVID-19 durante la primera ola pandémica, se obtuvieron las frecuencias de edades siguientes:
<span class="math display">\[
\begin{array}{c|ccccccccc}
\text{edad} &amp; 0\!-\!9 &amp; 10\!-\!19 &amp; 20\!-\!29 &amp; 30\!-\!39 &amp; 40\!-\!49 &amp; 50\!-\!59 &amp; 60\!-\!69 &amp; 70\!-\!79 &amp; 80\text{ o más}\\\hline
\text{frecuencia} &amp; 1 &amp; 1&amp; 5&amp;8&amp; 11&amp; 10&amp; 11&amp; 11&amp; 7
\end{array}
\]</span></p>
<p>Nos preguntamos si esta muestra aporta evidencia de que la distribución por edades de los españoles con COVID-19 durante la primera ola es diferente a la de la población española en general y por lo tanto de que la COVID-19 afectó de manera diferente unas franjas de edad que otras. Es un ejemplo típico de contraste de bondad de ajuste. La hipótesis nula del contraste es que nuestra muestra de edades se ajusta a la distribución de probabilidad dada por la distribución por edades de la población española, y la hipótesis alternativa es que esto no es verdad.</p>
<p>Tomamos como clases las 9 franjas de edad dadas. Sus probabilidades teóricas <span class="math inline">\(p_i\)</span> son las definidas por la población española, y sus frecuencias esperadas <span class="math inline">\(esp_i\)</span> serán las probabilidades teóricas multiplicadas por el tamaño de la muestra, 65.</p>
<p><span class="math display">\[
\begin{array}{c|ccccccccc}
C_i &amp; 0\!-\!9 &amp; 10\!-\!19 &amp; 20\!-\!29 &amp; 30\!-\!39 &amp; 40\!-\!49 &amp; 50\!-\!59 &amp; 60\!-\!69 &amp; 70\!-\!79 &amp; 80\text{ o más}\\\hline
obs_i &amp; 1 &amp; 1&amp; 5&amp;8&amp; 11&amp; 10&amp; 11&amp; 11&amp; 7\\
p_i &amp; 0.093 &amp; 0.100&amp; 0.100&amp; 0.132&amp; 0.170&amp; 0.149&amp; 0.110&amp; 0.084&amp; 0.062\\
esp_i &amp; 6.045 &amp;  6.500 &amp;  6.500  &amp; 8.580 &amp; 11.050 &amp;  9.685  &amp; 7.150  &amp; 5.460  &amp; 4.030
\end{array}
\]</span></p>
<p>El estadístico de contraste vale
<span class="math display">\[
\chi^2=\frac{(1-6.045)^2}{6.045}+\frac{(1-6.5)^2}{6.5}+\cdots+\frac{(7-4.03)^2}{4.03}=19.14
\]</span>
y el p-valor vale <span class="math inline">\(P(\chi_8^2\geqslant 19.14)=0.014\)</span>. En JAMOVI se hace como antes, solo que ahora en la columna “Razón” de la tabla de “Proporciones esperadas” entramos las probabilidades teóricas.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.MC1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Con un p-valor de 0.014, tenemos evidencia estadística de que la distribución por edades de los españoles con COVID-19 durante la primera ola fue diferente de la de la población española en general.</p>
<p>¿Seguro?</p>

<div class="rmderror">
<strong>¿Y la regla de Cochran?</strong>
</div>
<p>En este ejemplo no podemos usar tal cual el test <span class="math inline">\(\chi^2\)</span>, porque no se cumplen las condiciones teóricas que nos garantizan que sus conclusiones sean significativas: tenemos una clase con frecuencia esperada &lt;5. Por lo tanto, lo que hemos hecho no es correcto y no nos podemos fiar de la conclusión. ¿Qué podemos hacer en este caso?</p>
<p>Una opción es unir clases: si unimos las dos últimas clases en una única clase “70 o más” su frecuencia esperada será la suma de las frecuencias esperadas de las clases agrupadas, 9.49, y habremos solventado el problema. Os dejamos como ejercicio que terminéis el cálculo de esta manera.</p>
<p>Otra opción, si queréis mantener como clases las definidas al principio, es usar la versión <strong>MonteCarlo</strong> del test <span class="math inline">\(\chi^2\)</span>, basada en simulaciones. Este test consiste en:</p>
<ol style="list-style-type: decimal">
<li><p>Se genera un conjunto muy grande de muestras aleatorias simples (nosotros tomaremos 5000) con la distribución contrastada, todas del mismo tamaño que nuestra muestra.</p></li>
<li><p>Se calcula el estadístico de contraste <span class="math inline">\(\chi^2\)</span> para cada muestra.</p></li>
<li><p>Se estima el p-valor como la fracción de muestras que han dado un valor de <span class="math inline">\(\chi^2\)</span> mayor que el de nuestra muestra.</p></li>
</ol>
<p>JAMOVI no tiene implementado por ahora este test MonteCarlo, y es una pena porque es el que os recomendamos usar. Se puede efectuar con las funciones adecuadas en su ventana del editor de <code>R</code>:</p>
<ul>
<li>Definimos un vector <code>Obs</code> con las frecuencias observadas:</li>
</ul>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="qué-test-usar.html#cb76-1" tabindex="-1"></a>Obs<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">7</span>)</span></code></pre></div>
<ul>
<li>Definimos un vector <code>Probs</code> con las probabilidades teóricas</li>
</ul>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="qué-test-usar.html#cb77-1" tabindex="-1"></a>Probs<span class="ot">=</span><span class="fu">c</span>(<span class="fl">0.093</span>, <span class="fl">0.100</span>, <span class="fl">0.100</span>, <span class="fl">0.132</span>, <span class="fl">0.170</span>, <span class="fl">0.149</span>, <span class="fl">0.110</span>, <span class="fl">0.084</span>, <span class="fl">0.062</span>)</span></code></pre></div>
<ul>
<li>Ejecutamos la función siguiente (donde el valor de <code>B</code> es el número de simulaciones que queremos)</li>
</ul>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="qué-test-usar.html#cb78-1" tabindex="-1"></a><span class="fu">chisq.test</span>(Obs, <span class="at">p=</span>Probs, <span class="at">simulate.p.value=</span><span class="cn">TRUE</span>, <span class="at">B=</span><span class="dv">5000</span>)</span></code></pre></div>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.MC2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Obtenemos el p-valor (<code>p-value</code>) 0.01. Esto significa que <em>solo un 1% de las muestras de 65 personas cuyas edades siguen la distribución española en general, han dado un valor de <span class="math inline">\(\chi^2\)</span> mayor que el de nuestra muestra original</em>. Esto nos tiene que hacer concluir que nuestra muestra sería muy rara si se hubiera obtenido con la distribución de franjas de edad española en general. Así que, ahora sí de manera fiable, hemos obtenido evidencia estadística de que la distribución por edades de los españoles con COVID-19 durante la primera ola fue diferente a la de la población española en general.</p>

<div class="rmdnote">
El test de MonteCarlo se basa en simulaciones aleatorias, por lo que ejecuciones diferentes con los mismos datos pueden dar p-valores diferentes. Pero si el número de simulaciones es lo bastante grande, es muy robusto y las conclusiones no difieren.
</div>
<p>Veamos ahora un ejemplo detallado de la aplicación de un test <span class="math inline">\(\chi^2\)</span> a un contraste de bondad de ajuste a una familia de distribuciones, no a una distribución completamente determinada.</p>
<div class="example">
<p><span id="exm:GoFPoisson" class="example"><strong>Ejemplo 15.15  </strong></span>Si la concepción fuera un acontecimiento aleatorio en mujeres en edad fértil, los números de hijos de mujeres en edad fértil seguirían una distribución de Poisson. La tabla siguiente da los números de hijos de 125 mujeres entre 20 y 45 años (elegidas al azar entre las pacientes del servicio de ginecología de un hospital concreto).</p>
</div>
<p><span class="math display">\[
\begin{array}{l|ccccccc}
\hline
\text{hijos} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; \geqslant 6 \\ \hline
\text{frecuencia} &amp; 59 &amp; 44 &amp; 14 &amp; 3 &amp; 4 &amp;1 &amp; 0\\
\hline
\end{array}
\]</span></p>
<p>Queremos contrastar si podemos aceptar que estos números de hijos provienen de una distribución de Poisson. Es decir, queremos realizar el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}: \mbox{La muestra se ajusta a una distribución de Poisson}\\
H_{1}: \mbox{La muestra no se ajusta a una distribución de Poisson}
\end{array}
\right.
\]</span>
Fijaos antes de empezar en que <em>no</em> estamos en la situación general para poder efectuar un test <span class="math inline">\(\chi^2\)</span>: “una distribución de Poisson” no es una distribución completamente determinada, para la que podamos calcular probabilidades. Necesitamos saber su <span class="math inline">\(\lambda\)</span> para poder calcular probabilidades.</p>
<p>Como <span class="math inline">\(\lambda\)</span> es la esperanza de la variable aleatoria, la podemos estimar con la media muestral de nuestra muestra:
<span class="math display">\[
\lambda=
\frac{59\cdot 0+ 44\cdot 1+  14\cdot 2+ 3\cdot 3+ 4\cdot 4+1\cdot 5}{125}=0.816
\]</span></p>
<p>Pero <strong>¡ATENCIÓN!</strong> Cuando hay que estimar algún parámetro de la distribución con la muestra, se tiene que tener en cuenta la regla siguiente:</p>

<div class="rmdimportant">
<p>Si para determinar completamente la distribución hemos tenido que estimar algún parámetro (<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\lambda\)</span>, …) con nuestra muestra, para calcular el p-valor <em>se ha de restar a los grados de libertad el número de parámetros estimados</em>. Es decir, si se han estimado <span class="math inline">\(m\)</span> parámetros, el p-valor es
<span class="math display">\[
P(\chi_{k-1-m}^2\geqslant \chi_0).
\]</span></p>
</div>
<p>Tendremos que recordarlo al final, en el momento de calcular el p-valor. Por ahora seguimos con el proceso.</p>
<ul>
<li>Hay que partir el dominio de la distribución teórica en un número finito de clases. El dominio de una variable de Poisson en todo el conjunto de los números naturales, por lo que no podremos usar como clases sus elementos uno a uno. Lo que haremos por ahora será tomar las clases que nos dan en la tabla de frecuencias. Es decir, tomamos como clases <span class="math inline">\(C_1=\{0\}\)</span>, <span class="math inline">\(C_2=\{1\}\)</span>, <span class="math inline">\(C_3=\{2\}\)</span>, <span class="math inline">\(C_4=\{3\}\)</span>, <span class="math inline">\(C_5=\{4\}\)</span>, <span class="math inline">\(C_6=\{5\}\)</span> y <span class="math inline">\(C_7=\{6,7,8,\ldots\}\)</span>.
<span class="math display">\[
\begin{array}{l|ccccccc}
\hline
C_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp;  \geqslant 6 \\ \hline
obs_i &amp; 59 &amp; 44 &amp; 14 &amp; 3 &amp; 4 &amp;1 &amp; 0 \\
\hline
\end{array}
\]</span></li>
</ul>

<div class="rmdimportant">
Las clases han de cubrir todo el dominio de la distribución teórica que contrastamos, no solo los valores de la muestra. Si el dominio es todo <span class="math inline">\(\mathbb{N}\)</span>, las clases tienen que cubrir todo <span class="math inline">\(\mathbb{N}\)</span>.
</div>
<ul>
<li>Calculamos la probabilidad <span class="math inline">\(p_i\)</span> de cada clase para una variable <span class="math inline">\(X\)</span> con distribución de Poisson con <span class="math inline">\(\lambda=0.816\)</span> y su frecuencia esperada <span class="math inline">\(esp_i=p_i\cdot 125\)</span>:
<span class="math display">\[
\begin{array}{l|cccccc}
\hline
C_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; \geqslant 6 \\ \hline
obs_i &amp; 59 &amp; 44 &amp; 14 &amp; 3 &amp; 4 &amp;1 &amp; 0 \\\hline
p_i &amp; 0.442 &amp; 0.361 &amp; 0.147 &amp; 0.040 &amp; 0.008 &amp; 0.001 &amp; 0.001\\
\hline
esp_i&amp; 55.250 &amp; 45.125 &amp; 18.375  &amp; 5.000  &amp; 1.000   &amp;0.125 &amp;  0.125\\
\hline
\end{array}
\]</span></li>
</ul>
<p>Nuestra muestra es de tamaño mayor que 30 y las clases cubren todo el dominio de la variable teórica con la que comparamos nuestra muestra. Pero hay clases con frecuencia esperada menor que 5, por lo que tal cual no podemos usar el test <span class="math inline">\(\chi^2\)</span>.</p>
<p>Cuando hemos tenido que estimar parámetros, como en este ejemplo, no es adecuado usar la versión MonteCarlo del test <span class="math inline">\(\chi^2\)</span>, porque la conclusión sería sobre si la muestra se ajusta o no a la distribución de Poisson concreta usada en las simulaciones, no sobre si se ajusta o no a <em>una</em> distribución de Poisson.</p>
<p>Lo adecuado entonces es agrupar el mínimo número de clases consecutivas para conseguir que todas las frecuencias esperadas sean <span class="math inline">\(\geqslant 5\)</span>. En nuestro caso, agruparemos las clases <span class="math inline">\(C_4=\{3\}\)</span>, <span class="math inline">\(C_5=\{4\}\)</span>, <span class="math inline">\(C_6=\{5\}\)</span> y <span class="math inline">\(C_7=\{6,7,8,\ldots\}\)</span> en una sola.
<span class="math display">\[
\begin{array}{l|cccc}
\hline
C_i &amp; 0 &amp; 1 &amp; 2 &amp;  \geqslant 3  \\ \hline
obs_i &amp; 59 &amp; 44 &amp; 14 &amp; 8 &amp;  \\\hline
p_i &amp; 0.442 &amp; 0.361 &amp; 0.147 &amp; 0.05\\
\hline
esp_i&amp; 55.250 &amp; 45.125 &amp; 18.375  &amp; 6.250 \\
\hline
\end{array}
\]</span>
Ya estamos en las condiciones de efectuar el test <span class="math inline">\(\chi^2\)</span>: entramos en JAMOVI una variable con los valores 0, 1, 2, 3 (este último representará toda la clase <span class="math inline">\(\geqslant 3\)</span>), una variable con sus frecuencias observadas 59, 44, 14, 8, y en “Proporciones esperadas” de
<strong>Recuento/N Resultados (<span class="math inline">\(\chi^2\)</span> de bondad de ajuste)</strong> entramos las probabilidades teóricas:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor 0.612 indica que podemos aceptar que los números de hijos se ajustan a una distribución de Poisson.</p>

<div class="rmderrorpetit">
<strong>¡No!</strong> Para calcular el p-valor, hay que restar el número de parámetros estimados al número de grados de libertad.
</div>
<p><img src="INREMDN_files/figure-html/batman.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Como <code>R</code> no sabe que hemos estimado la <span class="math inline">\(\lambda\)</span> con nuestra muestra, ha usado 3 grados de libertad (<em>gl</em> en la tabla inferior), pero en realidad el p-valor ha de ser <span class="math inline">\(P(\chi^2_2\geqslant 1.81)\)</span>. Tenemos que calcularlo nosotros al final.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2.5.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El p-valor correcto es 0.405. Por lo tanto, ahora sí, podemos aceptar que nuestra muestra de números de hijos sigue una distribución de Poisson.</p>
</div>
<div id="contrastes-de-normalidad" class="section level4 hasAnchor" number="15.4.1.2">
<h4><span class="header-section-number">15.4.1.2</span> Contrastes de normalidad<a href="qué-test-usar.html#contrastes-de-normalidad" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Que una o varias muestras provengan de una distribución normal es una hipótesis en muchos teoremas. Por ejemplo, para efectuar un test t con muestras pequeñas, es necesario que las poblacionales sean normales, o lo que es lo mismo, que las muestras provengan de variables normales. En realidad, lo que miramos en estos casos es si cada muestra se ajusta a una variable normal. Si lo podemos rechazar, entonces podemos rechazar que provenga de una variable con distribución normal. Si no lo podemos rechazar, entonces no podemos rechazar que provenga de una variable con distribución normal y aceptamos que lo cumple.</p>
<p>Hay muchos tests de normalidad diferentes. Ya hemos cómo efectuar algunos en un Inciso en la sección de contrastes de una media, así que no lo repetiremos aquí, aunque convendría que, ahora que tenéis una nueva luz sobre contrastes de bondad de ajuste, revisitarais ese Inciso.</p>
</div>
</div>
<div id="contrastes-de-igualdad-de-dos-o-más-distribuciones" class="section level3 hasAnchor" number="15.4.2">
<h3><span class="header-section-number">15.4.2</span> Contrastes de igualdad de dos o más distribuciones<a href="qué-test-usar.html#contrastes-de-igualdad-de-dos-o-más-distribuciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que tenemos <span class="math inline">\(m\)</span> variables aleatorias <span class="math inline">\(X_1,\ldots,X_m\)</span>, todas ellas con el mismo dominio finito <span class="math inline">\(\{x_1,\ldots,x_k\}\)</span>. Usualmente, se tratará de la restricción de una variable aleatoria <span class="math inline">\(X\)</span> a diferentes subpoblaciones de la población en la que está definida.</p>
<p>Queremos contrastar si es verdad o no que todas estas variables aleatorias tienen la misma distribución de probabilidad. Es decir, si se cumple que
<span class="math display">\[
P(X_i=x_l)=P(X_j=x_l)\text{ para todos $i,j=1,\ldots,m$ y $l=1,\ldots,k$}
\]</span>
o si, por el contrario, al menos dos variables <span class="math inline">\(X_{i_0}\)</span> y <span class="math inline">\(X_{j_0}\)</span> tienen diferentes probabilidades de tomar algún mismo valor.</p>
<p>Por lo tanto, el contraste que nos interesa es
<span class="math display">\[
\left\{\begin{array}{l}
H_0:\text{ $X_1,\ldots,X_m$ tienen todas la misma distribución de probabilidad}\\
H_1:\text{ No es verdad que $X_1,\ldots,X_m$ tengan todas la misma distribución de probabilidad}
\end{array}\right.
\]</span></p>
<p>Un caso particular de este contraste es el de <strong>igualdad de varias proporciones</strong>: si <span class="math inline">\(X_1,\ldots,X_m\)</span> son de Bernoulli, contrastar si tienen o no la misma distribución es exactamente lo mismo que contrastar si tienen o no la misma probabilidad de éxito.</p>
<p>Otro caso particular son los <strong>contrastes de independencia</strong> en los que tenemos dos variables aleatorias con dominio finito, llamémoslas <span class="math inline">\(A\)</span> con dominio <span class="math inline">\(\{a_1,\ldots,a_m\}\)</span> y <span class="math inline">\(B\)</span> con dominio <span class="math inline">\(\{b_1,\ldots,b_k\}\)</span>, y nos preguntamos si son independientes o no: es decir, si
es verdad que para todos <span class="math inline">\(i,j=1,\ldots,m\)</span> y <span class="math inline">\(l=1,\ldots,k\)</span>
<span class="math display">\[
P(B=b_l|A=a_i)=P(B=b_l|A=a_j)
\]</span></p>
<p>Si llamamos <span class="math inline">\(B_i\)</span> a la variable <span class="math inline">\(B\)</span> restringida a los sujetos de la población en los que <span class="math inline">\(A\)</span> vale <span class="math inline">\(a_i\)</span>, tenemos que la independencia de <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> es equivalente a que las variables <span class="math inline">\(B_1,\ldots,B_m\)</span> tengan todas la misma distribución.</p>
<p>Volvamos a la situación inicial: <span class="math inline">\(m\)</span> variables aleatorias <span class="math inline">\(X_1,\ldots,X_m\)</span> con dominio <span class="math inline">\(\{x_1,\ldots,x_k\}\)</span>. Para contrastar la igualdad de sus distribuciones, tomamos una muestra aleatoria simple de cada una de ellas, independientes las unas de las otras. Estas muestras se pueden tomar de manera estratificada, escogiendo una muestra de tamaño prefijado de cada una, o de manera transversal, si se trataba de la misma variable definida sobre diferentes subpoblaciones y hemos elegido una muestra transversal de la población global.</p>
<p>Sea como sea, obtendremos una tabla de frecuencias como la siguiente:
<span class="math display">\[
\begin{array}{c|cccc}
&amp; X_1 &amp; X_2 &amp; \ldots &amp; X_m\\ \hline
x_1 &amp; n_{1,1} &amp; n_{1,2} &amp; \ldots &amp; n_{1,m}\\
x_2 &amp; n_{2,1} &amp; n_{2,2} &amp; \ldots &amp; n_{2,m}\\
\vdots &amp; \vdots &amp;\vdots &amp;\ddots &amp; \vdots \\
x_k &amp; n_{k,1} &amp; n_{k,2} &amp; \ldots &amp; n_{k,m}\\
\end{array}
\]</span></p>
<div class="example">
<p><span id="exm:unnamed-chunk-610" class="example"><strong>Ejemplo 15.16  </strong></span>Queremos contrastar si el tipo de parto de una gestante que haya tenido COVID-19 durante el embarazo depende de la sintomatología de la enfermedad. Para ello, hemos tomado una muestra de 1000 gestantes españolas que dieron positivo en COVID-19 durante su embarazo y hemos anotado el nivel de gravedad de la infección (clasificado en asintomático, leve o grave) y el tipo de parto que tuvieron (eutócico, instrumental, cesárea programada o cesárea urgente). Hemos obtenido la tabla de frecuencias siguiente:</p>
</div>
<p><span class="math display">\[
\begin{array}{c}
\qquad\qquad\qquad\qquad\qquad\qquad      \textbf{Síntomas}\\[-2ex]
\begin{array}{lr|ccc|c}
&amp; &amp; \text{Asintomática} &amp; \text{Leve} &amp; \text{Grave} &amp; \text{Total}\\ \hline
&amp;  \text{Eutócico}       &amp;             305 &amp;  234   &amp;  95 &amp; 634\\
\textbf{Tipo de} &amp;  \text{Instrumental} &amp;                  48 &amp;  46 &amp;   13 &amp; 107\\
\textbf{parto} &amp;  \text{Cesárea programada} &amp;           28 &amp;  43  &amp;  30 &amp; 101\\
&amp; \text{Cesárea urgente}    &amp;         72  &amp; 58 &amp;   28 &amp; 158\\ \hline
&amp; \text{Total} &amp; 453   &amp;       381   &amp;       166 &amp; 1000
\end{array}
\end{array}
\]</span></p>
<p>En este ejemplo, queremos contrastar si las variables aleatorias</p>
<ul>
<li><p><span class="math inline">\(X_a\)</span>: Tomamos una gestante que tuvo COVID-19 asintomático durante el embarazo y anotamos su tipo de parto</p></li>
<li><p><span class="math inline">\(X_l\)</span> y <span class="math inline">\(X_g\)</span>: Lo mismo, para COVID-19 leve y grave, respectivamente</p></li>
</ul>
<p>tienen la misma distribución de probabilidad:</p>
<p><span class="math display">\[
\left\{
\begin{array}{l}
H_0: \text{ $X_a$, $X_l$ y $X_g$ tienen la misma distribución de probabilidad}\\
H_0: \text{ No es verdad que $X_a$, $X_l$ y $X_g$ tengan la misma distribución de probabilidad}
\end{array}
\right.
\]</span></p>
<p>En este ejemplo, la muestra aleatoria de cada variable proviene de una muestra transversal de gestantes con COVID-19, asignando cada gestante a su grupo sintomático y anotando su tipo de parto.</p>
<p>Volvamos a la situación general. Para cada <span class="math inline">\(i=1,\ldots,m\)</span>, sea <span class="math inline">\(n_{\bullet,i}\)</span> la suma de la columna <span class="math inline">\(i\)</span>-ésima de la tabla de frecuencias, es decir, el tamaño de la muestra de la variable <span class="math inline">\(X_i\)</span>, y para cada <span class="math inline">\(l=1,\ldots,k\)</span> sea <span class="math inline">\(n_{l,\bullet}\)</span> la suma de la fila <span class="math inline">\(l\)</span>-ésima de la tabla de frecuencias, es decir, el número total de apariciones de <span class="math inline">\(x_l\)</span> en la muestra global. Finalmente, sea <span class="math inline">\(n\)</span> el tamaño de la muestra total.</p>
<p><span class="math display">\[
\begin{array}{c|cccc|c}
&amp; X_1 &amp; X_2 &amp; \ldots &amp; X_m &amp; \text{Total}\\ \hline
x_1 &amp; n_{1,1} &amp; n_{1,2} &amp; \ldots &amp; n_{1,m} &amp; n_{1,\bullet}\\
x_2 &amp; n_{2,1} &amp; n_{2,2} &amp; \ldots &amp; n_{2,m}&amp; n_{2,\bullet}\\
\vdots &amp; \vdots &amp;\vdots &amp;\ddots &amp; \vdots &amp; \vdots \\
x_k &amp; n_{k,1} &amp; n_{k,2} &amp; \ldots &amp; n_{k,m} &amp; n_{k,\bullet}\\\hline
\text{Total} &amp; n_{\bullet,1} &amp;  n_{\bullet,2} &amp;\ldots &amp;  n_{\bullet,m} &amp; n
\end{array}
\]</span></p>
<p>Resulta que el contraste de igualdad de varias distribuciones se puede efectuar como contraste de bondad de ajuste. La manera más sencilla de entenderlo es suponer que, como en nuestro ejemplo, las variables <span class="math inline">\(X_1,\ldots,X_m\)</span> que comparamos son la restricción de una cierta variable aleatoria <span class="math inline">\(X\)</span> a diferentes poblaciones que forman una partición de la población donde <span class="math inline">\(X\)</span> está definida. Es el caso de nuestro ejemplo, donde esta variable <span class="math inline">\(X\)</span> es la que toma una embarazada con COVID-19 y anota su tipo de parto, y las variables <span class="math inline">\(X_a,X_l,X_g\)</span> se obtienen partiendo el conjunto de embarazadas en tres grupos sintomáticos y restringiendo la <span class="math inline">\(X\)</span> a cada uno de ellos.</p>
<p>En este caso, que las variables <span class="math inline">\(X_1,\ldots,X_m\)</span> tengan todas exactamente la misma distribución de probabilidad es equivalente a que todas tengan la misma distribución de probabilidad que <span class="math inline">\(X\)</span>. En efecto, para cada <span class="math inline">\(l=1,\ldots,k\)</span>, si
<span class="math display">\[
P(X_1=x_l)=P(X_2=x_l)=\cdots=P(X_m=x_l)
\]</span>
entonces
<span class="math display">\[
P(X_1=x_l)=P(X_2=x_l)=\cdots=P(X_m=x_l)=P(X=x_l)
\]</span></p>
<p>Si la hipótesis nula es cierta, podemos estimar <span class="math inline">\(P(X=x_l)\)</span> a partir de la muestra global como <span class="math inline">\(n_{l,\bullet}/n\)</span>. Por lo tanto, si la hipótesis nula fuera cierta, para cada <span class="math inline">\(i=1,\ldots,m\)</span>, la frecuencia esperada del valor <span class="math inline">\(x_l\)</span> en la muestra de <span class="math inline">\(X_i\)</span> sería
<span class="math display">\[
P(X_i=x_l)\cdot n_{\bullet,i}=P(X=x_l)\cdot n_{\bullet,i}=\frac{n_{l,\bullet}\cdot n_{\bullet,i}}{n}
\]</span></p>
<p>Y resulta que podemos comparar las frecuencias que hemos observado, <span class="math inline">\(n_{i,l}\)</span>, con estas frecuencias esperadas si la hipótesis nula fuera cierta usando un estadístico <span class="math inline">\(\chi^2\)</span> como el de los contrastes de bondad de ajuste:</p>
<div class="theorem">
<p><span id="thm:unnamed-chunk-611" class="theorem"><strong>Teorema 15.2  </strong></span>Con las notaciones anteriores, si</p>
<ul>
<li><p><span class="math inline">\(n\)</span> es grande (digamos que <span class="math inline">\(n\geqslant 30\)</span>)</p></li>
<li><p><strong>Regla de Cochran</strong>: cada frecuencia esperada <span class="math inline">\((n_{l,\bullet}\cdot n_{\bullet,i})/n\)</span> es <span class="math inline">\(\geqslant 5\)</span></p></li>
</ul>
<p>entonces
<span class="math display">\[
\chi^2=\sum_{i=1}^m\sum\limits_{l=1}^k \frac{ \left( n_{ij}- \frac{n_{l,\bullet}\cdot n_{\bullet,i}}{n}\right)^2 } {\frac{n_{l,\bullet}\cdot n_{\bullet,i}}{n}}
\]</span>
tiene distribución aproximadamente <span class="math inline">\(\chi_{(m-1)(k-1))}^2\)</span>.</p>
</div>

<div class="rmdimportant">
Mirad el número de grados de libertad: número de filas menos 1 por número de columnas menos 1.
</div>
<p>Volvemos a nuestro ejemplo. Las probabilidades estimadas de la variable <span class="math inline">\(X\)</span> definida por el tipo de parto son:
<span class="math display">\[
\begin{array}{r|cc}
\textbf{Tipo} &amp; \textbf{Prob. estimada}\\ \hline
\text{Eutócico}       &amp;  634/1000=0.634\\
\text{Instrumental} &amp;  107/1000=0.107\\
\text{Cesárea programada} &amp;  101/1000=0.101\\
\text{Cesárea urgente}    &amp;  158/1000=0.158
\end{array}
\]</span>
y la tabla de frecuencias esperadas será</p>
<p><span class="math display">\[
\begin{array}{c}
\begin{array}{r|ccc}
&amp; \text{Asintomática} &amp; \text{Leve} &amp; \text{Grave} \\ \hline
\text{Eutócico}       &amp;  \frac{453\cdot 634}{1000} &amp;   \frac{381\cdot 634}{1000}   &amp;       \frac{166\cdot 634}{1000} \\
\text{Instrumental} &amp;   \frac{453\cdot 107}{1000}   &amp;       \frac{381\cdot 107}{1000}    &amp;       \frac{166\cdot 107}{1000} \\
\text{Cesárea programada} &amp;   \frac{453\cdot 101}{1000}    &amp;       \frac{381\cdot 101}{1000}   &amp;       \frac{166\cdot 101}{1000}\\
\text{Cesárea urgente}    &amp;  \frac{453\cdot 158}{1000}   &amp;       \frac{381\cdot 158}{1000}   &amp;       \frac{166\cdot 158}{1000}
\end{array}\\
\downarrow\\
\begin{array}{r|ccc}
&amp; \text{Asintomática} &amp; \text{Leve} &amp; \text{Grave} \\ \hline
\text{Eutócico}       &amp;  287.202   &amp; 241.554   &amp; 105.244 \\
\text{Instrumental} &amp;   48.471   &amp;  40.767    &amp; 17.762 \\
\text{Cesárea programada} &amp;  45.753   &amp;  38.481   &amp;  16.766\\
\text{Cesárea urgente}    &amp; 71.574   &amp;  60.198    &amp; 26.228
\end{array}
\end{array}
\]</span></p>
<p>El valor del estadístico de contraste es
<span class="math display">\[
\begin{array}{rl}
\chi^2 &amp;\displaystyle =\frac{(305-287.202)^2}{287.202}+\frac{(234-241.554)^2}{241.554}+\frac{(95-105.224)^2}{105.224}+\frac{(48-48.471)^2}{48.471}+\cdots\\ &amp;
=22.357
\end{array}
\]</span>
El número de grados de libertad de la <span class="math inline">\(\chi^2\)</span> con la que tenemos que calcular el p-valor es <span class="math inline">\((4-1)\cdot (3-1)=6\)</span>. Por lo tanto el p-valor es <span class="math inline">\(P(\chi^2_6\geqslant 22.357)=0.001\)</span>.</p>
<p>Hemos obtenido evidencia estadística de que las distribuciones de tipos de parto en los tres grupos sintomáticos de COVID-19 en embarazadas no son la misma. Esto se suele abreviar diciendo que hemos encontrado evidencia estadística <strong>de asociación</strong> entre el tipo de parto y el grupo sintomático de la embarazada.</p>
<p>En JAMOVI este test está implementado en la pestaña <strong>Frecuencias/Muestras independientes (Prueba de asociación de <span class="math inline">\(\chi^2\)</span>)</strong>. Se puede aplicar a una tabla de datos con los datos originales o a unas variables en las que hayamos entrado las frecuencias observadas. Vamos a hacerlo de esta última manera. En primer lugar, definimos tres variables: <code>Tipo</code>, con los tipos de parto, <code>Síntomas</code>, con el grupo sintomático, y <code>Frecuencias</code>, con las frecuencias observadas. Las dos primeras variables tienen que estar definidas de manera que formen cada par (Tipo,Grupo sintomático) y la tercera tiene que valer la frecuencia observada de dicho par.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2ind.1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>A continuación, en <strong>Frecuencias/Muestras independientes (Prueba de asociación de <span class="math inline">\(\chi^2\)</span>)</strong> seleccionamos como “Filas” y “Columnas” las variables <code>Tipo</code> y <code>Síntomas</code> y como “Frecuencias” la variable <code>Frecuencias</code>. Si además marcamos en <strong>Celdas</strong> la casilla de “Frecuencias esperadas” obtendremos las frecuencias esperadas y en particular podremos comprobar si se cumple la regla de Cochran y por lo tanto tiene sentido usar el test <span class="math inline">\(\chi^2\)</span>.</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2ind.2.png" width="100%" style="display: block; margin: auto;" /></p>

<div class="rmdnote">
<p>Por la fórmula que las calcula, la frecuencia esperada más pequeña va a ser la correspondiente a la fila de suma mínima y la columna de suma mínima, e igual al producto de estas dos sumas dividido por el tamaño total de la muestra. Si esta frecuencia esperada mínima es <span class="math inline">\(\geqslant 5\)</span>, el resto también lo serán y se cumplirá la regla de Cochran.</p>
<p>En nuestro ejemplo, la fila de suma mínima es la de las cesáreas programadas y la columna de suma mínima es la de las infectadas graves: la frecuencia esperada mínima es 166·101/1000=16.766, mayor que 5.</p>
</div>
<p>Veamos otro ejemplo, en este caso de comparación de proporciones.</p>
<div class="example">
<p><span id="exm:unnamed-chunk-614" class="example"><strong>Ejemplo 15.17  </strong></span>Para estudiar si hay asociación en los niños entre el hábito tabáquico y la tos nocturna, se tomó una muestra de 2847 niños de 12 años y se obtuvo la siguiente información:</p>
</div>
<p><span class="math display">\[
\begin{array}{c}
\qquad\qquad\qquad\qquad\textbf{Hábito tabáquico}\\
\begin{array}{lc|ccc|c}
&amp; &amp; \text{No fumador} &amp;  \text{Ocasional} &amp;  \text{Regular} &amp;  \text{Total} \\\hline
\textbf{Tos} &amp;\text{Sí} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\
\textbf{nocturna} &amp;\text{No}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\hline
&amp;\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847\\
\end{array}
\end{array}
\]</span></p>
<p>Llamemos <span class="math inline">\(p_n\)</span>, <span class="math inline">\(p_o\)</span> y <span class="math inline">\(p_r\)</span> a las probabilidades de que tenga tos nocturna un niño no fumador, un niño fumador ocasional y un niño fumador regular, respectivamente. Queremos realizar el contraste
<span class="math display">\[
\left\{\begin{array}{ll}
H_0:\ p_n=p_o=p_r\\
H_1:\text{ No es cierto que $p_n=p_o=p_r$}
\end{array}
\right.
\]</span></p>
<p>Si llamamos <span class="math inline">\(X_n\)</span> a la variable aleatoria de Bernoulli que toma un niño no fumador y da 1 si tiene tos nocturna y 0 si no, y <span class="math inline">\(X_o,X_r\)</span> a las variables aleatorias similares para niños fumadores ocasionales y regulares, respectivamente, el contraste planteado es equivalente a
<span class="math display">\[
\left\{\begin{array}{ll}
H_0:\text{ $X_n,X_o,X_r$ tienen la misma distribución de probabilidad}\\
H_1:\text{ No es cierto que $X_n,X_o,X_r$ tengan la misma distribución de probabilidad}
\end{array}
\right.
\]</span></p>
<p>La muestra es muy grande, pero para poder usar un test <span class="math inline">\(\chi^2\)</span> tenemos que confirmar que la frecuencia esperada mínima es <span class="math inline">\(\geqslant 5\)</span>. La frecuencia esperada mínima será el producte de la suma mínima de una fila por la suma mínima de una columna, dividido por el tamaño de la muestra: 172·741/2847=44.767. Por lo tanto todas las frecuencias esperadas serán mayores que esta, y en particular mayores que 5.</p>
<p>Entramos la tabla de frecuencias observadas en JAMOVI:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2ind.3.png" width="100%" style="display: block; margin: auto;" /></p>
<p>y efectuamos el test:</p>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2ind.4.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Como el p-valor es menor que 0.001, hemos obtenido evidencia estadística de asociación entre la tos nocturna y el hápito tabáquico en niños.</p>
<p>De nuevo, si el tamaño de la muestra no es lo bastante grande o si no se cumple la regla de Cochran, se puede usar la versión MonteCarlo. Por ejemplo, imaginad que la muestra de niños del ejemplo anterior hubiera sido 10 veces más pequeña, de tamaño 285, y las frecuencias hubieran sido las originales divididas por 10:</p>
<p><span class="math display">\[
\begin{array}{c}
\qquad\qquad\qquad\qquad\textbf{Hábito tabáquico}\\[-1ex]
\begin{array}{lc|ccc|c}
&amp; &amp; \text{No fumador} &amp;  \text{Ocasional} &amp;  \text{Regular} &amp;  \text{Total} \\\hline
\textbf{Tos} &amp;\text{Sí} &amp; 27 &amp; 39 &amp; 8 &amp; 74\\
\textbf{nocturna} &amp;\text{No}&amp; 104 &amp; 98 &amp; 9 &amp; 211\\\hline
&amp;\text{Total} &amp;131 &amp; 137 &amp; 17 &amp; 285\\
\end{array}
\end{array}
\]</span></p>
<p>Si las probabilidades de tos nocturna en los tres grupos de hábito tabáquico fueran las mismas, la menor frecuencia esperada sería 17·74/285=4.41, y no se podría usar el test <span class="math inline">\(\chi^2\)</span> tal cual.
Para usar el test MonteCarlo:</p>
<ol style="list-style-type: decimal">
<li>Definimos una matriz con la tabla de frecuencias (la función <code>r</code>bind` define una matriz con filas las que le entramos)</li>
</ol>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="qué-test-usar.html#cb79-1" tabindex="-1"></a>Obs<span class="ot">=</span><span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">27</span>, <span class="dv">39</span>, <span class="dv">8</span>), <span class="fu">c</span>(<span class="dv">104</span>, <span class="dv">98</span>, <span class="dv">9</span>))</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Ejecutamos la función siguiente:</li>
</ol>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="qué-test-usar.html#cb80-1" tabindex="-1"></a><span class="fu">chisq.test</span>(Obs, <span class="at">simulate.p.value=</span><span class="cn">TRUE</span>, <span class="at">B=</span><span class="dv">5000</span>)</span></code></pre></div>
<p><img src="INREMDN_files/figure-html/JAMOVI.ji2ind.MCF.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Como el p-valor es 0.04, volvemos a obtener evidencia estadística de asociación entre la tos nocturna y el hápito tabáquico en niños.</p>
</div>
</div>
<div id="contrastes-de-correlación" class="section level2 hasAnchor" number="15.5">
<h2><span class="header-section-number">15.5</span> Contrastes de correlación<a href="qué-test-usar.html#contrastes-de-correlación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Imaginad que queremos estudiar si el consumo de frutos secos se asocia a una disminución del nivel de colesterol. Una posibilidad es plantear la pregunta <em>¿Consumir habitualmente frutos secos reduce el nivel medio de colesterol?</em>. Para responder esta pregunta, tomaríamos una muestra grande de individuos y de cada uno de ellos anotaríamos su nivel de colesterol y si come frutos secos habitualmente o no. Entonces, con estos datos, podríamos efectuar un contraste de dos medias con muestras independientes.</p>
<p>Pero también podríamos plantear la pregunta <em>¿Cuanto más frutos secos se comen, menos colesterol se tiene?</em>. Tomaríamos una muestra grande de individuos y de cada uno de ellos anotaríamos su nivel de colesterol y la cantidad de frutos secos que come en una semana. ¿Y ahora qué?</p>
<p>Recordad de la lección de Estadística descriptiva de datos continuos que dados los valores de dos variables medidas sobre una misma muestra de sujetos, podíamos medir la tendencia a crecer, o decrecer, conjuntamente de estos dos conjuntos de valores mediante su <strong>correlación</strong>, bien de Pearson o de Spearman. Resulta que la correlación de Pearson de los valores de dos variables medidas sobre una misma muestra de sujetos estima la <strong>correlación poblacional</strong> de estas variables, y que el signo de esta correlación sirve para determinar si, a nivel poblacional, las dos variables tienden a crecer o a decrecer conjuntamente (y su valor absoluto mide la tendencia a hacerlo de manera lineal). En particular, podremos usar la correlación dos muestras emparejadas para contrastar si las variables poblacionales tienen tendencia a crecer o decrecer conjuntamente o si, por el contrario, el comportamiento de una no tienen nada que ver con el de la otra.</p>
<p>Hay que introducir algunos conceptos para poder fijar exactamente de qué estamos hablando.
Sean <span class="math inline">\(X,Y\)</span> dos variables aleatorias, de medias <span class="math inline">\(\mu_X,\mu_Y\)</span> y desviaciones típicas <span class="math inline">\(\sigma_X,\sigma_Y\)</span>, definidas sobre una misma población.</p>
<p>La <strong>covarianza</strong> de <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> es
<span class="math display">\[
\sigma_{X,Y}=E((X-\mu_X)\cdot ( Y-\mu_Y)) = E(X\cdot Y) -\mu_X\cdot \mu_Y
\]</span>
Si <span class="math inline">\(X,Y\)</span> son discretas,
<span class="math display">\[
\sigma_{X,Y}=\sum_{x,y} x\cdot y\cdot P(X=x,Y=y) -\Big(\sum_{x} x\cdot P(X=x)\Big)\Big(\sum_{y} y\cdot P(Y=y)\Big)
\]</span></p>
<div class="example">
<p><span id="exm:unnamed-chunk-617" class="example"><strong>Ejemplo 15.18  </strong></span>Sea <span class="math inline">\(X\)</span> la variable que cuenta el número de caras al lanzar 2 veces una moneda equilibrada e
<span class="math inline">\(Y\)</span> la variable de Bernoulli que vale 1 si al lanzar 2 veces una moneda equilibrada dan el mismo resultado, y 0 si no.</p>
</div>
<p><span class="math display">\[
\begin{array}{c|c|c}
\text{Resultado} &amp; X &amp; Y\\ \hline
\text{Cara-Cara} &amp; 2 &amp; 1\\
\text{Cara-Cruz} &amp; 1&amp; 0\\
\text{Cruz-Cara} &amp; 1&amp; 0\\
\text{Cruz-Cruz} &amp; 0&amp; 1
\end{array}
\]</span>
Calculemos las probabilidades involucradas en el cálculo de <span class="math inline">\(\sigma_{X,Y}\)</span>:</p>
<ul>
<li><p><span class="math inline">\(P(X=0)=0.25\)</span>, <span class="math inline">\(P(X=1)=0.5\)</span>, <span class="math inline">\(P(X=2)=0.25\)</span></p></li>
<li><p><span class="math inline">\(P(Y=0)=0.5\)</span>, <span class="math inline">\(P(Y=1)=0.5\)</span></p></li>
<li><p><span class="math inline">\(P(X=2,Y=1)=0.25\)</span>, <span class="math inline">\(P(X=1,Y=0)=0.5\)</span>, <span class="math inline">\(P(X=0,Y=1)=0.25\)</span>, <span class="math inline">\(P(X=2,Y=0)=P(X=1,Y=1)=P(X=0,Y=0)=0\)</span></p></li>
</ul>
<p>Entonces
* <span class="math inline">\(\mu_X=\sum_{x} x\cdot P(X=x)=0\cdot 0.25+1\cdot 0.5+2\cdot 0.25=1\)</span></p>
<ul>
<li><p><span class="math inline">\(\mu_Y=\sum_{y} y\cdot P(Y=y)=0\cdot 0.5+1\cdot 0.5=0.5\)</span></p></li>
<li><p><span class="math inline">\(E(X\cdot Y)=\sum_{x,y} x\cdot y\cdot P(X=x,Y=y)=2\cdot 1\cdot 0.25+1\cdot 0\cdot 0.5+0\cdot 1\cdot 0.25=0.5\)</span></p></li>
</ul>
<p>y finalmente
<span class="math display">\[
\sigma_{X,Y}=E(X\cdot Y) -\mu_X\cdot \mu_Y=0.5-1\cdot 0.5=0
\]</span></p>
<p>La covarianza de <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> tiene las mismas propiedades para toda la población que la covarianza de dos muestras.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\sigma_{X,Y}\)</span> mide la <em>tendencia al crecimiento conjunto</em> de <span class="math inline">\(X,Y\)</span></p>
<ul>
<li><p><span class="math inline">\(\sigma_{X,Y}&gt;0\)</span> significa que</p>
<ul>
<li><p>Cuando <span class="math inline">\(X\)</span> es más <em>grande</em> en individuo 1 que en individuo 2, <span class="math inline">\(Y\)</span> tiende a ser más <em>grande</em> en individuo 1 que en individuo 2</p></li>
<li><p>Cuando <span class="math inline">\(X\)</span> es más <em>pequeño</em> en individuo 1 que en individuo 2, <span class="math inline">\(Y\)</span> tiende a ser más <em>pequeño</em> en individuo 1 que en individuo 2</p></li>
</ul></li>
<li><p><span class="math inline">\(\sigma_{X,Y}&lt;0\)</span> significa que</p>
<ul>
<li><p>Cuando <span class="math inline">\(X\)</span> es más <em>grande</em> en individuo 1 que en individuo 2, <span class="math inline">\(Y\)</span> tiende a ser más<em>pequeño</em> en individuo 1 que en individuo 2</p></li>
<li><p>Cuando <span class="math inline">\(X\)</span> es más <em>pequeño</em> en individuo 1 que en individuo 2, <span class="math inline">\(Y\)</span> tiende a ser más <em>grande</em> en individuo 1 que en individuo 2</p></li>
</ul></li>
<li><p><span class="math inline">\(\sigma_{X,Y}=0\)</span> significa que no hay ninguna tendencia en este sentido</p></li>
</ul></li>
</ol>
<ul>
<li><p>Las unidades son las de <span class="math inline">\(X\)</span> por las de <span class="math inline">\(Y\)</span></p></li>
<li><p>La covarianza es simétrica: <span class="math inline">\(\sigma_{X,Y}=\sigma_{Y,X}\)</span></p></li>
<li><p>La covarianza de una variable consigo misma es si varianza: <span class="math inline">\(\sigma_{X,X}=\sigma^2_X\)</span></p></li>
<li><p>Si <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> son independientes, <span class="math inline">\(\sigma_{X,Y}=0\)</span></p></li>
<li><p>Pero <span class="math inline">\(\sigma_{X,Y}=0\)</span> no implica que <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> sean independientes.</p>
<p>Por ejemplo, las variables <span class="math inline">\(X,Y\)</span> del ejemplo anterior tienen <span class="math inline">\(\sigma_{X,Y}=0\)</span> pero no son independientes porque
<span class="math display">\[
P(X=1,Y=1)=0,\ P(X=1)\cdot P(Y=1)=0.5\cdot 0.5=0.25
\]</span></p></li>
</ul>
<p><span class="math inline">\(\sigma_{X,Y}\)</span> mide la “tendencia al crecimiento conjunto” de <span class="math inline">\(X,Y\)</span>, y el signo es fácil de interpretar, pero el valor absoluto no</p>
<p>La <strong>correlación</strong> (o <strong>coeficiente de correlación lineal de Pearson</strong>) de <span class="math inline">\(X,Y\)</span> es
<span class="math display">\[
\rho_{X,Y}=\frac{\sigma_{X,Y}}{\sigma_{X}\cdot \sigma_{Y}}
\]</span></p>
<p>De nuevo, sus propiedades son las de la correlación de Pearson de muestras, pero ahora para toda la población:</p>
<ul>
<li><p><span class="math inline">\(\rho_{X,Y}\)</span> no tiene unidades</p></li>
<li><p><span class="math inline">\(\rho_{X,Y}=\rho_{Y,X}\)</span></p></li>
<li><p><span class="math inline">\(\rho_{X,X}=1\)</span></p></li>
<li><p><span class="math inline">\(\rho_{X,Y}=0 \Longleftrightarrow \sigma_{X,Y}=0\)</span></p>
<p>Por lo tanto</p>
<ul>
<li>Si <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> son independientes, <span class="math inline">\(\rho_{X,Y}=0\)</span></li>
<li>Pero <span class="math inline">\(\rho_{X,Y}=0\)</span> no implica que <span class="math inline">\(X\)</span> y <span class="math inline">\(Y\)</span> sean independientes</li>
</ul>
<p>Se dice que dos variables <span class="math inline">\(X,Y\)</span> son <strong>incorreladas</strong> cuando <span class="math inline">\(\rho_{X,Y}=0\)</span></p></li>
<li><p><span class="math inline">\(-1\leq \rho_{X,Y}\leq 1\)</span></p></li>
<li><p><span class="math inline">\(\rho_{X,Y}=\pm 1\)</span> si, y solo si, <span class="math inline">\(Y=a X+b\)</span>. La pendiente <span class="math inline">\(a\)</span> de esta recta tiene el mismo signo que <span class="math inline">\(\rho_{X,Y}\)</span>.</p></li>
<li><p>Cuanto más se acerca <span class="math inline">\(|\rho_{X,Y}|\)</span> a 1, más se acerca <span class="math inline">\(Y\)</span> a ser función lineal de <span class="math inline">\(X\)</span></p>
<ul>
<li>Si <span class="math inline">\(\rho_{X,Y}&gt;0\)</span>, la dependencia lineal es creciente</li>
<li>Si <span class="math inline">\(\rho_{X,Y}&lt;0\)</span>, la dependencia lineal es decreciente</li>
</ul></li>
</ul>

<div class="rmdimportant">
La correlación de Pearson mide la tendencia de dos variables a variar conjuntamente de manera lineal. <strong>No</strong> mide
que el aumento de una variable implique o sea la causa del crecimiento o decrecimiento de la otra.
</div>
<p>Un ejemplo, que además es importante tener siempre en cuenta:</p>
<div class="theorem">
<p><span id="thm:unnamed-chunk-619" class="theorem"><strong>Teorema 15.3  </strong></span>Si <span class="math inline">\(X_1,X_2\)</span> son dos copias independientes de una misma variable aleatoria <span class="math inline">\(X\)</span>,
<span class="math display">\[
\rho_{X_1,X_2-X_1}=-\frac{1}{\sqrt{2}}\approx -0.71
\]</span></p>
</div>
<p>Por lo tanto, <span class="math inline">\(X_2-X_1\)</span> decrece “bastante” linealmente en <span class="math inline">\(X_1\)</span>. Por ejemplo, suponed que un día hacéis un test (su nota es <span class="math inline">\(X_1\)</span>) y que al día siguiente hacéis otro test (su nota será <span class="math inline">\(X_2\)</span>) de dificultad similar y sin haber estudiado más.</p>
<ul>
<li><p>Si sacáis una nota baja en <span class="math inline">\(X_1\)</span>, lo más probable es que <span class="math inline">\(X_2-X_1\)</span> sea grande (positivo) y por lo tanto <span class="math inline">\(X_2\)</span> sea más alta</p></li>
<li><p>Si sacáis una nota alta en <span class="math inline">\(X_1\)</span>, lo más probable es que <span class="math inline">\(X_2-X_1\)</span> sea pequeño (negativo) y por lo tanto <span class="math inline">\(X_2\)</span> sea más baja</p></li>
</ul>
<div class="example">
<p><span id="exm:unnamed-chunk-620" class="example"><strong>Ejemplo 15.19  </strong></span>Sea <span class="math inline">\(X\)</span> el resultado de lanzar un dado de 4 caras, y sean <span class="math inline">\(X_1,X_2\)</span> dos copias independientes de <span class="math inline">\(X\)</span>, es decir, los resultados de lanzar dos veces consecutivas el dado.</p>
</div>
<p><span class="math display">\[
\begin{array}{c|cccc}
X_1\backslash X_2&amp; 1 &amp; 2 &amp; 3 &amp; 4\\\hline
1 &amp; X_1=1 &amp; X_1=1 &amp; X_1=1 &amp; X_1=1\\
&amp; X_2\!-\!X_1=0&amp; X_2\!-\!X_1=1&amp; X_2\!-\!X_1=2&amp; X_2\!-\!X_1=3\\\hline
2 &amp; X_1=2&amp; X_1=2&amp; X_1=2&amp; X_1=2\\
&amp; X_2\!-\!X_1=\!-\!1&amp; X_2\!-\!X_1=0&amp; X_2\!-\!X_1=1&amp; X_2\!-\!X_1=2\\\hline
3 &amp; X_1=3&amp; X_1=3&amp; X_1=3&amp; X_1=3\\
&amp; X_2\!-\!X_1=\!-\!2&amp; X_2\!-\!X_1=\!-\!1&amp; X_2\!-\!X_1=0&amp; X_2\!-\!X_1=1\\\hline
4&amp; X_1=4&amp; X_1=4&amp; X_1=4&amp; X_1=4\\
&amp; X_2\!-\!X_1=\!-\!3&amp; X_2\!-\!X_1=\!-\!2&amp; X_2\!-\!X_1=\!-\!1&amp; X_2\!-\!X_1=0\\\hline
\end{array}
\]</span></p>
<p>**Dibuixar´ho RplotCorDaus</p>

<div class="rmdcorbes">
Por si alguien necesita la demostración del teorema anterior, aquí va. Es pura manipulación algebraica recordando que la covarianza de dos variables independientes es 0. Por definición,
<span class="math display">\[
\rho_{X_1,X_2-X_1}=\dfrac{\sigma_{X_1,X_2-X_1}}{\sigma_{X_1}\sigma_{X_2-X_1}}
\]</span>
donde
<span class="math display">\[
\begin{array}{l}
\sigma_{X_2-X_1}=\sqrt{\sigma^2_{X_2-X_1}}\\[2ex]
\quad =\sqrt{\sigma^2_{X_2}+\sigma^2_{X_1}}\ \text{(porque son independientes)}\\[2ex]
\quad =\sqrt{\sigma^2_{X}+\sigma^2_{X}}\ \text{(porque $X_1,X_2$ son copias de $X$)}\\[2ex]
\quad =\sqrt{2\sigma^2_{X}}=\sigma_{X}\sqrt{2}
\end{array}
\]</span>
y
<span class="math display">\[
\begin{array}{l}
\sigma_{X_1,X_2-X_1}=E(X_1(X_2-X_1))-E(X_1)E(X_2-X_1)\\[1ex]
\quad =E(X_1X_2-X_1^2)-E(X_1)(E(X_2)-E(X_1))\\[1ex]
\quad =E(X_1X_2)-E(X_1^2)-E(X_1)E(X_2)+E(X_1)E(X_1)\\[1ex]
\quad =E(X_1)E(X_2)-E(X_1^2)-E(X_1)E(X_2)+E(X_1)E(X_1)\\[1ex]
\quad \text{(porque son independientes)}\\[1ex]
\quad =-E(X_1^2)+E(X_1)E(X_1)=-\sigma^2_{X_1}=-\sigma^2_{X}
\end{array}
\]</span>
de donde
<span class="math display">\[
\rho_{X_1,X_2-X_1}=\dfrac{\sigma_{X_1,X_2-X_1}}{\sigma_{X_1}\sigma_{X_2-X_1}}=\dfrac{-\sigma^2_{X}}{\sigma_{X}\cdot \sigma_{X}\sqrt{2}} =-\frac{1}{\sqrt{2}}
\]</span>
</div>
<p>Un <strong>contraste de correlación</strong> de dos variables aleatorias <span class="math inline">\(X,Y\)</span> es un contraste de la forma
<span class="math display">\[
\left\{
\begin{array}{ll}
H_0: &amp; \rho_{X,Y}=0\\
H_1: &amp; \rho_{X,Y}&gt; 0\text{ o }\rho_{X,Y}&lt; 0\text{ o }\rho_{X,Y}\neq 0
\end{array}
\right.
\]</span>
Si rechazamos <span class="math inline">\(H_0\)</span>, en particular rechazamos que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sean independientes</p>
<p><strong>Ejemplo</strong></p>

</div>
</div>






            </section>

          </div>
        </div>
      </div>
<a href="contrastes-de-hipótesis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
