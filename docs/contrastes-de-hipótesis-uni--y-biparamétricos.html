<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lección 15 Contrastes de hipótesis uni- y biparamétricos | Bioestadística (Medicina UIB)</title>
  <meta name="description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Lección 15 Contrastes de hipótesis uni- y biparamétricos | Bioestadística (Medicina UIB)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="github-repo" content="AprendeR-UIB/INREMDN" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lección 15 Contrastes de hipótesis uni- y biparamétricos | Bioestadística (Medicina UIB)" />
  
  <meta name="twitter:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  

<meta name="author" content="Irene García, Francesc Rosselló" />


<meta name="date" content="2023-09-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="contrastes-de-hipótesis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">INREMDN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a></li>
<li class="part"><span><b>Tema I: Introducción a los estudios médicos y la estadística</b></span></li>
<li class="chapter" data-level="1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="estudios-médicos.html"><a href="estudios-médicos.html"><i class="fa fa-check"></i><b>2</b> Estudios médicos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:pasos"><i class="fa fa-check"></i><b>2.1</b> Pasos de un estudio médico</a></li>
<li class="chapter" data-level="2.2" data-path="estudios-médicos.html"><a href="estudios-médicos.html#algunos-calificativos-para-los-estudios-médicos"><i class="fa fa-check"></i><b>2.2</b> Algunos calificativos para los estudios médicos</a></li>
<li class="chapter" data-level="2.3" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-descriptivos"><i class="fa fa-check"></i><b>2.3</b> Estudios descriptivos</a></li>
<li class="chapter" data-level="2.4" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:cyc"><i class="fa fa-check"></i><b>2.4</b> Estudios de casos y controles</a></li>
<li class="chapter" data-level="2.5" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-de-cohorte"><i class="fa fa-check"></i><b>2.5</b> Estudios de cohorte</a></li>
<li class="chapter" data-level="2.6" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-transversales"><i class="fa fa-check"></i><b>2.6</b> Estudios transversales</a></li>
<li class="chapter" data-level="2.7" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:ecol"><i class="fa fa-check"></i><b>2.7</b> Estudios ecológicos</a></li>
<li class="chapter" data-level="2.8" data-path="estudios-médicos.html"><a href="estudios-médicos.html#ensayos-clínicos"><i class="fa fa-check"></i><b>2.8</b> Ensayos clínicos</a></li>
<li class="chapter" data-level="2.9" data-path="estudios-médicos.html"><a href="estudios-médicos.html#a-modo-de-resumen"><i class="fa fa-check"></i><b>2.9</b> A modo de resumen</a></li>
<li class="chapter" data-level="2.10" data-path="estudios-médicos.html"><a href="estudios-médicos.html#revisiones-sistemáticas-y-metaanálisis"><i class="fa fa-check"></i><b>2.10</b> Revisiones sistemáticas y metaanálisis</a></li>
<li class="chapter" data-level="2.11" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:causalidad"><i class="fa fa-check"></i><b>2.11</b> (Bonus track) Unos criterios de causalidad</a></li>
<li class="chapter" data-level="2.12" data-path="estudios-médicos.html"><a href="estudios-médicos.html#bonus-track-preguntas-clínicas-en-formato-pico"><i class="fa fa-check"></i><b>2.12</b> (Bonus track) Preguntas clínicas en formato PICO</a></li>
<li class="chapter" data-level="2.13" data-path="estudios-médicos.html"><a href="estudios-médicos.html#test"><i class="fa fa-check"></i><b>2.13</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html"><i class="fa fa-check"></i><b>3</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#unidad-de-observación"><i class="fa fa-check"></i><b>3.1</b> Unidad de observación</a></li>
<li class="chapter" data-level="3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#población-y-muestra"><i class="fa fa-check"></i><b>3.2</b> Población y muestra</a></li>
<li class="chapter" data-level="3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:muestreo"><i class="fa fa-check"></i><b>3.3</b> Tipos básicos de muestreo</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mas"><i class="fa fa-check"></i><b>3.3.1</b> Muestreo aleatorio con y sin reposición</a></li>
<li class="chapter" data-level="3.3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sist"><i class="fa fa-check"></i><b>3.3.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="3.3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:estr"><i class="fa fa-check"></i><b>3.3.3</b> Muestreo aleatorio estratificado</a></li>
<li class="chapter" data-level="3.3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mcluster"><i class="fa fa-check"></i><b>3.3.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="3.3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:oport"><i class="fa fa-check"></i><b>3.3.5</b> Muestreos no aleatorios</a></li>
<li class="chapter" data-level="3.3.6" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:poli"><i class="fa fa-check"></i><b>3.3.6</b> Muestreo polietápico</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sesgos"><i class="fa fa-check"></i><b>3.4</b> Sesgos</a></li>
<li class="chapter" data-level="3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#test-1"><i class="fa fa-check"></i><b>3.5</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema II: Probabilidades</b></span></li>
<li class="chapter" data-level="4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html"><i class="fa fa-check"></i><b>4</b> Probabilidades elementales: Las mates</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#álgebra-de-conjuntos"><i class="fa fa-check"></i><b>4.1</b> Álgebra de conjuntos</a></li>
<li class="chapter" data-level="4.2" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#algunas-fórmulas-básicas"><i class="fa fa-check"></i><b>4.2</b> Algunas fórmulas básicas</a></li>
<li class="chapter" data-level="4.3" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sec:odds"><i class="fa fa-check"></i><b>4.3</b> Odds</a></li>
<li class="chapter" data-level="4.4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>4.4</b> Probabilidad condicionada</a></li>
<li class="chapter" data-level="4.5" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sucesos-independientes"><i class="fa fa-check"></i><b>4.5</b> Sucesos independientes</a></li>
<li class="chapter" data-level="4.6" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#odds-condicionadas-y-odds-ratios-relativas"><i class="fa fa-check"></i><b>4.6</b> Odds condicionadas y odds ratios relativas</a></li>
<li class="chapter" data-level="4.7" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#el-teorema-de-la-probabilidad-total"><i class="fa fa-check"></i><b>4.7</b> El teorema de la probabilidad total</a></li>
<li class="chapter" data-level="4.8" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#la-fórmula-de-bayes"><i class="fa fa-check"></i><b>4.8</b> La fórmula de Bayes</a></li>
<li class="chapter" data-level="4.9" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#test-2"><i class="fa fa-check"></i><b>4.9</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html"><i class="fa fa-check"></i><b>5</b> Probabilidades elementales: Aplicaciones en medicina</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#pruebas-diagnósticas"><i class="fa fa-check"></i><b>5.1</b> Pruebas diagnósticas</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sensibilidad-especificidad-valores-predictivos-etc."><i class="fa fa-check"></i><b>5.1.1</b> Sensibilidad, especificidad, valores predictivos etc.</a></li>
<li class="chapter" data-level="5.1.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#curvas-roc"><i class="fa fa-check"></i><b>5.1.2</b> Curvas ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:probaplic2"><i class="fa fa-check"></i><b>5.2</b> Riesgos</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosRR"><i class="fa fa-check"></i><b>5.2.1</b> Riesgos relativos y absolutos</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosCyC"><i class="fa fa-check"></i><b>5.2.2</b> <em>Odds ratios</em></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#tratamientos"><i class="fa fa-check"></i><b>5.3</b> Tratamientos</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#test-3"><i class="fa fa-check"></i><b>5.4</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema II: Estadística descriptiva</b></span></li>
<li class="chapter" data-level="6" data-path="sec:tiposdatos.html"><a href="sec:tiposdatos.html"><i class="fa fa-check"></i><b>6</b> Tipos de datos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec:tiposdatos.html"><a href="sec:tiposdatos.html#test-4"><i class="fa fa-check"></i><b>6.1</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html"><i class="fa fa-check"></i><b>7</b> Descripción de datos cualitativos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:frecs"><i class="fa fa-check"></i><b>7.1</b> Frecuencias</a></li>
<li class="chapter" data-level="7.2" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#gráficos"><i class="fa fa-check"></i><b>7.2</b> Gráficos</a></li>
<li class="chapter" data-level="7.3" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#tablas-de-frecuencias-multidimensionales"><i class="fa fa-check"></i><b>7.3</b> Tablas de frecuencias multidimensionales</a></li>
<li class="chapter" data-level="7.4" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:barrasbidim"><i class="fa fa-check"></i><b>7.4</b> Diagramas de barras bidimensionales</a></li>
<li class="chapter" data-level="7.5" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#diagramas-de-mosaico"><i class="fa fa-check"></i><b>7.5</b> Diagramas de mosaico</a></li>
<li class="chapter" data-level="7.6" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#test-5"><i class="fa fa-check"></i><b>7.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html"><i class="fa fa-check"></i><b>8</b> Descripción de datos ordinales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#frecuencias-y-diagramas-de-barras"><i class="fa fa-check"></i><b>8.1</b> Frecuencias y diagramas de barras</a></li>
<li class="chapter" data-level="8.2" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#test-6"><i class="fa fa-check"></i><b>8.2</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html"><i class="fa fa-check"></i><b>9</b> Descripción de datos cuantitativos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#frecuencias"><i class="fa fa-check"></i><b>9.1</b> Frecuencias</a></li>
<li class="chapter" data-level="9.2" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-tendencia-central"><i class="fa fa-check"></i><b>9.2</b> Medidas de tendencia central</a></li>
<li class="chapter" data-level="9.3" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-posición"><i class="fa fa-check"></i><b>9.3</b> Medidas de posición</a></li>
<li class="chapter" data-level="9.4" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>9.4</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="9.5" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#diagramas-de-puntos-y-de-caja"><i class="fa fa-check"></i><b>9.5</b> Diagramas de puntos y de caja</a></li>
<li class="chapter" data-level="9.6" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#histogramas"><i class="fa fa-check"></i><b>9.6</b> Histogramas</a></li>
<li class="chapter" data-level="9.7" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#polígonos-de-frecuencias"><i class="fa fa-check"></i><b>9.7</b> Polígonos de frecuencias</a></li>
<li class="chapter" data-level="9.8" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#asimetría-y-curtosis"><i class="fa fa-check"></i><b>9.8</b> Asimetría y curtosis</a></li>
<li class="chapter" data-level="9.9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#sec:estagrup"><i class="fa fa-check"></i><b>9.9</b> Estadísticos sobre datos agrupados</a></li>
<li class="chapter" data-level="9.10" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#datos-cuantitativos-bivariantes"><i class="fa fa-check"></i><b>9.10</b> Datos cuantitativos bivariantes</a></li>
<li class="chapter" data-level="9.11" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#gráficos-en-escala-logarítmica"><i class="fa fa-check"></i><b>9.11</b> Gráficos en escala logarítmica</a></li>
<li class="chapter" data-level="9.12" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#test-7"><i class="fa fa-check"></i><b>9.12</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html"><i class="fa fa-check"></i><b>10</b> Variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#densidad-y-distribución"><i class="fa fa-check"></i><b>10.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="10.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#esperanza"><i class="fa fa-check"></i><b>10.2</b> Esperanza</a></li>
<li class="chapter" data-level="10.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#varianza-y-desviación-típica"><i class="fa fa-check"></i><b>10.3</b> Varianza y desviación típica</a></li>
<li class="chapter" data-level="10.4" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#cuantiles"><i class="fa fa-check"></i><b>10.4</b> Cuantiles</a></li>
<li class="chapter" data-level="10.5" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#familias-importantes-de-variables-aleatorias-discretas"><i class="fa fa-check"></i><b>10.5</b> Familias importantes de variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-binomiales"><i class="fa fa-check"></i><b>10.5.1</b> Variables aleatorias binomiales</a></li>
<li class="chapter" data-level="10.5.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-hipergeométricas"><i class="fa fa-check"></i><b>10.5.2</b> Variables aleatorias hipergeométricas</a></li>
<li class="chapter" data-level="10.5.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-de-poisson"><i class="fa fa-check"></i><b>10.5.3</b> Variables aleatorias de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#test-8"><i class="fa fa-check"></i><b>10.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html"><i class="fa fa-check"></i><b>11</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#densidad-y-distribución-1"><i class="fa fa-check"></i><b>11.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="11.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#esperanza-varianza-cuantiles"><i class="fa fa-check"></i><b>11.2</b> Esperanza, varianza, cuantiles…</a></li>
<li class="chapter" data-level="11.3" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#sec:normal"><i class="fa fa-check"></i><b>11.3</b> Variables aleatorias normales</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#propiedades-básicas"><i class="fa fa-check"></i><b>11.3.1</b> Propiedades básicas</a></li>
<li class="chapter" data-level="11.3.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#intervalos-de-referencia"><i class="fa fa-check"></i><b>11.3.2</b> Intervalos de referencia</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#test-9"><i class="fa fa-check"></i><b>11.4</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="estimadores.html"><a href="estimadores.html"><i class="fa fa-check"></i><b>12</b> Estimadores</a>
<ul>
<li class="chapter" data-level="12.1" data-path="estimadores.html"><a href="estimadores.html#la-media-muestral"><i class="fa fa-check"></i><b>12.1</b> La media muestral</a></li>
<li class="chapter" data-level="12.2" data-path="estimadores.html"><a href="estimadores.html#la-proporción-muestral"><i class="fa fa-check"></i><b>12.2</b> La proporción muestral</a></li>
<li class="chapter" data-level="12.3" data-path="estimadores.html"><a href="estimadores.html#la-varianza-muestral"><i class="fa fa-check"></i><b>12.3</b> La varianza muestral</a></li>
<li class="chapter" data-level="12.4" data-path="estimadores.html"><a href="estimadores.html#la-distribución-t-de-student"><i class="fa fa-check"></i><b>12.4</b> La distribución t de Student</a></li>
<li class="chapter" data-level="12.5" data-path="estimadores.html"><a href="estimadores.html#test-10"><i class="fa fa-check"></i><b>12.5</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>13</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#sec:IC"><i class="fa fa-check"></i><b>13.1</b> Definiciones básicas</a></li>
<li class="chapter" data-level="13.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-ejemplo-ic-95-para-la-media-de-una-variable-aleatoria-normal"><i class="fa fa-check"></i><b>13.2</b> Un ejemplo: IC-95% para la media de una variable aleatoria normal</a></li>
<li class="chapter" data-level="13.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-basado-en-la-t-de-student"><i class="fa fa-check"></i><b>13.3</b> Intervalo de confianza para la media basado en la t de Student</a></li>
<li class="chapter" data-level="13.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-proporciones"><i class="fa fa-check"></i><b>13.4</b> Intervalos de confianza para proporciones</a></li>
<li class="chapter" data-level="13.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#bonus-track-otros-intervalos-de-confianza"><i class="fa fa-check"></i><b>13.5</b> (Bonus track) Otros intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-intervalo-de-confianza-para-la-diferencia-de-proporciones"><i class="fa fa-check"></i><b>13.5.1</b> Un intervalo de confianza para la diferencia de proporciones</a></li>
<li class="chapter" data-level="13.5.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-diferencias-de-medias"><i class="fa fa-check"></i><b>13.5.2</b> Intervalos de confianza para diferencias de medias</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#test-11"><i class="fa fa-check"></i><b>13.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>14</b> Contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="14.1" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#hipótesis-nula-y-alternativa"><i class="fa fa-check"></i><b>14.1</b> Hipótesis nula y alternativa</a></li>
<li class="chapter" data-level="14.2" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:moneda"><i class="fa fa-check"></i><b>14.2</b> Un ejemplo</a></li>
<li class="chapter" data-level="14.3" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:pval"><i class="fa fa-check"></i><b>14.3</b> El p-valor</a></li>
<li class="chapter" data-level="14.4" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#tipo-de-errores"><i class="fa fa-check"></i><b>14.4</b> Tipo de errores</a></li>
<li class="chapter" data-level="14.5" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#sec:exttest"><i class="fa fa-check"></i><b>14.5</b> Ejemplo: El test t</a></li>
<li class="chapter" data-level="14.6" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#la-potencia-de-un-contraste"><i class="fa fa-check"></i><b>14.6</b> La potencia de un contraste</a></li>
<li class="chapter" data-level="14.7" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#intervalo-de-confianza-de-un-contraste"><i class="fa fa-check"></i><b>14.7</b> Intervalo de confianza de un contraste</a></li>
<li class="chapter" data-level="14.8" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#resultados-estadísticamente-significativos-versus-resultados-clínicamente-significativos"><i class="fa fa-check"></i><b>14.8</b> Resultados estadísticamente significativos <em>versus</em> resultados clínicamente significativos</a></li>
<li class="chapter" data-level="14.9" data-path="contrastes-de-hipótesis.html"><a href="contrastes-de-hipótesis.html#test-12"><i class="fa fa-check"></i><b>14.9</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html"><i class="fa fa-check"></i><b>15</b> Contrastes de hipótesis uni- y biparamétricos</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#contrastes-para-medias"><i class="fa fa-check"></i><b>15.1</b> Contrastes para medias</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#test-t-para-una-media"><i class="fa fa-check"></i><b>15.1.1</b> Test t para una media</a></li>
<li class="chapter" data-level="15.1.2" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#tests-t-para-dos-medias"><i class="fa fa-check"></i><b>15.1.2</b> Tests t para dos medias</a></li>
<li class="chapter" data-level="15.1.3" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#tests-no-paramétricos"><i class="fa fa-check"></i><b>15.1.3</b> Tests no paramétricos</a></li>
<li class="chapter" data-level="15.1.4" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#ejemplos"><i class="fa fa-check"></i><b>15.1.4</b> Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="contrastes-de-hipótesis-uni--y-biparamétricos.html"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#contrastes-de-varianzas"><i class="fa fa-check"></i><b>15.2</b> Contrastes de varianzas</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bioestadística (Medicina UIB)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="contrastes-de-hipótesis-uni--y-biparamétricos" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Lección 15</span> Contrastes de hipótesis uni- y biparamétricos<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#contrastes-de-hipótesis-uni--y-biparamétricos" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En esta lección simplemente vamos a comentar por encima los contrastes de hipótesis más importantes sobre:</p>
<ul>
<li><p>Una o dos medias</p></li>
<li><p>Dos varianzas</p></li>
<li><p>Una o dos proporciones</p></li>
</ul>
<div id="contrastes-para-medias" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Contrastes para medias<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#contrastes-para-medias" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="test-t-para-una-media" class="section level3 hasAnchor" number="15.1.1">
<h3><span class="header-section-number">15.1.1</span> Test t para una media<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#test-t-para-una-media" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria de media <span class="math inline">\(\mu\)</span>. Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=\mu_0\\
H_{1}:\mu \neq\mu_0\text{ o }\mu &gt;\mu_0\text{ o }\mu&lt;\mu_0
\end{array}
\right.
\]</span>
Para ello, medimos <span class="math inline">\(X\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de sujetos de la población.</p>
<p>Supongamos que estamos en una de las dos situaciones siguientes:</p>
<ul>
<li><p><span class="math inline">\(X\)</span> es normal</p></li>
<li><p><span class="math inline">\(X\)</span> no es normal pero el tamaño <span class="math inline">\(n\)</span> de la muestra que tomamos es grande (digamos, para fijar ideas, que <span class="math inline">\(n\geq 40\)</span>)</p></li>
</ul>
<p>En cualquiera de estas dos situaciones, podemos usar el <strong>test t</strong> que hemos explicado en la lección anterior para realizar el contraste. Recordad que este test se basa en el estadístico de contraste
<span class="math display">\[
T= \frac{\overline{X}-\mu_{0}}{{\widetilde{S}_X}/{\sqrt{n}}}
\]</span>
que, bajo las condiciones supuestas, sigue (aproximadamente, si <span class="math inline">\(X\)</span> no es normal pero la muestra es grande) una distribución t de Student con <span class="math inline">\(n-1\)</span> grados de libertad. Como ya hemos hecho varios ejemplos de este tipo de test en la lección anterior, aquí no nos vamos a entretener más con él.</p>
</div>
<div id="tests-t-para-dos-medias" class="section level3 hasAnchor" number="15.1.2">
<h3><span class="header-section-number">15.1.2</span> Tests t para dos medias<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#tests-t-para-dos-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean ahora <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias de medias <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span>, respectivamente. Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 &gt;\mu_2\text{ o }\mu_1&lt;\mu_2
\end{array}
\right.
\]</span>
Para ello, medimos <span class="math inline">\(X_1\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span>, y <span class="math inline">\(X_2\)</span> sobre una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span>.</p>
<p>Supongamos que estamos en una de las dos situaciones siguientes:</p>
<ul>
<li><p><span class="math inline">\(X_1,X_2\)</span> son ambas normales</p></li>
<li><p><span class="math inline">\(X_1,X_2\)</span> no son ambas normales pero los tamaños <span class="math inline">\(n_1,n_2\)</span> de las muestras son <strong>ambos</strong> grandes (digamos, para fijar ideas, que <span class="math inline">\(n_1,n_2\geq 40\)</span>)</p></li>
</ul>
<p>Si se cumple alguna de estas dos condiciones, podemos usar un <strong>test t</strong>, basado en un estadístico de contraste <span class="math inline">\(T\)</span> adecuado que sigue una ley t de Student (aproximadamente, si alguna variable poblacional no es normal pero las dos muestras son grandes). El estadístico de contraste concreto y los grados de libertad de su distribución t de Student dependen de las mismas condiciones que comentábamos al hablar de intervalos de confianza para la diferencia de dos medias:</p>
<ul>
<li><p>De si las dos muestras son:</p>
<ul>
<li><strong>independientes</strong>: hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre dos muestras aleatorias simples obtenidas de manera independiente la una de la otra; o</li>
<li><strong>emparejadas</strong>: hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre los individuos de una misma muestra aleatoria simple o hay un emparejamiento natural entre los sujetos de las dos muestras; en particular, en el caso emparejado ha de pasar que <span class="math inline">\(n_1=n_2\)</span>.</li>
</ul></li>
<li><p>Cuando las muestras son independientes, también dependen de si <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> tienen la <strong>misma varianza</strong> o no, que se ha de decidir con otro contraste.</p></li>
</ul>
<p>A continuación os damos las fórmulas, por si tenéis que realizar algún contraste de dos medias “a mano”.</p>
<p>Cuando las muestras son <strong>emparejadas</strong>, podemos entender que tenemos una sola muestra (formada por las parejas de sujetos) y consideramos los pares de valores <span class="math inline">\((X_1,X_2)\)</span> sobre dichas parejas. Entonces, podemos medir para cada pareja la diferencia <span class="math inline">\(D=X_1-X_2\)</span>, que tendrá media poblacional <span class="math inline">\(\mu_D=\mu_1-\mu_2\)</span>, y traducir el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 &gt;\mu_2\text{ o }\mu_1&lt;\mu_2
\end{array}
\right.
\]</span>
en el contraste de una sola media
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_1-\mu_2=0\\
H_{1}:\mu_D \neq 0\text{ o }\mu_D &gt;0\text{ o }\mu_D&lt;0
\end{array}
\right.
\]</span>
Es decir, cuando las muestras son emparejadas, consideramos nuestro contraste de dos medias como un contraste de una sola media, usando como muestra las diferencias <span class="math inline">\(X_1-X_2\)</span> sobre nuestras parejas de sujetos. Por lo tanto, si llamamos <span class="math inline">\(\overline{D}\)</span> a la media muestral de <span class="math inline">\(D\)</span> y <span class="math inline">\(\widetilde{S}_D\)</span> a la desviación típica muestral de <span class="math inline">\(D\)</span> sobre nuestra muestra de parejas, y <span class="math inline">\(n\)</span> es el tamaño de la muestra de parejas, el estadístico de contraste es
<span class="math display">\[
T=\frac{\overline{D}}{\widetilde{S}_D/\sqrt{n}}
\]</span>
que, cuando <span class="math inline">\(\mu_D=0\)</span>, tiene (aproximadamente, si <span class="math inline">\(X_1,X_2\)</span> no son normales pero la <span class="math inline">\(n\)</span> es grande) distribución <span class="math inline">\(t_{n-1}\)</span>.</p>
<p>Supongamos ahora que las dos muestras son <strong>independientes</strong>. Sean <span class="math inline">\(\overline{X}_1\)</span> y <span class="math inline">\(\widetilde{S}^2_1\)</span> la media muestral y la varianza muestral de la muestra de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(\overline{X}_2\)</span> y <span class="math inline">\(\widetilde{S}^2_2\)</span> la media muestral y la varianza muestral de la muestra de <span class="math inline">\(X_2\)</span>. Sean, además, <span class="math inline">\(\sigma_1^2\)</span> y <span class="math inline">\(\sigma_2^2\)</span> las varianzas (poblacionales) de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>. Entonces:</p>
<ul>
<li><p>Si <span class="math inline">\(\sigma_1^2=\sigma_2^2\)</span>, el estadístico de contraste es
<span class="math display">\[
T=\frac{\overline{X}_1-\overline{X}_2}{\sqrt{(\frac{1}{n_1}+\frac{1}{n_2})\cdot \frac{(n_1-1)\widetilde{S}_1^2+(n_2-1)\widetilde{S}_2^2}{n_1+n_2-2}}}
\]</span>
que, cuando <span class="math inline">\(\mu_1=\mu_2\)</span>, tiene distribución (aproximadamente, si <span class="math inline">\(X_1,X_2\)</span> no son normales pero <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span> son ambas grandes) <span class="math inline">\(t_{n_1+n_2-2}\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\sigma_1^2\neq \sigma_2^2\)</span>, el estadístico de contraste es
<span class="math display">\[
T=\frac{\overline{X}_1-\overline{X}_2}{\sqrt{\frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}}}
\]</span>
que, cuando <span class="math inline">\(\mu_1=\mu_2\)</span>, tiene distribución (aproximadamente, si <span class="math inline">\(X_1,X_2\)</span> no son normales pero <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span> son ambas grandes) <span class="math inline">\(t_{\nu}\)</span> con
<span class="math display">\[
\nu=\frac{\displaystyle \left( \frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}
\right)^2}{\displaystyle \frac{1}{n_1-1}\left(\frac{\widetilde{S}_1^2}{n_1}\right)^2+\frac{1}{n_2-1}\left(\frac{\widetilde{S}_2^2}{n_2}\right)^2}
\]</span></p></li>
</ul>

<div class="rmdmercifulgod">
No hace falta que sepáis estas fórmulas para muestras independientes, pero sí que tenéis que recordar que el estadístico de contraste y su distribución dependen de si las varianzas poblacionales son iguales o diferentes.
</div>
<p>Los grados de libertad de la distribución t de Student usada en un contraste sobre dos muestras de tamaño <span class="math inline">\(n\)</span>:</p>
<ul>
<li><p>Si las muestras son independientes, es aproximadamente <span class="math inline">\(2(n-1)\)</span></p></li>
<li><p>Si las muestras están emparejadas, es <span class="math inline">\(n-1\)</span></p></li>
</ul>
<p>Esto hace que la probabilidad de error de tipo I de un contraste con muestras emparejadas de tamaño <span class="math inline">\(n\)</span> suela ser más pequeña que la de un contraste con dos muestras independientes de tamaño <span class="math inline">\(n\)</span>. Por ejemplo, supongamos que queremos realizar el contraste
<span class="math display">\[
\left\{
\begin{array}{l}
H_0: \mu_1=\mu_2\\
H_1: \mu_1&gt;\mu_2
\end{array}\right.
\]</span>
y que el estadístico del contraste <span class="math inline">\(T\)</span> sobre dos muestras de tamaños <span class="math inline">\(n_1=n_2=20\)</span> da 1.7.</p>
<ul>
<li><p>Si las muestras son independientes,
<span class="math display">\[
\text{p-valor}=P(T&gt;1.7)\approx `1-pt(1.7,38)}=0.0487
\]</span></p></li>
<li><p>Si las muestras son emparejadas,
<span class="math display">\[
\text{p-valor}=P(T&gt;1.7)=`1-pt(1.7,19)}=0.0527
\]</span></p></li>
</ul>
<p>Por lo tanto, con nivel de significación <span class="math inline">\(\alpha=0.05\)</span>, rechazaríamos la hipótesis nula con las muestras independientes y la aceptaríamos con las muestras emparejadas.</p>
<p>A consecuencia de la diferencia en los números de grados de libertad de la distribución del estadístico de contraste, en general <strong>los contrastes con muestras emparejadas permiten usar menos sujetos</strong>.</p>
<p>Todos estos tests t están implementados en la función <code>t.test</code> de R. Su argumento es:</p>
<ul>
<li><p>Una muestra de <span class="math inline">\(X\)</span> y el valor con el que queremos contrastar <span class="math inline">\(\mu\)</span>, <strong>o</strong><br />
una muestra de <span class="math inline">\(X_1\)</span> y una muestra de <span class="math inline">\(X_2\)</span>.</p></li>
<li><p>El tipo de contraste, que se especifica igualando el parámetro <code>alternative</code> a <code>"two.sided"</code> (para contrastes bilaterales, es decir, con <span class="math inline">\(\neq\)</span>), <code>"less"</code> (<span class="math inline">\(&lt;\)</span>) o <code>"greater"</code> (<span class="math inline">\(&gt;\)</span>); no os olvidéis de las comillas en los valores de este parámetro.</p></li>
<li><p>El tipo de muestras, que se especifica igualando el parámetro <code>paired</code> a <code>FALSE</code> si son independientes o a <code>TRUE</code> si son emparejadas.</p></li>
<li><p>En caso de muestras independientes, si las varianzas son iguales o diferentes, que se especifica igualando el parámetro <code>var.equal</code> a <code>TRUE</code> o a <code>FALSE</code>.</p></li>
<li><p>El nivel de confianza <span class="math inline">\(1-\alpha\)</span>, que se especifica con el parámetro <code>conf.level</code>; si el nivel de significación es <span class="math inline">\(\alpha=0.05\)</span>, es decir, el nivel de confianza 0.95, no hace falta especificarlo (es su valor por defecto).</p></li>
</ul>
</div>
<div id="tests-no-paramétricos" class="section level3 hasAnchor" number="15.1.3">
<h3><span class="header-section-number">15.1.3</span> Tests no paramétricos<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#tests-no-paramétricos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si las variables aleatorias de interés no son (aproximadamente) normales y alguna muestra es pequeña, no podemos usar un test t. Entonces, hay que usar algún <strong>test no paramétrico</strong> que no presuponga nada sobre las distribuciones de las variables aleatorias.</p>
<p>Para contrastes de medias, los recomendados son:</p>
<ul>
<li><p><strong>Test de Wilcoxon</strong> para una media o para dos medias usando muestras emparejadas (que, recordad, se traduce en un contraste sobre la media de las diferencias).</p></li>
<li><p><strong>Test de Mann-Whitney(-Wilcoxon)</strong> para dos medias usando muestras independientes.</p></li>
</ul>
<p>Ambos se calculan con R con la función <code>wilcox.test</code>, con una sintaxis idéntica a la de <code>t.test</code> (excepto que no dispone del parámetro <code>var.equal</code> ya que ahora no nos interesa lo más mínimo saber si las variables tienen varianzas iguales o diferentes en el caso de contrastes de dos medias con muestras independientes).</p>

<div class="rmdimportant">
<p>Usad tests paramétricos siempre que podáis, pero solo cuando podáis:</p>
<ul>
<li><p>Los mejores tests no paramétricos suelen tener potencia inferior a los mejores tests paramétricos.</p></li>
<li><p>Los tests no paramétricos no suelen producir intervalos de confianza, solo p-valores.</p></li>
<li><p>Pero usar, por ejemplo, un test t cuando no toca, porque alguna variable no sea normal y alguna muestra sea pequeña, puede llevar a conclusiones equivocadas.</p></li>
</ul>
</div>

<div class="rmdexercici">
<p>Típca pregunta de MIR (esta, de 2017):</p>
<p>El grosor del pliegue subcutáneo de grasa a nivel del tríceps se utiliza a veces para evaluar la cantidad de grasa corporal. Esta variable no se distribuye normalmente en las poblaciones. Queremos comparar el valor medio de esta variable en dos poblaciones que suponemos presentan distinta condición nutricional. La prueba estadística más adecuada para contrastar la hipótesis es:</p>
<ul>
<li>La prueba de Mann-Whitney.<br />
</li>
<li>La prueba t de Student.<br />
</li>
<li>El cálculo del coeficiente de correlación de Pearson.</li>
<li>La prueba F de Snedecor.</li>
</ul>
</div>
</div>
<div id="ejemplos" class="section level3 hasAnchor" number="15.1.4">
<h3><span class="header-section-number">15.1.4</span> Ejemplos<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#ejemplos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="example">
<p><span id="exm:temp" class="example"><strong>Ejemplo 15.1  </strong></span>La temperatura media del cuerpo humano, ¿es el valor comúnmente aceptado de 37<sup>o</sup> C?</p>
</div>
<p>Primero de todo, traducimos esta pregunta en un contraste de hipótesis:</p>
<ul>
<li><p><strong>Variable aleatoria poblacional</strong>: <span class="math inline">\(X\)</span>: temperatura del cuerpo humano en <sup>o</sup>C, de media <span class="math inline">\(\mu\)</span></p></li>
<li><p><strong>Contraste</strong>:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu=37\\
H_{1}:\mu\neq 37
\end{array}\right.
\]</span></p></li>
</ul>
<p>Necesitamos una muestra de temperaturas. Vamos a usar las recogidas por P.A. Mackowiak, S. S. Wasserman y M.M. Levine que ya usamos en el Ejemplo <a href="intervalos-de-confianza.html#exm:tempsIC">13.9</a>, y que tenemos guardadas (en grados C) en la variable <strong>Temperatura</strong> de la tabla de datos <strong>Temperaturas.txt</strong>.</p>
<p>El código siguiente define un vector llamado <code>Temps</code> con estas temperaturas y calcula su tamaño (la función <code>str(Temperaturas)</code> nos muestra la estructura de la tabla de datos <code>Temperaturas</code> que hemos definido al importar el fichero <strong>Temperaturas.txt</strong>):</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb80-1" tabindex="-1"></a>Temperaturas<span class="ot">=</span><span class="fu">read.table</span>(<span class="st">&quot;Temperaturas.txt&quot;</span>,<span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb80-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb80-2" tabindex="-1"></a><span class="fu">str</span>(Temperaturas)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    230 obs. of  3 variables:
##  $ Sexo       : chr  &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; ...
##  $ Pulsaciones: int  69 72 68 75 68 79 71 73 77 81 ...
##  $ Temperatura: num  36.1 37.1 35.7 36.6 37.1 38.5 36.6 36.3 37.3 37.3 ...</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb82-1" tabindex="-1"></a>Temps<span class="ot">=</span>Temperaturas<span class="sc">$</span>Temperatura</span>
<span id="cb82-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb82-2" tabindex="-1"></a><span class="fu">length</span>(Temps)</span></code></pre></div>
<pre><code>## [1] 230</code></pre>
<p>Como la muestra es muy grande, podemos usar un test t:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb84-1" tabindex="-1"></a><span class="fu">t.test</span>(Temps, <span class="at">mu=</span><span class="dv">37</span>, <span class="at">alternative=</span><span class="st">&quot;two.sided&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  Temps
## t = -5.7104, df = 229, p-value = 3.479e-08
## alternative hypothesis: true mean is not equal to 37
## 95 percent confidence interval:
##  36.76549 36.88581
## sample estimates:
## mean of x 
##  36.82565</code></pre>
<p>El resultado contiene:</p>
<ul>
<li>El p-valor (<code>p-value</code>) del contraste: 3.5·10<sup>-8</sup>, muy pequeño</li>
<li>El intervalo de confianza del 95% (<code>95 percent confidence interval</code>): va de 36.76549<sup>o</sup> C a 36.88581<sup>o</sup> C</li>
<li>La media muestral (<code>mean of x</code>): 36.82565</li>
</ul>
<p>Por tanto, hemos encontrado evidencia estadísticamente significativa de que la temperatura media del cuerpo humano no es de 37<sup>o</sup> C, y estimamos con un 95% de confianza que esta temperatura media está entre 36.8<sup>o</sup> C a 36.9<sup>o</sup> C, entre una y dos décimas por debajo del valor usual de 37<sup>o</sup> C. Si esto es clínicamente importante o no para definir “fiebre” ya no es un problema de estadística.</p>
<div class="example">
<p><span id="exm:tempHD" class="example"><strong>Ejemplo 15.2  </strong></span>La temperatura media de las hombres, ¿es menor que la de las mujeres?</p>
</div>
<p>Traducimos esta pregunta en un contraste de hipótesis:</p>
<ul>
<li><p><strong>Variables aleatorias poblacionales</strong>:</p>
<ul>
<li><span class="math inline">\(X_h\)</span>: temperatura de un hombre en <sup>o</sup>C, de media <span class="math inline">\(\mu_h\)</span></li>
<li><span class="math inline">\(X_m\)</span>: temperatura de una mujer en <sup>o</sup>C, de media <span class="math inline">\(\mu_m\)</span></li>
</ul></li>
<li><p><strong>Contraste</strong>:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_h=\mu_m\\
H_{1}:\mu_h&lt; \mu_m
\end{array}\right.
\]</span></p></li>
</ul>
<p>Necesitamos una muestra de temperaturas de hombres y de mujeres. La tabla de datos <strong>Temperaturas.txt</strong> que hemos usado en el ejemplo anterior contiene una variable <strong>Sexo</strong> con el sexo de los sujetos: <strong>M</strong> para hombres y <strong>F</strong> para mujeres. La muestra fue trasnversal, así que las muestras de hombres y mujeres son independientes (las que salieron en la muestra global).</p>
<p>El código siguiente define vectores <code>TempsH</code> y <code>TempsM</code> con las temperaturas de los hombres y las mujeres de esta tabla, y calcula sus tamaños:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb86-1" tabindex="-1"></a>TempsH<span class="ot">=</span>Temperaturas[Temperaturas<span class="sc">$</span>Sexo<span class="sc">==</span><span class="st">&quot;M&quot;</span>,<span class="st">&quot;Temperatura&quot;</span>] <span class="co">#Temperaturas de hombres</span></span>
<span id="cb86-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb86-2" tabindex="-1"></a><span class="fu">length</span>(TempsH)</span></code></pre></div>
<pre><code>## [1] 114</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb88-1" tabindex="-1"></a>TempsM<span class="ot">=</span>Temperaturas[Temperaturas<span class="sc">$</span>Sexo<span class="sc">==</span><span class="st">&quot;F&quot;</span>,<span class="st">&quot;Temperatura&quot;</span>] <span class="co">#Temperaturas de mujeres</span></span>
<span id="cb88-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb88-2" tabindex="-1"></a><span class="fu">length</span>(TempsM)</span></code></pre></div>
<pre><code>## [1] 116</code></pre>
<p>Las muestras de hombres y mujeres son grandes (116 y 114 sujetos, respectivamente), podemos usar un test t. Como estamos usando dos muestras independientes, necesitamos saber si <span class="math inline">\(X_h\)</span> y <span class="math inline">\(X_m\)</span> tienen la misma varianza. Lo que vamos a hacer es realizar el test bajo ambs supuestos y cruzar los dedos para que salga lo mismo.</p>
<ul>
<li>Suponiendo que las varianzas son iguales:</li>
</ul>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb90-1" tabindex="-1"></a><span class="fu">t.test</span>(TempsH, TempsM, <span class="at">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="at">paired=</span><span class="cn">FALSE</span>, <span class="at">var.equal=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  TempsH and TempsM
## t = -2.5728, df = 228, p-value = 0.005361
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##         -Inf -0.05557844
## sample estimates:
## mean of x mean of y 
##  36.74737  36.90259</code></pre>
<ul>
<li>Suponiendo que las varianzas son diferentes:</li>
</ul>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb92-1" tabindex="-1"></a><span class="fu">t.test</span>(TempsH, TempsM, <span class="at">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="at">paired=</span><span class="cn">FALSE</span>, <span class="at">var.equal=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  TempsH and TempsM
## t = -2.5708, df = 225.42, p-value = 0.005395
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##         -Inf -0.05549587
## sample estimates:
## mean of x mean of y 
##  36.74737  36.90259</code></pre>
<p>En ambos casos el p-valor (<code>p-value</code>) es del orden de 0.005, muy pequeño. Así, pues, hemos obtenido evidencia estadísticamente significativa que los hombres tienen una temperatura corporal media inferior a la de las mujeres. Además, ambos intervalos de confianza del 95% (<code>95 percent confidence interval</code>) van de <span class="math inline">\(-\infty\)</span> (<code>-Inf</code>) a alrededor de -0.055, por lo que tenemos un 95% de confianza de que la temperatura corporal media de los hombres es 0.06<sup>o</sup> C (6 centésimas de grado) menor que la de las mujeres. Las medias muestrales <span class="math inline">\(\overline{X}_h\)</span> y <span class="math inline">\(\overline{X}_h\)</span> (<code>mean of x</code> y <code>mean of y</code>; fijaos que hemos entrado en primer lugar las temperaturas de los hombres, por lo que <code>x</code> representa <code>TempsH</code> y <code>y</code> representa <code>TempsM</code>) han sido 36.75<sup>o</sup> C y 36.9<sup>o</sup> C, respectivamente, por lo que la media muestral de temperaturas de mujeres ha sido 0.15<sup>o</sup> C mayor que la de temperaturas de hombres.</p>
<div class="example">
<p><span id="exm:oatbran" class="example"><strong>Ejemplo 15.3  </strong></span>Desayunar salvado de avena en lugar de copos de maíz, ¿ayuda a reducir el nivel de colesterol?</p>
</div>
<p>Planteémoslo como un contraste de hipótesis.</p>
<ul>
<li><p><strong>Variables aleatorias poblacionales</strong>:</p>
<ul>
<li><span class="math inline">\(X_{ob}\)</span>: nivel de colesterol al consumir salvado de avena (<em>oat bran</em>), de media <span class="math inline">\(\mu_{ob}\)</span></li>
<li><span class="math inline">\(X_{cf}\)</span>: nivel de colesterol al consumir copos de maíz (<em>corn flakes</em>), de media <span class="math inline">\(\mu_{cf}\)</span></li>
</ul></li>
<li><p><strong>Contraste</strong>:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\mu_{ob}=\mu_{cf}\\
H_{1}:\mu_{ob}&lt; \mu_{cf}
\end{array}\right.
\]</span></p></li>
</ul>
<p>Vamos a usar los datos obtenidos por J. Anderson <em>et al</em> en su estudio <a href="https://academic.oup.com/ajcn/article-abstract/52/3/495/4650821">“Oat-bran cereal lowers serum total and LDL cholesterol in hypercholesterolemic men</a> (<em>The American journal of clinical nutrition</em> 52 (1990), pp. 495-499). Se trata de un ensayo clínico cruzado sobre 14 individuos. A cada uno de ellos se le asignó uno de los dosdesayunos de manera aleatoria y lo tomaron durante 15 días. Al final de este periodo, se les midió el nivel de colesterol en sangre. Pasado un mes de descanso, cada participante desayunó durante 15 días el otro producto, y al final se los volvió a medir el nivel de colesterol en sangre. Tenemos los niveles de colesterol que obtuvieron en la tabla de datos <strong>oatbran.txt</strong>, donde están medidos en milimoles por litro (mmol/l), así que esta será la unidad que tomamos en las variables poblacionales.</p>
<p>Cargamos la tabla de datos, consultamos su contenido y extraemos los vectores correspondientes a los niveles de colesterol para cada tipo de desayuno: <code>OAT</code> para <em>oatbran</em> y <code>CFL</code> para <em>cornflakes</em>.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb94-1" tabindex="-1"></a>OBR<span class="ot">=</span><span class="fu">read.table</span>(<span class="st">&quot;oatbran.txt&quot;</span>,<span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb94-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb94-2" tabindex="-1"></a><span class="fu">str</span>(OBR)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    14 obs. of  2 variables:
##  $ CORNFLK: num  4.61 6.42 5.4 4.54 3.98 3.82 5.01 4.34 3.8 4.56 ...
##  $ OATBRAN: num  3.94 5.57 5.85 4.8 3.68 2.96 4.41 3.72 3.49 3.94 ...</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb96-1" tabindex="-1"></a>Oatbran<span class="ot">=</span>OBR<span class="sc">$</span>OATBRAN</span>
<span id="cb96-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb96-2" tabindex="-1"></a>Cornflake<span class="ot">=</span>OBR<span class="sc">$</span>CORNFLK</span></code></pre></div>
<p>Como unas muestras de tamaño 14 son pequeñas, si queremos aplicar un test t necesitamos que provengan de variables normales. Para decidir si esto es verdad o no, se puede usar un <strong>contraste de bondad de ajuste</strong>, con hipótesis nula “Esta muestra proviene de una variable aleatoria con tal distribución” e hipótesis alternativa “No es verdad que esta muestra provenga de una variable aleatoria con tal distribución”. Pero aun no los hemos explicado, así que por ahora nos conformaremos con decidirlo a partir de un gráfico.</p>
<p>Una posibilidad es dibujar un histograma de la muestra y añadir la densidad de una distribución normal con media y desviación típica las de la muestra, y mirar si parece que los datos siguen esta distribución normal. Pero con pocos datos esto es difícil de ver:</p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-594-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>En este caso, una opción mejor es dibujar un <strong>q-q-plot</strong>. Un <strong>q-q-plot</strong> de una muestra y una distribución teórica es el gráfico de los llamados <strong>q-q-puntos</strong>: los puntos de la forma <em>(<span class="math inline">\(q\)</span>-cuantil de la distribución, <span class="math inline">\(q\)</span>-cuantil de la muestra)</em>, para varios valores de <span class="math inline">\(q\)</span>.</p>
<p>Si la muestra proviene de la distribución usada para dibujar el q-q-plot, es de esperar que el q-cuantil de la muestra sea muy parecido al q-cuantil de la distribución y por lo tanto que estos q-q-puntos estén cerca de la diagonal principal <span class="math inline">\(y=x\)</span>.</p>
<p>La función <code>qqPlot</code> del paquete <strong>car</strong> produce unos q-q-plots adecuados que además muestran una “región de confianza del 95%”, con el significado usual de nivel de confianza (para el 95% de las muestras de la distribución, los q-q-plot caen dentro de esta región; por lo tanto, si nuestro q-q-plot está completamente dentro de esta región, aceptamos con este nivel de confianza que proviene de la distribución usada).</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb97-1" tabindex="-1"></a><span class="fu">require</span>(car)</span>
<span id="cb97-2"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb97-2" tabindex="-1"></a><span class="fu">qqPlot</span>(Oatbran, <span class="at">distribution=</span><span class="st">&quot;norm&quot;</span>, <span class="at">mean=</span><span class="fu">mean</span>(Oatbran), <span class="at">sd=</span><span class="fu">sd</span>(Oatbran),</span>
<span id="cb97-3"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb97-3" tabindex="-1"></a>        <span class="at">ylab=</span><span class="st">&quot;Cuantiles de OATBRAN&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Cuantiles de normal&quot;</span>, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">id=</span><span class="cn">FALSE</span>)</span>
<span id="cb97-4"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb97-4" tabindex="-1"></a><span class="fu">qqPlot</span>(Cornflake, <span class="at">distribution=</span><span class="st">&quot;norm&quot;</span>, <span class="at">mean=</span><span class="fu">mean</span>(Cornflake),<span class="at">sd=</span><span class="fu">sd</span>(Cornflake),</span>
<span id="cb97-5"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb97-5" tabindex="-1"></a>       <span class="at">ylab=</span><span class="st">&quot;Cuantiles de CORNFLK&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Cuantiles de normal&quot;</span>, <span class="at">pch=</span><span class="dv">20</span>, <span class="at">id=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-596-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Aceptamos por lo tanto que nuestros datos provienen de dos distribuciones normales: podemos usar un test t de dos medias.</p>
<p>En este caso, el test t es de muestras emparejadas (hemos medido las dos variable aleatorias sobre los mismos individuos), por lo que tenemos que especificar <code>paired=TRUE</code> y no tenemos que especificar el parámetro <code>var.equal</code>. Usaremos el parámetro <code>alternative="less"</code> para indicar que el test es unilateral: la hipótesis alternativa es que la media de la primera variable es más pequeña que la de la segunda.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb98-1" tabindex="-1"></a><span class="fu">t.test</span>(Oatbran, Cornflake, <span class="at">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="at">paired=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  Oatbran and Cornflake
## t = -3.3195, df = 13, p-value = 0.002768
## alternative hypothesis: true mean difference is less than 0
## 95 percent confidence interval:
##        -Inf -0.1626132
## sample estimates:
## mean difference 
##      -0.3485714</code></pre>
<p>Obtenemos un p-valor de 0.003. Por lo tanto, hemos encontrado evidencia estadísticamente significativa de que desayunar salvado reduce el nivel medio de colesterol respecto de desayunar copos de maíz. El intervalo de confianza del 95% para <span class="math inline">\(\mu_{ob}-\mu_{cf}\)</span> va de <span class="math inline">\(-\infty\)</span> a -0.163. Por lo tanto, tenemos un 95% de confianza en que desayunar salvado reduce en al menos 0.163 mmol/l el nivel medio de colesterol respecto de desayunar copos de maíz.</p>
<p>¿Y si no quisiéramos, o no pudiéramos, suponer que las muestras provienen de distribuciones normales? Entonces usaríams un test de Wilcoxon:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#cb100-1" tabindex="-1"></a><span class="fu">wilcox.test</span>(Oatbran, Cornflake, <span class="at">alternative=</span><span class="st">&quot;less&quot;</span>, <span class="at">paired=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  Oatbran and Cornflake
## V = 12, p-value = 0.006008
## alternative hypothesis: true location shift is less than 0</code></pre>
<p>El p-valor da 0.006, por lo que la conclusión es la misma, pero no nos da intervalo de confianza.</p>
<!--
::: {.example #fototerapia}
La fototerapia, ¿es más eficaz  como tratamiento del eccema atípico que un placebo?
  

:::

Para comprobar la eficacia de la fototerapia como tratamiento del eccema atípico, se tomaron 10 pacientes con un eccema de más de 9 meses y se los trató durante dos periodos de 3 semanas (ordenados aleatoriamente y separados por un periodo de recuperación) con un placebo y con fototerapia.

Después de cada periodo de tratamiento, se evaluó en cada paciente  la importancia del eccema en una escala de 0 (no eccema) a 10 (máximo eccema). Resultados:
\begin{center}
\begin{tabular}{l|cccccccccc}
Placebo&6&8&3&8&5&6&5&6&4&5\\\hline
Fototerapia&5&6&4&5&3&5&6&2&2&6
\end{tabular}
\end{center}


\frametitle{Ejemplo 4}

**Variables aleatorias de interés}:
\begin{itemize}
* $X_1$: Importancia del eccema tras la fototerapia, de media $\mu_1$
* $X_2$: Importancia del eccema tras el placebo, de media $\mu_2$
\end{itemize}

**Contraste}:
$$
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\
H_{1}:\mu_1< \mu_2
\end{array}\right.
$$

**Datos}: La tabla anterior. Observad que es un contraste con muestras emparejadas.

Como la muestra es pequeña y no sabemos si $X_1$ y $X_2$ son normales (en realidad, son ordinales), usaremos el test de Wilcoxon




[fragile]
\frametitle{Ejemplo 4}

\begin{lstlisting}
> X.fot=c(5,6,4,5,3,5,6,2,2,6)
> X.pl=c(6,8,3,8,5,6,5,6,4,5)
> wilcox.test(X.fot, X.pl, 
   alternative="less",paired=TRUE)
    Wilcoxon signed rank test with continuity correction

data:  X.fot and X.pl
V = 9, p-value = 0.03116
alternative hypothesis: true location shift is less than 0
\end{lstlisting}



**Conclusión}: Como el \blue{p-valor $=0.03<0.005$}, concluimos a este nivel de significación que la fototerapia es, de media, más efectiva que el placebo
-->
</div>
</div>
<div id="contrastes-de-varianzas" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Contrastes de varianzas<a href="contrastes-de-hipótesis-uni--y-biparamétricos.html#contrastes-de-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sean <span class="math inline">\(X_1,X_2\)</span> dos variables aleatorias normales de desviaciones típicas <span class="math inline">\(\sigma_1\)</span>, <span class="math inline">\(\sigma_2\)</span></p>
<p>Nos interesa el contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:\sigma_1=\sigma_2\\
H_{1}:\sigma_1\neq \sigma_2
\end{array}
\right.
\mbox{ o, equivalentemente, }
\left\{\begin{array}{l}
H_{0}:\sigma_1^2=\sigma_2^2\\
H_{1}:\sigma_1^2\neq \sigma_2^2
\end{array}
\right.\]</span>
En este caso se usa el <strong>F-test}, basado en el estadístico <span class="math inline">\(\widetilde{S}^2_{X_1}/\widetilde{S}^2_{X_2}\)</span> que (si <span class="math inline">\(H_0\)</span> es cierta) tiene una distribución conocida (la </strong>F de Fisher-Snedecor}, `f} con R)</p>
<p>Implementado en la función **<code>var.test}} de R: se aplica a las dos muestras, con sintaxis similar a</code>t.test}</p>
<p>El test F-test no sirve a poco que las variables difieran de normales</p>
<p>En este caso, es necesario usar un test no paramétrico</p>
<p>Os recomendamos usar el <strong>test de Fligner-Killeen}, implementado en R en la función </strong>`fligner.test}}, que en la práctica ha mostrado ser más exacto (mayor suma de especificidad y sensibilidad) para variables aleatorias muy diferentes de normales</p>
[fragile]
<p>Vamos a suponer que ambas son normales (los temperaturas lo suelen ser)</p>
**Conclusión}:
<p>Por lo tanto, si los tests t con <code>var.equal=TRUE} y</code>var.equal=FALSE} hubieran dado conclusiones diferentes, tomaríamos la correspondiente a varianzas iguales</p>
<p>¿Era adecuado suponer que provienen de distribuciones normales?</p>
<p>hics[width=0.5]{histTF}
\end{center}</p>
<p>¿Era adecuado suponer que provienen de distribuciones normales?</p>
<p>hics[width=0.5]{qqplotTF}
\end{center}</p>
<p>Mejor usar un test no paramétrico, para mayor seguridad</p>
[fragile]
<p>Aceptamos que <span class="math inline">\(X_h\)</span> y <span class="math inline">\(X_m\)</span> tienen la misma varianza</p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria Bernoulli de parámetro <span class="math inline">\(p\)</span></p>
<p>Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p=p_0\\
H_{1}:p\neq p_0\text{ o }p&gt; p_0\text{ o }p&lt; p_0
\end{array}
\right.
\]</span></p>
<p>Podemos usar el **test binomial exacto}, que contrasta si el número de éxitos en una muestra de tamaño <span class="math inline">\(n\)</span> tiene distribución <span class="math inline">\(B(n,p_0)\)</span></p>
<p>Está implementado en la función **`binom.test}} de R: se aplica al número de éxitos, el tamaño de la muestra, el valor a contrastar <span class="math inline">\(p_0\)</span> y el nivel de confianza (por defecto, 0.95)</p>
<p>En la situación anterior, si el tamaño <span class="math inline">\(n\)</span> de la muestra es grande (<span class="math inline">\(\geq 30\)</span> o mejor <strong><span class="math inline">\(\geq 40\)</span>}), podemos usar el </strong>test aproximado}, que usa que, si <span class="math inline">\(H_0\)</span> es verdadera y <span class="math inline">\(n\)</span> grande,
<span class="math display">\[
\frac{\widehat{p}_X-p_0}{\sqrt{\frac{\widehat{p}_X(1-\widehat{p}_X)}{n}}}\approx N(0,1)
\]</span></p>
<p>Está implementado en la función **<code>prop.test}} de R con la misma sintaxis que</code>binom.test}</p>
<p>Es más popular</p>
<p>El porcentaje estimado de zurdos en España es del 10%.</p>
<p>De 30 estudiantes de la UIB encuestados al azar, 1 ha sido zurdo.</p>
<p>Sea <span class="math inline">\(p\)</span> la proporción de estudiantes zurdos en la UIB.</p>
<p>**Contraste:}
<span class="math display">\[
\left\{
\begin{array}{l}
H_0:p=0.1\\
H_1:p\neq 0.1
\end{array}
\right.
\]</span></p>
<p>**Datos}: Nuestra muestra</p>
[fragile]
Como la muestra es relativamente grande (<span class="math inline">\(n=30\)</span>) vamos a usar de entrada `prop.test}.
**Conclusión}:
[fragile]
<p>Potencia?</p>
[fragile]
¿Qué hubiera pasado con una muestra de 150 estudiantes, 5 de ellos zurdos?
[fragile]
¿Qué hubiera pasado con una muestra de 150 estudiantes, 5 de ellos zurdos?
[fragile]
¿Cuál hubiera sido la conclusión usando el test binomial?
<p>p-valor <span class="math inline">\(=0.36\)</span>, IC 95% de 0.0008 a 0.17; misma conclusión</p>
<p>Siguin <span class="math inline">\(X_1\)</span> i <span class="math inline">\(X_2\)</span> dues variables aleatorias Bernoulli de paràmetres <span class="math inline">\(p_1\)</span> i <span class="math inline">\(p_2\)</span></p>
<p>Les mesurem sobre dues mostres independents</p>
Volem realitzar un contrast
$$
{
<span class="math display">\[\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1
eq p_2\text{ o }p_1&gt; p_2\text{ o }p_1&lt; p_2
\end{array}\]</span>
<p>ight.
$$</p>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias Bernoulli de parámetros <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span></p>
<p>Las medimos sobre dos muestras independientes</p>
<p>Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2\text{ o }p_1&gt; p_2\text{ o }p_1&lt; p_2
\end{array}
\right.
\]</span></p>
Cuando las muestras son grandes, podemos usar el <strong>test <span class="math inline">\(\chi^2\)</span>}, implementado también en la función </strong>`prop.test}} de R (ya hablaremos de este test más adelante): se aplica a la tabla de frecuencias absolutas de las muestras
<p>en forma de matriz o de tabla de contingencia</p>
<p>Por otro lado, podemos usar el <strong>test exacto de Fisher}, implementado en la función </strong>`fisher.test}}: de nuevo, se aplica a la tabla de frecuencias absolutas de las muestras</p>
<p>**}: El test de Fisher en realidad no compara las proporciones <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, sino sus
<span class="math display">\[
\frac{p_1}{1-p_1}\mbox{ y }\frac{p_2}{1-p_2}
\]</span>
y el intervalo de confianza que da es para el cociente de estas odds: para su </p>
En un estudio transversal, se tomaron 1319 niños de 14 años, se miró si en ese momento tenían tos crónica y si a los 5 años habían tenido bronquitis. El resultado fue la tabla siguiente:
**Variables aleatorias de interés}:
<p>**Contraste}:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1&gt;p_2
\end{array}\right.
\]</span></p>
<p>**Datos}: La tabla anterior</p>
[fragile]
<p>Las muestras son grandes, usaremos `prop.test}</p>
**Conclusión}:
[fragile]
<p>Veamos con el test de Fisher</p>
**Conclusión}:
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables aleatorias Bernoulli de parámetros <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span></p>
<p>Las medimos sobre los sujetos de una misma muestra de tamaño <span class="math inline">\(n\)</span>, o sobre los sujetos de dos muestras del mismo tamaño <span class="math inline">\(n\)</span> con un emparejamiento definido entre los mismos (e.g., gemelos)</p>
<p>Queremos realizar un contraste
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2
\end{array}
\right.
\]</span></p>
Cuando <span class="math inline">\(n\)</span> es grande (<span class="math inline">\(\geq 100\)</span>) y el número de (<span class="math inline">\(b+c\)</span> en la tabla inferior) es razonablemente grande (<span class="math inline">\(\geq 20\)</span>), podemos usar el , que usa el estadístico
<span class="math display">\[
Z^2=\frac{(b-c)^2}{b+c}\approx \chi^2_1
\]</span>
Está implementado en la función **`mcnemar.test}}: se aplica a la tabla de frecuencias absolutas siguiente:
**Variables aleatorias de interés}:
<p>**Contraste}:
<span class="math display">\[
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\
H_{1}:p_1\neq p_2
\end{array}\right.
\]</span></p>
<p>**Datos}: En un ensayo clínico, se trató un grupo de 1244 pacientes, emparejadas según diferentes características. En cada pareja se repartieron los dos tratamientos al azar: quimioterapia perioperatoria y mastectomía o quimioterapia perioperatoria y mastectomía y quimioterapia postoperatoria durante 6 meses.</p>
<p>Supervivencia a los 5 años de las parejas de pacientes:</p>
<p><span class="math display">\[
\widehat{p}_1=\frac{515}{622}=0.828\quad
\widehat{p}_2=\frac{527}{622}=0.847
\]</span></p>
[fragile]
<p>La muestra es grande, y el número de casos discordantes supera (por poco) los 20, usaremos `macnemar.test}</p>
<p>El permite concluir que hay evidencia significativa de que hay diferencia en las tasas de supervivencia a los 5 años.</p>
<p>Si no podéis usar el test de McNemar, siempre podéis usar el , que simplemente contrasta si las probabilidades poblacionales de los pares (Sí,No) y (No,Sí) son la misma, 0.5.</p>
<p>Convenientemente implementado en la función **<code>mcnemar.exact}} del paquete</code>exact2x2}</p>
<p><strong>}: El intervalo de confianza que calcula esta función es para una estimación de la que además no es la que hemos explicado en clase. </strong>Mirad solo el p-valor}.</p>
[fragile]
<p>El es <span class="math inline">\(0.017\)</span></p>

</div>
</div>






            </section>

          </div>
        </div>
      </div>
<a href="contrastes-de-hipótesis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
