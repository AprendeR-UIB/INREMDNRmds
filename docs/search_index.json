[
["index.html", "Bioestadística (Medicina UIB) Presentación", " Bioestadística (Medicina UIB) 2020-11-19 Presentación Esto es una edición en línea de los apuntes de Introducción a la Investigación en Salud y Bioestadística del grado de Medicina de la UIB. Este trabajo se publica bajo licencia Atribución-No Comercial-SinDerivados 4.0 Estos apuntes están en construcción. En la lista siguiente iremos anunciando las actualizaciones: 2020-11-19: Publicadas las lecciones 10 a 12. 2020-11-07: Corregidos errores varios en la lección 5. 2020-11-03: Corregido error en las “consideraciones” al principio de la sección 5.2. 2020-11-01: Publicadas las lecciones 6 a 9. 2020-10-24: Publicada la lección 5. 2020-10-21: Corregido el error en la Figura 2.14 (la clasificación de los estudios de cohorte y de casos y controles estaba intercambiada). 2020-10-05: Publicada la lección 4. 2020-09-30: Cambios cosméticos en la lección 2: añadidos algunos dibujos, reescrito algunas frases, añadido un ejemplo (2.10) sobre la importancia de la elección de controles. 2020-09-27: Publicadas las lecciones 1, 2 y 3. El libro está escrito en R Markdown, usando RStudio como editor de textos y el paquete bookdown para convertir los ficheros markdown en un libro. Significado de algunas cajas: Material muy importante. ¡Cuidado! Ejercicio. Detalles matemáticos que os pueden interesar, pero que podéis obviar sin ningún problema. Comentario que queremos enfatizar. Comentario que queremos que recordéis Cuestión en la que queremos que caigáis en la cuenta. Acabamos de matar un gatito "],
["distribuciones-muestrales.html", "Lección 1 Distribuciones muestrales 1.1 Estimadores 1.2 La media muestral 1.3 La proporción muestral 1.4 La varianza muestral 1.5 La distribución t de Student 1.6 Test", " Lección 1 Distribuciones muestrales 1.1 Estimadores En un problema típico de estadística inferencial: Queremos conocer el valor de una característica en el total de una población, pero no podemos medir esta característica en todos los individuos de la población. Entonces, extraemos una muestra de la población, medimos la característica en los individuos de esta muestra, calculamos algo con los datos obtenidos e inferimos el valor de la característica en el global de la población. Inmediatamente surgen varias preguntas, que responderemos entre esta lección y la próxima: ¿Cómo tiene que ser la muestra? ¿Qué tenemos que calcular? ¿Con qué precisión podemos inferir la característica de la población? ¿Qué tipo de muestra tenemos que tomar? Vamos a suponer de ahora en adelante que tomamos muestras aleatorias simples. Esto incluye las muestras aleatorias sin reposición si la población es mucho más grande que la muestra, ya que entonces no hay diferencia práctica entre permitir y prohibir las repeticiones. En algunos casos muy concretos permitiremos muestras aleatorias sin reposición en general. Sí, ya sabemos que en la práctica casi nunca tomamos muestras aleatorias, sino oportunistas. En este caso, recordad lo que os explicábamos en la Sección ??. Lo que hay que hacer es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, es razonablemente representativa de la población y podría pasar por aleatoria. ¿Qué calculamos? Pues un estimador: alguna función adecuada aplicada a los valores de la muestra, y que dependerá de lo que queramos estimar. Por ejemplo: Si queremos estimar la altura media de los estudiantes de la UIB, tomaremos una muestra aleatoria de estudiantes de la UIB, mediremos sus alturas y calcularemos su media aritmética. Si queremos estimar la proporción de estudiantes de la UIB que han pasado la COVID-19, tomaremos una muestra aleatoria de estudiantes de la UIB, les haremos un test de anticuerpos y calcularemos la proporción muestral de positivos en la muestra. Si queremos estimar el riesgo relativo para un estudiante de la UIB de suspender alguna asignatura si es fumador, tomaremos una muestra aleatoria de estudiantes de la UIB, anotaremos si fuman o no y si han suspendido alguna asignatura o no, y calcularemos la diferencia entre las proporciones muestrales de suspensos entre los fumadores y los no fumadores de la muestra. Fijaos que un estimador es una variable aleatoria, definida sobre la población formada por las muestras de la población de partida. Por lo tanto, tiene función de densidad, función de distribución (que genéricamente llamaremos distribución muestral, para indicar que mide la probabilidad de que le pase algo al valor del estimador sobre una muestra), esperanza, desviación típica, etc. 1.2 La media muestral Cuando queremos estimar el valor medio de una variable sobre una población, tomamos una muestra de valores y calculamos su media aritmética, ¿verdad? Pues eso es la media muestral. Dada una variable aleatoria \\(X\\), llamamos media muestral de (muestras de) tamaño \\(n\\)) a la variable aleatoria \\(\\overline{X}\\) “Tomamos una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calculamos la media aritmética de sus valores”. Fijaos en que definimos la media muestral solo para muestras aleatorias simples. Naturalmente, tiene sentido definirla para muestras cualesquiera, pero entonces en general su distribución muestral dejaría de cumplir las propiedades que damos en esta sección. Lo mismo se aplica a los estimadores que definimos en las próximas secciones. Veamos algunas propiedades de la distribución muestral de \\(\\overline{X}\\): Teorema 1.1 Sea \\(X\\) una variable aleatoria de media \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\), y sea \\(\\overline{X}\\) la media muestral de tamaño \\(n\\) de \\(X\\). Entonces: \\(E(\\overline{X})=\\mu_X\\) \\(\\sigma(\\overline{X})=\\dfrac{\\sigma_X}{\\sqrt{n}}\\) Formalmente, la media muestral de tamaño \\(n\\) de una variable aleatoria \\(X\\) se define como la variable aleatoria \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] donde \\(X_1,\\ldots,X_n\\) son \\(n\\) copias independientes de la variable \\(X\\). Entonces, por la linealidad de la esperanza \\[ E(\\overline{X})=\\frac{E(X_1)+\\cdots+E(X_n)}{n}=\\frac{n\\cdot \\mu_X}{n}=\\mu_X \\] porque, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(E(X_1)=\\cdots=E(X_n)=\\mu_X\\). Y por la linealidad de la varianza de la suma de variables independientes \\[ \\sigma(\\overline{X})^2=\\frac{\\sigma(X_1)^2+\\cdots+\\sigma(X_n)^2}{n^2}=\\frac{n\\cdot \\sigma_X^2}{n^2}=\\frac{\\sigma_X^2}{n} \\] porque, de nuevo, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(\\sigma(X_1)^2=\\cdots=\\sigma(X_n)^2=\\sigma_X^2\\). Que \\(E(\\overline{X})\\) sea \\(\\mu_X\\) nos indica que \\(\\overline{X}\\) sirve para estimar \\(\\mu_X\\), porque su valor esperado es \\(\\mu_X\\): Si calculáramos muchas medias de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a \\(\\mu_X\\). Cuando el valor esperado de un estimador es precisamente el parámetro poblacional que se quiere estimar, se dice que el estimador es insesgado. Así, el primer punto del teorema anterior nos dice que la media muestral \\(\\overline{X}\\) es un estimador insesgado de la media poblacional \\(\\mu_X\\). Que \\(\\sigma(\\overline{X})\\) sea \\(\\sigma_X/\\sqrt{n}\\) implica que la variabilidad de las medias muestrales crece con la variabilidad de \\(X\\) y decrece si tomamos muestras de mayor tamaño. Esto último es razonable. Aunque la variabilidad de \\(X\\) sea grande, si tomamos muestras grandes, al calcular la media los valores extremos se compensarán y las medias resultantes tendrán menos variabilidad que \\(X\\). A \\(\\sigma_X/\\sqrt{n}\\) se le llama el error típico de la media muestral (para la variable aleatoria \\(X\\) y muestras de tamaño \\(n\\)). Ejemplo 1.1 Vamos a realizar un experimento. Vamos a tomar una población de 106 sujetos y una variable aleatoria \\(X\\) que sobre cada sujeto toma un valor real entre 0 y 1, todos estos valores con la misma probabilidad. Llamaremos X al vector con los 106 valores de esta variable aleatoria, y dibujaremos un histograma de este vector de números para que veáis que los valores salen muy dispersos. Mostramos el código de R para que podáis repetir el experimento por vuestra cuenta; como es una simulación, cada vez que lo ejecutéis dará resultados diferentes, pero el mismo efecto global. X=runif(10^6) hist(X,freq=FALSE,main=&quot;Histograma de X&quot;,xlab=&quot;&quot;,ylab=&quot;Densidad&quot;) La desviación típica \\(\\sigma_X\\) de la variable \\(X\\) sobre nuestra población es sd(X) ## [1] 0.2886765 Ahora vamos a tomar 1000 medias muestrales de tamaño 100 de esta población, las organizaremos en un vector que llamaremos Medias y dibujaremos un histograma de este vector de medias. Medias=replicate(1000,mean(sample(X,100,replace=TRUE))) hist(Medias,freq=FALSE,main=&quot;Histograma de las medias muestrales&quot;,xlab=&quot;&quot;,ylab=&quot;Densidad&quot;) Podéis observar cómo los valores de estas medias se concentran alrededor de 0.5. Veamos su desviación típica: sd(Medias) ## [1] 0.02907574 Fijaos cómo se acerca mucho al valor \\(\\sigma_X/\\sqrt{100}=0.02886765\\) predicho por el teorema anterior. No coinciden exactamente, porque \\(\\sigma_X/\\sqrt{100}\\) es el valor de la desviación típica poblacional de \\(\\overline{X}\\), es decir, para toda la “población” de medias muestrales de muestras aleatorias simples de tamaño 100 de nuestra población de partida, y nosotros hemos tomado una muestra de “solo” 1000 medias de estas. La media muestral \\(\\overline{X}\\) de tamaño \\(n\\) de una variable aleatoria \\(X\\) se interpreta formalmente como la variable aleatoria obtenida tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n}. \\] Por lo tanto, es una combinación lineal de \\(n\\) copias independientes de \\(X\\). Recordando que una combinación de variables aleatorias normales independientes es normal, tenemos el resultado siguiente: Teorema 1.2 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\), entonces \\(\\overline{X}\\) es \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\), y por lo tanto \\[ Z=\\frac{\\overline{X}-\\mu_X}{\\sigma_X/\\sqrt{n}} \\] es \\(N(0,1)\\). Si \\(X\\) no es normal, la tesis del teorema anterior sigue siendo cierta “aproximadamente” siempre y cuando \\(n\\) es grande. Este resultado, llamado el Teorema Central del Límite es, como su nombre indica, uno de los más importantes en estadística. Teorema 1.3 Sea \\(X\\) una variable aleatoria cualquiera de esperanza \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\). Si \\(n\\) es suficientemente grande, \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X, {\\sigma_X}/{\\sqrt{n}})\\) y por lo tanto \\[ Z=\\frac{\\overline{X}-\\mu_X}{{\\sigma_X}/{\\sqrt{n}}} \\] es aproximadamente \\(N(0,1)\\). Dos observaciones: ¿Cuándo una muestra es lo suficientemente grande como para poder invocar el Teorema Central del Límite? En realidad, depende de la \\(X\\). Cuánto más se parezca \\(X\\) a una variable normal, más pequeñas pueden ser la muestras. Por fijar un valor, aceptaremos que “suficientemente grande” es \\(n\\geq 40\\). ¿Qué quiere decir que una variable aleatoria sea “aproximadamente” normal? Pues que su función de distribución \\(F_X\\) toma valores muy cercanos a la función de distribución de una normal. Recordad cómo una \\(B(n,p)\\) con \\(n\\) grande era “aproximadamente normal” en la lección anterior. Si miráis el histograma de las 1000 medias muestrales del Ejemplo 1.1, veréis que se parece al de una muestra de una variable normal. Es que \\(\\overline{X}\\) es aproximadamente normal, por el Teorema Central del Límite, aunque la variable \\(X\\) sea muy diferente de una normal. En resumen: Si \\(X\\) es normal, \\(\\overline{X}\\) es \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\). Si \\(X\\) no es normal pero \\(n\\) es grande (pongamos \\(n\\geq 40\\), aunque puede ser menor si \\(X\\) se parece a una normal y seguramente tendrá que ser mayor si \\(X\\) es muy diferente de una normal), \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\). Las afirmaciones del bloque anterior son verdaderas para medias muestrales de muestras aleatorias simples. Si la muestra que usemos no podemos suponer que sea aleatoria simple, ninguno de los dos resultados es válido. Per bueno, si no tenemos nada más… 1.3 La proporción muestral Cuando queremos estimar la proporción de sujetos de una población que tienen una determinada característica, tomamos una muestra y calculamos la proporción de sujetos de la muestra con esta característica. Esta será la proporción muestral de sujetos con esta característica en nuestra muestra. Dada una variable aleatoria \\(X\\) de Bernoulli \\(Be(p_X)\\), llamamos proporción muestral, \\(\\widehat{p}_X\\), a la variable aleatoria consistente en tomar una muestra aleatoria de tamaño \\(n\\) de \\(X\\) y calcular la proporción de éxitos en la muestra: es decir, contar el número total de éxitos y dividir el resultado por \\(n\\). Fijaos en que \\(\\widehat{p}_X\\) es un caso particular de media muestral \\(\\overline{X}\\): estamos calculando medias muestrales de muestras de la variable de Bernoulli \\(X\\). Por lo tanto, todo lo que hemos dicho para medias muestrales vale también para proporciones muestrales: Teorema 1.4 Si \\(X\\) es una variable aleatoria de Bernoulli con probabilidad poblacional de éxito \\(p_X\\): \\(E(\\widehat{p}_X)=p_X\\) \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\). \\(E(\\widehat{p}_X)=p_X\\) nos dice que \\(\\widehat{p}_X\\) es un estimador insesgado de \\(p_X\\). Si calculáramos muchas proporciones muestrales de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a la proporción poblacional de éxitos \\(p_X\\). \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) nos dice que, fijada la variable \\(X\\), si tomamos muestras de tamaño mayor, la variabilidad de los resultados de \\(\\widehat{p}_X\\) disminuye. En el caso de la proporción muestral, a veces vamos a permitir tomar muestras aleatorias sin reposición. En este caso, seguimos teniendo que \\(E(\\widehat{p}_X)=p_X\\), pero ahora, si \\(N\\) es el tamaño de la población, \\[ \\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(p_X}N-n}{N-1}}. \\] A este factor \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que transforma \\(\\sigma({\\widehat{p}_X})\\) para muestras aleatorias simples en la desviación típica de \\({\\widehat{p}_X}\\) para muestras aleatorias sin reposición se le llama el factor de población finita, y si os fijáis, es el que transformaba la desviación típica de una variable binomial (que cuenta éxitos en muestras aleatorias simples) en la desviación típica de una variable hipergeométrica (que cuenta éxitos en muestras aleatorias sin reposición). Y recordad que si el tamaño de la población \\(N\\) es muy grande comparado con \\(n\\), podemos suponer que una muestra aleatoria sin reposición es simple. Si tomamos muestras aleatorias simples de tamaño \\(n\\) de una variable aleatoria Bernoulli \\(X\\): \\(\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) es el error típico de la variable aleatoria \\(\\widehat{p}_X\\): su desviación típica. Para cada muestra, \\(\\sqrt{\\dfrac{\\widehat{p}_X(1-\\widehat{p}_X)}{n}}\\) es el error típico de la muestra, que estima el error típico de \\(\\widehat{p}_X\\). Y como la proporción muestral es un caso particular de media muestral, por el Teorema Central del Límite tenemos el resultado siguiente: Teorema 1.5 Si \\(n\\) es grande y las muestras aleatorias son simples, \\(\\widehat{p}_X\\) es aproximadamente \\(N\\big (p_X,\\sqrt{{p_X(1-p_X)}/{n}}\\big)\\) y por lo tanto \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}} \\] es aproximadamente \\(N(0,1)\\). 1.4 La varianza muestral Dada una variable aleatoria \\(X\\), llamamos: Varianza muestral, \\(\\widetilde{S}_{X}^2\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la varianza muestral de sus valores. Desviación típica muestral, \\(\\widetilde{S}_{X}\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la desviación típica muestral de sus valores. Formalmente, estas variables se definen tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1},\\quad \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] Tenemos los dos resultados siguientes para variables poblacionales normales. El primero nos dice que en este caso \\(\\widetilde{S}_{X}^2\\) es un estimador insesgado de la varianza poblacional \\(\\sigma_{X}^2\\). Teorema 1.6 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\), \\(E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2\\). Por lo tanto, si \\(X\\) es normal, esperamos que la varianza muestral de una muestra aleatoria simple grande sea \\(\\sigma_{X}^2\\), en el sentido usual de que si tomamos muestras aleatorias simples de \\(X\\) de tamaño \\(n\\) grande y calculamos sus varianzas muestrales, esperamos de media obtener un valor muy cercano a \\(\\sigma_{X}^2\\). El segundo resultado nos dice que un cierto múltiplo de \\(\\widetilde{S}_{X}^2\\) tiene distribución muestral conocida, lo que nos permite calcular la probabilidad de que le pase algo a \\(\\widetilde{S}_{X}^2\\). Teorema 1.7 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras de tamaño \\(n\\), la variable aleatoria \\[ \\chi^2= \\dfrac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] tiene una distribución conocida, llamada ji cuadrado con \\(n-1\\) grados de libertad, \\(\\chi_{n-1}^2\\). La distribución \\(\\chi_m^2\\) (la letra griega \\(\\chi\\) en castellano se lee ji; en catalán, khi; en inglés, chi, pronunciado “xai”), donde \\(m\\) es un parámetro llamado sus grados de libertad, es la distribución de probabilidad de la suma de los cuadrados de \\(m\\) variables aleatorias normales estándar independientes. Para R es chisq. Os puede interesar recordar que una variable \\(\\chi_m^2\\) de tipo ji cuadrado con \\(m\\) grados de libertad: Tien valor esperado \\(E(\\chi_m^2)=m\\) y varianza \\(\\sigma(\\chi_m^2)^2=2 m\\). Tiene una distribución asimétrica a la derecha, como muestra el gráfico siguiente: A medida que el número de grados de libertad \\(m\\) crece, la asimetría tiende a desaparecer y, por el Teorema Central del Límite, la distribución \\(\\chi_m^2\\) se aproxima a la de una variable normal \\(N(m,\\sqrt{2m})\\). Tened cuidado: Si la variable poblacional \\(X\\) no es normal, las conclusiones de los dos teoremas anteriores no son verdaderas, ni tan solo aproximadamente. Aunque \\(X\\) sea normal, \\(E(\\widetilde{S}_{X})\\neq \\sigma_{X}\\). La desviación típica muestral es un estimador sesgado de \\(\\sigma_{X}\\) (pero tiene otras buenas propiedades que hacen que lo usemos igualmente). Aunque \\(X\\) sea normal, si \\(S^2_{X}\\) es la varianza “a secas” (dividiendo por \\(n\\) en vez de por \\(n-1\\)), \\(E(S^2_{X})\\neq \\sigma^2_{X}\\). Esto lo podéis comprobar fácilmente, porque \\(S_X^2\\) se obtiene a partir de \\(\\widetilde{S}_{X}^2\\) cambiando el denominador, \\[ S_X^2=\\frac{n-1}{n} \\widetilde{S}_{X}^2 \\] y por lo tanto \\[ E(S_X^2)=\\frac{n-1}{n}E(\\widetilde{S}_{X}^2)=\\frac{n-1}{n}\\sigma^2_{X} \\] 1.5 La distribución t de Student Recordad que si la variable poblacional \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras aleatorias simples de tamaño \\(n\\), entonces la variable \\[ \\frac{\\overline{X}-\\mu_X}{\\sigma_{X}/\\sqrt{n}} \\] es normal estándar. Desde el punto de vista teórico, para óbtener fórmulas, esto será útil, pero normalmente no nos sirve para calcular la probabilidad de que a \\(\\overline{X}\\) le pase algo, porque casi nunca sabemos la desviación típica poblacional \\(\\sigma_{X}\\). ¿Qué pasa si la estimamos por medio de \\(\\widetilde{S}_{X}\\) con la misma muestra con la que calculamos \\(\\overline{X}\\)? Pues que el resultado siguiente nos salva el día, porque la variable que resulta tiene distribución conocida. Teorema 1.8 Sea \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\). Si tomamos muestras aleatorias simples de tamaño \\(n\\), la variable aleatoria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene una distribución conocida, llamada t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Al denominador \\(\\widetilde{S}_{X}/\\sqrt{n}\\) de la \\(T\\) del teorema anterior se le llama el error típico de la muestra, y estima el error típico \\(\\sigma_X/\\sqrt{n}\\) de la media muestral \\(\\overline{X}\\). Algunas propiedades que conviene que recordéis de las variables \\(T_m\\) que tienen distribución \\(t\\) de Student con \\(m\\) grados de libertad, \\(t_m\\): Su valor esperado es \\(E(T_m)=0\\) y su varianza es \\(\\sigma(T_m)=\\dfrac{m}{m-2}\\) (en realidad esto solo es verdad si \\(m\\geq 3\\), pero no hace falta recordarlo). Su función de distribución es simétrica respecto de \\(0\\) (como la de una \\(N(0,1)\\)): \\[ P(T_m\\leq -x)=P(T_m\\geq x)=1-P(T_m\\leq x) \\] Si \\(m\\) es grande (digamos, de nuevo, \\(m\\geq 40\\)), \\(T_m\\) es aproximadamente una \\(N(0,1)\\) (pero con un poco más de varianza, porque \\(m/(m-2)&gt;1\\), y por lo tanto un poco más achatada). Esto es consecuencia del Teorema Central del Límite. Denotaremos por \\(t_{m,q}\\) el \\(q\\)-cuantil de una variable aleatoria \\(T_{m}\\) con distribución \\(t_m\\). Es decir, \\(t_{m,q}\\) es el valor tal que \\[ P(T_{m}\\leq t_{m,q})=q \\] Entonces: Por la simetría de la distribución \\(t_m\\), \\[ t_{m,q}=-t_{m,1-q}. \\] Exactamente lo mismo que pasaba con la normal estándar Si \\(m\\) es grande, \\(T_m\\) será aproximadamente una \\(N(0,1)\\) y por lo tanto \\(t_{m,q}\\approx z_q\\). No confundáis: Desviación típica de una variable aleatoria: El parámetro poblacional, normalmente desconocido. Es \\(\\sigma_X\\). Desviación típica (muestral o no) de una muestra: El estadístico que calculamos sobre la muestra. Es \\(\\widetilde{S}_X\\) (la muestral) o \\({S}_X\\) (la “a secas”). Error típico de la media muestral: La desviación típica de la variable media muestral. Es \\(\\sigma_X/\\sqrt{n}\\), con \\(n\\) el tamaño de las muestras. Error típico de una muestra: Estimación del error típico del estimador a partir de la muestra. Es \\(\\widetilde{S}_X/\\sqrt{n}\\), con \\(n\\) el tamaño de la muestra. Fijaos en que el denominador \\(\\sqrt{n}\\) hace que, en general, los errores típicos sean mucho más pequeños que las desviaciones típicas. 1.6 Test (1) Si el tamaño de una muestra aleatoria simple de una variable aleatoria aumenta (marcad todas las afirmaciones correctas): La media muestral siempre disminuye. El error típico de la media muestral siempre disminuye. El error típico de la muestra siempre disminuye. La varianza muestral siempre aumenta. El número de grados de libertad del estimador \\(\\chi^2\\) asociado a la varianza muestral siempre aumenta. Ninguna de las otras afirmaciones es correcta (2) Si queremos disminuir a la mitad el error típico de la media muestral: Tenemos que aumentar en un 50% el tamaño de las muestras. Tenemos que doblar el tamaño de las muestras. Tenemos que cuadruplicar el tamaño de las muestras. Tenemos que dividir por 2 el tamaño de las muestras. Tenemos que dividir por 4 el tamaño de las muestras. Ninguna de las otras respuestas es correcta. (3) La prevalencia de una afección en una población es del 10%. Si estimamos dicha prevalencia repetidamente mediante las proporciones muestrales de muestras aleatorias simples de tamaño 1000, estas estimaciones siguen una distribución que (marcad todas las afirmaciones correctas): Es una distribución muestral. Es aproximadamente normal. Es binomial. Tiene media 0.1. Tiene media 900. Ninguna de las otras afirmaciones es correcta (4) Sobre una muestra de 100 mujeres se obtuvo una concentración media de la hemoglobina de 10 con una desviación típica de 2. ¿Qué vale el error típico de la muestra (para la media muestral, se entiende)? 0.02 0.04 0.2 0.4 1 Ninguno de los anteriores (5) ¿Cuáles de las afirmaciones siguientes sobre la media muestral son verdaderas? Marcad todas las respuestas correctas. Si la distribución poblacional es normal, siempre coincide con la media de la distribución poblacional. Si la distribución poblacional es normal, siempre coincide con la mediana de la distribución poblacional. Siempre sirve para estimar la media poblacional. Si la distribución poblacional es normal, sirve para estimar la mediana poblacional. Se calcula sumando todos los valores de la muestra y dividiendo por \\(n-1\\), donde \\(n\\) indica el tamaño de la muestra. Ninguna de las otras respuestas es correcta. (6) La concentración de un cierto metabolito en sangre tiene un valor medio \\(\\mu\\). Si tomamos muestras aleatorias simples de 20 individuos, calculamos su media muestral \\(\\overline{X}\\) y su desviación típica muestral \\(\\widetilde{S}_X\\) (marcad la continuación más correcta): El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene siempre distribución normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene siempre distribución t de Student. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene distribución normal si la concentración sigue una ley normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene distribución t de Student si la concentración tiene distribución normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) no tiene nunca ni distribución normal ni distribución t de Student, porque las muestras no son lo suficientemente grandes. (7) Tenemos una variable aleatoria \\(X\\) normal de media \\(\\mu\\) y desviación típica \\(\\sigma\\). Tomamos muestras aleatorias simples de tamaño \\(n\\), y denotamos por \\(\\widetilde{S}_X\\) su desviación típica muestral. ¿Cuáles de las afirmaciones siguientes son verdaderas? Marcad todas las respuestas verdaderas: \\(E(\\widetilde{S}_X^2)=\\sigma^2\\). \\(E(\\widetilde{S}_X)=\\sigma\\). \\(\\widetilde{S}_X^2\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. \\((n-1)\\widetilde{S}_X^2/\\sigma^2\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. Todas las otras respuestas son falsas. "],
["intervalos-de-confianza.html", "Lección 2 Intervalos de confianza 2.1 Definiciones básicas 2.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal 2.3 Intervalo de confianza para la media basado en la t de Student 2.4 Intervalos de confianza para proporciones 2.5 Intervalos de confianza para diferencias de medias 2.6 Test", " Lección 2 Intervalos de confianza Los estimadores de la lección anterior nos permiten estimar el valor de una característica de una población, pero no nos indican el error que cometemos con esta estimación. En la práctica, lo que se suele hacer es complementar una estimación puntual con un intervalo que indique la precisión de la estimación. Esta precisión va a depender: De la variabilidad de la variable aleatoria de interés, es decir, de su desviación típica. Del tamaño de la muestra. Y del nivel de confianza, o de seguridad, deseado para la estimación: cómo de seguros queremos estar de que la estimación es correcta. 2.1 Definiciones básicas Un intervalo de confianza del Q% (para abreviar, un IC-Q%) de un parámetro poblacional es un intervalo obtenido aplicando a una muestra aleatoria simple de tamaño \\(n\\) una fórmula que satisface la propiedad siguiente: El intervalo obtenido contiene el valor del parámetro poblacional el Q% de las veces que aplicamos la fórmula a muestras aleatorias simples de tamaño \\(n\\) tomadas al azar. Tener una confianza del Q% significa pues que empleamos una fórmula que acierta el Q% de las veces; o, para ser precisos, el Q% de las veces que la aplicamos bien. Pero asumimos que en un (100-Q)% de las veces que la aplicamos da un intervalo que no contiene el valor del parámetro poblacional, y no sabemos cuándo sí y cuándo no. De manera que solo podemos tener una cierta confianza, fruto del optimismo, de que con nuestra muestra acierta, pero no podemos estar seguros del todo. Ejemplo 2.1 En un experimento hemos medido el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. En el Ejemplo 2.3 calcularemos con los datos obtenidos en este experimento un IC-95% para el porcentaje de aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Obtendremos el intervalo [40.53, 41.87]. Esto significa que estamos un 95% seguros de que el aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza está entre el 40.53% y el 41.87%, porque este intervalo lo habremos calculado con una fórmula que el 95% de las veces que la aplicamos a muestras aleatorias de 40 personas da un intervalo que contiene la media poblacional que queremos estimar. Nosotros somos optimistas y “confiamos” estar dentro de este 95% de aciertos. No confundáis: Intervalo de referencia del Q% para una variable aleatoria: Intervalo que contiene el valor de la variable aleatoria en un individuo con probabilidad Q%. Intervalo de confianza del Q% para un parámetro: Intervalo que contiene el valor poblacional del parámetro de la variable aleatoria “con probabilidad” Q%, en el sentido de que lo hemos calculado con una fórmula que da un intervalo que contiene el parámetro el Q% de las veces que la aplicamos a una muestra aleatoria. Intervalo de referencia del Q% para un estimador*: Intervalo que contiene el valor del estimador sobre una muestra aleatoria con probabilidad Q%. Por ejemplo: Si decimos que un intervalo de referencia del 95% para la concentración de una proteína en suero en individuos sanos medida en g/dl es [11,16], esto significa que un 95% de los individuos sanos tienen una concentración de esta proteína en suero entre 11 y 16 g/dl o, equivalentemente, que si escogemos al azar un individuo sano,la probabilidad de que su concentración de esta proteína en suero esté entre 11 y 16 g/dl es del 95%. Si decimos que un intervalo de confianza del 95% para la concentración media de una proteína en suero en individuos sanos medida en g/dl es [11,16], esto significa que hemos tomado una muestra aleatoria de concentraciones de esta proteína en suero en individuos sanos y a partir de esta muestra hemos estimado que, con un 95% de seguridad, la concentración media de esta proteína en suero en el total de la población de individuos sanos está entre 11 y 16 g/dl; y que tenemos este 95% de seguridad porque hemos calculado este intervalo con una fórmula que da un intervalo que contiene la media poblacional un 95% de las veces que la empleamos sobre muestras aleatorias del misma tamaño que la nuestra. Si decimos que el 95% de las muestras de 100 concentraciones de una determinada proteína en suero en individuos sanos tienen la media muestral entre 11 y 16, esto es un intervalo de referencia del 95% para la media muestral de muestras de tamaño 100, no un intervalo de confianza para la concentración media poblacional ni un intervalo de referencia para el valor de la concentración en un individuo. Que un IC-Q% para un parámetro \\(\\theta\\) sea \\([a,b]\\) sirve: Para estimar \\(\\theta\\) con este margen de confianza: Estamos bastante seguros de que el valor poblacional de \\(\\theta\\) está entre \\(a\\) y \\(b\\) (porque la fórmula empleada acierta a menudo). Para descartar, con este margen de confianza, que \\(\\theta\\) valga un valor concreto: Estamos bastante seguros de que el valor real de \\(\\theta\\) no está ni por debajo de \\(a\\) ni por encima de \\(b\\) y por tanto de que es diferente de todos los valores \\(&lt;a\\) o \\(&gt;b\\). Por ejemplo: si un IC-95% para la prevalència \\(p\\) de una determinada enfermedad en una población va de 0.025 a 0.047: Estamos muy (“un 95%”) seguros de que \\(p\\in [0.025,0.047]\\) (porque la fórmula empleada para calcular este intervalo acierta en un 95% de las veces). Estamos muy (“un 95%”) seguros de que \\(p\\neq 0.05\\) (porque 0.05 no pertenece al intervalo que estamos muy seguros que contiene el valor real de \\(p\\)). Pero no estamos muy seguros de que \\(p=0.03\\), por mucho que \\(0.03\\in [0.025,0.047]\\): estamos muy seguros de que \\(p\\) está entre 0.025 y 0.047, pero no tenemos ninguna seguridad de que valga un valor concreto entre estos límites, solo que está entre estos límites. Hay dos tipos de métodos básicos de cálculo de intervalos de confianza a partir de una muestra aleatoria: Paramétricos: Usando alguna fórmula basada en la distribución muestral del estimador. Se basan en algún teorema y solo tiene sentido usarlos si la variable aleatoria y la muestra aleatoria satisfacen (aproximadamente) las hipótesis del teorema. No paramétricos. Los otros. El más popular, y nuestro favorito, es el bootstrap: De nuestra muestra, tomamos al azar muchas (miles) muestras aleatorias simples (permitiendo repeticiones) del misma tamaño que nuestra muestra. Calculamos el estimador para cada una de estas muestras. Usamos el vector de resultados para estimar un intervalo de confianza. Por ejemplo, tomamos como IC-95% el intervalo entre los cuantiles 0.025 y 0.975 de este vector. El bootstrap se puede usar siempre y funciona bien si la muestra es aleatoria, pero se basa en un proceso aleatorio y por lo tanto cada ejecución sobre una misma muestra puede dar un intervalo diferente. El bootstrap es una herramienta muy poderosa para calcular intervalos de confianza y, en general, para estimar la distribución muestral de un estadístico. Tanto, que en la práctica ya empieza a sustituir los métodos paramétricos. Pero no hace milagros: si la muestra es pequeña o muy poco representativa de la población, un IC calculado con el bootstrap sirve de tan poco como uno calculado con un método paramétrico. 2.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal Una de las fórmulas más conocidas para intervalos de confianza y que tenéis que saber es la siguiente: Si \\(X\\) es \\(N(\\mu,\\sigma)\\) y tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y varianza muestral \\(\\widetilde{S}^2_X\\), un IC-95% para \\(\\mu\\) es \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] donde \\(t_{n-1,0.975}\\) denota el 0.975-cuantil de la distribución t de Student \\(t_{n-1}\\). Este intervalo lo escribiremos \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] para recalcar que estamos estimando \\(\\mu\\) por medio de \\(\\overline{X}\\) más menos un cierto error. A algunos de vosotros os habrán explicado en Bachillerato, o encontraréis en libros que consultéis, una fórmula para el IC-95% para \\(\\mu\\) similar a esta, pero cambiando la \\(\\widetilde{S}_X\\) por \\(\\sigma\\) y el \\(t_{n-1,0.975}\\) por \\(z_{0.975}\\), el 0.975-cuantil de la normal estándar. Esta otra fórmula solo se puede usar si se conoce la desviación típica poblacional \\(\\sigma\\), lo que, en la práctica, nunca pasará. Por lo tanto, por favor, olvidadla. Vamos a explicar de dónde sale esta fórmula, puesto que es un paradigma de cómo se obtienen la mayoría de las fórmulas paramétricas para intervalos de confianza. Quien se la quiera tomar como dogma de fe, que pase al Ejemplo 2.2. Supongamos pues que \\(X\\) es \\(N(\\mu,\\sigma)\\) y que tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y varianza muestral \\(\\widetilde{S}^2_X\\). En esta situación, sabemos que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Si podemos encontrar \\(A,B\\in \\mathbb{R}\\) tales que \\[ P(A\\leq T\\leq B)=0.95, \\] entonces: \\[ \\begin{array}{rl} 0.95\\!\\!\\!\\! &amp; =P\\Bigg(A\\leq \\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leq B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\overline{X}-\\mu \\leq B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq -\\mu \\leq -\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\mu \\leq \\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Como \\(P(A\\leq T\\leq B)=0.95\\) significa que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) el valor de \\(T\\) está entre \\(A\\) y \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\mu \\leq \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significará que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) la \\(\\mu\\) cae dentro del intervalo \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Por lo tanto, ¡esto será un IC-95% para \\(\\mu\\)! Nos falta encontrar los \\(A,B\\) tales que \\(P(A\\leq T\\leq B)=0.95\\). Para encontrarlos, emplearemos cuantiles de la distribución de \\(T\\). Recordemos que, por definición de cuantil, \\[ P(T\\leq t_{n-1,0.975})=0.975 \\] y por la simetría de la \\(t\\) de Student, \\[ P(T\\leq -t_{n-1,0.975})=P(T\\geq t_{n-1,0.975})=0.025 \\] Por tanto: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leq T\\leq t_{n-1,0.975})\\\\ \\quad =P(T\\leq t_{n-1,0.975})-P(T\\leq -t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Así pues, podemos tomar \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] y obtenemos el IC-95% para \\(\\mu\\) anunciado: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Ejemplo 2.2 Hagamos un experimento para ver que, efectivamente, esta fórmula “acierta”, en el sentido de que el intervalo que produce contiene la \\(\\mu\\), alrededor del 95% de las veces. En el bloque de código de R siguiente: Generamos al azar una Población de 107 “individuos” que siguen una ley normal estándar y calculamos la media mu de esta población. Definimos una función IC que calcula el IC-95% para la media \\(\\mu\\) con la fórmula anterior. Tomamos, al azar, 200 muestras aleatorias simples de tamaño 50 de nuestra población y les aplicamos esta función. Obtenemos una matriz M de 200 columnas formadas por los dos extremos de los intervalos (el inferior en la primera fila y el superior en la segunda fila). Dibujamos los intervalos en un gráfico, donde aparecerán en gris los que aciertan y en rojo los que no aciertan. La recta vertical marca la media poblacional \\(\\mu\\). Población=rnorm(10^7) mu=mean(Población) IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Población,50,replace=TRUE))) plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valores&quot;,ylab=&quot;Repeticiones&quot;, main=&quot;200 IC-95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Si contáis los intervalos rojos, veréis que hemos fallado 11 veces y por lo tanto hemos acertado 189 veces, es decir, en un 94.5% de los intervalos. Es aproximadamente el que esperábamos. Si lo probáis en casa, ejecutando el código de R que hemos dado, obtendréis otros resultados, a veces mejores, a veces peores. Es lo que tiene la aleatoriedad. ¡Atención! De media, un IC-Q% NO contiene el valor real del parámetro en un (100-Q)% de las ocasiones. Por ejemplo, de media, un 5% de las veces que calculemos un IC-95%, el parámetro poblacional no pertenecerá al intervalo obtenido. En nuestro experimento, de los 200 IC-95% que hemos calculado, 11 no han contenido el valor real de \\(\\mu\\). Por lo tanto, si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, el número de veces que el intervalo resultante será erróneo, es decir, no contendrá el parámetro poblacional, seguirá una distribución binomial \\(B(n,0.05)\\). El gráfico siguiente representa el valor de \\(P(X\\geq 1)\\) para una variable aleatoria \\(X\\) de tipo \\(B(n,0.05)\\), para \\(n=0,...,100\\), y por tanto la probabilidad de que si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, al menos uno de ellos no contenga el parámetro poblacional deseado. Esto es un problema grave en artículos científicos donde se calculen intervalos de confianza para muchos parámetros. De cada 20 IC-95% que calculemos, hemos de esperar que 1 sea erróneo. Y no podemos hacer nada al respecto, salvo aumentar el nivel de confianza de todos ellos (pero entonces, como veremos, los intervalos serán más anchos). Ejemplo 2.3 Volvamos al experimento en el que medimos el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. La media y la desviación típica muestral de estos porcentajes de incremento fueron \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1 \\] Para calcular un IC-95% para el porcentaje medio de aumento, \\(\\mu\\), supondremos que la variable aleatoria de interés (de la que queremos estimar la media) \\(X\\), que es “Tomamos una persona y le medimos el porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza”, es normal y que la muestra que hemos tomado de esta variable es aleatoria simple. Entonces, como \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC-95% para \\(\\mu\\) es \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41. 87] \\] Por lo tanto, estimamos con un 95% de confianza que el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza está entre el 40.53% y el 41. 87%. Para calcular el intervalo anterior hemos supuesto que la variable poblacional “Porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza” sigue una distribución normal. ¿Y si no fuera normal? En este caso, como el tamaño de la muestra \\(n=40\\) es grande, y gracias al Teorema Central del Límite, por el Teorema 2.2 de la próxima sección el intervalo obtenido sigue siendo (aproximadamente) un intervalo de confianza del 95% para \\(\\mu\\). Si \\(n\\) fuera pequeño y \\(X\\) muy diferente de una normal, no se puede usar esta fórmula y hay que buscarse la vida (por ejemplo, emplear el método bootstrap). También hemos supuesto que era una muestra aleatoria simple. ¿Y si no lo es? Si es aleatoria, como la población sobre la que tenemos definida nuestra variable aleatoria, las personas del mundo que pueden tomar 4 cañas de cerveza, es muy grande, a efectos prácticos la podemos considerar simple. Pero seguro que no es aleatoria, sino oportunista. En este caso, no hemos sacado 40 personas por sorteo de la lista de toda la población mundial, ni siquiera de la de Mallorca, sino que hemos buscado voluntarios. Entonces, no podemos hacer nada para salvar la fórmula, y su validez depende de si la muestra de personas usada puede pasar por aleatoria o no. 2.3 Intervalo de confianza para la media basado en la t de Student A partir de ahora, para evitar ambigüedades, en las fórmulas expresaremos el nivel de confianza de los intervalos en tanto por uno, no en tanto por ciento; es decir, como una proporción en vez de como un porcentaje. Por lo tanto, hablaremos de intervalos de confianza de nivel de confianza \\(q\\) (IC-\\(q\\)), con \\(q\\) entre 0 y 1, en lugar de intervalos de confianza del Q% con Q=100q. Con estas notaciones, por ejemplo, los intervalos de confianza del 95% serán intervalos de confianza de nivel de confianza 0.95. El mismo argumento de la sección anterior, cambiando 0.95 por \\(q\\), da: Teorema 2.1 Si \\(X\\) es \\(N(\\mu,\\sigma)\\) y tomamos una muestra aleatoria simple de tamaño \\(n\\), un IC-\\(q\\) para \\(\\mu\\) es \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Recordad que en los IC-0.95, \\(q=0.95\\) y por tanto \\((1+q)/2=1. 95/2=0.975\\). La fórmula de la sección anterior es un caso particular de esta. Usando el Teorema Central del Límite y algunas aproximaciones, tenemos el siguiente resultado: Teorema 2.2 Si \\(X\\) es una variable aleatoria cualquiera de media poblacional \\(\\mu\\) y tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande (digamos, de 40 o más elementos), entonces, un IC-\\(q\\) para \\(\\mu\\) es aproximadamente \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La aproximación del teorema anterior es mejor cuanto mayor sea \\(n\\) o cuanto más próxima a una normal sea la variable poblacional \\(X\\). En resumen: Podemos usar la fórmula para el IC-\\(q\\) para la media poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] si la variable poblacional es normal o si la muestra aleatoria simple es grande. Observad que la estructura del IC-\\(q\\) para \\(\\mu\\) dado por esta fórmula es estimador \\(\\pm\\) (\\(\\frac{1+q}{2}\\)-cuantil de la distr. muestral)\\(\\times\\)(error típico de la muestra) Esta estructura es muy típica (pero no todos los intervalos de confianza paramétricos tienen esta forma, ¿eh?) y cumple que: El intervalo de confianza está centrado en la estimación puntual. La “probabilidad de equivocarnos” se reparte por igual a los dos lados del intervalo: una fracción \\(q/2\\) de las veces el parámetro estará a la izquierda del extremo inferior y una fracción \\(q/2\\) de las veces estará a la derecha del extremo superior. Además, tenemos que: Para una misma muestra y una misma fórmula (paramétrica) para calcular el intervalo de confianza, si el nivel de confianza crece, el intervalo se ensancha. Esto es general, para todos los intervalos de confianza paramétricos. La idea intuitiva es que, para estar más seguros de que un intervalo contiene un valor, el intervalo tiene que ser más ancho. En un intervalo de confianza con la estructura descrita hace un momento, el motivo matemático es que a mayor \\(q\\), mayor \\((1+q)/2\\)-cuantil de la distribución muestral. Por ejemplo, en el Ejemplo 2.3, teníamos \\(n=40\\), \\(\\overline{x}=41. 2\\) y \\(\\widetilde{s}=2.1\\): El IC-95% tiene \\(q=0.95\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), y daba $$ 22.0241. 20.67 $$ El IC-99% tiene \\(q=0.99\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), y da $$ 22.7141. 20.9 $$ más ancho Pero si cambiamos de muestra (o de fórmula, si hay más de una) para calcular el intervalo de confianza, puede pasar cualquier cosa. 2.4 Intervalos de confianza para proporciones Supongamos que tenemos una variable Bernoulli \\(X\\) con probabilidad poblacional de éxito \\(p_X\\) desconocida. Queremos calcular un intervalo de confianza para \\(p_X\\). Para hacerlo, tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\), con número de éxitos \\(S\\) y por tanto proporción muestral de éxitos \\(\\widehat{p}_{X}=S/n\\) Explicaremos tres métodos para calcular este intervalo de confianza: Método “exacto” de Clopper-Pearson Este método se basa en que el número de éxitos \\(S\\) en muestras aleatorias simples de tamaño \\(n\\) de \\(X\\) tiene una distribución conocida: es binomial \\(B(n,p_X)\\). Razonando de manera similar a cómo obteníamos el intervalo para \\(\\mu\\) basado en la t de Student se llega a una fórmula que os vamos a ahorrar, ya que nunca la vais a aplicar “a mano”. Este método tiene la ventaja de que se puede aplicar siempre, independientemente del tamaño de la muestra, y es “exacto” porque se basa en la distribución exacta de \\(S\\). Pero tiene algunos inconvenientes: Como las proporciones muestrales en muestras de tamaño fijo avanzan a saltos (0, \\(1/n\\), \\(2/n\\), \\(3/n\\)…), suele dar intervalos de confianza más anchos de lo necesario. Los intervalos que produce no son de la forma “probabilidad muestral \\(\\pm\\) algo”. Se necesita un ordenador para calcularlo, no se puede calcular a mano. Método aproximado de Wilson Supongamos ahora que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande digamos, \\(n\\geq 40\\), y proporción muestral de éxitos \\(\\widehat{p}_{X}\\). En estas condiciones, por el Teorema Central del Límite, sabemos que \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\approx N(0,1) \\] Por lo tanto \\[ P\\Big(-z_{(1+q)/2}\\leq \\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leq z_{(1+q)/2}\\Big)=q \\] Despejando \\(p_X\\) como en el cálculo del IC-95% para la \\(\\mu\\) usando la t de Student, obtenemos el resultado siguiente (que no hay que saber, tranquilos): Teorema 2.3 Si \\(n\\geq 40\\), un IC-\\(q\\) para \\(p_X\\) es aproximadamente: \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}}\\pm \\frac{z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Fijaos en que: Este método no se puede usar con muestras de cualquier tamaño, han de ser grandes para poder invocar el Teorema Central del Límite. El centro del intervalo vuelve a no ser \\(\\widehat{p}_X\\). Se basa en la aproximación a la normal dada por el Teorema Central del Límite, y por lo tanto el intervalo resultante es un intervalo de confianza “aproximado”, no exacto como el de Clopper-Pearson. Esto no es un gran problema, porque total, la muestra usada seguramente tampoco será simple. Fórmula de Laplace Supongamos finalmente que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) todavía más grande y que el valor de \\(\\widehat{p}_{X}\\) no es muy próximo ni a 0 ni a 1. Para fijar ideas, supongamos que: \\(n\\geq 100\\) El número de éxitos en la muestra es \\(\\geq 10\\) El número de fracasos en la muestra es \\(\\geq 10\\) En este caso, en la fórmula del intervalo de Wilson los términos \\(z_{(1+q)/{2}}^2/n\\) son despreciablemente pequeños comparados con los otros. Si los igualamos a 0, obtenemos la fórmula siguiente: Teorema 2.4 En las condiciones explicadas, un IC-\\(q\\) para \\(p_X\\) es (aproximadamente): \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Esta fórmula es la más popular, hasta el punto que forma parte de la “cultura general” de un científico. De hecho, tiene más de 200 años y precede en más de 100 años a la de Wilson. Además, tiene la forma familiar “estimador \\(\\pm\\) cuantil\\(\\times\\)error típico”. Os tenéis que saber la fórmula de Laplace, no hay que saber las fórmulas de los otros dos intervalos. Pero sí cuándo se pueden usar y cuándo no. Cuando podemos calcular más de un intervalo para \\(p_X\\), ¿cuál calculamos? De entrada hay que decir que si podemos calcular más de un intervalo, seguramente los que podamos calcular darán resultados muy parecidos. Además, recordad que las tres fórmulas solo nos dan “un nivel de confianza \\(q\\)” si se aplican a muestras aleatorias simples, y nuestras muestras casi siempre serán oportunistas, en cuyo caso, si nos ponemos tiquismiquis, no podemos aplicar ninguno. Solo un consejo: Si podéis usar la fórmula de Laplace, usadla. Todo el mundo lo conoce, forma parte de la cultura general del científico, y da un intervalo centrado en la proporción muestral. Ejemplo 2.4 En una muestra de 20 pacientes operados de cáncer de próstata con una nueva técnica, ninguno desarrolló complicaciones importantes en las 24 horas siguientes a la operación. ¿Cuál sería un IC-95% para la proporción de pacientes operados con esta técnica nueva que desarrollan complicaciones importantes en las 24 horas siguientes a la operación? Para calcularlo solo podemos usar el método de Clopper-Pearson, y este es uno de los pocos casos en que este intervalo tiene una expresión analítica sencilla: Si en una muestra aleatoria simple de tamaño \\(n\\) de una variable \\(Be(p_X)\\) obtenemos 0 éxitos, el IC-\\(q\\) de Clopper-Pearson para \\(p_X\\) es \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] En nuestro caso, \\(n=20\\), da el intervalo [0,0.1684]. Por lo tanto, estimamos con un 95% de confianza que menos del 16.84% de los pacientes operados con esta técnica nueva desarrollan complicaciones importantes en las 24 horas siguientes. Cuando se tiene que calcular “a ojo” un intervalo de confianza del 95% para una probabilidad \\(p_X\\) a partir de una muestra aleatoria simple donde no ha habido ningún éxito, a menudo se usa la regla siguiente: Regla del 3: Cuando en una muestra aleatoria simple de tamaño \\(n\\) de una variable aleatoria de Bernoulli de parámetro \\(p_X\\) no encontramos ningún éxito, un IC-95% para \\(p_X\\) va, aproximadamente, de 0 a \\(3/n\\). Con esta regla, en nuestro ejemplo con \\(n=20\\) obtendríem el intervalo [0,3/20]=[0,0.15], no muy lejos del [0,0.1684] que hemos obtenido. Para ver como la regla del 3 aproxima el intervalo de Clopper-Pearson, el gráfico siguiente muestra los valores \\(3/n\\) y el extremo superior del IC-95% de Clopper-Pearson a partir de una muestra de tamaño \\(n\\) con 0 éxitos: Si la muestra hubiera sido mayor, pongamos de 50 pacientes y de nuevo 0 complicaciones graves, hubiéramos podido usar el método de Wilson. Podéis comprobar con algo de paciencia que da [0,0.0713]. El método de Clopper-Pearson da en este caso [0,0.0711] y la regla del 3 [0,0.06]. El gráfico siguiente muestra los valores \\(3/n\\) y los extremos superiores de los IC-95% de Clopper-Pearson y de Wilson a partir de una muestra de tamaño \\(n\\) (\\(n\\geq 40\\) para los intervalos de confianza de Wilson) con 0 éxitos: Los extremos superiores de los intervalos de Clopper-Pearson y Wilson se superponen en este último gráfico. Aunque la muestra de pacientes hubiera sido enorme, yo qué sé, de 30000 pacientes, con 0 casos de complicaciones graves no se puede usar la fórmula de Laplace. De hecho, si la aplicáis con 0 éxitos obtenéis el interval [0,0]. Ejemplo 2.5 En un ensayo de un tratamiento de quimioterapia, en una muestra de 100 pacientes tratados, 25 desarrollaron cáncer testicular secundario. ¿Cuál es un IC-95% para la proporción de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular. En este caso podemos emplear los tres métodos. Clopper-Pearson, porque se puede usar siempre Wilson, porque \\(n=100\\geq 40\\) Laplace, porque \\(n\\geq 100\\), hay \\(25\\geq 10\\) éxitos y \\(75\\geq 10\\) fracasos. Vamos a aplicar la fórmula de Laplace, que es la única que es sensato calcular a mano (y es la que os recomendamos usar si podéis). Tenemos que \\(\\widehat{p}_{X}=25/100=0.25\\) y, como \\(z_{0.975}=1.96\\). Da: \\[ 0.25\\pm 1.96\\sqrt{\\frac{0.25\\cdot 0.75}{100}}=0.25\\pm 0.085\\Rightarrow [0.165, 0.335] \\] Concluimos, con un nivel de confianza del 95%, que entre aproximadamente un 16.5% y un 33.5% de los pacientes tratados con esta quimioterapia desarrollan cáncer testicular. Por si os interesan: El intervalo de Clopper-Pearson da [0.169, 0.347] El intervalo de Wilson da [0.175, 0.343] Como podéis ver, los tres dan muy parecidos, con diferencias en los extremos de una centésima de punto. Cálculo del tamaño de la muestra para fijar el error El margen de error (o la precisión) del intervalo de confianza de Laplace es \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] porque el intervalo de confianza de Laplace es \\(\\widehat{p}_X\\pm M\\) y por lo tanto, si contiene el valor real de \\(p_X\\), el error \\(|\\widehat{p}_X-p_X|\\) que cometemos cuando decimos que el valor de \\(p_X\\) es \\(\\widehat{p}_X\\) es como máximo \\(M\\). Una típica pregunta al diseñar un estudio es ¿de qué tamaño he de tomar la muestra para garantizar que el error en la estimación sea como máximo tal valor concreto? En el caso del intervalo de Laplace para una proporción, podemos dar un tamaño \\(n\\) que garantice un error máximo dado valga lo que valga \\(\\widehat{p}_{X}\\in [0,1]\\). Fijaos que la función \\(y=p(1-p)\\), con \\(p\\in [0,1]\\), es una parábola cóncava con vértice en su punto \\(p=0.5\\) Por lo tanto, toma su valor máximo en \\(p=0.5\\). Así, pues \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leq 0.5(1-0.5)=0.5^2\\texto{ para todo $\\widehat{p}_X\\in[0,1]$} \\] y por lo tanto \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leq z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] De este modo, si tomamos \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leq M_{max} \\] entonces seguro que \\(M\\leq M_{max}\\), valga lo que valga \\(\\widehat{p}_{X}\\). Por consiguiente, lo que haremos será calcular la \\(n\\) para obtener un error como máximo \\(M_{max}\\) en el caso más desfavorable (o en el peor de los casos): cuando el intervalo es lo más ancho posible, es decir , suponiendo que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geq \\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Rightarrow n\\geq \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}} \\right)^2 \\] En resumen: Teorema 2.5 Si \\[ n\\geq \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] el error del intervalo de Laplace calculado con una muestra de tamaño \\(n\\) siempre será \\(\\leq M_{max}\\). Ejemplo 2.6 ¿Cuál es el menor tamaño de una muestra que nos garantice un error de como máximo 0.05 al estimar una proporción \\(p_X\\) empleando un intervalo de confianza de Laplace del 95%? Por el teorema anterior, para garantizar un error de 0.05 al calcular un IC 95% para una proporción \\(p_X\\) usando la fórmula de Laplace, tenemos que emplear una muestra de tamaño \\(n\\) tal que \\[ n\\geq \\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] El tamaño más pequeño que satisface esta condición es \\(n=385\\). La respuesta correcta no es 384, por mucho que 384.16 se redondee a 384. Fijaos en que 384 no es más grande que 384.16. Observad tres cosas: El valor de \\(n\\) solo depende del error y del nivel de confianza, no de la naturaleza del estudio. Tal y como hemos encontrado la \\(n\\), estamos seguros de que si tomamos una muestra como mínimo de este tamaño, el margen de error del intervalo de confianza de Laplace será como máximo \\(M_{max}\\), sea cual sea la muestra. ¡Es de las pocas veces que podemos estar seguros de algo en estadística! El teorema anterior es para el intervalo de Laplace, pero la \\(n\\) seguramente os saldrá muy grande y en este caso el intervalo de Laplace aproxima muy bien los otros dos intervalos, si la proporción muestral luego no os sale muy extrema. “Poblaciones finitas” En esta sección hasta ahora hemos usado muestras aleatorias simples. Ya sabemos que si tomamos muestras aleatorias sin reposición y la población es mucho más grande que el tamaño \\(n\\) de las muestras, las fórmulas dadas hasta ahora van a funcionar (aproximadamente) bien. Pero, ¿qué pasa si tomamos muestras aleatorias sin reposición y la población no es mucho más grande que el tamaño \\(n\\) de las muestras? Por un lado, hay métodos tipo el de Clopper-Pearson que usan que el número de éxitos en muestras aleatorias sin reposición sigue una distribución hipergeométrica, pero son aun más complicados que el de Clopper-Pearson. Lo que se hace habitualmente es usar la fórmula de Laplace teniendo en cuenta el factor de población finita. Obtenemos por tanto que: Si \\(X\\) una variable aleatoria de Bernoulli \\(Be(p_X)\\) definida sobre una población de tamaño \\(N\\) y tomamos una muestra aleatoria sin reposición de \\(X\\), con \\(n\\geq 100\\) y números de éxitos y fracasos \\(\\geq 10\\), un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) es, aproximadamente, \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En las condiciones del punto anterior, para obtener un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) con un margen de error \\(M_{max}\\) en el caso más desfavorable (\\(\\widehat{p}_X=0.5\\)) habrá que tomar una muestra de tamaño \\[ n\\geq \\frac{Nz_{(q+1)/2}^2}{4M_{max}^2(N-1)+z_{(q+1)/2}^2} \\] Ejemplo 2.7 En una muestra aleatoria de 727 estudiantes (diferentes) de la UIB (\\(N=12000\\)), 557 afirmaron haber cometido plagio en algún trabajo durante sus estudios. ¿Cuál sería un intervalo de confianza del 95% para la proporción \\(p_X\\) de estudiantes de la UIB que han cometido plagio en algún trabajo? Una muestra de 727 estudiantes diferentes es muy grande respecto del total de estudiantes de la UIB, por lo cual conviene emplear la fórmula de Laplace con el factor de población finita \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] donde \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) y \\(N=12000\\): da \\[ 0.766\\pm \\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.751,0.781] \\] Estimamos con un nivel de confianza del 95% que entre un 75.1 y un 78.1 de los estudiantes de la UIB han cometido plagio en algún trabajo. Figura 2.1: https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf 2.5 Intervalos de confianza para diferencias de medias Sean \\(X_1\\) y \\(X_2\\) dos variables de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de medias \\(\\mu_1-\\mu_2\\). Para ello, tomamos una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de media muestral \\(\\overline{X}_1\\), y una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de media muestral \\(\\overline{X}_1\\). Si \\(X_1\\) y \\(X_2\\) son aproximadamente normales o si las muestras aleatorias simples usadas son grandes (de nuevo, digamos, ambas de tamaño como mínimo 40), entonces podemos usar un método paramétrico basado en una distribución t de Student, que da un intervalo de la forma \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\times\\text{error típico} \\] Pero el número de grados de libertad \\(\\nu\\) a usar en el cuantil y el error típico van a depender de dos factores. Por un lado, de que las muestras sean independientes (hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras obtenidas de manera independiente la una de la otra) o emparejadas (hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra o hay un emparejamiento natural entre los sujetos de las dos muestras; en particular, si las muestras son emparejadas ha de pasar que \\(n_1=n_2\\)). Y si las muestras son independientes, la fórmula a usar depende de si las varianzas de \\(X_1\\) y \\(X_2\\) son iguales o diferentes. Os damos las fórmulas, aunque no hace falta saberlas, solo recordar que la fórmula concreta a usar depende de varios factores. 2.6 Test (1) Un intervalo de confianza del 99% para la concentración de un determinado metabolito en sangre es [10,12]. De acuerdo con esto, esperamos encontrar fuera de este intervalo: Un 1% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de las concentraciones medias de las muestras grandes (con \\(n\\geq 40\\)) Un 99% de las concentraciones medias de las muestras de cualquier tamaño Un 1% de todas las concentraciones en la población Un 99% de todas las concentraciones en la población Ninguna de las anteriores respuestas es correcta. (2) Para estimar una cierta media poblacional con un nivel de confianza 0.95, hemos usado una muestra de 100 individuos y un método paramétrico y hemos obtenido un IC 95% con un margen de error de 0.02. Si usamos una muestra de 200 individuos y la misma fórmula para calcular el IC, estamos seguros de que (marcad todas las afirmaciones correctas): El IC 95% obtenido tendrá un margen de error \\(&lt;0.02\\) El IC 95% obtenido tendrá un margen de error \\(&gt;0.02\\) Si calculamos un IC 99%, su margen de error será \\(&gt;0.02\\) Si calculamos un IC 90%, su margen de error será \\(&gt;0.02\\) Ninguna de las otras afirmaciones es correcta (3) Para calcular un IC 95% para la media poblacional \\(\\mu\\) de un cierto parámetro con la fórmula basada en la t de Student, hemos tomado una muestra aleatoria simple de 100 individuos con \\(\\overline{x}=2\\) y \\(\\widetilde{s}_X^2=0.8\\). Si ahora usamos otra muestra aleatoria simple de 100 individuos y obtenemos \\(\\overline{x}=3\\) y \\(\\widetilde{s}_X^2=0.6\\), ¿como será el IC 95% que obtengamos? Igual de ancho que el anterior. Más estrecho que el anterior. Más ancho que el anterior. No podemos saber si el nuevo IC será más ancho, más estrecho o igual de ancho que el anterior. (4) Un artículo de una revista científica informa de que el intervalo de confianza al 95% del nivel medio de colesterolemia en los adultos atendidos en un Centro de Salud es 192-208. Se aceptó que la variable tenía una distribución normal y el número de pacientes estudiados fue de 100. ¿Cuáles de las siguientes afirmaciones son verdaderas? Es muy probable que el nivel medio poblacional esté comprendido entre 192 y 208. Si se repitiera el estudio muchas veces, en un 95% de ellas se obtendría una media muestral comprendida entre 192 y 208. El 95% de los adultos de la población tiene un nivel de colesterolemia comprendido entre 192 y 208. La media muestral encontrada en el estudio es de 200. La desviación típica muestral encontrada en el estudio ha sido aproximadamente 40 o 41. "]
]
