[["index.html", "Presentación", " Presentación Esto es una edición en línea de los apuntes de Introducción a la Investigación en Salud y Bioestadística del grado de Medicina de la UIB. Este trabajo se publica bajo licencia Atribución-No Comercial-SinDerivados 4.0 Estos apuntes están permanentemente en construcción. En la lista siguiente iremos anunciando las actualizaciones: 2021-09-15: El libro está escrito en R Markdown, usando RStudio como editor de textos y el paquete bookdown para convertir los ficheros markdown en un libro. Significado de algunas cajas: Material muy importante. ¡Cuidado! Ejercicio. Detalles matemáticos que os pueden interesar, pero que podéis obviar sin ningún problema. Comentario que queremos enfatizar. Comentario que queremos que recordéis Cuestión en la que queremos que caigáis en la cuenta. Acabamos de matar un gatito "],["distribuciones-muestrales.html", "Lección 1 Distribuciones muestrales 1.1 Estimadores 1.2 La media muestral 1.3 La proporción muestral 1.4 La varianza muestral 1.5 La distribución t de Student 1.6 Test", " Lección 1 Distribuciones muestrales 1.1 Estimadores En un problema típico de estadística inferencial: Queremos conocer el valor de una característica en el total de una población, pero no podemos medir esta característica en todos los individuos de la población. Entonces, extraemos una muestra de la población, medimos la característica en los individuos de esta muestra, calculamos algo con los datos obtenidos e inferimos el valor de la característica en el global de la población. Inmediatamente surgen varias preguntas, que responderemos entre esta lección y la próxima: ¿Cómo tiene que ser la muestra? ¿Qué tenemos que calcular? ¿Con qué precisión podemos inferir la característica de la población? ¿Qué tipo de muestra tenemos que tomar? Vamos a suponer de ahora en adelante que tomamos muestras aleatorias simples. Esto incluye las muestras aleatorias sin reposición si la población es mucho más grande que la muestra, ya que entonces no hay diferencia práctica entre permitir y prohibir las repeticiones. En algunos casos muy concretos permitiremos muestras aleatorias sin reposición en general. Sí, ya sabemos que en la práctica casi nunca tomamos muestras aleatorias, sino oportunistas. En este caso, recordad lo que os explicábamos en la Sección ??. Lo que hay que hacer es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, es razonablemente representativa de la población y podría pasar por aleatoria. ¿Qué calculamos? Pues un estimador: alguna función adecuada aplicada a los valores de la muestra, y que dependerá de lo que queramos estimar. Por ejemplo: Si queremos estimar la altura media de los estudiantes de la UIB, tomaremos una muestra aleatoria de estudiantes de la UIB, mediremos sus alturas y calcularemos su media aritmética. Si queremos estimar la proporción de estudiantes de la UIB que han pasado la COVID-19, tomaremos una muestra aleatoria de estudiantes de la UIB, les haremos un test de anticuerpos y calcularemos la proporción muestral de positivos en la muestra. Si queremos estimar el riesgo relativo para un estudiante de la UIB de suspender alguna asignatura si es fumador, tomaremos una muestra aleatoria de estudiantes de la UIB, anotaremos si fuman o no y si han suspendido alguna asignatura o no, y calcularemos el cociente entre las proporciones muestrales de suspensos entre los fumadores y los no fumadores de la muestra. Un estimador es una variable aleatoria, definida sobre la población formada por las muestras de la población de partida. Por lo tanto, tiene función de densidad, función de distribución (que genéricamente llamaremos distribución muestral, para indicar que mide la probabilidad de que le pase algo al valor del estimador sobre una muestra), esperanza, desviación típica, etc. 1.2 La media muestral Cuando queremos estimar el valor medio de una variable sobre una población, tomamos una muestra de valores y calculamos su media aritmética, ¿verdad? Pues eso es la media muestral. Dada una variable aleatoria \\(X\\), llamamos media muestral de (muestras de) tamaño \\(n\\) a la variable aleatoria \\(\\overline{X}\\) “Tomamos una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calculamos la media aritmética de sus valores”. Fijaos en que definimos la media muestral solo para muestras aleatorias simples. Naturalmente, tiene sentido definirla para muestras cualesquiera, pero entonces su distribución muestral dejaría de cumplir las propiedades que damos en esta sección. La misma advertencia vale a los estimadores que definimos en las próximas secciones. Veamos algunas propiedades de la distribución muestral de \\(\\overline{X}\\): Teorema 1.1 Sea \\(X\\) una variable aleatoria cualquiera de media \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\), y sea \\(\\overline{X}\\) la media muestral de tamaño \\(n\\) de \\(X\\). Entonces: \\(E(\\overline{X})=\\mu_X\\) \\(\\sigma(\\overline{X})=\\dfrac{\\sigma_X}{\\sqrt{n}}\\) Formalmente, la media muestral de tamaño \\(n\\) de una variable aleatoria \\(X\\) se define como la variable aleatoria \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] donde \\(X_1,\\ldots,X_n\\) son \\(n\\) copias independientes de la variable \\(X\\). Entonces, por la linealidad de la esperanza \\[ E(\\overline{X})=\\frac{E(X_1)+\\cdots+E(X_n)}{n}=\\frac{n\\cdot \\mu_X}{n}=\\mu_X \\] porque, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(E(X_1)=\\cdots=E(X_n)=\\mu_X\\). Y por la linealidad de la varianza de la suma de variables independientes \\[ \\sigma(\\overline{X})^2=\\frac{\\sigma(X_1)^2+\\cdots+\\sigma(X_n)^2}{n^2}=\\frac{n\\cdot \\sigma_X^2}{n^2}=\\frac{\\sigma_X^2}{n} \\] porque, de nuevo, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(\\sigma(X_1)^2=\\cdots=\\sigma(X_n)^2=\\sigma_X^2\\). Que \\(E(\\overline{X})\\) sea \\(\\mu_X\\) nos indica que \\(\\overline{X}\\) sirve para estimar \\(\\mu_X\\), porque su valor esperado es \\(\\mu_X\\): Si calculáramos muchas medias de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a \\(\\mu_X\\). Cuando el valor esperado de un estimador es precisamente el parámetro poblacional que se quiere estimar, se dice que el estimador es insesgado. Así, el primer punto del teorema anterior nos dice que la media muestral \\(\\overline{X}\\) es un estimador insesgado de la media poblacional \\(\\mu_X\\). Que \\(\\sigma(\\overline{X})\\) sea \\(\\sigma_X/\\sqrt{n}\\) implica que la variabilidad de las medias muestrales crece con la variabilidad de \\(X\\) y decrece si tomamos muestras de mayor tamaño. Esto último es razonable. Aunque la variabilidad de \\(X\\) sea grande, si tomamos muestras grandes, es probable que los valores extremos se compensen al calcular sus medias y éstas tengan menos variabilidad que la variable \\(X\\) original. A \\(\\sigma_X/\\sqrt{n}\\) se le llama el error típico de la media muestral (para la variable aleatoria \\(X\\) y muestras de tamaño \\(n\\)). Ejemplo 1.1 Vamos a realizar un experimento. Vamos a tomar una población de 106 sujetos y una variable aleatoria \\(X\\) que sobre cada sujeto toma un valor real entre 0 y 1, todos estos valores con la misma probabilidad. Llamaremos X al vector con los 106 valores de esta variable aleatoria, y dibujaremos un histograma de este vector de números para que veáis que los valores salen muy dispersos. Mostramos el código de R para que podáis repetir el experimento por vuestra cuenta; como es una simulación, cada vez que lo ejecutéis dará resultados diferentes, pero el mismo efecto global. X=runif(10^6) hist(X,freq=FALSE,main=&quot;Histograma de X&quot;,xlab=&quot;&quot;,ylab=&quot;Densidad&quot;,col=&quot;light blue&quot;) La desviación típica \\(\\sigma_X\\) de la variable \\(X\\) sobre nuestra población es sd(X)*sqrt((10^6-1)/10^6) ## [1] 0.2884943 La función sd calcula la desviación típica muestral, con denominador \\(\\sqrt{n-1}\\). Para calcular la desviación típica de verdad, con denominador \\(\\sqrt{n}\\) hay que multiplicarla por \\(\\sqrt{n-1}\\) y dividirla por \\(\\sqrt{n}\\). Ahora vamos a tomar 1000 medias muestrales de tamaño 100 de esta población, las organizaremos en un vector que llamaremos Medias y dibujaremos un histograma de este vector de medias. Medias=replicate(1000,mean(sample(X,100,replace=TRUE))) hist(Medias, breaks=15,freq=FALSE,main=&quot;Histograma de las medias muestrales&quot;,xlab=&quot;&quot;,ylab=&quot;Densidad&quot;,col=&quot;light blue&quot;,xlim=c(0.4,0.6)) Podéis observar cómo los valores de estas medias se concentran alrededor de 0.5. Veamos su desviación típica: sd(Medias)*sqrt((1000-1)/1000) ## [1] 0.02921408 Fijaos cómo se acerca mucho al valor \\(\\sigma_X/\\sqrt{100}=0.0288494\\) predicho por el teorema anterior. No coinciden exactamente, porque \\(\\sigma_X/\\sqrt{100}\\) es el valor de la desviación típica poblacional de \\(\\overline{X}\\), es decir, para toda la “población” de medias muestrales de muestras aleatorias simples de tamaño 100 de nuestra población de partida, y nosotros hemos tomado una muestra de “solo” 1000 medias de estas. La media muestral \\(\\overline{X}\\) de tamaño \\(n\\) de una variable aleatoria \\(X\\) se interpreta formalmente como la variable aleatoria obtenida tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n}. \\] Por lo tanto, es una combinación lineal de \\(n\\) copias independientes de \\(X\\). Recordando que una combinación de variables aleatorias normales independientes es normal, tenemos el resultado siguiente: Teorema 1.2 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\), entonces \\(\\overline{X}\\) es \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\), y por lo tanto \\[ Z=\\frac{\\overline{X}-\\mu_X}{\\sigma_X/\\sqrt{n}} \\] es \\(N(0,1)\\). Si \\(X\\) no es normal, la tesis del teorema anterior sigue siendo cierta “aproximadamente” siempre y cuando \\(n\\) sea grande. Este resultado, llamado el Teorema Central del Límite es, como su nombre indica, uno de los más importantes en estadística. Teorema 1.3 Sea \\(X\\) una variable aleatoria cualquiera de esperanza \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\). Si \\(n\\) es suficientemente grande, \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X, {\\sigma_X}/{\\sqrt{n}})\\) y por lo tanto \\[ Z=\\frac{\\overline{X}-\\mu_X}{{\\sigma_X}/{\\sqrt{n}}} \\] es aproximadamente \\(N(0,1)\\). Dos observaciones: ¿Cuándo una muestra es lo suficientemente grande como para poder invocar el Teorema Central del Límite? En realidad, depende de la \\(X\\). Cuánto más se parezca \\(X\\) a una variable normal, más pequeñas pueden ser la muestras. Por fijar un valor, aceptaremos que “suficientemente grande” es \\(n\\geqslant 40\\). ¿Qué quiere decir que una variable aleatoria sea “aproximadamente” normal? Pues que su función de distribución \\(F_X\\) toma valores muy cercanos a la función de distribución de una normal. Recordad cómo una \\(B(n,p)\\) con \\(n\\) grande era “aproximadamente normal” en la lección anterior. Si miráis el histograma de las 1000 medias muestrales del Ejemplo 1.1, veréis que se parece al de una muestra de una variable normal. Es que \\(\\overline{X}\\) es aproximadamente normal, por el Teorema Central del Límite, aunque la variable \\(X\\) sea muy diferente de una normal. Para verlo, en la figura que sigue superponemos al histograma de las medias la gráfica de la densidad de una variable normal de media y desviación típica las predichas por el Teorema Central del Límite. En resumen: Si \\(X\\) es normal, \\(\\overline{X}\\) es \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\). Si \\(X\\) no es normal pero \\(n\\) es grande (pongamos \\(n\\geqslant 40\\), aunque puede ser menor si \\(X\\) se parece a una normal y seguramente tendrá que ser mayor si \\(X\\) es muy diferente de una normal), \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\). Las afirmaciones del bloque anterior son verdaderas para medias muestrales de muestras aleatorias simples. Si la muestra que usemos no podemos suponer que sea aleatoria simple, ninguno de los dos resultados es válido. 1.3 La proporción muestral Cuando queremos estimar la proporción de sujetos de una población que tienen una determinada característica, tomamos una muestra y calculamos la proporción de sujetos de la muestra con esta característica. Esta será la proporción muestral de sujetos con esta característica en nuestra muestra. Dada una variable aleatoria \\(X\\) de Bernoulli \\(Be(p_X)\\), la proporción muestral de (muestras de) tamaño \\(n\\), \\(\\widehat{p}_X\\), es la variable aleatoria consistente en tomar una muestra aleatoria de tamaño \\(n\\) de \\(X\\) y calcular la proporción de éxitos en la muestra: es decir, contar el número total de éxitos y dividir el resultado por \\(n\\). Fijaos en que \\(\\widehat{p}_X\\) es un caso particular de media muestral \\(\\overline{X}\\): estamos calculando medias muestrales de muestras aleatorias simples de la variable de Bernoulli \\(X\\). Por lo tanto, todo lo que hemos dicho para medias muestrales vale también para proporciones muestrales: Teorema 1.4 Si \\(X\\) es una variable aleatoria de Bernoulli con probabilidad poblacional de éxito \\(p_X\\) y \\(\\widehat{p}_X\\) es la proporción muestral de tamaño \\(n\\): \\(E(\\widehat{p}_X)=p_X\\) \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) \\(E(\\widehat{p}_X)=p_X\\) nos dice que \\(\\widehat{p}_X\\) es un estimador insesgado de \\(p_X\\). Si calculáramos muchas proporciones muestrales de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a la proporción poblacional de éxitos \\(p_X\\). \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) nos dice que, fijada la variable \\(X\\), si tomamos muestras de tamaño mayor, la variabilidad de los resultados de \\(\\widehat{p}_X\\) disminuye. En el caso de la proporción muestral, a veces vamos a permitir tomar muestras aleatorias sin reposición. En este caso, seguimos teniendo que \\(E(\\widehat{p}_X)=p_X\\), pero ahora, si \\(N\\) es el tamaño de la población, \\[ \\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(p_X}N-n}{N-1}}. \\] El factor \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que transforma \\(\\sigma({\\widehat{p}_X})\\) para muestras aleatorias simples en la desviación típica de \\({\\widehat{p}_X}\\) para muestras aleatorias sin reposición es el factor de población finita que transformaba la desviación típica de una variable binomial (que cuenta éxitos en muestras aleatorias simples) en la desviación típica de una variable hipergeométrica (que cuenta éxitos en muestras aleatorias sin reposición). Y recordad que si el tamaño de la población \\(N\\) es muy grande comparado con \\(n\\), podemos suponer que una muestra aleatoria sin reposición es simple. Si tomamos muestras aleatorias simples de tamaño \\(n\\) de una variable aleatoria Bernoulli \\(X\\): \\(\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) es el error típico de la variable aleatoria \\(\\widehat{p}_X\\): su desviación típica. Para cada muestra, \\(\\sqrt{\\dfrac{\\widehat{p}_X(1-\\widehat{p}_X)}{n}}\\) es el error típico de la muestra, que estima el error típico de \\(\\widehat{p}_X\\). Y como la proporción muestral es un caso particular de media muestral, por el Teorema Central del Límite tenemos el resultado siguiente: Teorema 1.5 Si \\(n\\) es grande y las muestras aleatorias son simples, \\(\\widehat{p}_X\\) es aproximadamente \\(N\\big (p_X,\\sqrt{{p_X(1-p_X)}/{n}}\\big)\\) y por lo tanto \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}} \\] es aproximadamente \\(N(0,1)\\). 1.4 La varianza muestral Dada una variable aleatoria \\(X\\), llamamos: Varianza muestral de (muestras de) tamaño \\(n\\), \\(\\widetilde{S}_{X}^2\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la varianza muestral de sus valores. Desviación típica muestral de (muestras de) tamaño \\(n\\), \\(\\widetilde{S}_{X}\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la desviación típica muestral de sus valores. Formalmente, estas variables se definen tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1},\\quad \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] Tenemos los dos resultados siguientes. El primero nos dice que \\(\\widetilde{S}_{X}^2\\) es un estimador insesgado de la varianza poblacional \\(\\sigma_{X}^2\\). Teorema 1.6 \\(E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2\\). Por lo tanto, esperamos que la varianza muestral de una muestra aleatoria simple de \\(X\\) valga \\(\\sigma_{X}^2\\), en el sentido usual de que si tomamos muestras aleatorias simples de \\(X\\) de tamaño \\(n\\) grande y calculamos sus varianzas muestrales, muy probablemente obtengamos de media un valor muy cercano a \\(\\sigma_{X}^2\\). Y por lo tanto no esperamos que la varianza “a secas” de una muestra aleatoria simple valga \\(\\sigma_{X}^2\\), porque la varianza muestral y la varianza “a secas” dan valores diferentes (tienen el mismo numerador y denominadores diferentes). El segundo resultado nos dice que si la variable \\(X\\) es normal, un múltiplo adecuado de \\(\\widetilde{S}_{X}^2\\) tiene distribución muestral conocida, lo que nos permitirá calcular probabilidades de sucesos relativos a \\(\\widetilde{S}_{X}^2\\). Teorema 1.7 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras de tamaño \\(n\\), la variable aleatoria \\[ \\chi^2= \\dfrac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] tiene una distribución conocida, llamada ji cuadrado con \\(n-1\\) grados de libertad, \\(\\chi_{n-1}^2\\). La letra griega \\(\\chi\\) en castellano se lee ji; en catalán, khi; en inglés, chi, pronunciado “xai”. La distribución \\(\\chi_\\nu^2\\), donde \\(\\nu\\) es un parámetro llamado sus grados de libertad, es la distribución de probabilidad de la suma de los cuadrados de \\(\\nu\\) variables aleatorias normales estándar independientes. Para R es chisq. Os puede interesar recordar que una variable \\(\\chi_\\nu^2\\) de tipo ji cuadrado con \\(\\nu\\) grados de libertad: Tiene valor esperado \\(E(\\chi_\\nu^2)=\\nu\\) y varianza \\(\\sigma(\\chi_\\nu^2)^2=2 \\nu\\). Su función de distribución es estrictamente creciente. Tiene una distribución asimétrica a la derecha, como muestra el gráfico siguiente: A medida que el número de grados de libertad \\(\\nu\\) crece, la asimetría tiende a desaparecer y, por el Teorema Central del Límite, si \\(\\nu\\) es lo bastante grande, la distribución \\(\\chi_\\nu^2\\) se aproxima a la de una variable normal \\(N(\\nu,\\sqrt{2\\nu})\\). Tened cuidado: Si la variable poblacional \\(X\\) no es normal, la conclusión del Teorema 1.7 no es verdadera. Aunque \\(X\\) sea normal, \\(E(\\widetilde{S}_{X})\\neq \\sigma_{X}\\). La desviación típica muestral es un estimador sesgado de \\(\\sigma_{X}\\) (pero tiene otras buenas propiedades que hacen que la usemos igualmente). Ya lo hemos comentado antes. Si \\(S^2_{X}\\) es la varianza “a secas” (dividiendo por \\(n\\) en vez de por \\(n-1\\)), \\(E(S^2_{X})\\neq \\sigma^2_{X}\\). Esto lo podéis comprobar fácilmente, porque \\(S_X^2\\) se obtiene a partir de \\(\\widetilde{S}_{X}^2\\) cambiando el denominador, \\[ S_X^2=\\frac{n-1}{n} \\widetilde{S}_{X}^2 \\] y por lo tanto \\[ E(S_X^2)=\\frac{n-1}{n}E(\\widetilde{S}_{X}^2)=\\frac{n-1}{n}\\sigma^2_{X} \\] 1.5 La distribución t de Student Recordad que si la variable poblacional \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras aleatorias simples de tamaño \\(n\\), entonces la variable \\[ \\frac{\\overline{X}-\\mu_X}{\\sigma_{X}/\\sqrt{n}} \\] es normal estándar. Desde el punto de vista teórico, para obtener fórmulas, esto será útil, pero normalmente no nos sirve para calcular la probabilidad de que a \\(\\overline{X}\\) le pase algo, porque casi nunca sabemos la desviación típica poblacional \\(\\sigma_{X}\\). ¿Qué pasa si la estimamos por medio de \\(\\widetilde{S}_{X}\\) con la misma muestra con la que calculamos \\(\\overline{X}\\)? Pues que el resultado siguiente nos salva el día, porque la variable que resulta tiene distribución conocida. Teorema 1.8 Sea \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\). Si tomamos muestras aleatorias simples de tamaño \\(n\\), la variable aleatoria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene una distribución conocida, llamada t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Al denominador \\(\\widetilde{S}_{X}/\\sqrt{n}\\) de la \\(T\\) del teorema anterior se le llama el error típico de la muestra, y estima el error típico \\(\\sigma_X/\\sqrt{n}\\) de la media muestral \\(\\overline{X}\\). Fijaos en que el teorema anterior es solo para variables poblacionales \\(X\\) normales. Por el Teorema Central del Límite, si \\(n\\) es grande, \\(T\\) es aproximadanente \\(t_{n-1}\\) aunque \\(X\\) no sea normal. Para R, la distribución t de Student es t, a secas. Algunas propiedades que conviene que recordéis de las variables \\(T_\\nu\\) que tienen distribución \\(t\\) de Student con \\(\\nu\\) grados de libertad, \\(t_\\nu\\): Su valor esperado es \\(E(T_\\nu)=0\\) y su varianza es \\(\\sigma(T_\\nu)=\\dfrac{\\nu}{\\nu-2}\\) (en realidad esto solo es verdad si \\(\\nu\\geqslant 3\\), pero no hace falta recordarlo). Su función de distribución es estrictamente creciente. Su función de distribución es simétrica respecto de 0 (como la de una \\(N(0,1)\\)): \\[ P(T_\\nu\\leqslant-x)=P(T_\\nu\\geqslant x)=1-P(T_\\nu\\leqslant x) \\] Si \\(\\nu\\) es grande (digamos, de nuevo, \\(\\nu\\geqslant 40\\)), \\(T_\\nu\\) es aproximadamente una \\(N(0,1)\\) (pero con un poco más de varianza, porque \\(\\nu/(\\nu-2)&gt;1\\), y por lo tanto un poco más achatada). Esto es consecuencia del Teorema Central del Límite. Denotaremos por \\(t_{\\nu,q}\\) el \\(q\\)-cuantil de una variable aleatoria \\(T_{\\nu}\\) con distribución \\(t_\\nu\\). Es decir, \\(t_{\\nu,q}\\) es el valor tal que \\[ P(T_{\\nu}\\leqslant t_{\\nu,q})=q \\] Entonces: Por la simetría de la distribución \\(t_\\nu\\), \\[ t_{\\nu,q}=-t_{\\nu,1-q}. \\] Exactamente lo mismo que pasaba con la normal estándar Si \\(\\nu\\) es grande, \\(T_\\nu\\) será aproximadamente una \\(N(0,1)\\) y por lo tanto \\(t_{\\nu,q}\\) es aproximadamente igual a \\(z_q\\). No confundáis: Desviación típica de una variable aleatoria: El parámetro poblacional, normalmente desconocido. Es \\(\\sigma_X\\). Desviación típica (muestral o no) de una muestra: El estadístico que calculamos sobre la muestra. Es \\(\\widetilde{S}_X\\) (la muestral) o \\({S}_X\\) (la “a secas”). Error típico de la media muestral: La desviación típica de la variable media muestral. Es \\(\\sigma_X/\\sqrt{n}\\), con \\(n\\) el tamaño de las muestras. Error típico de una muestra: Estimación del error típico del estimador a partir de la muestra. Es \\(\\widetilde{S}_X/\\sqrt{n}\\), con \\(n\\) el tamaño de la muestra. Fijaos en que el denominador \\(\\sqrt{n}\\) hace que, en general, los errores típicos sean mucho más pequeños que las desviaciones típicas. Id con cuidado, porque esto se usa a menudo en artículos para enmascarar los resultados. Si una muestra ha salido con una dispersión muy grande, se da su error típico en vez de su desviación típica y parece que ha salido más concentrada. 1.6 Test (1) Si el tamaño de una muestra aleatoria simple aumenta (marca todas las afirmaciones correctas): La media muestral siempre disminuye. El error típico de la media muestral siempre disminuye. El error típico de la muestra siempre disminuye. La varianza muestral siempre aumenta. El número de grados de libertad del estimador \\(\\chi^2\\) asociado a la varianza muestral siempre aumenta. Ninguna de las otras afirmaciones es correcta (2) Si queremos disminuir a la mitad el error típico de la media muestral: Tenemos que aumentar en un 50% el tamaño de las muestras. Tenemos que doblar el tamaño de las muestras. Tenemos que cuadruplicar el tamaño de las muestras. Tenemos que dividir por 2 el tamaño de las muestras. Tenemos que dividir por 4 el tamaño de las muestras. Ninguna de las otras respuestas es correcta. (3) La prevalencia de una afección en una población es del 10%. Si estimamos dicha prevalencia repetidamente mediante las proporciones muestrales de muestras aleatorias simples de tamaño 1000, estas estimaciones siguen una distribución que (marca todas las afirmaciones correctas): Es una distribución muestral. Es aproximadamente normal. Es binomial. Tiene media 0.1. Tiene media 900. Ninguna de las otras afirmaciones es correcta (4) Sobre una muestra de 100 mujeres se obtuvo una concentración media de la hemoglobina de 10 con una desviación típica de 2. ¿Qué vale el error típico de la muestra (para la media muestral, se entiende)? 0.02 0.04 0.2 0.4 1 Ninguno de los anteriores (5) ¿Cuáles de las afirmaciones siguientes sobre la media muestral son verdaderas? Marca todas las respuestas correctas. Si la distribución poblacional es normal, siempre coincide con la media de la distribución poblacional. Si la distribución poblacional es normal, siempre coincide con la mediana de la distribución poblacional. Siempre sirve para estimar la media poblacional, aunque la distribución poblacional no sea normal. Si la distribución poblacional es normal, sirve para estimar la mediana poblacional. Se calcula sumando todos los valores de la muestra y dividiendo por \\(n-1\\), donde \\(n\\) indica el tamaño de la muestra. Ninguna de las otras respuestas es correcta. (6) La concentración de un cierto metabolito en sangre tiene un valor medio \\(\\mu\\). Si tomamos muestras aleatorias simples de 20 individuos, calculamos su media muestral \\(\\overline{X}\\) y su desviación típica muestral \\(\\widetilde{S}_X\\) (marca la continuación más correcta): El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene siempre distribución normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene siempre distribución t de Student. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene distribución normal si la concentración sigue una ley normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) tiene distribución t de Student si la concentración tiene distribución normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{n}}\\) no tiene nunca ni distribución normal ni distribución t de Student, porque las muestras no son lo suficientemente grandes. (7) Tenemos una variable aleatoria \\(X\\) normal de media \\(\\mu\\) y desviación típica \\(\\sigma\\). Tomamos muestras aleatorias simples de tamaño \\(n\\), y denotamos por \\(\\widetilde{S}_X\\) su desviación típica muestral. ¿Cuáles de las afirmaciones siguientes son verdaderas? Marca todas las respuestas verdaderas: \\(E(\\widetilde{S}_X^2)=\\sigma^2\\). \\(E(\\widetilde{S}_X)=\\sigma\\). \\(\\widetilde{S}_X^2\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. \\((n-1)\\widetilde{S}_X^2/\\sigma^2\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. \\((n-1)\\widetilde{S}_X/\\sigma\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. Todas las otras respuestas son falsas. "],["chap-IC.html", "Lección 2 Intervalos de confianza 2.1 Definiciones básicas 2.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal 2.3 Intervalo de confianza para la media basado en la t de Student 2.4 Intervalos de confianza para proporciones 2.5 Un intervalo de confianza para la diferencia de proporciones 2.6 Intervalos de confianza para diferencias de medias 2.7 Test", " Lección 2 Intervalos de confianza Los estimadores de la lección anterior nos permiten estimar el valor de una característica de una población, pero no nos indican el error que cometemos con esta estimación. En la práctica, lo que se suele hacer es complementar la estimación puntual llevada a cabo aplicando un estimador a una muestra con un intervalo que indique la precisión de dicha estimación. Esta precisión va a depender: De la variabilidad del estimador: cuánta menos variabilidad tenga, más precisa será la estimación. Normalmente, la variabilidad del estimador crece con la desviación típica de la variable poblacional y decrece con el tamaño de las muestras. Del nivel de confianza, o de seguridad, deseado para la estimación: cómo de seguros queremos estar de que la estimación es correcta. 2.1 Definiciones básicas Un intervalo de confianza del Q% (para abreviar, un IC-Q%) de un parámetro poblacional es un intervalo obtenido aplicando a una muestra aleatoria simple de tamaño \\(n\\) una fórmula que satisface la propiedad siguiente: El intervalo obtenido contiene el valor del parámetro poblacional el Q% de las veces que aplicamos la fórmula a muestras aleatorias simples de tamaño \\(n\\) tomadas al azar. Tener una confianza del Q% significa pues que usamos una fórmula que acierta el Q% de las veces que la aplicamos. Pero asumimos que en un (100-Q)% de las veces da un intervalo que no contiene el valor del parámetro poblacional, y no sabemos cuándo sí y cuándo no. De manera que solo podemos tener una cierta confianza, fruto del optimismo, de que esta fórmula con nuestra muestra acierta. Ejemplo 2.1 En un experimento medimos el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. En el Ejemplo 2.3 calcularemos con los datos obtenidos en este experimento un IC-95% para el porcentaje de aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Obtendremos el intervalo [40.53, 41.87]. Esto significará que tenemos un 95% de seguridad en que el aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza está entre el 40.53% y el 41.87%, porque este intervalo lo habremos calculado con una fórmula que el 95% de las veces que la aplicamos a muestras aleatorias de 40 personas da un intervalo que contiene la media poblacional que queremos estimar. Nosotros somos optimistas y “confiamos” estar dentro de este 95% de aciertos. A menudo esto lo escribiremos diciendo que: Hay un 95% de probabilidad de que el intervalo [40.53, 41.87] contenga el valor real del aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Pero hay que entender lo que dice esta frase: Por definición, un 95% de los intervalos de confianza del 95% para el aumento medio de alcohol etc. contienen el valor real de este aumento medio. [40.53, 41.87] es un intervalo de confianza del 95% para el aumento medio de alcohol etc., obtenido a partir de una muestra aleatoria. Entonces, [40.53, 41.87] tiene una probabilidad del 95% de contener el valor real del aumento medio de alcohol etc. en el mismo sentido que si un 95% de las personas tienen una determinada característica, y cojo una persona al azar, esta persona tiene un 95% de probabilidad de tener esa característica. No confundáis: Intervalo de referencia del Q% para una variable aleatoria: Intervalo que contiene el valor de la variable aleatoria en un individuo con probabilidad Q%. Intervalo de confianza del Q% para un parámetro: Intervalo que contiene el valor poblacional del parámetro de la variable aleatoria “con probabilidad” Q%, en el sentido de que lo hemos calculado con una fórmula que da un intervalo que contiene el parámetro el Q% de las veces que la aplicamos a una muestra aleatoria. Intervalo de referencia del Q% para un estimador: Intervalo que contiene el valor del estimador sobre una muestra aleatoria con probabilidad Q%. Por ejemplo: Si decimos que un intervalo de referencia del 95% para la concentración de una proteína en suero en individuos sanos medida en g/dl es [11,16], esto significa que un 95% de los individuos sanos tienen una concentración de esta proteína en suero entre 11 y 16 g/dl es decir, que si escogemos al azar un individuo sano, la probabilidad de que su concentración de esta proteína en suero esté entre 11 y 16 g/dl es del 95%. Si decimos que un intervalo de confianza del 95% para la concentración media de una proteína en suero en individuos sanos medida en g/dl es [11,16], esto significa que este intervalo tiene un 95% de probabilidad de contener la concentración media de esta proteína en suero en individuos sanos medida en g/dl, en el sentido de que lo hemos obtenido aplicando a una muestra aleatoria de concentraciones de esta proteína en suero en individuos sanos una fórmula que da un intervalo que contiene la media poblacional un 95% de las veces que la aplicamos a muestras aleatorias del mismo tamaño que la nuestra. Si decimos que el 95% de las muestras de 100 concentraciones de una determinada proteína en suero en individuos sanos tienen la media muestral entre 11 y 16 g/dl, esto es un intervalo de referencia del 95% para la media muestral de muestras de tamaño 100, no un intervalo de confianza para la concentración media poblacional ni un intervalo de referencia para el valor de la concentración en un individuo. A menudo calcularéis un intervalo de confianza del Q% para un cierto parámetro \\(\\theta\\) de una población, os dará \\([a,b]\\), y con el poco rigor con el que a veces os expresáis, os será igual decir “el valor real de \\(\\theta\\) tiene una probabilidad del Q% de pertenecer a \\([a,b]\\)” que “\\([a,b]\\) tiene una probabilidad del Q% de contener el valor real de \\(\\theta\\)” Pero estas dos frases no dicen exactamente lo mismo, y de hecho la primera es falsa y la segunda la interpretamos como verdadera. Fijaos en que, en la primera frase hablamos de la probabilidad de que a \\(\\theta\\) le pase algo, y en la segunda de que a \\([a,b]\\) le pase algo. La primera frase dice que \\(\\theta\\) varía y un Q% de sus valores pertenece a \\([a,b]\\). Esto es falso. “El valor real de \\(\\theta\\)” es un número que no varía. Para nuestra población vale algo concreto, desconocido pero concreto, que pertenecerá o no al intervalo \\([a,b]\\). La segunda frase en cambio se puede entender de la manera siguiente. El intervalo \\([a,b]\\) forma parte de toda la población de intervalos de confianza del Q% para \\(\\theta\\) calculados a partir de muestras aleatorias simples de nuestra población. Un Q% de estos intervalos contiene el valor real de \\(\\theta\\). Por lo tanto, podemos decir que nuestro intervalo \\([a,b]\\) tiene una probabilidad del Q% de contener el valor real de \\(\\theta\\). Esta interpretación es correcta. Aunque lo mejor es no mezclar probabilidad con confianza, y decir simplemente que tenéis un 95% de confianza, o un 95% de seguridad, en que \\([a,b]\\) contiene el valor real de \\(\\theta\\). Así no os pilláis los dedos. Que un IC-Q% para un parámetro \\(\\theta\\) sea \\([a,b]\\) sirve: Para estimar \\(\\theta\\) con este margen de confianza: Estamos bastante seguros de que el valor poblacional de \\(\\theta\\) está entre \\(a\\) y \\(b\\) (porque la fórmula usada acierta a menudo). Para descartar, con este margen de confianza, que \\(\\theta\\) valga cualquier valor concreto fuera de \\([a,b]\\): Estamos bastante seguros de que el valor real de \\(\\theta\\) no está ni por debajo de \\(a\\) ni por encima de \\(b\\) y por tanto de que es diferente de cualquier valor menor que \\(a\\) o mayor que \\(b\\). Por ejemplo: si un IC-95% para la prevalencia \\(p\\) de una determinada enfermedad en una población va de 0.025 a 0.047: Estamos muy (“un 95%”) seguros de que \\(p\\in [0.025,0.047]\\) (porque la fórmula usada para calcular este intervalo acierta en un 95% de las veces). Estamos muy (“un 95%”) seguros de que \\(p\\neq 0.05\\) (porque 0.05 no pertenece al intervalo donde estamos muy seguros de que cae el valor real de \\(p\\)). Pero no estamos muy seguros de que \\(p=0.03\\), por mucho que \\(0.03\\in [0.025,0.047]\\): estamos muy seguros de que \\(p\\) está entre 0.025 y 0.047, pero no tenemos ninguna seguridad de que valga un valor concreto entre estos límites, solo de que está entre estos límites. Hay dos tipos de métodos básicos de cálculo de intervalos de confianza a partir de una muestra aleatoria: Paramétricos: Usando alguna fórmula basada en la distribución muestral del estimador. Se basan en teoremas y solo tiene sentido usarlos si la variable aleatoria y la muestra aleatoria satisfacen (aproximadamente) las hipótesis de los teoremas. No paramétricos. Los otros. El más popular, y nuestro favorito, es el bootstrap: De nuestra muestra, tomamos al azar muchas (miles de) muestras aleatorias simples (permitiendo repeticiones) del mismo tamaño que nuestra muestra. Calculamos el estimador para cada una de estas muestras. Usamos el vector de resultados para estimar un intervalo de confianza. Por ejemplo, tomamos como IC-95% el intervalo entre los cuantiles 0.025 y 0.975 de este vector. El bootstrap se puede usar siempre y funciona bien si la muestra es aleatoria, pero se basa en un proceso aleatorio y por lo tanto cada ejecución sobre una misma muestra puede dar un intervalo diferente. El bootstrap es una herramienta muy poderosa para calcular intervalos de confianza y, en general, para estimar la distribución muestral de un estadístico. Tanto, que en la práctica ya empieza a sustituir los métodos paramétricos. Pero no hace milagros: si la muestra es pequeña o muy poco representativa de la población, un intervalo de confianza calculado con el bootstrap sirve de tan poco como uno calculado con un método paramétrico. 2.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal Una de las fórmulas más conocidas para intervalos de confianza es la siguiente: Si \\(X\\) es \\(N(\\mu,\\sigma)\\) y tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y varianza muestral \\(\\widetilde{S}^2_X\\), un IC-95% para \\(\\mu\\) es \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] donde \\(t_{n-1,0.975}\\) denota el 0.975-cuantil de la distribución t de Student \\(t_{n-1}\\). Este intervalo lo escribiremos \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] para recalcar que estamos estimando \\(\\mu\\) por medio de \\(\\overline{X}\\) más menos un cierto error. A algunos de vosotros os habrán explicado en Bachillerato, o encontraréis en libros que consultéis, una fórmula para el IC-95% para \\(\\mu\\) similar a esta, pero cambiando la \\(\\widetilde{S}_X\\) por \\(\\sigma\\) y el \\(t_{n-1,0.975}\\) por \\(z_{0.975}\\), el 0.975-cuantil de la normal estándar. Esta otra fórmula solo se puede usar si se conoce la desviación típica poblacional \\(\\sigma\\), lo que, en la práctica, nunca pasará. Por lo tanto, por favor, olvidadla. Vamos a explicar de dónde sale esta fórmula, puesto que es un paradigma de cómo se obtienen la mayoría de las fórmulas paramétricas para intervalos de confianza. Quien se la quiera tomar como dogma de fe, que salte directamente al Ejemplo 2.2. Supongamos pues que \\(X\\) es \\(N(\\mu,\\sigma)\\) y que tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y varianza muestral \\(\\widetilde{S}^2_X\\). En esta situación, sabemos que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Si podemos encontrar \\(A,B\\in \\mathbb{R}\\) tales que \\[ P(A\\leqslant T\\leqslant B)=0.95, \\] entonces: \\[ \\begin{array}{rl} 0.95\\!\\!\\!\\! &amp; =P\\Bigg(A\\leqslant\\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leqslant B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\overline{X}-\\mu \\leqslant B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant-\\mu \\leqslant-\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu \\leqslant\\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Como \\(P(A\\leqslant T\\leqslant B)=0.95\\) significa que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) el valor de \\(T\\) está entre \\(A\\) y \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu \\leqslant\\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significará que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) la \\(\\mu\\) cae dentro del intervalo \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Por lo tanto, ¡esto será un IC-95% para \\(\\mu\\)! Nos falta encontrar los \\(A,B\\) tales que \\(P(A\\leqslant T\\leqslant B)=0.95\\). Para encontrarlos, usaremos cuantiles de la distribución de \\(T\\). Recordemos que, por definición de cuantil, \\[ P(T\\leqslant t_{n-1,0.975})=0.975 \\] y por la simetría de la \\(t\\) de Student, \\[ P(T\\leqslant-t_{n-1,0.975})=P(T\\geqslant t_{n-1,0.975})=0.025 \\] Por tanto: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leqslant T\\leqslant t_{n-1,0.975})\\\\ \\quad =P(T\\leqslant t_{n-1,0.975})-P(T\\leqslant-t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Así pues, podemos tomar \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] y obtenemos el IC-95% para \\(\\mu\\) anunciado: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Ejemplo 2.2 Hagamos un experimento para ver que, efectivamente, esta fórmula “acierta”, en el sentido de que el intervalo que produce contiene la \\(\\mu\\), alrededor del 95% de las veces. En el bloque de código de R siguiente: Generamos al azar una Población de 107 “individuos” que siguen una ley normal estándar y calculamos la media mu de esta población. Definimos una función IC que calcula el IC-95% para la media \\(\\mu\\) con la fórmula anterior. Tomamos, al azar, 200 muestras aleatorias simples de tamaño 50 de nuestra población y les aplicamos esta función. Obtenemos una matriz M de 200 columnas formadas por los dos extremos de los intervalos (el inferior en la primera fila y el superior en la segunda fila). Dibujamos los intervalos de confianza en un gráfico, donde aparecerán en gris los que contienen el valor “poblacional” de mu y en rojo los que no lo contienen. La recta vertical marca el valor de mu. Población=rnorm(10^7) mu=mean(Población) mu ## [1] 0.0002423589 IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Población,50,replace=TRUE))) plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valores&quot;,ylab=&quot;Repeticiones&quot;, main=&quot;200 IC-95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Si contáis los intervalos rojos, veréis que hemos fallado 11 veces y por lo tanto hemos acertado 189 veces, es decir, en un 94.5% de los intervalos. Es aproximadamente lo que esperábamos. Si lo probáis en casa, ejecutando el código de R que hemos dado, obtendréis otros resultados, a veces mejores, a veces peores. Es lo que tiene la aleatoriedad. (Si queréis obtener exactamente nuestro gráfico, justo antes de Población=rnorm(10^7) ejecutad set.seed(1200).) Queremos remarcar que, en nuestra simulación, de los 200 IC-95% que hemos calculado, 11 no han contenido el valor real de \\(\\mu\\). Un intervalo de confianza no siempre acierta. De media, un IC-Q% NO contiene el valor real del parámetro en un (100-Q)% de las ocasiones. Por ejemplo, de media, un 5% de las veces que calculemos un IC-95%, el parámetro poblacional no pertenecerá al intervalo obtenido. Por lo tanto, si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, el número de veces que el intervalo resultante no contendrá el parámetro poblacional seguirá una distribución binomial \\(B(n,0.05)\\). El gráfico siguiente representa el valor de \\(P(X\\geqslant 1)\\) para una variable aleatoria \\(X\\) de tipo \\(B(n,0.05)\\), para \\(n=0,...,100\\), y por lo tanto la probabilidad de que si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, al menos uno de ellos no contenga el parámetro poblacional deseado. Esto es un problema grave en artículos científicos donde se calculen intervalos de confianza para muchos parámetros. De media, 1 de cada 20 IC-95% que se calculan es erróneo. Y no se puede hacer nada al respecto, forma parte de la definición. Ejemplo 2.3 Volvamos al experimento en el que medimos el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. La media y la desviación típica muestral de estos porcentajes de incremento fueron \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1. \\] Para calcular un IC-95% para el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza, \\(\\mu\\) para abreviar, supondremos que la variable aleatoria de interés (de la que queremos estimar la media) \\(X\\), que es “Tomamos una persona y le medimos el porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza”, es normal y que la muestra que hemos tomado de esta variable es aleatoria simple. Entonces, como \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC-95% para \\(\\mu\\) es \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Por lo tanto, estimamos con un 95% de confianza que el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza está entre el 40.5% y el 41.9%, o que es del 41.2% más menos 0.7 puntos porcentuales. Para calcular el intervalo anterior hemos supuesto que la variable poblacional “Porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza” sigue una distribución normal. ¿Y si no fuera normal? En este caso, como el tamaño de la muestra \\(n=40\\) es lo bastante grande como para poder invocar el Teorema Central del Límite, el Teorema 2.2 de la próxima sección nos dice que el intervalo obtenido sigue siendo (aproximadamente) un intervalo de confianza del 95% para \\(\\mu\\). Si \\(n\\) fuera pequeño y \\(X\\) muy diferente de una normal, no se puede usar esta fórmula y habría que buscarse la vida (por ejemplo, usar el método bootstrap). También hemos supuesto que era una muestra aleatoria simple. ¿Y si no lo es? Si es aleatoria, como la población sobre la que tenemos definida nuestra variable aleatoria, las personas que pueden tomar 4 cañas de cerveza, es muy grande, a efectos prácticos la podemos considerar simple. Pero seguro que no es aleatoria, sino oportunista. En este caso, no hemos sacado 40 personas por sorteo de la lista de toda la población mundial, ni siquiera de la de Mallorca, sino que hemos buscado voluntarios. Entonces, no podemos hacer nada para salvar la fórmula, y su validez depende de si la muestra de personas usada puede pasar por aleatoria o no. 2.3 Intervalo de confianza para la media basado en la t de Student A partir de ahora, para evitar ambigüedades, en las fórmulas expresaremos el nivel de confianza de los intervalos en tanto por uno, no en tanto por ciento; es decir, como una proporción en vez de como un porcentaje. Por lo tanto, hablaremos de intervalos de confianza de nivel de confianza \\(q\\) (IC-\\(q\\)), con \\(q\\) entre 0 y 1, en vez de intervalos de confianza del Q% con Q=100q. Con estas notaciones, por ejemplo, los intervalos de confianza del 95% serán intervalos de confianza de nivel de confianza 0.95. El mismo argumento de la sección anterior, cambiando 0.95 por \\(q\\), da: Teorema 2.1 Si \\(X\\) es \\(N(\\mu,\\sigma)\\) y tomamos una muestra aleatoria simple de tamaño \\(n\\), un IC-\\(q\\) para \\(\\mu\\) es \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La fórmula de la sección anterior es un caso particular de esta, porque en los IC-0.95, \\(q=0.95\\) y por lo tanto \\((1+q)/2=1.95/2=0.975\\). Usando el Teorema Central del Límite y algunas aproximaciones, tenemos el siguiente resultado: Teorema 2.2 Si \\(X\\) es una variable aleatoria cualquiera de media poblacional \\(\\mu\\) y tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande (digamos, de 40 o más elementos), entonces, un IC-\\(q\\) para \\(\\mu\\) es aproximadamente \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La aproximación del teorema anterior es mejor cuanto mayor sea \\(n\\) o cuanto más próxima a una normal sea la variable poblacional \\(X\\). En resumen: Podemos usar la fórmula para el IC-\\(q\\) para la media poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] si la variable poblacional es normal o si la muestra aleatoria simple es grande. Observad que la estructura del IC-\\(q\\) para \\(\\mu\\) dado por esta fórmula es estimador \\(\\pm\\) (\\(\\frac{1+q}{2}\\)-cuantil de la distr. muestral)\\(\\times\\)(error típico de la muestra) Esta estructura es muy típica (pero no universal: no creáis que todos los intervalos de confianza paramétricos tienen esta forma) y cumple que: El intervalo de confianza está centrado en la estimación puntual. La “probabilidad de equivocarnos” se reparte por igual a los dos lados del intervalo: en una fracción \\((1-q)/2\\) de las veces que apliquemos la fórmula, el valor real del parámetro estará a la izquierda del extremo inferior y en otra fracción \\((1-q)/2\\) de estas ocasiones estará a la derecha del extremo superior. Para una misma muestra y una misma fórmula (paramétrica) para calcular el intervalo de confianza, si el nivel de confianza crece, el intervalo se ensancha. Esto es general, para todos los intervalos de confianza paramétricos. La idea intuitiva es que, para estar más seguros de que un intervalo contiene un valor, el intervalo tiene que ser más ancho. En un intervalo de confianza con la estructura descrita hace un momento, el motivo matemático es que a mayor \\(q\\), mayor \\((1+q)/2\\)-cuantil de la distribución muestral. Por ejemplo, en el Ejemplo 2.3, teníamos \\(n=40\\), \\(\\overline{x}=41.2\\) y \\(\\widetilde{s}=2.1\\): El IC-95% tiene \\(q=0.95\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), y daba \\[ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] El IC-99% tiene \\(q=0.99\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), y da \\[ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] más ancho Pero si cambiamos de muestra (o de fórmula, si hay más de una) para calcular el intervalo de confianza, puede pasar cualquier cosa. 2.4 Intervalos de confianza para proporciones Supongamos que tenemos una variable Bernoulli \\(X\\) con probabilidad poblacional de éxito \\(p_X\\) desconocida. Queremos calcular un intervalo de confianza para \\(p_X\\). Para hacerlo, tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\), con número de éxitos \\(S\\) y por tanto proporción muestral de éxitos \\(\\widehat{p}_{X}=S/n\\). Explicaremos tres métodos para calcular este intervalo de confianza: el método de Clopper-Pearson, el de Wilson y el de Laplace. Método “exacto” de Clopper-Pearson Este método se basa en que el número de éxitos \\(S\\) en muestras aleatorias simples de tamaño \\(n\\) de \\(X\\) tiene una distribución conocida: es binomial \\(B(n,p_X)\\). Razonando de manera similar a cómo obteníamos el intervalo para \\(\\mu\\) basado en la t de Student se llega a una fórmula de un intervalo de confianza para \\(p_X\\) que os vamos a ahorrar, ya que nunca se aplica “a mano”. Este método tiene la ventaja de que se puede usar siempre, independientemente del tamaño de la muestra, y es “exacto” porque se basa en la distribución exacta de \\(S\\). Pero tiene algunos inconvenientes: Como los números de éxitos en muestras de tamaño fijo avanzan a saltos (0, 1, 2, 3,…), suele dar intervalos de confianza más anchos de lo necesario. Los intervalos que produce no son de la forma “probabilidad muestral \\(\\pm\\) algo”. Se necesita un ordenador para calcularlo, no basta una calculadora. Con R, se calcula con la función binom.exact del paquete epitools. Su sintaxis es binom.exact(x,n,conf.level) donde x y n representan, respectivamente, el número de éxitos y el tamaño de la muestra, y conf.level es \\(q\\), el nivel de confianza en tanto por uno. El valor por defecto de conf.level es 0.95, por lo que no hace falta especificarlo si queréis calcular un IC-95%. Método aproximado de Wilson Supongamos ahora que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande, pongamos \\(n\\geqslant 40\\), y proporción muestral de éxitos \\(\\widehat{p}_{X}\\). En estas condiciones, por el Teorema Central del Límite, sabemos que la distribución de \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}} \\] es aproximadamente la de una \\(N(0,1)\\). Por lo tanto \\[ P\\Big(-z_{(1+q)/2}\\leqslant\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leqslant z_{(1+q)/2}\\Big)\\approx q \\] Despejando \\(p_X\\) como en el cálculo del IC-95% para la \\(\\mu\\) usando la t de Student, obtenemos el resultado siguiente (que no hay que saber, tranquilos): Teorema 2.3 Si \\(n\\) es grande, un IC-\\(q\\) para \\(p_X\\) es aproximadamente: \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}}\\pm \\frac{z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Podéis calcular este intervalo con la función binom.wilson del paquete epitools. Su sintaxis es binom.wilson(x,n,conf.level) con los mismos parámetros que binom.exact. Fijaos en que: Este método no se puede usar con muestras de cualquier tamaño, han de ser lo bastante grandes como para poder invocar el Teorema Central del Límite. El centro del intervalo no es \\(\\widehat{p}_X\\). Se basa en la aproximación a la normal dada por el Teorema Central del Límite, y por lo tanto el intervalo resultante es un intervalo de confianza “aproximado”, no exacto como el de Clopper-Pearson. Esto no es un gran problema, porque total, la muestra usada seguramente tampoco será aleatoria simple. Fórmula de Laplace Supongamos finalmente que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) todavía más grande y que el valor de \\(\\widehat{p}_{X}\\) no es muy próximo ni a 0 ni a 1. Para fijar unas condiciones que suelen ser suficientes, supongamos que: \\(n\\geqslant 100\\). Tanto el número de éxitos, \\(S\\), como el número de fracasos, \\(n-S\\), en la muestra son \\(\\geqslant 10\\). En este caso, en la fórmula del intervalo de Wilson los términos \\(z_{(1+q)/{2}}^2/n\\) son despreciablemente pequeños comparados con los otros. Si los igualamos a 0, obtenemos la fórmula siguiente: Teorema 2.4 En las condiciones explicadas, un IC-\\(q\\) para \\(p_X\\) es aproximadamente \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Esta fórmula es la más popular, y forma parte de la “cultura general” de un científico. De hecho, tiene más de 200 años y precede en más de 100 años a los otros dos métodos. Además, tiene la forma familiar “estimador \\(\\pm\\) cuantil\\(\\times\\)error típico”. Podéis calcular este intervalo con la función binom.approx del paquete epitools. Su sintaxis es la misma que la de binom.exact y binom.wilson. Os tenéis que saber la fórmula de Laplace, no hay que saber las fórmulas de los otros dos métodos. Pero sí cuándo se pueden usar y cuándo no. Cuando podemos calcular más de un intervalo de confianza para \\(p_X\\), ¿cuál calculamos? De entrada hay que advertir que si podemos calcular más de un intervalo, seguramente los que podamos calcular darán resultados muy parecidos. Además, recordad que las tres fórmulas solo nos dan “un nivel de confianza \\(q\\)” si se aplican a muestras aleatorias simples, y nuestras muestras casi siempre serán oportunistas, en cuyo caso, si nos ponemos tiquismiquis, no podemos aplicar ninguna. Solo un consejo: Si podéis usar la fórmula de Laplace, usadla. Todo el mundo lo conoce, forma parte de la cultura general del científico, y da un intervalo centrado en la proporción muestral. Ejemplo 2.4 En una muestra de 20 pacientes operados de cáncer de próstata con una nueva técnica, ninguno desarrolló complicaciones importantes en las 24 horas siguientes a la operación. ¿Cuál sería un IC-95% para la proporción de pacientes operados con esta técnica nueva que desarrollan complicaciones importantes en las 24 horas siguientes a la operación? Para calcularlo solo podemos usar el método de Clopper-Pearson, y este es uno de los pocos casos en que este intervalo tiene una expresión analítica sencilla. Si en una muestra aleatoria simple de tamaño \\(n\\) de una variable \\(Be(p_X)\\) obtenemos 0 éxitos, el IC-\\(q\\) de Clopper-Pearson para \\(p_X\\) es \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] En nuestro caso, \\(n=20\\), da el intervalo [0,0.1684]. Por lo tanto, estimamos con un 95% de confianza que menos del 16.84% de los pacientes operados con esta técnica nueva desarrollan complicaciones importantes en las 24 horas siguientes a la operación. Con R, hubiéramos entrado library(epitools) binom.exact(0,20) ## x n proportion lower upper conf.level ## 1 0 20 0 0 0.1684335 0.95 El intervalo que se obtiene tiene como extremo inferior el valor lower y extremo superior el valor upper. Cuando se tiene que calcular “a mano” un intervalo de confianza del 95% para una probabilidad \\(p_X\\) a partir de una muestra aleatoria simple donde no ha habido ningún éxito, a menudo se usa la regla siguiente: Regla del 3: Cuando en una muestra aleatoria simple de tamaño \\(n\\) de una variable aleatoria de Bernoulli de parámetro \\(p_X\\) no encontramos ningún éxito, un IC-95% para \\(p_X\\) va, aproximadamente, de 0 a \\(3/n\\). Con esta regla, en nuestro ejemplo con \\(n=20\\) obtendríamos el intervalo [0,3/20]=[0,0.15], no muy lejos del [0,0.1684] que hemos obtenido. Para ver como la regla del 3 aproxima el intervalo de Clopper-Pearson, el gráfico siguiente muestra los valores \\(3/n\\) y el extremo superior del IC-95% de Clopper-Pearson a partir de una muestra de tamaño \\(n\\) con 0 éxitos: Si la muestra hubiera sido mayor, pongamos de 50 pacientes y de nuevo 0 complicaciones graves, podríamos usar el método de Wilson. Calculémoslo con R: binom.wilson(0,50) ## x n proportion lower upper conf.level ## 1 0 50 0 0 0.0713476 0.95 Da el intervalo [0,0.0713]. El método de Clopper-Pearson da en este caso binom.exact(0,50) ## x n proportion lower upper conf.level ## 1 0 50 0 0 0.07112174 0.95 y la regla del 3 da [0,0.06]. El gráfico siguiente muestra los valores \\(3/n\\) y los extremos superiores de los IC-95% de Clopper-Pearson y de Wilson a partir de una muestra de tamaño \\(n\\) (\\(n\\geqslant 40\\) para los intervalos de confianza de Wilson) con 0 éxitos: Los extremos superiores de los intervalos de Clopper-Pearson y Wilson se superponen en este último gráfico. Aunque la muestra de pacientes hubiera sido enorme, yo qué sé, de 30000 pacientes, con 0 casos de complicaciones graves no se puede usar la fórmula de Laplace. De hecho, si la aplicáis con 0 éxitos obtenéis el interval [0,0]. Comprobadlo. Ejemplo 2.5 En un ensayo de un tratamiento de quimioterapia, en una muestra de 100 pacientes tratados, 25 desarrollaron cáncer testicular secundario. ¿Cuál es un IC-95% para la proporción de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular. En este caso podemos usar los tres métodos. Clopper-Pearson, porque se puede usar siempre. Wilson, porque \\(n=100\\geqslant 40\\). Laplace, porque \\(n\\geqslant 100\\), \\(S=25\\geqslant 10\\) y \\(n-S=75\\geqslant 10\\). Vamos a aplicar a mano la fórmula de Laplace, que es la única que es sensato calcular a mano (y es la que os recomendamos usar si podéis). Tenemos que \\(\\widehat{p}_{X}=25/100=0.25\\) y \\(z_{0.975}=1.96\\). Da: \\[ 0.25\\pm 1.96\\sqrt{\\frac{0.25\\cdot 0.75}{100}}=0.25\\pm 0.085\\Rightarrow [0.165, 0.335] \\] Concluimos, con un nivel de confianza del 95%, que entre aproximadamente un 16.5% y un 33.5% de los pacientes tratados con esta quimioterapia desarrollan cáncer testicular. En este caso podríamos decir que estimamos, con un nivel de confianza del 95%, que el porcentaje de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular es del 25% más menos 8.5 puntos porcentuales. Por si os interesan: El intervalo de Clopper-Pearson da binom.exact(25,100) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1687797 0.3465525 0.95 El intervalo de Wilson da binom.wilson(25,100) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1754521 0.3430446 0.95 Ya que estamos, calculamos el intervalo de Laplace con R: binom.approx(25,100) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1651311 0.3348689 0.95 Da lo mismo que a mano. Como podéis ver, los tres dan muy parecidos, con diferencias en los extremos de un punto porcentual. Cálculo del tamaño de la muestra para fijar el error Llamaremos margen de error (o error, precisión…) del intervalo de confianza de Laplace a la mitad de su amplitud, es decir, a lo que sumamos y restamos a la proporción muestral para obtenerlo: \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Fijaos en que el intervalo de confianza de Laplace es \\(\\widehat{p}_X\\pm M\\) y por lo tanto, si contiene el valor real de \\(p_X\\), el error \\(|\\widehat{p}_X-p_X|\\) que cometemos cuando decimos que el valor de \\(p_X\\) es \\(\\widehat{p}_X\\) es como máximo este \\(M\\). Una típica pregunta al diseñar un estudio es ¿de qué tamaño he de tomar la muestra para garantizar que el margen de error en la estimación sea como máximo un valor dado \\(M_{max}\\)? En el caso del intervalo de Laplace para una proporción, podemos dar un tamaño \\(n\\) que garantice un error máximo dado \\(M_{max}\\) valga lo que valga \\(\\widehat{p}_{X}\\in [0,1]\\). Fijaos en que la función \\(y=p(1-p)\\), con \\(p\\in [0,1]\\), es una parábola cóncava con vértice en su punto \\(p=0.5\\). Por lo tanto, \\(y=p(1-p)\\) toma su valor máximo en \\(p=0.5\\). Así, pues \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leqslant 0.5(1-0.5)=0.5^2 \\] y por lo tanto \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leqslant z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] Concluimos que si tomamos \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leqslant M_{max} \\] entonces seguro que \\(M\\leqslant M_{max}\\), valga lo que valga \\(\\widehat{p}_{X}\\). Por consiguiente, lo que haremos será calcular la \\(n\\) para obtener un margen de error como máximo \\(M_{max}\\) en el caso más desfavorable (o en el peor de los casos): cuando el intervalo da lo más ancho posible, es decir, suponiendo que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geqslant\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Rightarrow n\\geqslant\\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}} \\right)^2 \\] En resumen: Teorema 2.5 Si \\[ n\\geqslant\\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] el margen de error del intervalo de Laplace calculado con una muestra de tamaño \\(n\\) será como máximo \\(M_{max}\\). Ejemplo 2.6 ¿Cuál es el menor tamaño de una muestra que nos garantice un margen de error de como máximo 0.05 al estimar una proporción \\(p_X\\) usando un intervalo de confianza de Laplace del 95%? Por el teorema anterior, para garantizar un margen de error de 0.05 al calcular un IC-95% para una proporción \\(p_X\\) usando la fórmula de Laplace, tenemos que usar una muestra de tamaño \\(n\\) tal que \\[ n\\geqslant\\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] El menor tamaño que satisface esta condición es \\(n=385\\). La respuesta correcta no es 384, por mucho que 384.16 se redondee a 384. Fijaos en que 384 no es más grande que 384.16. Observad tres cosas: El valor de \\(n\\) solo depende del margen de error deseado y del nivel de confianza, no de la naturaleza del estudio. Tal y como hemos encontrado la \\(n\\), estamos seguros de que si tomamos una muestra como mínimo de este tamaño, el margen de error del intervalo de confianza de Laplace será como máximo \\(M_{max}\\), sea cual sea la muestra. ¡Es de las pocas veces que podemos estar seguros de algo en estadística! El teorema anterior es para el intervalo de Laplace, pero la \\(n\\) seguramente os saldrá muy grande y en este caso el intervalo de Laplace aproxima muy bien los otros dos intervalos si la proporción muestral luego no os sale muy extrema. “Poblaciones finitas” En esta sección hasta ahora hemos usado muestras aleatorias simples. Ya sabemos que si tomamos muestras aleatorias sin reposición y la población es mucho más grande que el tamaño \\(n\\) de las muestras, las fórmulas que hemos dado siguen funcionando (aproximadamente) bien. Pero, ¿qué pasa si tomamos una muestra aleatoria sin reposición y la población no es mucho más grande que la muestra? Por un lado, hay métodos tipo el de Clopper-Pearson que usan que el número de éxitos en muestras aleatorias sin reposición sigue una distribución hipergeométrica, pero son aun más complicados que el de Clopper-Pearson. Lo que se hace cuando se puede es usar la fórmula de Laplace teniendo en cuenta el factor de población finita: Si \\(X\\) una variable aleatoria de Bernoulli \\(Be(p_X)\\) definida sobre una población de tamaño \\(N\\) y tomamos una muestra aleatoria sin reposición de \\(X\\), con \\(n\\geqslant 100\\) y números de éxitos y fracasos \\(\\geqslant 10\\), un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) es, aproximadamente, \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En las condiciones del punto anterior, para obtener un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) con un margen de error \\(M_{max}\\) en el caso más desfavorable (\\(\\widehat{p}_X=0.5\\)) habrá que tomar una muestra de tamaño \\[ n\\geqslant\\frac{Nz_{(q+1)/2}^2}{4(N-1)M_{max}^2+z_{(q+1)/2}^2} \\] Ejemplo 2.7 En una muestra aleatoria de 727 estudiantes diferentes de la UIB (\\(N=12000\\)), 557 afirmaron haber cometido plagio en algún trabajo durante sus estudios. ¿Cuál sería un intervalo de confianza del 95% para la proporción \\(p_X\\) de estudiantes de la UIB que han cometido plagio en algún trabajo? Una muestra de 727 estudiantes diferentes es muy grande respecto del total de estudiantes de la UIB, por lo cual conviene usar la fórmula de Laplace con el factor de población finita: \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] donde \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) y \\(N=12000\\): da \\[ 0.766\\pm 1.96\\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.736, 0.796] \\] Estimamos con un nivel de confianza del 95% que entre un 73.6% y un 79.6% de los estudiantes de la UIB han cometido plagio en algún trabajo. Figura 2.1: https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf 2.5 Un intervalo de confianza para la diferencia de proporciones Sean \\(X_1\\) y \\(X_2\\) dos variables Bernoulli de probabilidades poblacionales de éxito \\(p_1\\) y \\(p_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de estas probabilidades, \\(p_1-p_2\\). Para ello, tomamos dos muestras independientes, una de cada variable: Una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de proporción muestral \\(\\widehat{p}_1\\). Una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de proporción muestral \\(\\widehat{p}_2\\). Si las dos muestras son grandes, pongamos cada una de 50 o más sujetos, y las proporciones muestrales no son muy cercanas a 0 o a 1 (para fijar ideas, que en cada muestra haya como mínimo 5 éxitos y 5 fracasos), un IC-\\(q\\) para la diferencia \\(p_1-p_2\\) es, aproximadamente, \\[ \\widehat{p}_1-\\widehat{p}_2 \\pm z_{(q+1)/2}\\cdot \\sqrt{\\frac{n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2}{n_1 +n_2}\\cdot \\frac{n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)}{n_1 +n_2}\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)} \\] Notad que \\(n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) es el número total de éxitos y \\(n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)\\) el número total de fracasos en las dos muestras. Ejemplo 2.8 En un estudio francés sobre la efectividad de la hidroxicloroquina en el tratamiento de la COVID-19 leve o moderada en personas de edad avanzada, participaron 247 pacientes de este grupo de riesgo. Se dividieron al azar en dos grupos de 124 y 123 sujetos. Los del primer grupo fueron tratados con hidroxicloroquina y los del segundo grupo, con un placebo. Se anotó en cada grupo cuántos fallecieron o necesitaron intubación en los 14 días siguientes al inicio del tratamiento (lo resumiremos en “desenlace negativo”). En el grupo tratado con hidroxicloroquina hubo 9 desenlaces negativos y en el grupo del placebo, 8. Llamemos \\(p_1\\) a la probabilidad de que un paciente de edad avanzada con COVID-19 leve o moderada tratado con placebo tenga un desenlace negativo, y \\(p_2\\) a la correspondiente probabilidad para los tratados con hidroxicloroquina. Queremos calcular un IC-95% para la RAR de desenlace negativo con hidroxicloroquina comparado con placebo, es decir, para la diferencia \\(p_1-p_2\\). Las variables de interés son: \\(X_1\\): Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con placebo y miramos si tiene un desenlace negativo; es Bernoulli \\(Be(p_1)\\). \\(X_2\\): Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con hidroxicloroquina y miramos si tiene un desenlace negativo; es Bernoulli \\(Be(p_2)\\). Hemos tomado una muestra de \\(X_1\\) de tamaño \\(n_1=123\\) y ha tenido 8 éxitos, de manera que su proporción muestral ha sido \\(\\widehat{p}_1=8/123=0.06504\\), y hemos tomado una muestra de \\(X_2\\) de tamaño \\(n_2=124\\) y ha tenido 9 éxitos, de manera que su proporción muestral ha sido \\(\\widehat{p}_2=9/124=0.07258\\). El número total de éxitos (es decir, de desenlaces negativos) ha sido \\(8+9=17\\) y el de fracasos \\(247-17=230\\). Las dos muestras son independientes, ya que hemos asignado al azar los sujetos a uno u otro grupo. Suponiendo que las muestras puedan pasar por aleatorias, estamos en condiciones de aplicar la fórmula anterior. Obtenemos \\[ \\begin{array}{l} \\displaystyle 0.06504-0.07258 \\pm 1.96\\cdot \\sqrt{\\frac{17}{247}\\cdot \\frac{230}{247}\\cdot \\Big(\\frac{1}{123}+\\frac{1}{124} \\Big)}\\\\ \\qquad\\qquad =-0.00754\\pm 0.06314\\Rightarrow [-0.0707, 0.0556] \\end{array} \\] Así pues, estimamos con un 95% de confianza que la RAR de desenlace negativo con hidroxicloroquina entre estos pacientes está entre -0.0707 y 0.0556. Es decir, estimamos con una confianza del 95% que el efecto de administrar hidroxicloroquina está entre el aumento en 7.1 puntos porcentuales del riesgo de desenlace negativo y su disminución en 5.6 puntos porcentuales. En particular, no podemos descartar ni que su uso empeore el pronóstico del paciente ni que lo mejore. 2.6 Intervalos de confianza para diferencias de medias Sean \\(X_1\\) y \\(X_2\\) dos variables de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de medias \\(\\mu_1-\\mu_2\\). Para ello, tomamos: Una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de media muestral \\(\\overline{X}_1\\). Una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de media muestral \\(\\overline{X}_2\\). Si \\(X_1\\) y \\(X_2\\) son aproximadamente normales o si las muestras usadas son grandes (de nuevo, digamos, ambas de tamaño como mínimo 40), entonces podemos usar un método paramétrico basado en una distribución t de Student, que da un intervalo centrado en la diferencia de medias muestrales, de la forma \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\times\\text{error típico} \\] Pero el número de grados de libertad \\(\\nu\\) a usar en el cuantil y el error típico van a depender de dos factores. Por un lado, de que las muestras sean independientes (hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras obtenidas de manera independiente la una de la otra) o emparejadas (hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra o hay un emparejamiento natural entre los sujetos de las dos muestras; en particular, si las muestras son emparejadas ha de pasar que \\(n_1=n_2\\)). Y si las muestras son independientes, la fórmula a usar depende de si las varianzas de \\(X_1\\) y \\(X_2\\) son iguales o diferentes. (¿Y cómo podemos saber si son iguales o diferentes? No os perdáis las próximas lecciones.) Os damos las fórmulas por si algún día tenéis que calcular uno a mano. No hace falta saberlas, solo recordar que la fórmula concreta a usar depende de estas condiciones. Supongamos, pues, que \\(X_1\\) y \\(X_2\\) son aproximadamente normales o que \\(n_1,n_2\\geqslant 40\\). Entonces: Si las muestras son emparejadas y \\(n_1=n_2=n\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{n-1,(q+1)/2}\\cdot \\frac{\\widetilde{S}_D}{\\sqrt{n}} \\] donde \\(\\widetilde{S}_D\\) es la desviación típica muestral de las diferencias \\(X_1-X_2\\) sobre las parejas de la muestra. Esta fórmula es simplemente la traducción de la fórmula basada en la t de Student del IC-\\(q\\), aplicada a estimar la media \\(\\mu_1-\\mu_2\\) de la variable \\(X_1-X_2\\) a partir de una muestra de valores de esta diferencia. Si las muestras son independientes y \\(\\sigma_{X_1}^2=\\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{n_1+n_2-2,(q+1)/2} \\sqrt{\\Big(\\frac{1}{n_1}+\\frac{1}{n_2}\\Big)\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2} {n_1+n_2-2}} \\] donde \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente. Si las muestras son independientes y \\(\\sigma_{X_1}^2\\neq \\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\cdot\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}} \\] donde, de nuevo, \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente, y ahora el número de grados de libertad que tenemos que usar al calcular el cuantil es \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2}{\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} \\] Ejemplo 2.9 Queremos calcular un intervalo de confianza del 95% para la diferencia en la temperatura media de los hombres y las mujeres. Para ello, usamos unos datos recogidos por P.A. Mackowiak, S. S. Wasserman y M.M. Levine en un estudio de 1992, en el que tomaron la temperatura a 114 hombres y 116 mujeres; las muestras de ambos sexos fueron independientes una de la otra. Pongamos algunos nombres. Las variables aleatorias de interés son: \\(X_h\\): “Tomamos un hombre y le tomamos la temperatura, en grados C”, de media \\(\\mu_h\\) y desviación típica \\(\\sigma_h\\). \\(X_m\\): “Tomamos una mujer y le tomamos la temperatura, en grados C”,de media \\(\\mu_m\\) y desviación típica \\(\\sigma_m\\). Vamos a calcular un IC-95% para \\(\\mu_h-\\mu_m\\). Como ambas muestras son grandes, vamos a usar una fórmula basada en la t de Student. Hemos calculado los datos siguientes: Para la muestra de \\(X_h\\), su tamaño es \\(n_h=114\\), su media muestral es \\(\\overline{X}_h=36.75\\) y su varianza muestral es \\(\\widetilde{S}_h^2=0.228\\). Para la muestra de \\(X_m\\), su tamaño es \\(n_m=116\\), su media muestral es \\(\\overline{X}_m=36.9\\) y su varianza muestral es \\(\\widetilde{S}_m^2=0.191\\). Para calcular el IC-95%, necesitamos saber si \\(\\sigma_h^2=\\sigma_m^2\\) o \\(\\sigma_h^2\\neq \\sigma_m^2\\). Vamos a suponer que \\(\\sigma_h^2=\\sigma_m^2\\), es decir, que las temperaturas de las mujeres son “igual de variadas” que las de los hombres, básicamente porque no vemos ningún motivo para que no sea así (bueno, y porque en una próxima lección veremos cómo decidir, con una cierta probabilidad de equivocarnos, si dos desviaciones típicas poblacionales son iguales o diferentes, y en concreto concluiremos que, en este caso, \\(\\sigma_h^2=\\sigma_m^2\\)). Así que hemos de usar la fórmula para muestras independientes y varianzas iguales: \\[ \\overline{X}_h-\\overline{X}_m\\pm t_{n_h+n_m-2,0.975} \\sqrt{\\Big(\\frac{1}{n_h}+\\frac{1}{n_m}\\Big)\\cdot \\frac{(n_h-1)\\widetilde{S}_h^2+(n_m-1)\\widetilde{S}_m^2} {n_h+n_m-2}} \\] donde \\(t_{n_h+n_m-2,0.975}=t_{228,0.975}=1.97\\). Da \\[ \\begin{array}{l} \\displaystyle 36.75-36.9\\pm 1.97 \\sqrt{\\Big(\\frac{1}{114}+\\frac{1}{116}\\Big)\\cdot \\frac{113\\cdot 0.228+115\\cdot 0.191} {228}}\\\\ \\qquad \\displaystyle = -0.15\\pm 0.06\\Longrightarrow [-0.21,-0.09] \\end{array} \\] Estimamos con un 95% de confianza que la temperatura media de los hombres es entre una y dos décimas de grado C más baja que la de las mujeres. 2.7 Test (1) Un intervalo de confianza del 99% para la concentración de un determinado metabolito en sangre es [10,12]. De acuerdo con esto, esperamos encontrar fuera de este intervalo: Un 1% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de las concentraciones medias de las muestras grandes (con \\(n\\geqslant 40\\)) Un 99% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de todas las concentraciones en la población Un 99% de todas las concentraciones en la población Ninguna de las anteriores respuestas es correcta. (2) Para estimar una cierta media poblacional con un nivel de confianza 0.95, hemos usado una muestra de 100 individuos y un método paramétrico y hemos obtenido un IC-95% con un margen de error de 0.02. Si usamos una muestra de 200 individuos y la misma fórmula para calcular el IC, estamos seguros de que (marca todas las afirmaciones correctas): El IC-95% obtenido tendrá un margen de error \\(&lt;0.02\\) El IC-95% obtenido tendrá un margen de error \\(&gt;0.02\\) Si calculamos un IC-99%, su margen de error será \\(&gt;0.02\\) Si calculamos un IC-90%, su margen de error será \\(&gt;0.02\\) Ninguna de las otras afirmaciones es correcta (3) Para calcular un IC de nivel de confianza \\(q\\) para la media poblacional \\(\\mu\\) de un cierto parámetro con la fórmula basada en la t de Student, hemos tomado una muestra aleatoria simple de 100 individuos con \\(\\overline{x}=2\\) y \\(\\widetilde{s}_X^2=0.8\\). Si ahora usamos otra muestra aleatoria simple de 100 individuos y obtenemos \\(\\overline{x}=3\\) y \\(\\widetilde{s}_X^2=0.6\\), ¿cómo será el IC-\\(q\\) que obtengamos? Igual de ancho que el anterior. Más estrecho que el anterior. Más ancho que el anterior. No podemos saber si el nuevo IC será más ancho, más estrecho o igual de ancho que el anterior. (4) Un artículo de una revista científica informa de que el intervalo de confianza del 95% del nivel medio de colesterolemia en los adultos atendidos en un Centro de Salud es 192-208. Se aceptó que la variable tenía una distribución normal y el número de pacientes estudiados fue de 100. ¿Cuáles de las siguientes afirmaciones son verdaderas? Es muy probable que el nivel medio poblacional esté comprendido entre 192 y 208. Si se repitiera el estudio muchas veces, en un 95% de ellas se obtendría una media muestral comprendida entre 192 y 208. El 95% de los adultos de la población tiene un nivel de colesterolemia comprendido entre 192 y 208. La media muestral encontrada en el estudio es de 200. La desviación típica muestral encontrada en el estudio ha sido aproximadamente 40 o 41. Ninguna de las anteriores respuestas es correcta. (5) Un intervalo de confianza del 95% para la media estimado a partir de una muestra (marca las afirmaciones correctas): Es un intervalo en el cual, a largo plazo, caen el 95% de las observaciones. Es una manera de expresar la precisión de la estimación de la media. Es un intervalo que se ha calculado con una fórmula para que incluya la media muestral en el 95% de las ocasiones que la apliquemos a muestras. Es un intervalo que se ha calculado con una fórmula para que incluya la media de la población en el 95% de las ocasiones que la apliquemos a muestras. Es una manera de expresar la variabilidad de un conjunto de observaciones. (6) Para estimar una cierta proporción con un nivel de confianza 0.95, hemos usado una muestra de 100 individuos y uno de los métodos paramétricos explicados en el curso y hemos obtenido un IC-95% con un margen de error de 0.02.¿Cuáles de las afirmaciones siguientes son verdaderas? Si calculamos un IC-99% con la misma muestra y el mismo método, su margen de error será \\(\\geqslant\\) 0.02 Si calculamos un IC-99% con la misma muestra y el mismo método, su margen de error será \\(\\leqslant\\) 0.02 Si calculamos un IC-90% con la misma muestra y el mismo método, su margen de error será \\(\\geqslant\\) 0.02 Si calculamos un IC-90% con la misma muestra y el mismo método, su margen de error será \\(\\leqslant\\) 0.02 Ninguna de las otras afirmaciones es seguro que sea verdadera "],["contrastes-de-hipótesis.html", "Lección 3 Contrastes de hipótesis 3.1 Hipótesis nula y alternativa 3.2 Un ejemplo 3.3 El p-valor 3.4 Tipo de errores 3.5 Ejemplo: El test t 3.6 Recapitulación 3.7 Test", " Lección 3 Contrastes de hipótesis En muchas situaciones, queremos tomar una decisión sobre si podemos aceptar o rechazar una hipótesis relativa al valor de un parámetro en una o varias poblaciones, y para tomar esta decisión, nos basamos en los datos de una muestra. Por ejemplo: Queremos saber si una moneda está trucada a favor de cara. Para decidirlo, la lanzamos varias veces y contamos cuántas caras salen. Queremos decidir si un tratamiento nuevo A es más efectivo que el tratamiento anterior B en la curación de una enfermedad X. Para decidirlo, llevamos a cabo un ensayo clínico, tratando con A un grupo de enfermos y con B otro grupo de enfermos, y comparamos la tasa de curación de los tratamientos sobre estos dos grupos. El método estadístico que se usa para aceptar o rechazar una hipótesis a partir de los datos de una muestra recibe el nombre de contraste de hipótesis. 3.1 Hipótesis nula y alternativa En un contraste de hipótesis, se comparan siempre dos hipótesis alternativas: la hipótesis nula \\(H_{0}\\) y la hipótesis alternativa \\(H_{1}\\). Se suele plantear formalmente \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{hipótesis nula}\\\\ H_{1}:\\text{hipótesis alternativa} \\end{array} \\right. \\] En los contrastes de hipótesis de este curso: La hipótesis nula \\(H_{0}\\) es “no hay diferencia”, “no pasa nada”, “no hay nada extraño” o el equivalente en el contexto del contraste: La moneda es equilibrada (50% de probabilidad de cara). Los tratamientos A y B son igual de efectivos en la curación de la enfermedad X. La hipótesis alternativa \\(H_{1}\\) plantea la diferencia de la que buscamos evidencia: La moneda está trucada a favor de cara (más del 50% de probabilidad de cara). A es más efectivo que B en la curación de la enfermedad X. Por defecto, estamos dispuestos a aceptar \\(H_0\\): que no hay diferencia, que no pasa nada. Por defecto, estamos dispuestos a aceptar que la moneda es equilibrada (la mayoría lo son, ¿no?). Por defecto, estamos dispuestos a aceptar que los dos tratamientos son igual de efectivos (en general, si tomáis dos tratamientos cualesquiera, al azar, y los aplicáis a enfermos de X, los dos van a ser igual de (in)efectivos). Si obtenemos evidencia suficiente de que \\(H_0\\) es falsa, rechazaremos \\(H_0\\) en favor de \\(H_1\\) y concluiremos que \\(H_1\\) es verdadera. ¿Qué quiere decir “obtener evidencia suficiente de que \\(H_0\\) es falsa”? Pues que las pruebas obtenidas hacen que \\(H_0\\) sea inverosímil (difícil de creer) por comparación con \\(H_1\\): Tendremos evidencia de que la moneda está trucada a favor de cara si en nuestra serie de lanzamientos la proporción de caras es tan y tan grande que hace muy difícil creer que la moneda no esté trucada a favor de cara. Tendremos evidencia de que A es más efectivo que B en la curación de X si en nuestro ensayo la tasa de curación de la enfermedad X con el tratamiento A es tan y tan superior a la de B que hace muy difícil creer que los dos tratamientos sean igual de efectivos. Si no obtenemos evidencia suficiente de que \\(H_0\\) es falsa, es decir, si nuestros datos son razonablemente compatibles con \\(H_0\\), no podremos rechazarla. Entonces, aceptaremos la hipótesis nula. Aceptaremos que la moneda no está trucada a favor de cara si en nuestra serie de lanzamientos la proporción de caras no es lo bastante grande como para hacer muy difícil creer que sea equilibrada Aceptaremos que A es igual de efectivo que B en la curación de X si en nuestro ensayo la tasa de curación de la enfermedad X con el tratamiento A no es lo bastante superior a la de B como para hacer muy difícil creer que los dos tratamientos sean igual de efectivos. Si rechazamos \\(H_0\\) en favor de \\(H_1\\) no será porque hayamos demostrado que \\(H_0\\) sea imposible, ni siquiera que sea improbable: tan solo habremos observado que es difícil de creer que sea verdad a la vista de los resultados de nuestro experimento. Por ejemplo, si en una secuencia de 30 lanzamientos de una moneda obtenemos todas las veces cara, seguramente lo consideraremos evidencia de que la moneda está trucada, pero no demuestra que la moneda esté trucada. Sí, cuesta creer que no esté trucada, pero no es imposible: la moneda podría ser equilibrada y por puro azar nosotros haber tenido esta racha de caras. Y tampoco podemos decir que sea improbable que sea equilibrada, puesto que nosotros sabemos calcular \\[ P(\\text{30 caras en 30 lanzamientos}\\,|\\,\\text{La moneda es equilibrada}) \\] que vale \\(0.5^{30}=9.3\\cdot 10^{-10}\\) (y por lo tanto, de media, aproximadamente en una de cada mil millones de veces que se efectúan 30 lanzamientos seguidos de una moneda equilibrada, se obtienen 30 caras: no es imposible). Pero no sabemos calcular \\[ P(\\text{La moneda es equilibrada}\\,|\\,\\text{30 caras en 30 lanzamientos}). \\] Si aceptamos la hipótesis nula es porque no encontramos motivos para dudar de ella, pero no habremos encontrado evidencia de que sea verdadera ni habremos demostrado que sea probable (y posible en principio lo es siempre). Por ejemplo, si en una secuencia de 4 lanzamientos de una moneda obtenemos 2 caras, tendremos que aceptar que la moneda es equilibrada. Pero podría ser que estuviera ligeramente sesgada hacia cara y no haberse notado en una secuencia tan corta de lanzamientos. Así que no hemos encontrado evidencia de que sea equilibrada, simplemente no lo podemos descartar (como tampoco podemos descartar que la probabilidad de cara sea, yo qué sé, 0.50001). Ejemplo 3.1 En un juicio (en el que el acusado es inocente si no se demuestra lo contrario, es decir, en el que estamos dispuestos a aceptar por defecto que es inocente), se busca evidencia de que el acusado es culpable. Por lo tanto, esta es la hipótesis alternativa. Así: El contraste es \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El acusado es inocente}\\\\ H_{1}:\\text{El acusado es culpable} \\end{array} \\right. \\] Se aportan pruebas. Si el jurado encuentra las pruebas lo bastante incriminatorias, “más allá de toda duda razonable”, declara culpable el acusado (rechaza \\(H_0\\) en favor de \\(H_1\\)). Si el jurado no las encuentra lo bastante incriminatorias, lo considera no culpable (no rechaza \\(H_{0}\\)). Observad que considerar no culpable no es lo mismo que demostrar que es inocente: simplemente, se considera que el acusado no es culpable porque no se ha encontrado evidencia suficiente de que sea culpable. Ejemplo 3.2 Un examen es un contraste de hipótesis. En este caso, “no pasa nada” significa que el estudiante es como si no hubiera ido al curso, no ha aprendido nada, y por tanto esta es la hipótesis nula. Con el examen buscamos evidencia de que el estudiante ha aprendido la materia, por lo tanto esta será la hipótesis alternativa. Así: Contraste: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El estudiante no sabe la materia}\\\\ H_{1}:\\text{El estudiante sabe la materia} \\end{array} \\right. \\] Tomamos una muestra del conocimiento del estudiante (el estudiante hace el examen). Si hay suficiente evidencia en favor de \\(H_1\\) (si el examen le sale lo bastante bien), rechazamos \\(H_0\\): decidimos que el estudiante sabe la materia, aprueba la asignatura. Si no hay evidencia suficiente en favor de \\(H_1\\) (si el examen no le sale lo bastante bien), nos quedamos con \\(H_0\\): concluimos que el estudiante no ha aprendido la materia, suspende la asignatura. Ejemplo 3.3 Una prueba diagnóstica de una enfermedad es un contraste de hipótesis. En este caso, “no pasa nada” significa que la persona está sana, y por tanto esta es la hipótesis nula. Con la prueba diagnóstica buscamos evidencia de que tiene la enfermedad, por lo tanto esta será la hipótesis alternativa. Es decir, el contraste es \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{La persona no tiene la enfermedad}\\\\ H_{1}:\\text{La persona sí tiene la enfermedad} \\end{array} \\right. \\] Ejemplo 3.4 Si leemos la noticia siguiente en el diario, puede que nos preguntemos si es verdad que las mujeres practican menos deporte que los hombres. Esta pregunta la podemos plantear de muchas maneras: ¿Toda mujer hace cada día menos horas de deporte que cualquier hombre? Si tomo una mujer y un hombre al azar, ¿es más probable que ella practique menos deporte que él? ¿La mayoría de las mujeres hacen cada día menos horas de deporte que la mayoría de los hombres? ¿La proporción de practicantes de deporte entre las mujeres es menor que entre los hombres? ¿La media semanal de veces que las mujeres practican deporte es menor que la de los hombres? ¿La media semanal de horas que las mujeres practican deporte es menor que la de los hombres? … Cada una de estas preguntas se traduciría en un contraste de hipótesis diferente. Puesto que aquí estamos tratando contrastes sobre parámetros poblacionales (medias, proporciones, etc.), podríamos plantear alguno de los tres últimos contrastes. Vamos a centrarnos en la última cuestión, sobre medias semanales de horas de deporte. En este contraste, las variables poblacionales de interés son: \\(X_m\\): “Tomo una mujer y calculo su número medio de horas semanales de deporte”, con media \\(\\mu_m\\): la media semanal de horas de deporte de las mujeres (la media de las medias de horas semanales de deporte de todas las mujeres es la media de horas semanales de deporte de las mujeres). \\(X_h\\): “Tomo un hombre y calculo su número medio de horas semanales de deporte”, con media \\(\\mu_h\\): la media semanal de horas de deporte de los hombres. El contraste que queremos realizar es Hipótesis nula: no hay diferencia entre las medias semanales de horas de deporte de hombres y mujeres. Hipótesis alternativa: la media semanal de horas de deporte de las mujeres es más pequeña que la de los hombres. Es decir \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&lt;\\mu_h \\end{array} \\right. \\] El procedimiento para llevar a cabo este contraste sería: Tomaríamos muestras aleatorias de mujeres y de hombres y les preguntaríamos sus hábitos de práctica de deporte. Calcularíamos la media muestral \\(\\overline{X}_m\\) de horas semanales de deporte de las mujeres de la muestra. Calcularíamos la media muestral \\(\\overline{X}_h\\) de horas semanales de deporte de los hombres de la muestra. Si \\(\\overline{X}_m\\) fuera mucho menor que \\(\\overline{X}_h\\), lo tomaríamos como evidencia de que \\(\\mu_m&lt;\\mu_h\\). Si \\(\\overline{X}_m\\) no fuera mucho menor que \\(\\overline{X}_h\\), no podríamos rechazar que \\(\\mu_m=\\mu_h\\). ¿Qué significa “\\(\\overline{X}_m\\) mucho menor que \\(\\overline{X}_h\\)”? Una opción, que podríamos importar del tema anterior, seria calcular un intervalo de confianza del 95% para \\(\\mu_m-\\mu_h\\) a partir de la muestra. Entonces: Si este intervalo de confianza estuviera totalmente a la izquierda del 0, con un 95% de confianza podríamos concluir que \\(\\mu_m&lt;\\mu_h\\) (porque tendríamos un 95% de seguridad de que el valor real de la diferencia \\(\\mu_m-\\mu_h\\) pertenece a un intervalo de números estrictamente negativos). En caso contrario (si contuviera el 0 o si estuviera totalmente a la derecha del 0), con un 95% de confianza no podríamos concluir que \\(\\mu_m&lt;\\mu_h\\). Aquí querremos afinar un poco más que lo del “nivel de confianza”, por lo que el procedimiento será algo más complicado (básicamente, la idea es que vamos a usar diferentes fórmulas para calcular los intervalos de confianza según la forma de la hipótesis alternativa). Antes de cerrar esta sección, queremos destacar algunas advertencias. Las hipótesis de los contrastes son sobre parámetros de las poblaciones, NO sobre estadísticos de las muestras. En el ejemplo anterior, las hipótesis del contraste comparaban las medias poblacionales de horas semanales de deporte de las mujeres y los hombres, no las medias de horas semanales de deporte de las mujeres y los hombres de la muestra. Para comparar las medias muestrales no nos hace falta un contraste de hipótesis: las calculamos y punto. En cambio, como no podemos calcular las medias semanales de horas de deporte de todas las mujeres y de todos los hombres, nos vemos obligados a hacer un contraste de hipótesis. La falta de evidencia en favor de \\(H_1\\) no es evidencia en favor de \\(H_0\\). Si no podemos asegurar que las mujeres practiquen menos deporte que los hombres (porque no hayamos encontrado evidencia a favor de esta hipótesis), esto no significará que hayamos encontrado evidencia de que los hombres y las mujeres practiquen la misma cantidad de deporte o de que las mujeres practiquen más deporte. Lo que significará es que la evidencia en favor de \\(H_1\\) no ha sido lo bastante fuerte como para poder afirmar que es verdadera y por tanto aceptamos que no hay diferencia en la media semanal de horas de deporte practicada por ambos sexos. De hecho, nunca podremos encontrar evidencia de la hipótesis nula. Si por ejemplo en nuestro estudio hubiéramos encontrado que \\(\\overline{X}_m=\\overline{X}_h\\), esto sería compatible con la hipótesis nula \\(\\mu_m=\\mu_h\\), y por eso no la podríamos rechazar, pero no aportaría evidencia de que \\(\\mu_m=\\mu_h\\), puesto que seguramente también sería compatible, por ejemplo, con \\(\\mu_m=\\mu_h+0.0007\\) (las mujeres hacen, de media, un minuto más de deporte a la semana que los hombres). La pregunta (el contraste) os lo tenéis que plantear a priori a partir de hipótesis o suposiciones previas, antes de llevar a cabo la recolección de datos. No vale cambiar de contraste a la vista de los datos obtenidos. La pregunta la tenemos que plantear antes de obtener la muestra. Si estamos interesados en el contraste \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&lt;\\mu_h \\end{array} \\right. \\] y obtenemos que \\(\\overline{X}_m\\) es mucho mayor que \\(\\overline{X}_h\\) en nuestra muestra, concluimos que no tenemos evidencia de que \\(\\mu_m&lt;\\mu_h\\) y punto. Sería hacer trampas decir: “No hemos encontrado evidencia de que las mujeres practiquen menos deporte que los hombres, pero si con estos mismos datos realizamos el contraste \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&gt;\\mu_h \\end{array} \\right. \\] sí que obtenemos evidencia de que ellas practican más deporte que ellos.” De esto se dice ir a pescar evidencias o también torturar los datos: obtener unos datos y buscar de qué dan evidencia. Es mala praxis científica. Cualquier conjunto de datos, si lo torturamos lo suficiente, acaba dando evidencia de algo. Escoged la hipótesis alternativa en función de lo que buscáis evidencia. No confundáis \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&lt;\\mu_h \\end{array} \\right. \\] con \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m \\neq \\mu_h \\end{array} \\right. \\] que traduce la pregunta “Los hombres y las mujeres, de media, ¿practican deporte de media un número diferente de horas semanales?” Reglas para elegir \\(H_0\\) y \\(H_1\\) en este curso: \\(H_0\\) siempre tiene que significar “no hay diferencia” y se tiene que definir formalmente mediante una igualdad. \\(H_1\\) es la hipótesis de la que buscamos evidencia, y se tiene que definir formalmente mediante algo “estricto”: Hipótesis unilateral (one-sided; también de una cola, one-tailed): definida con &lt; o con &gt;. Hipótesis bilateral (two-sided; también de dos colas, two-tailed): definida con \\(\\mathbf{\\neq}\\). Los contrastes toman el nombre del tipo de hipótesis alternativa: contraste unilateral, contraste de dos colas, etc. 3.2 Un ejemplo Tenemos una moneda, y creemos que está trucada en favor de cara. Queremos contrastarlo. Aquí la variable aleatoria \\(X\\) que nos interesa es “lanzamos la moneda y miramos si sale cara”, que es de Bernoulli con probabilidad de éxito (es decir, probabilidad de sacar cara con nuestra moneda) \\(p_{\\mathit{Cara}}\\). La hipótesis nula será que la moneda no está trucada (no le pasa nada a nuestra moneda), y la alternativa (de la que busco evidencia), que la moneda está trucada en favor de cara. En términos de \\(p_{\\mathit{Cara}}\\), el contraste es \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Ejemplo 3.5 Supongamos que lanzamos la moneda 3 veces y obtenemos 3 caras. ¿Es evidencia suficiente de que está trucada? Llamemos \\(S_3\\) a la variable aleatoria “Número de caras en 3 lanzamientos de esta moneda.” Si la moneda no está trucada, \\(S_3\\) es binomial \\(B(3,0.5)\\), y por lo tanto \\[ P(S_3=3)=0.5^{3}=0.125. \\] El resultado obtenido no es muy improbable con una moneda equilibrada: pasa, de media, en 1 de cada 8 secuencias de 3 lanzamientos. Por lo tanto, no vamos a considerarlo evidencia suficiente de que la moneda esté trucada. Aceptamos que la moneda es equilibrada. A este tipo de procedimiento, usar la distribución binomial del número de éxitos en una muestra aleatoria simple de una variable aleatoria de Bernoulli para contrastar un valor de su probabilidad poblacional de éxito, lo llamaremos un test binomial. Ejemplo 3.6 Supongamos que ahora lanzamos la moneda 10 veces y obtenemos 10 caras. ¿Es evidencia suficiente de que está trucada? Llamemos \\(S_{10}\\) a la variable aleatoria “Número de caras en 10 lanzamientos.” Si la moneda no está trucada, \\(S_{10}\\) es \\(B(10,0.5)\\) y por lo tanto \\[ P(S_{10}=10)=0.5^{10}=0.001 \\] El resultado obtenido es bastante improbable si la moneda no está trucada: si la moneda fuera equilibrada, de media solo en 1 de cada 1000 secuencias de 10 lanzamientos obtendríamos 10 caras. Es decir: El resultado de nuestro experimento sería muy raro si la moneda fuera equilibrada, por lo tanto es inverosímil que sea equilibrada. Lo consideramos evidencia de que está trucada. Tenemos una hipótesis (la nula), realizamos un experimento para contrastarla y obtenemos un resultado que es muy improbable si la hipótesis de partida es verdadera. Una de dos: O la hipótesis de partida es falsa. O la hipótesis de partida es verdadera y ha pasado algo muy raro. ¿Qué es lo más sensato concluir? Teniendo en cuenta que las cosas muy raras no suelen pasar, lo más sensato es concluir que la hipótesis de partida es falsa. Fijaos en el procedimiento: Hemos planteado el contraste: \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Hemos recogido una muestra aleatoria simple de valores: la secuencia de lanzamientos. Hemos elegido un estadístico de contraste con distribución muestral conocida cuando \\(H_0\\) es verdadera: en nuestro caso, el número de caras. Hemos calculado el valor de este estadístico sobre nuestra muestra. Hemos calculado la probabilidad de que el estadístico tome el valor observado si \\(H_0\\) es verdadera. Si esta probabilidad es muy pequeña, lo consideramos evidencia de que \\(H_1\\) es verdadera Si no es lo bastante pequeña, no tenemos evidencia de que \\(H_0\\) sea falsa. Bien, esto es lo que hemos hecho, pero no es del todo correcto. En los puntos (5) y (6) decimos que: “Calculamos la probabilidad de que el estadístico tome el valor observado si \\(H_0\\) es verdadera y si es muy pequeña, lo consideramos evidencia de que \\(H_1\\) es verdadera.” ¿Seguro que queremos hacer esto? Supongamos que, en el contraste anterior, lanzamos la moneda 10 veces y obtenemos 10 cruces. ¿Es evidencia suficiente de que está trucada en favor de cara? Obviamente no lo puede ser, pero la probabilidad es la misma que antes: \\[ P(S_{10}=0)=0.5^{10}=0.001 \\] En muchos casos, la probabilidad de obtener exactamente lo que hemos obtenido puede ser muy pequeña, independientemente de lo que hayamos obtenido. Por ejemplo, supongamos que lanzamos la moneda 10000 veces y obtenemos 5000 caras. Si la moneda es equilibrada, el número de caras seguirá una distribución binomial \\(B(10000,0.5)\\) y la probabilidad de obtener 5000 caras será \\[ \\binom{10000}{5000}0.5^{10000}=0.008 \\] muy pequeña, pero claramente que la mitad de lanzamientos den cara no puede ser evidencia de que la moneda esté trucada. O, más exagerado aún, si el estadístico de contraste es una variable continua, la probabilidad de que tome un valor concreto, el que sea, es 0. Más pequeño imposible, pero no siempre rechazaremos la hipótesis nula. Figura 3.1: “Null hypothesis” (https://xkcd.com/892/ (CC-BI-NC 2.5)) Así que: En realidad, en (5) se calcula la probabilidad de que, si \\(H_0\\) es verdadera, el estadístico tome un valor tan extremo o más, en el sentido de \\(H_1\\), que el obtenido. A esta probabilidad la llamamos el p-valor. En nuestro ejemplo de la moneda, como la hipótesis nula es \\(p_{\\mathit{Cara}}= 0.5\\) y la hipótesis alternativa es \\(p_{\\mathit{Cara}}&gt; 0.5\\), el p-valor es la probabilidad de que, si \\(p_{\\mathit{Cara}}= 0.5\\), el número de caras sea igual o mayor que el obtenido en nuestra muestra. En los dos ejemplos anteriores concretos, donde obteníamos 3 caras en 3 lanzamientos y 10 caras en 10 lanzamientos, era lo mismo pedir que el número de caras fuera igual al obtenido y pedir que el número de caras fuera mayor o igual que el obtenido, porque en los dos experimentos hemos obtenido el número máximo posible de caras; por ejemplo, sacar 3 o más caras en 3 lanzamientos es exactamente lo mismo que sacar 3 caras en 3 lanzamientos. Pero en general esto no será así. Ejemplo 3.7 Volvamos a nuestro contraste \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Supongamos que lanzamos la moneda 10 veces y obtenemos 7 caras. ¿Es evidencia suficiente de que está trucada? Seguimos llamando \\(S_{10}\\) a la variable aleatoria “Número de caras en 10 lanzamientos”. Si la moneda no está trucada, \\(S_{10}\\) es \\(B(10,0.5)\\). Como la hipótesis alternativa es \\(p_{\\mathit{Cara}}&gt; 0.5\\), “obtener un número de caras tan extremo o más que el que hemos obtenido en el sentido de la hipótesis alternativa” es sacar tantas caras como las que hemos obtenido o más, es decir sacar 7 o más caras. Por lo tanto \\[ \\text{p-valor}=P(S_{10}\\geqslant 7)=1-P(S_{10}\\leqslant 6)=\\texttt{1-pbinom(6,10,0.5)}=0.172 \\] Un número de caras igual o superior al obtenido no es muy improbable si la moneda no está trucada: pasaría en 1 de cada 6 secuencias de 10 lanzamientos. Por lo tanto, como es bastante compatible con el hecho que la moneda sea equilibrada, no lo podemos considerar evidencia de que esté trucada a favor de cara. Ejemplo 3.8 Tenemos una moneda, y ahora creemos que está trucada a favor de cruz. Queremos contrastarlo. Planteado en términos de \\(p_{\\mathit{Cara}}\\), el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}: p_{\\mathit{Cara}}&lt; 0.5 \\end{array} \\right. \\] Lanzamos la moneda 10 veces y obtenemos 1 cara. ¿Es suficiente evidencia de que \\(p_{\\mathit{Cara}}&lt; 0.5\\)? Seguimos llamando \\(S_{10}\\) a la variable aleatoria “Número de caras en 10 lanzamientos de esta moneda.” Si la moneda no está trucada, \\(S_{10}\\) es \\(B(10,0.5)\\). Ahora, como \\(H_{1}\\) es \\(p_{\\mathit{Cara}}&lt; 0.5\\), “obtener un número de caras tan extremo o más que el que hemos obtenido, en el sentido de la hipótesis alternativa” es sacar tantas caras como las que hemos obtenido o menos, es decir sacar 1 cara o ninguna. Por lo tanto \\[ \\text{p-valor}=P(S_{10}\\leqslant 1)=\\texttt{pbinom(1,10,0.5)}=0.01 \\] Un resultado tan o más extremo como el obtenido es muy improbable si \\(p_{\\mathit{Cara}}= 0.5\\): de media, solo ocurre en 1 de cada 100 secuencias de 10 lanzamientos. Lo podemos considerar evidencia de que la moneda sí que está trucada en favor de cruz. 3.3 El p-valor El p-valor de un contraste es la probabilidad de que, si la hipótesis nula es verdadera, el estadístico de contraste tome en una muestra aleatoria simple del mismo tamaño que la nuestra un valor tan o más extremo, en el sentido de la hipótesis alternativa, que el obtenido con la muestra usada para realizar el contraste. Lo repetimos, poniendo énfasis en los componentes fundamentales de la definición. El p-valor es: La probabilidad de que, si la hipótesis nula es verdadera, el estadístico de contraste tome en una muestra aleatoria simple del mismo tamaño que la nuestra un valor tan o más extremo, en el sentido de la hipótesis alternativa, que el obtenido con nuestra muestra. Ejemplo 3.9 Supongamos que en el contraste de las medias semanales de horas de deporte de hombres y mujeres del Ejemplo 3.4 usamos como estadístico de contraste la diferencia entre las medias muestrales \\(\\overline{X}_m-\\overline{X}_h\\) (no será así: ¡solo es un ejemplo!), que hemos tomado muestras de 50 mujeres y de 50 hombres, y que la diferencia de medias muestrales ha sido -1.2. Entonces, el p-valor del contraste es La probabilidad de que, si la hipótesis nula es verdadera, si \\(\\mu_m=\\mu_h\\), es decir, si los hombres y las mujeres practican de media el mismo número de horas de deporte a la semana, el estadístico de contraste tome en una muestra aleatoria simple del mismo tamaño que la nuestra el valor de \\(\\overline{X}_m-\\overline{X}_h\\), es decir, de la diferencia entre las medias muestrales de horas semanales de deporte en las mujeres y en los hombres, en una muestra aleatoria formada por 50 mujeres y 50 hombres un valor tan o más extremo, en el sentido de la hipótesis alternativa, sea menor o igual (porque la hipótesis alternativa es \\(\\mu_m&lt;\\mu_h\\), es decir \\(\\mu_m-\\mu_h&lt;0\\)) que el obtenido con nuestra muestra. que el de nuestra muestra, -1.2. En resumen, el p-valor seria en este caso La probabilidad, suponiendo que \\(\\mu_m=\\mu_h\\), de que, si tomamos una muestra aleatoria de 50 mujeres y 50 hombres, el valor de \\(\\overline{X}_m-\\overline{X}_h\\) que obtengamos sea menor o igual que -1.2. Si esta probabilidad es muy pequeña, la muestra obtenida es poco consistente con la hipótesis nula y por tanto concluiremos que la hipótesis alternativa es verdadera. Si, en cambio, esta probabilidad no es muy pequeña, la muestra obtenida es consistente con la hipótesis nula y por tanto no podremos rechazar que \\(H_0\\) sea verdadera. El p-valor no es: Ni la probabilidad de que \\(H_0\\) sea verdadera condicionada a nuestro resultado. Ni la probabilidad de que \\(H_1\\) sea falsa condicionada a nuestro resultado. Es al revés: El p-valor es la probabilidad de nuestro resultado (o uno más extremo) condicionada al hecho de que \\(H_0\\) sea verdadera. Por lo tanto, el p-valor es una evidencia indirecta inversa de \\(H_1\\): Cuanto más pequeño sea el p-valor, más raro sería lo que hemos obtenido si \\(H_0\\) fuera verdadera y \\(H_1\\) falsa, y por tanto más evidencia tenemos de que \\(H_0\\) no puede ser verdadera y que la verdadera es \\(H_1\\). Por ejemplo, si el p-valor de un contraste vale 0.03: Significa que, si \\(H_0\\) es verdadera, la probabilidad de que el estadístico de contraste tome sobre una muestra un valor tan extremo o más, en el sentido de \\(H_1\\), que el que hemos obtenido es 0.03. ¿Lo encontráis pequeño? Lo tomáis como evidencia de que \\(H_0\\) es falsa y \\(H_1\\) verdadera. ¿No lo encontráis pequeño? No tenéis evidencia para rechazar que \\(H_0\\) es verdadera. No significa que: La probabilidad de que \\(H_0\\) sea verdadera es 0.03. \\(H_0\\) es verdadera un 3% de las veces. En un contraste de hipótesis no obtenemos ninguna información directa sobre la probabilidad de \\(H_0\\) o de \\(H_1\\). Ejemplo 3.10 Tenemos una moneda y creemos que está trucada; a favor de cara o a favor de cruz, no lo sabemos, solo sospechamos que no es equilibrada. Queremos contrastarlo. Planteado en términos de la probabilidad de sacar cara \\(p_{\\mathit{Cara}}\\), el contraste que queremos realizar ahora es \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}\\neq 0.5 \\end{array} \\right. \\] Supongamos que la lanzamos 10 veces y obtenemos 8 caras. ¿Es evidencia suficiente de que está trucada? Como en la sección anterior, sea \\(S_{10}\\) la variable “Número de caras en 10 lanzamientos”. Si \\(p_{\\mathit{Cara}}= 0.5\\), \\(S_{10}\\) es \\(B(10,0.5)\\). Si la hipótesis nula fuera verdadera, esperaríamos sacar 5 caras y 5 cruces. Como la hipótesis alternativa es \\(H_{1}:p_{\\mathit{Cara}}\\neq 0.5\\), ahora “obtener un resultado tan o más extremo, en el sentido de la hipótesis alternativa, que el obtenido” es sacar un resultado tan diferente o más de 5 caras y 5 cruces que el obtenido. Es decir, sacar al menos 8 caras o al menos 8 cruces, o lo que es el mismo, sacar o bien 8 o más caras, o bien 2 o menos caras. Por lo tanto, el p-valor es \\[ \\begin{array}{l} P(S_{10}\\geqslant 8\\text{ o }S_{10}\\leqslant 2) =P(S_{10}\\geqslant 8) + P(S_{10}\\leqslant 2)\\\\ \\qquad =1-P(S_{10}\\leqslant 7) + P(S_{10}\\leqslant 2)\\\\ \\qquad =\\texttt{1-pbinom(7,10,0.5)+pbinom(2,10,0.5)}\\\\ \\qquad =0.11 \\end{array} \\] Por lo tanto, si la moneda no está trucada, un resultado como el obtenido o más lejano de “mitad caras, mitad cruces” es improbable, pero no mucho (1 de cada 9 veces pasaría). ¿Es evidencia suficiente de que esté trucada? 3.4 Tipo de errores En el último ejemplo nos ha surgido la cuestión de qué p-valor marca el umbral entre obtener evidencia o no. ¿Es 0.11 lo bastante pequeño? La respuesta es que depende de cuánto estemos dispuestos a equivocarnos. La comparación entre la realidad y la conclusión de un contraste da lugar a cuatro situaciones posibles, resumidas en la tabla siguiente: Si \\(H_0\\) es la hipótesis verdadera en la realidad y nosotros decidimos que \\(H_1\\) es verdadera: La conclusión del contraste es errónea. Lo llamaremos un error de tipo I, error \\(\\alpha\\) o falso positivo. Denotaremos por \\(\\alpha\\) la probabilidad de cometer un error de tipo I, es decir, de rechazar \\(H_0\\) si es verdadera, y la llamaremos el nivel de significación: \\[ \\alpha=P(\\text{Rechazar } H_0\\,|\\, H_0\\text{ verdadera}). \\] Si \\(H_1\\) es la hipótesis verdadera en la realidad y nosotros aceptamos \\(H_0\\): La conclusión del contraste es errónea. Lo llamaremos error de tipo II, error \\(\\beta\\) o falso negativo. Denotaremos por \\(\\beta\\) la probabilidad de cometer un error de tipo II, es decir, de aceptar \\(H_0\\) si \\(H_1\\) es verdadera: \\[ \\beta=P(\\text{Aceptar } H_0\\,|\\, H_1\\text{ verdadera}). \\] Si \\(H_1\\) es la hipótesis verdadera en la realidad y nosotros decidimos rechazar \\(H_0\\) en favor de \\(H_1\\): La conclusión del contraste es correcta. Lo llamaremos un verdadero positivo. La probabilidad de acertar con un verdadero positivo es \\(1-\\beta\\) y la llamaremos la potencia: \\[ 1-\\beta=P(\\text{Rechazar } H_0\\,|\\, H_1\\text{ verdadera}). \\] Si \\(H_0\\) es la hipótesis verdadera en la realidad y nosotros la aceptamos: La conclusión del contraste es correcta. Lo llamaremos un verdadero negativo. La probabilidad de acertar con un verdadero negativo es \\(1-\\alpha\\) y la llamaremos el nivel de confianza: \\[ 1-\\alpha=P(\\text{Aceptar } H_0\\,|\\, H_0\\text{ verdadera}). \\] En el contexto de un contraste de hipótesis, Un resultado positivo es rechazar la hipótesis nula y decidir que la alternativa es la verdadera (hemos encontrado algo). Un resultado negativo es aceptar la hipótesis nula (no hemos encontrado nada y nos conformamos con la hipótesis nula). Repetimos: El nivel de significación de un contraste es la probabilidad de que, si la hipótesis nula es verdadera, nosotros nos equivoquemos y la rechacemos en favor de la alternativa: \\[ \\alpha=P(\\text{Rechazar } H_0\\,|\\, H_0\\text{ verdadera}). \\] La potencia de un contraste es la probabilidad de que, si la hipótesis alternativa es verdadera, nosotros lo detectemos y rechacemos la hipótesis nula en favor de la alternativa: \\[ 1-\\beta=P(\\text{Rechazar } H_0\\,|\\, H_1\\text{ verdadera}). \\] Ejemplo 3.11 En un test de embarazo, el contraste que se realiza es: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{No estás embarazada}\\\\ H_{1}:\\text{Estás embarazada} \\end{array} \\right. \\] Ejemplo 3.12 En un juicio, donde se tiene que declarar un acusado inocente o culpable, el contraste era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El acusado es inocente}\\\\ H_{1}:\\text{El acusado es culpable} \\end{array} \\right. \\] Se pueden cometer dos errores: Error de tipo I: Declarar culpable un inocente. Error de tipo II: Declarar no culpable un culpable. Es peor el error de tipo I, conviene minimizar la probabilidad de cometerlo. Por eso solo se declara a alguien culpable cuando las pruebas lo “demuestran más allá de toda duda razonable”. Ejemplo 3.13 En un examen, el contraste era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El estudiante no sabe la materia}\\\\ H_{1}:\\text{El estudiante sabe la materia} \\end{array} \\right. \\] Se pueden dar dos errores: Que el estudiante apruebe sin saber la materia. Que el estudiante suspenda sabiendo la materia. ¿Cuál es el de tipo I y cuál el de tipo II? ¿Cuál creéis que es peor? Recordad la interpretación de una prueba diagnóstica como un contraste de hipótesis (Ejemplo 3.3). Interpretad su especificidad y sensibilidad en términos de \\(\\alpha\\) y \\(\\beta\\). Normalmente, se considera peor cometer un error de tipo I que cometer un error de tipo II. Por lo tanto, el objetivo primario en un contraste es encontrar una regla de rechazo de \\(H_{0}\\) que tenga poca probabilidad \\(\\alpha\\) de error de tipo I. Pero también querríamos minimizar la probabilidad \\(\\beta\\) de error de tipo II. El problema es que cuando hacemos que \\(\\alpha\\) disminuya, \\(\\beta\\) suele aumentar, porque al hacer más difícil rechazar la hipótesis nula, aumenta el riesgo de no rechazarla aunque sea falsa. ¿Qué se suele hacer? Se da una regla de decisión para el nivel de significación \\(\\alpha\\) deseado. Después, se toma el tamaño \\(n\\) adecuado de la muestra para reducir la \\(\\beta\\) al valor deseado. Es costumbre tomar \\(\\alpha=0.05\\): algo menos que la probabilidad de sacar 4 caras seguidas con una moneda equilibrada. Antes de acabar con los errores, fijaos en que si efectuamos \\(M\\) contrastes (independientes) usando una regla de decisión que garantice un nivel de significación \\(\\alpha\\) dado, y en todos estos contrastes la \\(H_0\\) es verdadera, el número de contrastes donde nos equivocaremos y rechazaremos \\(H_0\\) tiene distribución binomial \\(B(M,\\alpha)\\). En particular, esperamos equivocarnos en \\(\\alpha M\\) de estos \\(M\\) contrastes en los que la hipótesis nula sea verdadera. En concreto, tomando \\(\\alpha=0.05\\), aceptamos una probabilidad de equivocarnos rechazando \\(H_0\\) en favor de \\(H_1\\) de 0.05. Es decir, asumimos que, de media, nos vamos a equivocar 1 de cada 20 veces que la hipótesis nula sea verdadera. Si efectuamos muchos contrastes, aumenta la probabilidad de “encontrar algo” aunque no haya nada que encontrar, y acabar diciendo que las gominolas verdes curan el acné. Figura 3.2: “Significant” (https://xkcd.com/882/ (CC-BI-NC 2.5)) 3.5 Ejemplo: El test t La concentración media de calcio en plasma en hombres sanos de 22 a 44 años es de 2.5 mmol/l. Supongamos que nos preguntamos si los hombres jóvenes con diabetes tienen una concentración de calcio en plasma superior a la de los hombres jóvenes sanos. Traducimos esta cuestión en un contraste de hipótesis sobre la concentración media de calcio en plasma en los hombres jóvenes con diabetes, a la que llamaremos \\(\\mu\\): La hipótesis nula será que no hay diferencia entre \\(\\mu\\) y la concentración media de calcio en plasma en los hombres jóvenes sanos, es decir, que \\(\\mu=2.5\\) La hipótesis alternativa es de lo que buscamos evidencia: que \\(\\mu&gt;2.5\\). Por lo tanto, el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt;2.5 \\end{array} \\right. \\] Llamemos \\(X\\) a la variable aleatoria “Tomamos un hombre diabético de 22 a 44 años y le medimos la concentración de calcio en plasma en mmol/l”. Vamos a suponer en esta sección que esta variable \\(X\\) sigue una ley normal. En una muestra de 40 diabéticos de esta franja de edad, se obtuvo una concentración media de calcio en plasma de \\(\\overline{x}=3.2\\) mmol/l con una desviación típica muestral \\(\\widetilde{s}=1.5\\). Vamos a suponer que podemos considerar esta muestra de diabéticos jóvenes como aleatoria. Nuestra situación, pues, es un caso particular del caso general siguiente. Tenemos una variable aleatoria poblacional \\(X\\) que es \\(N(\\mu,\\sigma)\\) y planteamos el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt;\\mu_0 \\end{array} \\right. \\] para un valor concreto \\(\\mu_0\\). Queremos tomar una decisión a partir de una muestra aleatoria simple. En esta situación, si \\(H_0\\) es verdadera, es decir, si la media de \\(X\\) es \\(\\mu_0\\), sabemos que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] tiene distribución \\(t_{n-1}\\). La idea que guiará el procedimiento para tomar una decisión en este contraste será: Rechazaremos \\(H_0\\) en favor de \\(H_1\\) si este estadístico de contraste \\(T\\) toma un valor “muy grande” sobre la muestra, es decir, si \\(\\overline{X}\\) es “muchos errores típicos” mayor que \\(\\mu_0\\). La definición precisa de “muy grande” dependerá del valor de \\(\\alpha\\) que queramos tomar, es decir, de la probabilidad de cometer un error de tipo I que estemos dispuestos a asumir: cuanto menor queramos que sea \\(\\alpha\\), mayor tendrá que ser la evidencia a favor de \\(\\mu&gt;\\mu_0\\), es decir, mayor tendrá que ser \\(T\\). Aquí vamos a tomar el valor usual \\(\\alpha=0.05\\). Sea \\(T_0\\) el valor que toma el estadístico de contraste \\(T\\) en nuestra muestra. Rechazaremos \\(H_{0}\\) si \\(T_0\\) es mayor que un cierto umbral \\(L_0\\), que determinamos a partir de \\(\\alpha\\): \\[ \\begin{array}{l} \\alpha = P(\\text{Rechazar } H_{0}\\,|\\, H_{0} \\text{ cierta})=P(T&gt; L_0)\\\\ \\qquad\\quad \\Longrightarrow 1-\\alpha= P(T\\leqslant L_0)\\Longrightarrow L_0= t_{n-1,1-\\alpha} \\end{array} \\] Por lo tanto, para que el nivel de significación del contraste sea \\(\\alpha\\), Rechazaremos \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) Llamaremos a esta regla una regla de rechazo para este tipo de contraste. Volvamos a nuestro ejemplo de los jóvenes diabéticos \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt; 2.5 \\end{array} \\right. \\] Si \\(\\alpha=0.05\\) y \\(n=40\\), el umbral a partir del cual rechazamos \\(H_0\\) es \\(t_{n-1,1-\\alpha}=t_{39,0.95}=\\)qt(0.95,39)=1.685. En nuestra muestra tenemos que \\(\\overline{x}=3.2\\), \\(\\widetilde{s}=1.5\\) y \\(n=40\\), por lo tanto el estadístico de contraste vale \\[ T_0=\\frac{3.2-2.5}{1.5/\\sqrt{40}}=2.95 \\] Como 2.95&gt;1.685, concluimos con un nivel de significación del 5% que el nivel medio de calcio en sangre en los jóvenes diabéticos es mayor que en los jóvenes sanos. Vamos a ver como entra en juego el p-valor. Recordemos que rechazamos \\(H_0\\) cuando \\(T_0&gt;t_{n-1,1-\\alpha}\\): \\[ \\begin{array}{l} \\text{Rechazamos $H_0$} \\Longleftrightarrow T_0&gt; t_{n-1,1-\\alpha}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; P(T\\geqslant t_{n-1,1-\\alpha})\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; 1-P(T\\leqslant t_{n-1,1-\\alpha})=1-(1-\\alpha)=\\alpha\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt;\\alpha \\end{array} \\] I ahora notad que \\(P(T\\geqslant T_0)\\) es la probabilidad de que, si \\(H_0\\) es verdadera, el estadístico de contraste \\(T\\) tome un valor tan o más extremo, en el sentido de \\(H_1: \\mu&gt;2.5\\), que el obtenido en nuestra muestra, \\(T_0\\): ¡es el p-valor del contraste! Por lo tanto, tenemos otra regla de rechazo (equivalente a la anterior): Rechazaremos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) En nuestro ejemplo, ya hemos calculado \\(T_0=2.95\\). Entonces, \\[ \\text{p-valor} =P(T\\geqslant 2.95)=\\texttt{1-pt(2.95,39)} =0.003 \\] Como el p-valor es menor que 0.05: Concluimos con un nivel de significación del 5% que el nivel medio de calcio en plasma en los jóvenes diabéticos es mayor que en los jóvenes sanos. Esto también se suele expresar diciendo que Hemos obtenido evidencia estadísticamente significativa de que el nivel medio de calcio en plasma en los jóvenes diabéticos es mayor que en los jóvenes sanos. A este tipo de procedimiento para comparar la \\(\\mu\\) de una variable con un valor dado \\(\\mu_0\\), usando que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] sigue una distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\), se le llama un test t. En la próxima lección explicaremos cuándo se puede usar. Fijaos en que nuestra conclusión ha sido que “concluimos con un nivel de significación del 5% que el nivel medio de calcio en sangre en los jóvenes diabéticos es mayor que en los jóvenes sanos.” Por lo tanto, reconocemos una probabilidad de equivocarnos del 5%. Si en realidad el nivel medio de calcio en sangre en los jóvenes diabéticos es el mismo que en los sanos, la probabilidad que tenemos de equivocarnos y concluir que el nivel medio de calcio en sangre en los jóvenes diabéticos es mayor que en los sanos es del 5%. Que tengamos un 5% de probabilidad de equivocarnos significa que, si la hipótesis nula es verdadera, un 5% de las muestras aleatorias de 40 diabéticos sanos dan un valor de \\(T\\) que nos hace rechazar la hipótesis nula. Ejemplo 3.14 Vamos a estudiar esta tasa de aciertos por medio de una simulación. Primero supondremos que el nivel medio real es 2.5, y simularemos la probabilidad de error de tipo I. Como estamos realizando el contraste con nivel de significación 0.05, esperamos alrededor de un 5% de errores de tipo I. Para fijar ideas, modelaremos la población de jóvenes diabéticos por medio de una variable aleatoria normal \\(N(2.5,0.5)\\). La \\(\\sigma=0.5\\) nos la hemos inventado. Damos el código R de la simulación, por si la queréis repetir en casa. Cada simulación dará resultados diferentes, pero en general serán muy parecidos a los nuestros. mu0=2.5 sigma0=0.5 El umbral \\(L_0\\) para \\(n=40\\) y \\(\\alpha=0.05\\) es \\(t_{39,0.975}\\): L0=qt(0.95,39) L0 ## [1] 1.684875 La función estadístico siguiente toma una muestra aleatoria de tamaño \\(n\\) de una variable \\(N(\\mu, \\sigma)\\) y calcula el estadístico de contraste \\(T\\): estadístico=function(n,mu,sigma){ muestra=rnorm(n,mu,sigma) (mean(muestra)-mu0)/(sd(muestra)/sqrt(n)) } Ahora, repetimos 200 veces el proceso de tomar una muestra aleatoria de tamaño 40 de nuestra población y calcular la \\(T\\) correspondiente. Llamamos Tes al vector de estos valores de \\(T\\): Tes=replicate(200,estadístico(40,mu0,sigma0)) Finalmente, calculamos la proporción de veces que la \\(T\\) ha dado un valor mayor que el umbral \\(L_0\\), es decir, la proporción de veces que rechazamos la hipótesis nula \\(\\mu=2.5\\) y que por lo tanto cometemos un error de tipo I. p.error.Tipo.I=length(which((Tes&gt;L0)==TRUE))/200 p.error.Tipo.I ## [1] 0.055 Hemos cometido un 5.5% de errores de tipo I, muy cercano al 5% “poblacional” (en el conjunto de todas las muestras aleatorias que pudiéramos tomar). Ahora vamos a suponer que el nivel medio real es estrictamente mayor que 2.5, y vamos a simular los errores de tipo II, para ver con qué frecuencia los cometemos. Para empezar, generamos al azar un vector de 100 \\(\\mu\\)’s entre 2.6 y 3, de manera que todos los valores tengan la misma probabilidad de salir. mus=runif(100,2.6,3) Y ahora lo que haremos será lo siguiente. Para cada \\(\\mu_i\\) de este vector, tomaremos como “población de diabéticos” una variable \\(N(\\mu_i,0.5)\\). A continuación, para cada una de estas poblaciones, repetiremos 200 veces el proceso de tomar una muestra aleatoria simple de tamaño 40 de esta población y calcular la \\(T\\) correspondiente. Después, para cada población, miraremos la proporción de veces que la \\(T\\) ha dado menor o igual que el umbral \\(L_0\\), es decir, la proporción de veces que aceptaríamos la hipótesis nula \\(\\mu=2.5\\) y que por lo tanto cometeríamos un error de tipo II. Organizamos todas estas proporciones en un vector que llamamos p.error.Tipo.II. p.error.Tipo.II=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístico(40,mus[j],sigma0)) p.error.Tipo.II[j]=length(which((Tes&lt;=L0)==TRUE))/200 } p.error.Tipo.II ## [1] 0.015 0.275 0.055 0.005 0.495 0.040 0.000 0.005 0.420 0.090 0.000 0.085 ## [13] 0.245 0.000 0.195 0.000 0.080 0.000 0.525 0.000 0.000 0.410 0.140 0.000 ## [25] 0.000 0.330 0.050 0.000 0.010 0.610 0.460 0.575 0.000 0.000 0.005 0.000 ## [37] 0.110 0.000 0.000 0.000 0.000 0.000 0.015 0.115 0.020 0.000 0.000 0.000 ## [49] 0.040 0.015 0.000 0.005 0.000 0.000 0.045 0.190 0.000 0.005 0.560 0.085 ## [61] 0.000 0.000 0.595 0.015 0.005 0.000 0.000 0.000 0.500 0.000 0.085 0.195 ## [73] 0.370 0.645 0.015 0.000 0.245 0.130 0.140 0.590 0.315 0.325 0.000 0.105 ## [85] 0.000 0.085 0.000 0.460 0.000 0.000 0.005 0.175 0.065 0.390 0.000 0.000 ## [97] 0.010 0.000 0.000 0.000 En algunos casos no hemos cometido ningún error de tipo II, y en otros, en más de la mitad de las veces. La proporción media de errores de tipo II ha sido: mean(p.error.Tipo.II) ## [1] 0.1179 Si tomamos muestras más grandes, la probabilidad de error de tipo II disminuye. Comprobémoslo repitiendo este segundo experimento con muestras de tamaño 400. p.error.Tipo.II.400=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístico(400,mus[j],sigma0)) p.error.Tipo.II.400[j]=length(which((Tes&lt;=L0)==TRUE))/200 } mean(p.error.Tipo.II.400) ## [1] 2e-04 Por si no os habéis encontrado nunca con la notación que ha usado R para dar este resultado, es la llamada notación científica y se usa para expresar números muy grandes o muy pequeños. La e significa “multiplica el número que me precede por 10 elevado al número que me sigue”. Así, 2e-04 significa \\(2\\times 10^{-4}\\). Multiplicando por 10 el tamaño de las muestras, hemos bajado de una tasa de errores de tipo II del 11.79% al 0.02%. Recordad que la potencia de un contraste es la probabilidad de no cometer un error de tipo II. Hemos visto que tomando muestras más grandes, la proporción de errores de tipos II ha disminuido. Esto es general: Si fijamos el nivel de significación, cuanto mayores son las muestras, mayor es la potencia del contraste. Volvemos a la situación general en la que tenemos una variable aleatoria \\(X\\) normal \\(N(\\mu,\\sigma)\\) y queremos comparar \\(\\mu\\) con cierto valor \\(\\mu_0\\) y supongamos que ahora buscamos evidencia de que \\(\\mu&lt;\\mu_0\\), de manera que el contraste es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] En este caso, el p-valor es \\(P(T\\leqslant T_0)\\) y, razonando exactamente igual que antes, obtenemos las dos reglas de rechazo equivalentes siguientes: Rechazaremos \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) Rechazaremos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) ¿Y qué pasa si ahora buscamos evidencia de que \\(\\mu\\) es diferente de \\(\\mu_0\\)? Es decir, si nos planteamos el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\ \\neq \\mu_0 \\end{array} \\right. \\] En este caso, rechazaremos \\(H_{0}\\) cuando \\(\\overline{X}\\) es lo bastante diferente de \\(\\mu_0\\), por encima o por debajo de \\(\\mu_0\\), y esto lo traducimos en que rechazaremos \\(H_{0}\\) cuando \\(|T_0|\\) (el valor absoluto de \\(T_0\\)) sea mayor que cierto umbral \\(L_0\\), que determinamos a partir de \\(\\alpha\\) como antes: \\[ \\begin{array}{l} \\alpha = P(\\text{Rechazar } H_{0}| H_{0} \\text{ verdadera})=P(|T|&gt; L_0)\\\\ \\hphantom{\\alpha} = P(T&lt; -L_0\\text{ o } T&gt;L_0)= P(T&lt; -L_0)+P(T&gt;L_0)\\\\ \\hphantom{\\alpha} =2P(T&gt;L_0) \\text{ (por la simetría de $t_{n-1}$)}\\\\ \\Longrightarrow \\alpha/2=P(T&gt;L_0)= 1-P(T\\leqslant L_0) \\\\ \\Longrightarrow P(T\\leqslant L_0)=1-\\alpha/2\\Longrightarrow L_0= t_{n-1,1-\\alpha/2} \\end{array} \\] Por lo tanto, en un contraste bilateral con nivel de significación \\(\\alpha\\), tenemos la regla de rechazo siguiente: Rechazaremos \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) En este caso, el p-valor será la probabilidad de que \\(T\\) tome un valor tan o más extremo que \\(T_0\\), en el sentido de la hipótesis alternativa, es decir, más lejos de 0 que \\(T_0\\): mayor que \\(|T_0|\\) o menor que \\(-|T_0|\\): \\[ \\text{p-valor} =P(T\\leqslant-|T_0|)+P(T\\geqslant|T_0|)=2 P(T\\geqslant|T_0|). \\] Fijaos en que usamos que, por la simetría de las variables t de Student, \\(P(T\\leqslant-|T_0|)=P(T\\geqslant|T_0|)\\). Por lo tanto, \\[ \\begin{array}{l} \\text{Rechazamos $H_0$} \\Longleftrightarrow |T_0|&gt;t_{n-1,1-\\alpha/2}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant|T_0|)&lt;{\\alpha}/{2}\\\\ \\qquad\\Longleftrightarrow 2 P(T\\geqslant|T_0|)&lt;\\alpha\\\\ \\qquad \\Longleftrightarrow \\text{p-valor} &lt; \\alpha \\end{array} \\] Así pues, en un contraste bilateral con nivel de significación \\(\\alpha\\) también tenemos la regla de rechazo: Rechazaremos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) En resumen, en un contraste de una media \\(\\mu\\) usando un test t sobre una muestra de tamaño \\(n\\) y nivel de significación \\(\\alpha\\): Si \\(H_1:\\mu&gt; \\mu_0\\): Rechazamos \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) El p-valor es \\(P(T\\geqslant T_0)\\) Rechazamos \\(H_0\\) si el p-valor es más pequeño que \\(\\alpha\\) Si \\(H_1:\\mu&lt; \\mu_0\\): Rechazamos \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) El p-valor es \\(P(T\\leqslant T_0)\\) Rechazamos \\(H_0\\) si el p-valor es más pequeño que \\(\\alpha\\) Si \\(H_1:\\mu\\neq \\mu_0\\): Rechazamos \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) El p-valor es \\(2P(T\\geqslant|T_0|)\\) Rechazamos \\(H_0\\) si el p-valor es más pequeño que \\(\\alpha\\) Ejemplo 3.15 Sea \\(X\\) una población normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Tomamos una muestra aleatoria simple de \\(n=25\\) observaciones y obtenemos \\(\\overline{x}=20.7\\) y \\(\\widetilde{s}=1.8\\). ¿Qué decidimos? Estadístico de contraste: \\[ T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}} \\] que si \\(\\mu=\\mu_0\\), tiene distribución \\(t_{n-1}\\). Toma el valor \\[ T_0=\\dfrac{20.7-20}{{1.8}/{\\sqrt{25}}}=1.944 \\] p-valor \\[ P(T\\geqslant 1.944)=\\texttt{1-pt(1.944,24)}=0.032 \\] Decisión: Como el p-valor es más pequeño que 0.05, rechazamos \\(H_0\\) y concluimos (con \\(\\alpha=0.05\\)) que \\(\\mu&gt;20\\). Es decir, hemos obtenido evidencia estadísticamente significativa de que \\(\\mu&gt;20\\). Ejemplo 3.16 Sea \\(X\\) una población normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] con un nivel de significación de 0.01. Con la misma muestra aleatoria simple del ejemplo anterior, ¿qué decidimos? El p-valor es el mismo que antes, 0.032, porque el contraste y la muestra son los mismos. Como este p-valor ahora es mayor que 0.01, no podemos rechazar \\(H_0\\) con \\(\\alpha=0.01\\) y tenemos que aceptar que \\(\\mu=20\\). Fijaos en que para reducir la probabilidad de equivocarnos rechazando \\(H_0\\) si es verdadera, facilitamos aceptarla “por si acaso”. Ejemplo 3.17 Sea \\(X\\) una población normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&lt; 20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Con la misma muestra aleatoria simple de los ejemplos anteriores (\\(n=25\\), \\(\\overline{x}=20.7\\), \\(\\widetilde{s}=1.8\\)), ¿qué decidimos? El estadístico de contraste y su valor \\(T_0\\) son el mismos que antes. p-valor \\[ P(T\\leqslant 1.944)=\\texttt{pt(1.944,24)}=0.968 \\] Decisión: Como el p-valor es mayor que 0.05, no podemos rechazar \\(H_0\\) y tenemos que aceptar que \\(\\mu=20\\). Es decir, no hemos obtenido evidencia estadísticamente significativa de que \\(\\mu&lt;20\\). Veamos, ¿cómo queríais que hubiéramos encontrado evidencia de que \\(\\mu&lt;20\\) si nos ha salido una media muestral 20.7, mayor que 20? No hacía falta hacer ningún cálculo (y exponernos a equivocarnos), bastaba razonar un poco. Ejemplo 3.18 Sea \\(X\\) una población normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu \\neq 20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Con la misma muestra aleatoria simple de los ejemplos anteriores, ¿qué decidimos? Recordemos que \\(n=25\\), \\(\\overline{x}=20.7\\) y \\(\\widetilde{s}=1.8\\). El estadístico de contraste tomaba el valor \\(T_0=1.944\\). Ahora el p-valor es \\[ 2\\cdot P(T\\geqslant 1.944)=\\texttt{2(1-pt(1.944,24))}=0.064 \\] Como el p-valor es más grande que \\(\\alpha\\), no podemos rechazar \\(H_0\\): no podemos afirmar con \\(\\alpha=0.05\\) que \\(\\mu\\neq 20\\). Es decir, no hemos obtenido evidencia estadísticamente significativa de que \\(\\mu\\neq 20\\). ¿Cómo puede ser que, con la misma muestra y mismo nivel de significación, podamos concluir que \\(\\mu&gt; 20\\) pero no podamos concluir que \\(\\mu \\neq 20\\)? ¿Acaso \\(\\mu&gt; 20\\) no implica que \\(\\mu \\neq 20\\)? Veamos, si hubiéramos demostrado que seguro que \\(\\mu&gt; 20\\), está claro que esto implicaría que \\(\\mu \\neq 20\\). Pero hemos llegado a la conclusión \\(\\mu&gt; 20\\) asumiendo una cierta probabilidad de cometer un error de tipo I, y nos preguntamos si podemos decidir que \\(\\mu \\neq 20\\) asumiendo el mismo riesgo de equivocarnos. En esta situación las reglas de la lógica aristotélica ya no funcionan. Fijaos en que, en realidad, lo que pasa es que encontraríamos evidencia de que \\(\\mu \\neq 20\\) si \\(T\\) fuera muy grande o muy pequeño. Por lo tanto, en el contraste bilateral tenemos dos fuentes de error de tipo I: que por puro azar \\(T\\) nos salga muy grande o que nos salga muy pequeño. En cambio, solo encontraremos evidencia de que \\(\\mu&gt; 20\\) si \\(T\\) es muy grande, y por tanto en el contraste unilateral tenemos una sola fuente de error de tipo I. Entonces, para garantizar la misma probabilidad de error de tipo I, tenemos que ser mucho más exigentes en el contraste bilateral, donde nos podemos equivocar de dos maneras diferentes, que en el unilateral. Por eso es más fácil rechazar la hipótesis nula en un contraste unilateral que en uno bilateral. Ejemplo 3.19 Sea \\(X\\) una población normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu \\neq 20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Tomamos una muestra aleatoria simple de \\(n=25\\) observaciones y obtenemos \\(\\overline{x}=19\\) y \\(\\widetilde{s}=1.8\\). ¿Qué decidimos? Estadístico de contraste: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Toma el valor \\[ T_0=\\dfrac{19-20}{{1.8}/{\\sqrt{25}}}=-2.778 \\] p-valor \\[ 2P(T\\geqslant-2.778)=\\texttt{2(1-pt(-2.778,24))}=1.99 \\] Decisión: como el p-valor es mayor que \\(\\alpha\\), no podemos rechazar \\(H_0\\). El p-valor es una probabilidad. ¿Cómo queréis que dé 1.99? NO! El p-valor no es \\(2\\cdot P(T\\geqslant T_0)\\), sino \\(2\\cdot P(T\\geqslant|T_0|)\\). Por lo tanto, el p-valor es \\[ 2\\cdot P(T\\geqslant 2.778)=\\texttt{2(1-pt(2.778,24))}=0.01 \\] y como este p-valor es más pequeño que \\(\\alpha\\), podemos rechazar \\(H_0\\) y concluir, con nivel de significación 0.05, que \\(\\mu\\neq 20\\). Es decir, hemos obtenido evidencia estadísticamente significativa de que \\(\\mu\\neq 20\\). 3.6 Recapitulación Repasemos los conceptos introducidos hasta ahora, y pongamos nombre a otros: Nivel de significación, \\(\\alpha\\): probabilidad de rechazar \\(H_0\\) si esta es verdadera (probabilidad de error de tipo I, de falso positivo). Nivel de confianza, \\(1-\\alpha\\): probabilidad de aceptar \\(H_0\\) si esta es verdadera (probabilidad de verdadero negativo). Potencia, \\(1-\\beta\\): probabilidad de rechazar \\(H_0\\) si \\(H_1\\) es verdadera (probabilidad de verdadero positivo). Estadístico de contraste: lo que calculamos sobre una muestra aleatoria simple y nos permite definir una regla de rechazo de \\(H_{0}\\). Región crítica o de rechazo: el rango de valores del estadístico de contraste para los que rechazamos \\(H_{0}\\) con un nivel de significación \\(\\alpha\\) dado. Región de aceptación: el complementario de la región de rechazo, es decir, el rango de valores del estadístico de contraste para los que aceptamos \\(H_{0}\\) con un nivel de significación \\(\\alpha\\) dado. p-valor: la probabilidad de que, si \\(H_0\\) es verdadera, el estadístico de contraste tome sobre una muestra aleatoria simple del mismo tamaño que la nuestra un valor tan o más extremo (en el sentido de \\(H_1\\)) que el obtenido sobre nuestra muestra. Ejemplo 3.20 Si realizamos un test t para efectuar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] rechazamos \\(H_0\\) con nivel de significación \\(\\alpha\\) (o con nivel de confianza \\(1-\\alpha\\)) cuando \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&gt;t_{n-1,1-\\alpha} \\] Por lo tanto: Estadístico de contraste: este \\(T\\) Región crítica para el nivel de significación \\(\\alpha\\): el intervalo \\((t_{n-1,1-\\alpha},\\infty)\\) Región de aceptación para el nivel de significación \\(\\alpha\\): el intervalo \\((-\\infty,t_{n-1,1-\\alpha}]\\) p-valor: \\(P(T\\geqslant T_0)\\), donde \\(T_0\\) denota el valor de \\(T\\) en nuestra muestra Si en cambio el contraste que queremos efectuar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] rechazamos \\(H_0\\) con nivel de significación \\(\\alpha\\) (o con nivel de confianza \\(1-\\alpha\\)) cuando \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&lt;t_{n-1,\\alpha} \\] Por lo tanto: Estadístico de contraste: el mismo \\(T\\) que antes Región crítica para el nivel de significación \\(\\alpha\\): el intervalo \\((-\\infty,t_{n-1,\\alpha})\\) Región de aceptación para el nivel de significación \\(\\alpha\\): el intervalo \\([t_{n-1,\\alpha},\\infty)\\) p-valor: \\(P(T\\leqslant T_0)\\) Finalmente, si el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] rechazamos \\(H_0\\) con nivel de significación \\(\\alpha\\) (o con nivel de confianza \\(1-\\alpha\\)) cuando \\[ |T|=\\left|\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\right|&gt;t_{n-1,1-\\alpha/2} \\] Por lo tanto: Estadístico de contraste: el mismo \\(T\\) que antes Región crítica para el nivel de significación \\(\\alpha\\): la unión de intervalos \\((-\\infty,-t_{n-1,1-\\alpha/2})\\cup (t_{n-1,1-\\alpha/2},\\infty)\\) Región de aceptación para el nivel de significación \\(\\alpha\\): el intervalo \\([-t_{n-1,1-\\alpha/2},t_{n-1,1-\\alpha/2}]\\) p-valor: \\(2P(T\\geqslant|T_0|)\\) Intervalo de confianza de un contraste El intervalo de confianza de nivel de confianza \\(1-\\alpha\\) de un contraste es un intervalo que tiene una probabilidad \\(1-\\alpha\\) de contener el parámetro poblacional que contrastamos, en el sentido de los intervalos de confianza del tema anterior: se calcula con una fórmula que en un \\((1-\\alpha)\\cdot 100%\\) de las veces que la aplicamos a una muestra aleatoria simple, produce un intervalo que contiene el parámetro poblacional. Este intervalo de confianza se obtiene imponiendo que el estadístico de contraste pertenezca a la región de aceptación para el nivel de significación \\(\\alpha\\) y despejando el parámetro poblacional. Cuando \\(H_1\\) es bilateral, coincide con el intervalo de confianza dado en el tema anterior. Cuando \\(H_1\\) es unilateral, da un intervalo infinito en el lado definido por la hipótesis alternativa. Por ejemplo, consideremos el caso de un test t para efectuar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] Aceptamos \\(H_0\\) con nivel de significación \\(\\alpha\\) cuando \\[ \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha} \\] Despejando \\(\\mu_0\\), obtenemos \\[ \\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu_0 \\] Por lo tanto, el intervalo de confianza de nivel de confianza \\(1-\\alpha\\) para este contraste es \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\infty\\Bigg) \\] Si la \\(\\mu_0\\) que contrastamos pertenece a este intervalo, no podemos concluir que la \\(\\mu\\) poblacional sea más mayor que \\(\\mu_0\\), y por tanto no podemos rechazar que \\(\\mu=\\mu_0\\). Los valores de \\(\\mu_0\\) en este intervalo son tan grandes, que con nuestra muestra no hemos obtenido evidencia de que la \\(\\mu\\) real sea mayor que ellos. En el ejemplo de los diabéticos de la Sección 3.5, da el intervalo \\[ \\Bigg[3.2- 1.73\\cdot \\dfrac{1.5}{\\sqrt{20}},\\infty\\Bigg)=[2.62,\\infty) \\] Obtenemos que, con un nivel de confianza del 95%, la concentración media de calcio en sangre en los jóvenes diabéticos es como mínimo 2.62, y que por lo tanto, con este nivel de confianza, no puede ser 2.5, aunque por poco. Si efectuamos un contraste bilateral con un test t \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] aceptamos \\(H_0\\) con nivel de significación \\(\\alpha\\) cuando \\[ -t_{n-1,1-\\alpha/2}\\leqslant\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha/2} \\] Despejando \\(\\mu_0\\), obtenemos: \\[ \\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu_0 \\leqslant\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}} \\] Por lo tanto, el intervalo de confianza de nivel de confianza \\(1-\\alpha\\) para este contraste es \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] ¿Os suena? Llamando \\(q\\) a \\(1-\\alpha\\), de manera que \\[ 1-\\frac{\\alpha}{2}=1-\\frac{1-q}{2}=\\frac{1+q}{2}, \\] es el del tema anterior. En resument, dado un contraste de hipótesis, podemos decidir si rechazamos \\(H_0\\) en favor de \\(H_1\\) con nivel de significación \\(\\alpha\\) usando: La región crítica: Si el estadístico de contraste cae dentro de la región crítica para el nivel de significación \\(\\alpha\\), rechazamos \\(H_0\\). El p-valor: Si el p-valor es menor que el nivel de significación \\(\\alpha\\), rechazamos \\(H_0\\). El intervalo de confianza: Si el valor que contrastamos del parámetro poblacional no pertenece al intervalo de confianza de nivel de confianza \\(1-\\alpha\\), rechazamos \\(H_0\\). Los tres métodos son equivalentes. Lo más adecuado es dar el p-valor y el intervalo de confianza: el p-valor para que el lector lo pueda comparar con el nivel de significación que considere oportuno y el intervalo de confianza porque muestra el margen con el cual hemos aceptado o rechazado la hipótesis nula con nuestro nivel de significación. Si no establecemos un nivel de significación \\(\\alpha\\), lo habitual es: Aceptar \\(H_0\\) si el p-valor es mayor que 0.1: se dice que el p-valor no es estadísticamente significativo Rechazar \\(H_0\\) si el p-valor es menor que 0.05: se dice que el p-valor es estadísticamente significativo Si el p-valor está entre 0.05 y 0.1 y no se ha fijado nivel de significación, lo mejor que podéis hacer es no concluir nada y decir que es necesario repetir el estudio con una muestra mayor. Cuando el p-valor es menor que 0.05, se suelen distinguir tres franjas: Significativo si está entre 0.01 y 0.05 Fuertemente significativo si está entre 0.001 y 0.01 Muy significativo si es menor que 0.001 Normalmente estas franjas se indican con un código de asteriscos: Un asterisco, *, para los p-valores entre 0.01 y 0.05 Dos asteriscos, **, para los p-valores entre 0.001 y 0.01 Tres asteriscos, ***, para los p-valores por debajo de 0.001 Aunque hay otras propuestas: Dado que rechazamos \\(H_0\\) si, y solo si, el p-valor es menor que \\(\\alpha\\), el p-valor de un contraste es el nivel de significación más pequeño para el cual rechazaríamos la hipótesis nula. Es decir: El p-valor obtenido en un contraste es la probabilidad mínima de equivocarnos que asumimos al rechazar la hipótesis nula si esta es verdadera. Por lo tanto, por favor, acostumbraos a dar el p-valor, y no la franja de significación donde cae. La potencia Recordad que la potencia \\(1-\\beta\\) es la probabilidad de rechazar \\(H_0\\) cuando \\(H_1\\) es verdadera. Por ejemplo, en el ejemplo del calcio en diabéticos de la Sección 3.5, la regla de rechazo era \\[ T=\\frac{\\overline{X}-2.5}{\\widetilde{S}_X/\\sqrt{n}}&gt;1.685, \\] por lo tanto la potencia era \\[ 1-\\beta=P(\\text{Rechazar } H_0\\,|\\, H_1\\text{ verdadera})=P(T&gt;1.685\\,|\\, \\mu&gt;2.5). \\] Esta probabilidad es imposible de calcular, pero hay programas que la saben estimar. Vamos a explicar muy por encima cómo. Para cada tipo de contraste se tiene una relación numérica entre: La potencia \\(1-\\beta\\) El tamaño de la muestra \\(n\\): la potencia crece con \\(n\\) El nivel de significación \\(\\alpha\\): la potencia decrece con \\(\\alpha\\) El tamaño del efecto, un valor que cuantifica la diferencia entre el parámetro muestral y el valor contrastado. La potencia crece con el valor absoluto del tamaño del efecto (puesto que, cuanto mayor es la diferencia entre el parámetro muestral y el valor contrastado, más probable es que sea estadísticamente significativa y por tanto rechacemos la hipótesis nula). Esta relación permite calcular cualquiera de los cuatro valores a partir de los otros tres. No entraremos en el detalle de cómo, pero al menos permitidnos mencionar que, con R, el paquete pwr proporciona las funciones que permiten hacerlo para los contrastes más usuales. Entonces, al planear un experimento para realizar un contraste, lo que hay que hacer es: Fijar el nivel de significación deseado Fijar la potencia deseada Estimar el tamaño del efecto esperado (a partir de nuestra teoría, de nuestra experiencia, de los resultados de otros estudios…) o que queramos detectar (¿para rechazar la hipótesis nula nos bastará un tamaño del efecto pequeño o lo requeriremos grande?) y usar un programa adecuado que calcule el tamaño de la muestra necesario para lograr la potencia deseada a partir de estos valores. Desconfiad de los trabajos donde esto no se haga. Podría ser que la potencia fuera muy baja y hubiera un sesgo de infrapotencia (underpower): se necesitaba un efecto muy grande para poder rechazar la hipótesis nula y publicar el artículo. El riesgo de falso positivo El paquete statcheck de R permite revisar de manera automática todos los cálculos de un artículo escrito en un formato concreto en psicología y comprobar los p-valores. Los autores del paquete analizaron 30,000 artículos y concluyeron que: “Hemos encontrado que la mitad de los artículos contienen al menos un p-valor erróneo. Y uno de cada ocho artículos contiene un p-valor erróneo que además afecta la conclusión estadística.” Por lo tanto, Cualquier artículo puede dar un p-valor pequeño que esté equivocado No os fiéis de los resultados. Si las conclusiones os interesan, revisad los cálculos. Además, tened presente que: Cualquier estudio mal diseñado o mal realizado puede dar un p-valor pequeño… que no signifique absolutamente nada. Si las conclusiones de un estudio os interesan, revisad si el experimento ha sido bien diseñado y ejecutado. Cualquier estudio perfectamente diseñado y realizado puede dar por puro azar un p-valor pequeño… que implique un positivo falso. Contra esto último no podemos hacer nada, salvo ser escépticos. Bueno. sí que podemos hacer algo. Calcular el riesgo de falso positivo, FPR, del contraste, que es \\[ P(H_0\\text{ verdadera}|H_0\\text{ rechazada}). \\] Por el teorema de Bayes (notad que interpretamos \\(H_1\\) como lo contrario de \\(H_0\\)) \\[ \\begin{array}{rl} FPR&amp;=\\dfrac{P(H_0)\\cdot P(H_0\\text{ rech.}|H_0)}{P(H_0)\\cdot P(H_0\\text{ rech.}|H_0)+P(H_1)\\cdot P(H_0\\text{ rech.}|H_1)}\\\\ &amp; =\\dfrac{P(H_0)\\cdot \\alpha}{P(H_0)\\cdot \\alpha+(1-P(H_0))\\cdot (1-\\beta)}\\\\ &amp; =\\dfrac{(1-P(H_1))\\cdot \\alpha}{(1-P(H_1))\\cdot \\alpha+ P(H_1)\\cdot (1-\\beta)} \\end{array} \\] Por lo tanto, para calcularlo, tenemos que saber el nivel de significación y la potencia y tenemos que decidir a priori qué probabilidad asignamos al hecho de que \\(H_1\\) sea verdadera. Ejemplo 3.21 En un estudio se repartieron 66 participantes en dos grupos de 33, a los que llamaremos grupo Bandera y grupo Control, y les mostraron las mismas 4 fotos de edificios. Dos de las fotografías del grupo Bandera mostraban una bandera de los EE.UU. En las fotografías del grupo Control, estas banderas habían sido eliminadas digitalmente. Para enmascarar el estudio, se les pidió que adivinaran la hora del día en que fueron tomadas las fotos. Después de mirar las fotos, los participantes rellenaron un cuestionario sobre ideas políticas, a partir del cual se puede calcular un “índice de republicanismo” (en el sentido norteamericano del término) \\(M\\) de quien lo ha contestado. Resulta que \\(M\\) fue significativamente más alto en el grupo Bandera que en el grupo Control, y con un nivel de significación \\(\\alpha=0.05\\) los autores del estudio concluyeron que mirar fotos con banderas estatales “derechiza” tus ideas políticas. Vamos a estimar el riesgo que este positivo sea falso. Como a priori encontramos muy improbable que la conclusión sea cierta, le asignaremos una probabilidad de \\(P(H_1)=0.1\\) y gracias. Usaremos su \\(\\alpha=0.05\\), y si se calcula la potencia del contraste publicado, da 0.5. Entonces \\[ FPR =\\dfrac{0.9\\cdot 0.05}{0.9\\cdot 0.05+0.1\\cdot 0.5}=0.47 \\] Por lo tanto, a posteriori, creemos que hay un 47% de probabilidades de que \\(H_1\\) sea falsa y un 53% de probabilidades de que \\(H_1\\) sea verdadera. 3.7 Test (1) ¿Qué significa que en un contraste de hipótesis tomemos un nivel de significación del 1%? Marca la respuesta correcta: Que un 1% de las veces que la hipótesis nula sea falsa la rechazaremos en favor de la alternativa. Que un 1% de las veces que la hipótesis nula sea falsa la aceptaremos. Que un 1% de las veces que la hipótesis nula sea verdadera la rechazaremos en favor de la alternativa. Que un 1% de las veces que la hipótesis nula sea verdadera la aceptaremos. Que un 1% de las veces rechazaremos la hipótesis nula. Que un 1% de las veces aceptaremos la hipótesis nula. Todas las otras respuestas son incorrectas. (2) Al analizar los resultados de un ensayo clínico, se concluye que la tasa de curación de los dos tratamientos estudiados son diferentes, con \\(p=0.034\\). Esto significa (marca todas las respuestas correctas): Que hay un 3.4% de probabilidad de que, si se repite el estudio, no se encuentren diferencias significativas. Que hay un 3.4% de probabilidad de que la tasa de curación de los tratamientos estudiados sean iguales. Que hay un 3.4% de diferencia, o más, en las tasas de curación de los tratamientos estudiados. Que ha habido un 3.4% de diferencia, o más, en las tasas de curación de los tratamientos en nuestras muestras. Que hay un 3.4% de probabilidad de que la diferencia obtenida entre las tasas de curación, o una aún mayor, se deba al azar. Todas las otras respuestas son incorrectas. (3) En un pequeño ensayo aleatorio simple ciego de un nuevo tratamiento en pacientes con infarto de miocardio agudo, la mortalidad en el grupo tratado fue la mitad que en el grupo control, pero la diferencia no resultó estadísticamente significativa. Podemos concluir que (marca todas las respuestas correctas): Como la diferencia no es estadísticamente significativa, el tratamiento es inútil. Podría ser que el contraste tuviera poca potencia, y por eso la diferencia detectada no ha sido estadísticamente significativa. La reducción observada de la mortalidad es tan grande que deberíamos introducir el tratamiento inmediatamente, aunque dicha reducción no sea estadísticamente significativa. Esto se debe a que el ensayo fue simple ciego, y no doble ciego. Es conveniente llevar a cabo un nuevo ensayo sobre una muestra de pacientes de mayor tamaño. Todas las otras respuestas son incorrectas. (4) En un estudio donde se contrastó si los individuos con hipertensión arterial tienen un mayor riesgo de sufrir un infarto de miocardio que los individuos normotensos, se obtuvo un p-valor de 0.02. ¿Qué quiere decir esto? (Marca una sola respuesta.) La probabilidad de que los hipertensos tengan más riesgo de sufrir un infarto de miocardio que los normotensos es 0.02 La probabilidad de que los hipertensos tengan más riesgo de sufrir un infarto de miocardio que los normotensos es 0.98 Un hipertenso tiene una probabilidad de sufrir un infarto de miocardio un 2% mayor que un normotenso. En las muestras que hemos usado en el estudio, la proporción de hipertensos que han sufrido un infarto de miocardio es un 2% mayor que la de normotensos que han sufrido un infarto de miocardio Ninguna de las otras respuestas es correcta. (5) En un estudio sobre lactancia materna e inteligencia, a 300 niños que fueron muy pequeños al nacer se les dio la leche materna de su madre o leche infantil, a elección de la madre. A la edad de 8 años, se midió el CI (cociente intelectual) de estos niños. El CI medio en el grupo de leche infantil fue 92.8, en comparación con un CI medio de 103.0 en el grupo de leche materna. La diferencia fue significativa, \\(p &lt;0.001\\). Marca todas las afirmaciones correctas: Hay evidencia estadísticamente significativa de que la alimentación mediante leche infantil de los bebés muy pequeños reduce su CI a los 8 años. Hay evidencia estadísticamente significativa de que elegir alimentar un bebé muy pequeño con leche materna aumenta el CI del niño a los 8 años. Hay evidencia estadísticamente significativa de que el tipo de leche no tiene ningún efecto en el CI subsecuente. La probabilidad de que el tipo de leche no afecte al CI subsiguiente es inferior al 0.1%. Si la elección del tipo de leche estuviera relacionada con el CI posterior, la probabilidad de que la diferencia observada entre el CI medio en el grupo de leche materna menos el del grupo de leche infantil y fuera la de este estudio, o menor, es menor que 0.001. Todas las otras respuestas son incorrectas. (6) En un contraste de hipótesis estadístico, si la hipótesis alternativa es verdadera pero se acepta la hipótesis nula (marca todas las conclusiones correctas, hay al menos una): Se comete un error de tipo I. Se comete un error de tipo II. La potencia disminuye. El p-valor es mayor que el nivel de significación. El p-valor es menor que el nivel de significación. (7) Siempre que en un contraste de hipótesis NO se rechaza la hipótesis nula, ¿cuáles de las siguientes afirmaciones son correctas? (Marca todas las respuestas correctas.) Se ha demostrado que la hipótesis nula es verdadera. Se ha demostrado que la hipótesis alternativa es falsa. Se ha encontrado evidencia de que la hipótesis nula es verdadera Se ha encontrado evidencia de que la hipótesis alternativa es falsa Ninguna de las otras afirmaciones es verdadera. (8) Si en un contraste de hipótesis tomamos un nivel de significación del 10% y una potencia del 60% y obtenemos un p-valor \\(p=0.28\\), ¿cuál de las afirmaciones siguientes es verdadera? Aceptamos la hipótesis nula porque \\(p&gt;0.1\\). Aceptamos la hipótesis nula porque \\(p&lt;0.6\\). Rechazamos la hipótesis nula porque \\(p&gt;0.1\\). Rechazamos la hipótesis nula porque \\(p&lt;0.6\\). Con los datos dados, no tenemos criterio para aceptar o rechazar la hipótesis nula. (9) En un estudio se trató con un suplemento dietético más dieta a 15 insuficientes renales y solamente con dieta a 16, de manera que los pacientes conocían qué tratamiento recibieron. Se compararon 20 variables entre ambos grupos y en una comparación se encontró una diferencia a favor del suplemento estadísticamente significativa con un nivel de significación del 5% (p-valor \\(p=0.021\\)). ¿Cómo interpretas estos resultados? El estudio no permite concluir nada, ya si realizamos 20 contrastes con un nivel de significación del 5%, esperamos que alguno dé un resultado estadísticamente significativo aunque no haya diferencia entre los tratamientos El p-valor tan pequeño descarta la posibilidad de un falso positivo en el caso en que se ha encontrado una diferencia estadísticamente significativa El hecho de haber encontrado una diferencia estadísticamente significativa en una comparación puede deberse a un error de tipo II Con unas muestras de pacientes tan pequeñas, la potencia de los contrastes es muy baja, lo que explica que hayamos obtenido algún resultado estadísticamente significativo Como en un 5% (el nivel de significación) de los contrastes se obtuvo un resultado favorable a favor del suplemento dietético, concluimos que su introducción es eficaz (10) En un contraste que hemos llevado a cabo con nivel de significación 0.05 hemos obtenido un p-valor de 1.8. ¿Cuál ha de ser nuestra decisión? Aceptar la hipótesis nula, porque el p-valor es mayor que el nivel de significación. Rechazar la hipótesis nula, porque el p-valor es tan raro que hace inverosímil que la hipótesis nula sea verdadera. Revisar los cálculos, a ver dónde nos hemos equivocado. Ninguna de las otras respuestas es correcta. "],["contrastes-de-hipótesis-uni-y-biparamétricos.html", "Lección 4 Contrastes de hipótesis uni- y biparamétricos 4.1 Contrastes para medias 4.2 Contrastes de varianzas", " Lección 4 Contrastes de hipótesis uni- y biparamétricos En esta lección simplemente vamos a comentar por encima los contrastes de hipótesis más importantes sobre: Una o dos medias Dos varianzas Una o dos proporciones 4.1 Contrastes para medias 4.1.1 Test t para una media Sea \\(X\\) una variable aleatoria de media \\(\\mu\\). Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq\\mu_0\\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] Para ello, medimos \\(X\\) sobre una muestra aleatoria simple de tamaño \\(n\\) de sujetos de la población. Supongamos que estamos en una de las dos situaciones siguientes: \\(X\\) es normal \\(X\\) no es normal pero el tamaño \\(n\\) de la muestra que tomamos es grande (digamos, para fijar ideas, que \\(n\\geqslant 40\\)) En cualquiera de estas dos situaciones, podemos usar el test t que hemos explicado en la lección anterior para realizar el contraste. Recordad que este test se basa en el estadístico de contraste \\[ T= \\frac{\\overline{X}-\\mu_{0}}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que, bajo las condiciones supuestas, sigue (aproximadamente, si \\(X\\) no es normal pero la muestra es grande) una distribución t de Student con \\(n-1\\) grados de libertad. Como ya hemos hecho varios ejemplos de este tipo de test en la lección anterior, aquí no nos vamos a entretener más con él. 4.1.2 Tests t para dos medias Sean ahora \\(X_1\\) y \\(X_2\\) dos variables aleatorias de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] Para ello, medimos \\(X_1\\) sobre una muestra aleatoria simple de tamaño \\(n_1\\), y \\(X_2\\) sobre una muestra aleatoria simple de tamaño \\(n_2\\). Supongamos que estamos en una de las dos situaciones siguientes: \\(X_1,X_2\\) son ambas normales \\(X_1,X_2\\) no son ambas normales pero los tamaños \\(n_1,n_2\\) de las muestras son ambos grandes (digamos, para fijar ideas, que \\(n_1,n_2\\geqslant 40\\)) Si se cumple alguna de estas dos condiciones, podemos usar un test t, basado en un estadístico de contraste \\(T\\) adecuado que sigue una ley t de Student (aproximadamente, si alguna variable poblacional no es normal pero las dos muestras son grandes). El estadístico de contraste concreto y los grados de libertad de su distribución t de Student dependen de las mismas condiciones que comentábamos al hablar de intervalos de confianza para la diferencia de dos medias: De si las dos muestras son: independientes: hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras aleatorias simples obtenidas de manera independiente la una de la otra; o emparejadas: hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra aleatoria simple o hay un emparejamiento natural entre los sujetos de las dos muestras; en particular, en el caso emparejado ha de pasar que \\(n_1=n_2\\). Cuando las muestras son independientes, también dependen de si \\(X_1\\) y \\(X_2\\) tienen la misma varianza o no, que se ha de decidir con otro contraste. A continuación os damos las fórmulas, por si tenéis que realizar algún contraste de dos medias “a mano”. Cuando las muestras son emparejadas, podemos entender que tenemos una sola muestra (formada por las parejas de sujetos) y consideramos los pares de valores \\((X_1,X_2)\\) sobre dichas parejas. Entonces, podemos medir para cada pareja la diferencia \\(D=X_1-X_2\\), que tendrá media poblacional \\(\\mu_D=\\mu_1-\\mu_2\\), y traducir el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] en el contraste de una sola media \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1-\\mu_2=0\\\\ H_{1}:\\mu_D \\neq 0\\text{ o }\\mu_D &gt;0\\text{ o }\\mu_D&lt;0 \\end{array} \\right. \\] Es decir, cuando las muestras son emparejadas, consideramos nuestro contraste de dos medias como un contraste de una sola media, usando como muestra las diferencias \\(X_1-X_2\\) sobre nuestras parejas de sujetos. Por lo tanto, si llamamos \\(\\overline{D}\\) a la media muestral de \\(D\\) y \\(\\widetilde{S}_D\\) a la desviación típica muestral de \\(D\\) sobre nuestra muestra de parejas, y \\(n\\) es el tamaño de la muestra de parejas, el estadístico de contraste es \\[ T=\\frac{\\overline{D}}{\\widetilde{S}_D/\\sqrt{n}} \\] que, cuando \\(\\mu_D=0\\), tiene (aproximadamente, si \\(X_1,X_2\\) no son normales pero la \\(n\\) es grande) distribución \\(t_{n-1}\\). Supongamos ahora que las dos muestras son independientes. Sean \\(\\overline{X}_1\\) y \\(\\widetilde{S}^2_1\\) la media muestral y la varianza muestral de la muestra de \\(X_1\\) y \\(\\overline{X}_2\\) y \\(\\widetilde{S}^2_2\\) la media muestral y la varianza muestral de la muestra de \\(X_2\\). Sean, además, \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\) las varianzas (poblacionales) de \\(X_1\\) y \\(X_2\\). Entonces: Si \\(\\sigma_1^2=\\sigma_2^2\\), el estadístico de contraste es \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{(\\frac{1}{n_1}+\\frac{1}{n_2})\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2}{n_1+n_2-2}}} \\] que, cuando \\(\\mu_1=\\mu_2\\), tiene distribución (aproximadamente, si \\(X_1,X_2\\) no son normales pero \\(n_1\\) y \\(n_2\\) son ambas grandes) \\(t_{n_1+n_2-2}\\). Si \\(\\sigma_1^2\\neq \\sigma_2^2\\), el estadístico de contraste es \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}}} \\] que, cuando \\(\\mu_1=\\mu_2\\), tiene distribución (aproximadamente, si \\(X_1,X_2\\) no son normales pero \\(n_1\\) y \\(n_2\\) son ambas grandes) \\(t_{\\nu}\\) con \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2} \\right)^2}{\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} \\] No hace falta que sepáis estas fórmulas para muestras independientes, pero sí que tenéis que recordar que el estadístico de contraste y su distribución dependen de si las varianzas poblacionales son iguales o diferentes. Los grados de libertad de la distribución t de Student usada en un contraste sobre dos muestras de tamaño \\(n\\): Si las muestras son independientes, es aproximadamente \\(2(n-1)\\) Si las muestras están emparejadas, es \\(n-1\\) Esto hace que la probabilidad de error de tipo I de un contraste con muestras emparejadas de tamaño \\(n\\) suela ser más pequeña que la de un contraste con dos muestras independientes de tamaño \\(n\\). Por ejemplo, supongamos que queremos realizar el contraste \\[ \\left\\{ \\begin{array}{l} H_0: \\mu_1=\\mu_2\\\\ H_1: \\mu_1&gt;\\mu_2 \\end{array}\\right. \\] y que el estadístico del contraste \\(T\\) sobre dos muestras de tamaños \\(n_1=n_2=20\\) da 1.7. Si las muestras son independientes, \\[ \\text{p-valor}=P(T&gt;1.7)\\approx `1-pt(1.7,38)}=0.0487 \\] Si las muestras son emparejadas, \\[ \\text{p-valor}=P(T&gt;1.7)=`1-pt(1.7,19)}=0.0527 \\] Por lo tanto, con nivel de significación \\(\\alpha=0.05\\), rechazaríamos la hipótesis nula con las muestras independientes y la aceptaríamos con las muestras emparejadas. A consecuencia de la diferencia en los números de grados de libertad de la distribución del estadístico de contraste, en general los contrastes con muestras emparejadas permiten usar menos sujetos. Todos estos tests t están implementados en la función t.test de R. Su argumento es: Una muestra de \\(X\\) y el valor con el que queremos contrastar \\(\\mu\\), o una muestra de \\(X_1\\) y una muestra de \\(X_2\\). El tipo de contraste, que se especifica igualando el parámetro alternative a \"two.sided\" (para contrastes bilaterales, es decir, con \\(\\neq\\)), \"less\" (\\(&lt;\\)) o \"greater\" (\\(&gt;\\)); no os olvidéis de las comillas en los valores de este parámetro. El tipo de muestras, que se especifica igualando el parámetro paired a FALSE si son independientes o a TRUE si son emparejadas. En caso de muestras independientes, si las varianzas son iguales o diferentes, que se especifica igualando el parámetro var.equal a TRUE o a FALSE. El nivel de confianza \\(1-\\alpha\\), que se especifica con el parámetro conf.level; si el nivel de significación es \\(\\alpha=0.05\\), es decir, el nivel de confianza 0.95, no hace falta especificarlo (es su valor por defecto). 4.1.3 Tests no paramétricos Si las variables aleatorias de interés no son (aproximadamente) normales y alguna muestra es pequeña, no podemos usar un test t. Entonces, hay que usar algún test no paramétrico que no presuponga nada sobre las distribuciones de las variables aleatorias. Para contrastes de medias, los recomendados son: Test de Wilcoxon para una media o para dos medias usando muestras emparejadas (que, recordad, se traduce en un contraste sobre la media de las diferencias). Test de Mann-Whitney(-Wilcoxon) para dos medias usando muestras independientes. Ambos se calculan con R con la función wilcox.test, con una sintaxis idéntica a la de t.test (excepto que no dispone del parámetro var.equal ya que ahora no nos interesa lo más mínimo saber si las variables tienen varianzas iguales o diferentes en el caso de contrastes de dos medias con muestras independientes). Usad tests paramétricos siempre que podáis, pero solo cuando podáis: Los mejores tests no paramétricos suelen tener potencia inferior a los mejores tests paramétricos. Los tests no paramétricos no suelen producir intervalos de confianza, solo p-valores. Pero usar, por ejemplo, un test t cuando no toca, porque alguna variable no sea normal y alguna muestra sea pequeña, puede llevar a conclusiones equivocadas. Típca pregunta de MIR (esta, de 2017): El grosor del pliegue subcutáneo de grasa a nivel del tríceps se utiliza a veces para evaluar la cantidad de grasa corporal. Esta variable no se distribuye normalmente en las poblaciones. Queremos comparar el valor medio de esta variable en dos poblaciones que suponemos presentan distinta condición nutricional. La prueba estadística más adecuada para contrastar la hipótesis es: La prueba de Mann-Whitney. La prueba t de Student. El cálculo del coeficiente de correlación de Pearson. La prueba F de Snedecor. 4.1.4 Ejemplos Ejemplo 4.1 La temperatura media del cuerpo humano, ¿es el valor comúnmente aceptado de 37o C? Primero de todo, traducimos esta pregunta en un contraste de hipótesis: Variable aleatoria poblacional: \\(X\\): temperatura del cuerpo humano en oC, de media \\(\\mu\\) Contraste: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=37\\\\ H_{1}:\\mu\\neq 37 \\end{array}\\right. \\] Necesitamos una muestra de temperaturas. Vamos a usar las recogidas por P.A. Mackowiak, S. S. Wasserman y M.M. Levine que ya usamos en el Ejemplo 2.9, y que tenemos guardadas (en grados C) en la variable Temperatura de la tabla de datos Temperaturas.txt. El código siguiente define un vector llamado Temps con estas temperaturas y calcula su tamaño (la función str(Temperaturas) nos muestra la estructura de la tabla de datos Temperaturas que hemos definido al importar el fichero Temperaturas.txt): Temperaturas=read.table(&quot;Temperaturas.txt&quot;,header=TRUE) str(Temperaturas) ## &#39;data.frame&#39;: 230 obs. of 3 variables: ## $ Sexo : chr &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; ... ## $ Pulsaciones: int 69 72 68 75 68 79 71 73 77 81 ... ## $ Temperatura: num 36.1 37.1 35.7 36.6 37.1 38.5 36.6 36.3 37.3 37.3 ... Temps=Temperaturas$Temperatura length(Temps) ## [1] 230 Como la muestra es muy grande, podemos usar un test t: t.test(Temps, mu=37, alternative=&quot;two.sided&quot;) ## ## One Sample t-test ## ## data: Temps ## t = -5.7104, df = 229, p-value = 3.479e-08 ## alternative hypothesis: true mean is not equal to 37 ## 95 percent confidence interval: ## 36.76549 36.88581 ## sample estimates: ## mean of x ## 36.82565 El resultado contiene: El p-valor (p-value) del contraste: 3.5·10-8, muy pequeño El intervalo de confianza del 95% (95 percent confidence interval): va de 36.76549o C a 36.88581o C La media muestral (mean of x): 36.82565 Por tanto, hemos encontrado evidencia estadísticamente significativa de que la temperatura media del cuerpo humano no es de 37o C, y estimamos con un 95% de confianza que esta temperatura media está entre 36.8o C a 36.9o C, entre una y dos décimas por debajo del valor usual de 37o C. Si esto es clínicamente importante o no para definir “fiebre” ya no es un problema de estadística. Ejemplo 4.2 La temperatura media de las hombres, ¿es menor que la de las mujeres? Traducimos esta pregunta en un contraste de hipótesis: Variables aleatorias poblacionales: \\(X_h\\): temperatura de un hombre en oC, de media \\(\\mu_h\\) \\(X_m\\): temperatura de una mujer en oC, de media \\(\\mu_m\\) Contraste: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_h=\\mu_m\\\\ H_{1}:\\mu_h&lt; \\mu_m \\end{array}\\right. \\] Necesitamos una muestra de temperaturas de hombres y de mujeres. La tabla de datos Temperaturas.txt que hemos usado en el ejemplo anterior contiene una variable Sexo con el sexo de los sujetos: M para hombres y F para mujeres. La muestra fue trasnversal, así que las muestras de hombres y mujeres son independientes (las que salieron en la muestra global). El código siguiente define vectores TempsH y TempsM con las temperaturas de los hombres y las mujeres de esta tabla, y calcula sus tamaños: TempsH=Temperaturas[Temperaturas$Sexo==&quot;M&quot;,&quot;Temperatura&quot;] #Temperaturas de hombres length(TempsH) ## [1] 114 TempsM=Temperaturas[Temperaturas$Sexo==&quot;F&quot;,&quot;Temperatura&quot;] #Temperaturas de mujeres length(TempsM) ## [1] 116 Las muestras de hombres y mujeres son grandes (116 y 114 sujetos, respectivamente), podemos usar un test t. Como estamos usando dos muestras independientes, necesitamos saber si \\(X_h\\) y \\(X_m\\) tienen la misma varianza. Lo que vamos a hacer es realizar el test bajo ambs supuestos y cruzar los dedos para que salga lo mismo. Suponiendo que las varianzas son iguales: t.test(TempsH, TempsM, alternative=&quot;less&quot;, paired=FALSE, var.equal=TRUE) ## ## Two Sample t-test ## ## data: TempsH and TempsM ## t = -2.5728, df = 228, p-value = 0.005361 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.05557844 ## sample estimates: ## mean of x mean of y ## 36.74737 36.90259 Suponiendo que las varianzas son diferentes: t.test(TempsH, TempsM, alternative=&quot;less&quot;, paired=FALSE, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: TempsH and TempsM ## t = -2.5708, df = 225.42, p-value = 0.005395 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.05549587 ## sample estimates: ## mean of x mean of y ## 36.74737 36.90259 En ambos casos el p-valor (p-value) es del orden de 0.005, muy pequeño. Así, pues, hemos obtenido evidencia estadísticamente significativa que los hombres tienen una temperatura corporal media inferior a la de las mujeres. Además, ambos intervalos de confianza del 95% (95 percent confidence interval) van de \\(-\\infty\\) (-Inf) a alrededor de -0.055, por lo que tenemos un 95% de confianza de que la temperatura corporal media de los hombres es 0.06o C (6 centésimas de grado) menor que la de las mujeres. Las medias muestrales \\(\\overline{X}_h\\) y \\(\\overline{X}_h\\) (mean of x y mean of y; fijaos que hemos entrado en primer lugar las temperaturas de los hombres, por lo que x representa TempsH y y representa TempsM) han sido 36.75o C y 36.9o C, respectivamente, por lo que la media muestral de temperaturas de mujeres ha sido 0.15o C mayor que la de temperaturas de hombres. Ejemplo 4.3 Desayunar salvado de avena en lugar de copos de maíz, ¿ayuda a reducir el nivel de colesterol? Planteémoslo como un contraste de hipótesis. Variables aleatorias poblacionales: \\(X_{ob}\\): nivel de colesterol al consumir salvado de avena (oat bran), de media \\(\\mu_{ob}\\) \\(X_{cf}\\): nivel de colesterol al consumir copos de maíz (corn flakes), de media \\(\\mu_{cf}\\) Contraste: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{ob}=\\mu_{cf}\\\\ H_{1}:\\mu_{ob}&lt; \\mu_{cf} \\end{array}\\right. \\] Vamos a usar los datos obtenidos por J. Anderson et al en su estudio \"Oat-bran cereal lowers serum total and LDL cholesterol in hypercholesterolemic men (The American journal of clinical nutrition 52 (1990), pp. 495-499). Se trata de un ensayo clínico cruzado sobre 14 individuos. A cada uno de ellos se le asignó uno de los dosdesayunos de manera aleatoria y lo tomaron durante 15 días. Al final de este periodo, se les midió el nivel de colesterol en sangre. Pasado un mes de descanso, cada participante desayunó durante 15 días el otro producto, y al final se los volvió a medir el nivel de colesterol en sangre. Tenemos los niveles de colesterol que obtuvieron en la tabla de datos oatbran.txt, donde están medidos en milimoles por litro (mmol/l), así que esta será la unidad que tomamos en las variables poblacionales. Cargamos la tabla de datos, consultamos su contenido y extraemos los vectores correspondientes a los niveles de colesterol para cada tipo de desayuno: OAT para oatbran y CFL para cornflakes. OBR=read.table(&quot;oatbran.txt&quot;,header=TRUE) str(OBR) ## &#39;data.frame&#39;: 14 obs. of 2 variables: ## $ CORNFLK: num 4.61 6.42 5.4 4.54 3.98 3.82 5.01 4.34 3.8 4.56 ... ## $ OATBRAN: num 3.94 5.57 5.85 4.8 3.68 2.96 4.41 3.72 3.49 3.94 ... Oatbran=OBR$OATBRAN Cornflake=OBR$CORNFLK Como unas muestras de tamaño 14 son pequeñas, si queremos aplicar un test t necesitamos que provengan de variables normales. Para decidir si esto es verdad o no, se puede usar un contraste de bondad de ajuste, con hipótesis nula “Esta muestra proviene de una variable aleatoria con tal distribución” e hipótesis alternativa “No es verdad que esta muestra provenga de una variable aleatoria con tal distribución”. Pero aun no los hemos explicado, así que por ahora nos conformaremos con decidirlo a partir de un gráfico. Una posibilidad es dibujar un histograma de la muestra y añadir la densidad de una distribución normal con media y desviación típica las de la muestra, y mirar si parece que los datos siguen esta distribución normal. Pero con pocos datos esto es difícil de ver: En este caso, una opción mejor es dibujar un q-q-plot. Un q-q-plot de una muestra y una distribución teórica es el gráfico de los llamados q-q-puntos: los puntos de la forma (\\(q\\)-cuantil de la distribución, \\(q\\)-cuantil de la muestra), para varios valores de \\(q\\). Si la muestra proviene de la distribución usada para dibujar el q-q-plot, es de esperar que el q-cuantil de la muestra sea muy parecido al q-cuantil de la distribución y por lo tanto que estos q-q-puntos estén cerca de la diagonal principal \\(y=x\\). La función qqPlot del paquete car produce unos q-q-plots adecuados que además muestran una “región de confianza del 95%”, con el significado usual de nivel de confianza (para el 95% de las muestras de la distribución, los q-q-plot caen dentro de esta región; por lo tanto, si nuestro q-q-plot está completamente dentro de esta región, aceptamos con este nivel de confianza que proviene de la distribución usada). require(car) qqPlot(Oatbran, distribution=&quot;norm&quot;, mean=mean(Oatbran), sd=sd(Oatbran), ylab=&quot;Cuantiles de OATBRAN&quot;, xlab=&quot;Cuantiles de normal&quot;, pch=20, id=FALSE) qqPlot(Cornflake, distribution=&quot;norm&quot;, mean=mean(Cornflake),sd=sd(Cornflake), ylab=&quot;Cuantiles de CORNFLK&quot;, xlab=&quot;Cuantiles de normal&quot;, pch=20, id=FALSE) Aceptamos por lo tanto que nuestros datos provienen de dos distribuciones normales: podemos usar un test t de dos medias. En este caso, el test t es de muestras emparejadas (hemos medido las dos variable aleatorias sobre los mismos individuos), por lo que tenemos que especificar paired=TRUE y no tenemos que especificar el parámetro var.equal. Usaremos el parámetro alternative=\"less\" para indicar que el test es unilateral: la hipótesis alternativa es que la media de la primera variable es más pequeña que la de la segunda. t.test(Oatbran, Cornflake, alternative=&quot;less&quot;, paired=TRUE) ## ## Paired t-test ## ## data: Oatbran and Cornflake ## t = -3.3195, df = 13, p-value = 0.002768 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.1626132 ## sample estimates: ## mean of the differences ## -0.3485714 Obtenemos un p-valor de 0.003. Por lo tanto, hemos encontrado evidencia estadísticamente significativa de que desayunar salvado reduce el nivel medio de colesterol respecto de desayunar copos de maíz. El intervalo de confianza del 95% para \\(\\mu_{ob}-\\mu_{cf}\\) va de \\(-\\infty\\) a -0.163. Por lo tanto, tenemos un 95% de confianza en que desayunar salvado reduce en al menos 0.163 mmol/l el nivel medio de colesterol respecto de desayunar copos de maíz. ¿Y si no quisiéramos, o no pudiéramos, suponer que las muestras provienen de distribuciones normales? Entonces usaríams un test de Wilcoxon: wilcox.test(Oatbran, Cornflake, alternative=&quot;less&quot;, paired=TRUE) ## ## Wilcoxon signed rank test with continuity correction ## ## data: Oatbran and Cornflake ## V = 12, p-value = 0.006008 ## alternative hypothesis: true location shift is less than 0 El p-valor da 0.006, por lo que la conclusión es la misma, pero no nos da intervalo de confianza. 4.2 Contrastes de varianzas Sean \\(X_1,X_2\\) dos variables aleatorias normales de desviaciones típicas \\(\\sigma_1\\), \\(\\sigma_2\\) Nos interesa el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1=\\sigma_2\\\\ H_{1}:\\sigma_1\\neq \\sigma_2 \\end{array} \\right. \\mbox{ o, equivalentemente, } \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2=\\sigma_2^2\\\\ H_{1}:\\sigma_1^2\\neq \\sigma_2^2 \\end{array} \\right.\\] En este caso se usa el F-test}, basado en el estadístico \\(\\widetilde{S}^2_{X_1}/\\widetilde{S}^2_{X_2}\\) que (si \\(H_0\\) es cierta) tiene una distribución conocida (la F de Fisher-Snedecor}, `f} con R) Implementado en la función **var.test}} de R: se aplica a las dos muestras, con sintaxis similar at.test} El test F-test no sirve a poco que las variables difieran de normales En este caso, es necesario usar un test no paramétrico Os recomendamos usar el test de Fligner-Killeen}, implementado en R en la función `fligner.test}}, que en la práctica ha mostrado ser más exacto (mayor suma de especificidad y sensibilidad) para variables aleatorias muy diferentes de normales [fragile] Vamos a suponer que ambas son normales (los temperaturas lo suelen ser) **Conclusión}: Por lo tanto, si los tests t con var.equal=TRUE} yvar.equal=FALSE} hubieran dado conclusiones diferentes, tomaríamos la correspondiente a varianzas iguales ¿Era adecuado suponer que provienen de distribuciones normales? ¿Era adecuado suponer que provienen de distribuciones normales? Mejor usar un test no paramétrico, para mayor seguridad [fragile] Aceptamos que \\(X_h\\) y \\(X_m\\) tienen la misma varianza Sea \\(X\\) una variable aleatoria Bernoulli de parámetro \\(p\\) Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:p=p_0\\\\ H_{1}:p\\neq p_0\\text{ o }p&gt; p_0\\text{ o }p&lt; p_0 \\end{array} \\right. \\] Podemos usar el **test binomial exacto}, que contrasta si el número de éxitos en una muestra de tamaño \\(n\\) tiene distribución \\(B(n,p_0)\\) Está implementado en la función **`binom.test}} de R: se aplica al número de éxitos, el tamaño de la muestra, el valor a contrastar \\(p_0\\) y el nivel de confianza (por defecto, 0.95) En la situación anterior, si el tamaño \\(n\\) de la muestra es grande (\\(\\geqslant 30\\) o mejor \\(\\geqslant 40\\)}), podemos usar el test aproximado}, que usa que, si \\(H_0\\) es verdadera y \\(n\\) grande, \\[ \\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{\\widehat{p}_X(1-\\widehat{p}_X)}{n}}}\\approx N(0,1) \\] Está implementado en la función **prop.test}} de R con la misma sintaxis quebinom.test} Es más popular El porcentaje estimado de zurdos en España es del 10%. De 30 estudiantes de la UIB encuestados al azar, 1 ha sido zurdo. Sea \\(p\\) la proporción de estudiantes zurdos en la UIB. **Contraste:} \\[ \\left\\{ \\begin{array}{l} H_0:p=0.1\\\\ H_1:p\\neq 0.1 \\end{array} \\right. \\] **Datos}: Nuestra muestra [fragile] Como la muestra es relativamente grande (\\(n=30\\)) vamos a usar de entrada `prop.test}. **Conclusión}: [fragile] Potencia? [fragile] ¿Qué hubiera pasado con una muestra de 150 estudiantes, 5 de ellos zurdos? [fragile] ¿Qué hubiera pasado con una muestra de 150 estudiantes, 5 de ellos zurdos? [fragile] ¿Cuál hubiera sido la conclusión usando el test binomial? p-valor \\(=0.36\\), IC 95% de 0.0008 a 0.17; misma conclusión Siguin \\(X_1\\) i \\(X_2\\) dues variables aleatorias Bernoulli de paràmetres \\(p_1\\) i \\(p_2\\) Les mesurem sobre dues mostres independents Volem realitzar un contrast $$ { \\[\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1 eq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array}\\] ight. $$ Sean \\(X_1\\) y \\(X_2\\) dos variables aleatorias Bernoulli de parámetros \\(p_1\\) y \\(p_2\\) Las medimos sobre dos muestras independientes Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] Cuando las muestras son grandes, podemos usar el test \\(\\chi^2\\)}, implementado también en la función `prop.test}} de R (ya hablaremos de este test más adelante): se aplica a la tabla de frecuencias absolutas de las muestras en forma de matriz o de tabla de contingencia Por otro lado, podemos usar el test exacto de Fisher}, implementado en la función `fisher.test}}: de nuevo, se aplica a la tabla de frecuencias absolutas de las muestras **}: El test de Fisher en realidad no compara las proporciones \\(p_1\\) y \\(p_2\\), sino sus \\[ \\frac{p_1}{1-p_1}\\mbox{ y }\\frac{p_2}{1-p_2} \\] y el intervalo de confianza que da es para el cociente de estas odds: para su En un estudio transversal, se tomaron 1319 niños de 14 años, se miró si en ese momento tenían tos crónica y si a los 5 años habían tenido bronquitis. El resultado fue la tabla siguiente: **Variables aleatorias de interés}: **Contraste}: \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1&gt;p_2 \\end{array}\\right. \\] **Datos}: La tabla anterior [fragile] Las muestras son grandes, usaremos `prop.test} **Conclusión}: [fragile] Veamos con el test de Fisher **Conclusión}: Sean \\(X_1\\) y \\(X_2\\) dos variables aleatorias Bernoulli de parámetros \\(p_1\\) y \\(p_2\\) Las medimos sobre los sujetos de una misma muestra de tamaño \\(n\\), o sobre los sujetos de dos muestras del mismo tamaño \\(n\\) con un emparejamiento definido entre los mismos (e.g., gemelos) Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2 \\end{array} \\right. \\] Cuando \\(n\\) es grande (\\(\\geqslant 100\\)) y el número de (\\(b+c\\) en la tabla inferior) es razonablemente grande (\\(\\geqslant 20\\)), podemos usar el , que usa el estadístico \\[ Z^2=\\frac{(b-c)^2}{b+c}\\approx \\chi^2_1 \\] Está implementado en la función **`mcnemar.test}}: se aplica a la tabla de frecuencias absolutas siguiente: **Variables aleatorias de interés}: **Contraste}: \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2 \\end{array}\\right. \\] **Datos}: En un ensayo clínico, se trató un grupo de 1244 pacientes, emparejadas según diferentes características. En cada pareja se repartieron los dos tratamientos al azar: quimioterapia perioperatoria y mastectomía o quimioterapia perioperatoria y mastectomía y quimioterapia postoperatoria durante 6 meses. Supervivencia a los 5 años de las parejas de pacientes: \\[ \\widehat{p}_1=\\frac{515}{622}=0.828\\quad \\widehat{p}_2=\\frac{527}{622}=0.847 \\] [fragile] La muestra es grande, y el número de casos discordantes supera (por poco) los 20, usaremos `macnemar.test} El permite concluir que hay evidencia significativa de que hay diferencia en las tasas de supervivencia a los 5 años. Si no podéis usar el test de McNemar, siempre podéis usar el , que simplemente contrasta si las probabilidades poblacionales de los pares (Sí,No) y (No,Sí) son la misma, 0.5. Convenientemente implementado en la función **mcnemar.exact}} del paqueteexact2x2} }: El intervalo de confianza que calcula esta función es para una estimación de la que además no es la que hemos explicado en clase. Mirad solo el p-valor}. [fragile] El es \\(0.017\\) "]]
