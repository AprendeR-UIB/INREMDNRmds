[["index.html", "Bioestadística (Medicina UIB) Presentación", " Bioestadística (Medicina UIB) Irene García, Francesc Rosselló 2024-04-16 Presentación Esto es una edición en línea de los apuntes de Introducción a la Investigación en Salud y Bioestadística del grado de Medicina de la UIB. El libro está escrito en R Markdown, usando RStudio como editor de textos y el paquete bookdown para convertir los ficheros markdown en un libro. Se ha usado la versión 4.3.2 de R y la versión 2.3.28.0 de JAMOVI para macOS. Este trabajo se publica bajo licencia Atribución-No Comercial-SinDerivados 4.0. Significado de algunas cajas: Material muy importante. ¡Cuidado! Ejercicio. Detalles matemáticos que os pueden interesar, pero que podéis obviar sin ningún problema. Comentario que queremos enfatizar. Comentario que queremos que recordéis Cuestión en la que queremos que caigáis en la cuenta. Acabamos de matar un gatito "],["introducción.html", "Lección 1 Introducción", " Lección 1 Introducción Imaginad que se ha realizado un estudio clínico sobre una muestra de individuos para determinar: si una nueva vacuna es efectiva para prevenir una cierta enfermedad; o si un grupo de riesgo concreto tiene una mayor probabilidad de complicaciones en la evolución de una enfermedad; o si un determinado comportamiento es efectivo en la prevención de una enfermedad; o si una nueva terapia es más efectiva, o tiene menos efectos secundarios adversos, que las terapias anteriores; o si una nueva técnica diagnóstica para una determinada enfermedad es más precisa que las anteriores, o igual de precisa pero más barata, o más rápida, o menos intrusiva… Estamos seguros de que aunque seáis recién llegados al grado de Medicina, con la que nos cayó encima en el 2020 este tipo de situaciones os es familiar, ¿verdad? Por norma general, la información obtenida en este estudio clínico se habrá recogido sobre un conjunto más o menos pequeño de individuos y se quiere generalizar al total de la población mundial, o al menos a la población de nuestro entorno. La estadística es la que nos permite determinar hasta qué punto es posible hacerlo. Se ha definido estadística de muchas maneras. La que más nos gusta, y que entronca con la situación que acabamos de explicar, es que La estadística es la ciencia que permite adquirir conocimiento generalizable a partir de datos. Una definición en la que apenas sobran palabras: En estadística, siempre se empieza obteniendo unos datos sobre un grupo (relativamente pequeño) de individuos de una población. Bueno, en realidad, no se empieza obteniendo los datos, sino planificando cuidadosamente cómo se van a obtener, pero todo forma parte de la “obtención” de los datos. Se generaliza la información que se ha obtenido sobre este grupo de personas al total de la población. Y no se trata de trucos de magia adivinatoria, sino de una ciencia cuya metodología ha sido validada por medio de demostraciones matemáticas o, en el peor de los casos, mediante simulaciones numéricas (el equivalente en matemáticas de los experimentos en las otras ciencias). Figura 1.1: Gaturro ((c) Nick) y la estadística. Así pues, la situación de partida a la hora de aplicar técnicas estadísticas es que disponemos de un conjunto de datos que describen algunas características de un grupo de individuos. El análisis estadístico de estos datos puede ser entonces de dos tipos básicos: Análisis descriptivo, cuando nuestro objetivo sea simplemente resumir, representar y explicar los datos concretos de los que disponemos. La estadística descriptiva es el conjunto de técnicas que se usan con este fin. Análisis inferencial, si nuestro objetivo es deducir (inferir), a partir de estos datos, información significativa sobre el total de la población de interés. Las técnicas que se usan en este caso forman la estadística inferencial. Figura 1.2: Estadística inferencial. Ambos tipos de análisis están relacionados. Por un lado, porque es conveniente (obligatorio, en nuestra opinión) empezar cualquier análisis inferencial dando un vistazo a los datos que se usarán. Por otro, porque muchas técnicas descriptivas permiten estimar propiedades de la población de la que se ha extraído la muestra. Por citar un ejemplo, la media aritmética de las alturas de un grupo de mallorquines nos da un valor más o menos representativo de sus alturas, pero también sirve para estimar la altura media de todos los mallorquines. La estadística inferencial entra en juego cuando se quiere obtener información sobre una población y no se puede acceder a todos sus miembros. Si por ejemplo queremos conocer la altura media de los estudiantes matriculados en esta asignatura de la UIB en este curso, en principio no necesitamos para nada la estadística inferencial. Sois pocos, os mediríamos a todos y calcularíamos la media. En todo caso, usaríamos técnicas de estadística descriptiva para arropar este valor representando la distribución de vuestras alturas de manera adecuada. Pero si quisiéramos conocer la altura media de los españoles de 18 años, sería muy complicado medirlos a todos. Entonces, lo que haríamos sería tomar una muestra representativa de esta población, medirlos y a partir de sus alturas estimar dicha altura media. Naturalmente, lo más seguro es que de esta manera no obtuviéramos el valor exacto de la altura media de los españoles de 18 años, nos tendríamos que conformar con obtener una aproximación dentro de un cierto margen de error y determinar la probabilidad de acertar con nuestra estimación y este margen de error. La estadística inferencial es la que nos permite acotar el error que podamos haber cometido y calcular la probabilidad de cometerlo, incluyendo la metodología que tendríamos que haber usado para tomar la muestra en primer lugar. Hace más de 80 años, la prestigiosa revista médica The Lancet ya avisaba en un editorial titulado “Matemáticas y medicina” que muchos de los problemas en medicina son de estadística. Nos encanta la frase (a partir de la segunda línea del fragmento mostrado en la Figura 1.3): “Los métodos estadísticos sencillos son mucho más de nuestra incumbencia que muchas de las cosas que nos obligan a estudiar en los seis largos años del currículo de Medicina”. Figura 1.3: Fragmento del editorial “Matemáticas y medicina” de The Lancet (2 de enero de 1937). En los últimos años, la necesidad de su conocimiento se ha reforzado con el auge de la Medicina Basada en la Evidencia. No vamos ahora a entrar en detalle sobre este enfoque de la medicina, porque seguro que os lo van a explicar en otras asignaturas mucho mejor de lo que lo haríamos aquí. Pero al menos hay que tener presente que su objetivo es tomar decisiones médicas en base a la mejor evidencia científica disponible. La evaluación de la evidencia disponible se tiene que basar en dos Es: en la Experiencia del médico y en la Estadística. La segunda E se debe a que la mayoría de estudios médicos fundamentan sus conclusiones por medio de la estadística. Ya sabéis, usan la estadística para generalizar lo observado sobre los sujetos de una muestra a toda una población. Por tanto, para evaluar la fuerza de la evidencia obtenida en los estudios que consultéis a la hora de tomar una decisión, os serán necesarios unos mínimos conocimientos de estadística. Tendréis que ser capaces, por ejemplo, de discernir si el estudio se ha llevado a cabo correctamente, si el análisis de los datos se ha realizado de manera correcta, si las conclusiones a las que han llegado sus autores están bien fundamentadas y hasta qué punto son válidas en el caso clínico concreto que os ocupe. Pues eso, el objetivo de esta asignatura es que adquiráis algunos de estos mínimos conocimientos de estadística. "],["estudios-médicos.html", "Lección 2 Estudios médicos 2.1 Pasos de un estudio médico 2.2 Algunos calificativos para los estudios médicos 2.3 Estudios descriptivos 2.4 Estudios de casos y controles 2.5 Estudios de cohorte 2.6 Estudios transversales 2.7 Estudios ecológicos 2.8 Ensayos clínicos 2.9 A modo de resumen 2.10 Revisiones sistemáticas y metaanálisis 2.11 (Bonus track) Unos criterios de causalidad 2.12 (Bonus track) Preguntas clínicas en formato PICO 2.13 Test", " Lección 2 Estudios médicos Un estudio es un proceso cuyo objetivo es obtener evidencia empírica sobre alguna cuestión. En el caso de los estudios médicos que nos ocupan en este curso, esta cuestión es, naturalmente, sobre algún aspecto de la salud de las personas: la efectividad de un tratamiento, la precisión de un test diagnóstico, las causas de una enfermedad, algún tema de salud pública… Figura 2.1: Estudios médicos. 2.1 Pasos de un estudio médico Para ir calentando motores, vamos a describir brevemente la estructura habitual de un estudio médico, y lo ilustraremos con el artículo “Marcha nórdica para prevención cardiovascular en pacientes con cardiopatía isquémica crónica o síndrome metabólico” (C. Vehí et al,1 Medicina Clínica 147 (2016), pp. 537-539) que convendría que fuerais consultando en paralelo a esta sección. En un estudio médico por norma general se llevan a cabo los pasos siguientes: Se definen los objetivos de la investigación. En este primer paso, Se describe la hipótesis general que se quiere investigar. Se concretan los objetivos específicos dentro de este marco general. En el artículo que estamos siguiendo a modo de ejemplo: La hipótesis general es que el ejercicio físico es efectivo en la prevención de riesgos cardiovasculares. El objetivo específico es determinar si la marcha nórdica reduce los factores de riesgo cardiovascular en los individuos del área sanitaria mediterránea. Se investigan los antecedentes sobre los objetivos específicos: ¿Qué se sabe sobre el tema? En nuestro ejemplo, los autores recogen algunos beneficios generales de la marcha nórdica y luego afirman que “no hay datos de esta modalidad de ejercicio en el ámbito médico de la población mediterránea”. Se planifica cómo se van a recoger los datos. En nuestro ejemplo, encontraréis el detalle de este punto en el apartado “Material y métodos” del artículo: diseño del estudio, criterios de inclusión de los participantes, actividad que tenían que realizar los participantes y cómo se recogieron los datos. Se ejecuta el plan trazado y se recogen los datos. Se analizan los datos. En nuestro ejemplo, los resultados de este análisis se recogen básicamente en la Tabla 2 del artículo. Se extraen conclusiones. En nuestro ejemplo, las encontraréis en el apartado “Discusión y conclusiones” del artículo. Básicamente, los autores concluyen que “Un programa de marcha nórdica es factible en el sistema sanitario público y puede ser útil para mejorar el control de los factores de riesgo cardiovascular”. Se publican los resultados. Pues eso, los resultados del estudio de nuestro ejemplo se publicaron en el artículo que estamos comentando. Es un buen momento para que volváis al artículo y observéis su estructura, típica de los artículos en ciencias experimentales. Se trata de la estructura IMRyD, acrónimo de: Introducción, donde se recogen los pasos 1 y 2 del proceso anterior. Metodología (“Material y métodos”, en este artículo concreto), donde se detallan los pasos 3 y 4. Resultados, donde se explica el análisis de los datos y los resultados “numéricos” del mismo, sin extraer conclusiones aún (en plan “obtuvimos esto, esto, esto y esto”). Discusión (“Discusión y conclusiones”, en este artículo concreto), donde se completa el análisis de los datos, se extraen las conclusiones y se discute su alcance. El artículo científico además tiene otras dos partes muy importantes: El Resumen (Abstract) al principio, describiendo lo más relevante de cada una de las cuatro partes centrales del artículo. Este resumen está relacionado con el último paso del proceso de investigación, la publicación de resultados, ya que en la mayoría de los casos es lo único que leemos, entrando solo en el detalle del artículo si, tras la lectura del resumen, decidimos que nos interesa de verdad. La Bibliografía al final, relacionada en parte con el paso 2 (los antecedentes). Figura 2.2: Correspondencia entre los pasos de un estudio y la estructura IMRyD de un artículo científico. 2.2 Algunos calificativos para los estudios médicos Podemos clasificar los estudios médicos de diferentes maneras: Según su intención: Descriptivos: Se limitan a describir las características de un grupo de individuos. Analíticos: Intentan inferir conclusiones sobre el total de la población. Por ejemplo: “A cinco pacientes con la enfermedad X les hemos administrado el tratamiento A y tres estaban curados a los 8 días de iniciar el tratamiento. Y punto.”: Descriptivo. “Hemos dividido un grupo de pacientes con la enfermedad X en dos grupos. A unos les hemos administrado el tratamiento A y a los otros el tratamiento B. Los tratados con A han tenido una tasa de curación a 8 días vista mucho más alta que los tratados con B. Llegamos a la conclusión de que el tratamiento A es más efectivo que el B para los enfermos de X.”: Analítico. Según el papel jugado por el investigador: Observacionales: El investigador se limita a recoger datos, sin ejercer ninguna influencia planificada sobre los acontecimientos que generan dichos datos. Intervencionista: El investigador lleva a cabo una intervención en los participantes (por ejemplo, les administra tratamientos farmacológicos o recomienda cambios de comportamiento) de manera planificada y con el objetivo de generar los datos que permitan evaluar el efecto de dicha intervención. Por ejemplo: “Hemos recogido datos de todos los pacientes con la enfermedad X en nuestro hospital durante un año y anotado qué tratamiento se les ha administrado. Los tratados con A han presentado una tasa de curación a 8 días vista más alta que los tratados con B.”: Observacional. “Hemos dividido al azar un grupo de pacientes con la enfermedad X en dos grupos del mismo tamaño. A unos les hemos administrado el tratamiento A y a los otros el tratamiento B. Los tratados con A han tenido una tasa de curación a 8 días vista más alta que los tratados con B.”: Intervencionista. Según el lapso de tiempo sobre el que se recoge la información: Transversales: Se recoge información sobre un solo momento. Longitudinales: Se recoge información sobre varios momentos de tiempo y se estudian los cambios producidos entre los mismos. A su vez, estos últimos suelen dividirse en: Prospectivos: Se recoge información en un momento concreto (normalmente, al inicio del estudio) y en momentos posteriores. Retrospectivos: Se recoge información en un momento concreto (de nuevo, normalmente, al inicio del estudio) y sobre momentos anteriores. Por ejemplo: “Hoy hemos tomado una muestra de 100 estudiantes de la UIB y les hemos hecho un test de COVID-19.” Transversal. “Hoy hemos tomado un grupo de enfermos de COVID-19 y les vamos a hacer un seguimiento para estudiar si la evolución de la enfermedad depende del Índice de Masa Corporal del enfermo en el momento del diagnóstico.” Longitudinal prospectivo. “Hoy hemos tomado un grupo de enfermos de COVID-19 con síntomas leves y un grupo con síntomas muy graves, y les hemos preguntado por su hábito tabáquico en las últimos años.” Longitudinal retrospectivo. Ejemplo 2.1 El estudio sobre la marcha nórdica de la sección anterior es: Analítico, puesto que su objetivo es inferir los efectos de la marcha nórdica en los factores de riesgo cardiovascular para las personas del área sanitaria mediterránea, no solo describir qué les pasó a los 23 individuos que participaron en el estudio. Longitudinal prospectivo, puesto que se compararon datos tomados en el momento de iniciar el estudio y al cabo de un año. Intervencionista, puesto que los investigadores influyeron en el comportamiento de los participantes al hacerles realizar unas sesiones semanales de marcha nórdica con el fin de estudiar su efecto. Si los investigadores hubieran recetado una terapia de marcha nórdica a los participantes porque, según su criterio médico, lo necesitaban y no porque participaban en un estudio, este no hubiera sido intervencionista, sino observacional. Para que el estudio sea intervencionista, la “intervención” del investigador ha de estar motivada por el estudio, de manera que si los sujetos no hubieran participado en el mismo, podrían no haber recibido dicha intervención. “Para estudiar si la vacunación reduce el riesgo de síntomas graves en la COVID-19, en julio de 2021 se tomó un grupo de infectados y se anotó por un lado la gravedad de sus síntomas y por otro lado si estaban vacunados con la pauta completa, vacunados con una sola dosis o no vacunados.” ¿Longitudinal o transversal? Combinando los tipos de estudio según el papel jugado por el investigador y según el lapso de tiempo sobre el que se recoge la información, tenemos estudios: Observacionales transversales Observacionales prospectivos Observacionales retrospectivos Intervencionistas transversales Intervencionistas prospectivos Intervencionistas retrospectivos Acabamos de ver que hay estudios intervencionistas prospectivos. ¿Los hay de las otras cinco clases de estudios de esta lista, o hay algún par de características que es imposible que se den simultáneamente? En las siguientes secciones discutimos con más detalle los tipos más básicos de estudios médicos, listados en la Figura 2.3. Figura 2.3: Tipos básicos de estudios médicos. 2.3 Estudios descriptivos Los tres tipos principales de estudios descriptivos son: Informe de caso: La descripción detallada de un paciente. Serie de casos: Descripción detallada de un conjunto pequeño de pacientes (pero más de uno, o sería un informe de un caso) con algún problema de salud en común. La información se recoge por medio de sus historias clínicas y entrevistas clínicas. En el contexto de los estudios médicos, el término casos siempre refiere a sujetos enfermos, o con algún problema de salud. Encuesta (Survey): Descripción de un conjunto “grande” de individuos con alguna característica en común. La información se recoge por medio de cuestionarios o entrevistas. Recordad que los estudios descriptivos solo describen un sujeto o un conjunto de sujetos, sin pretender ir más allá. Aparte de su utilidad como anécdota (“¡Mira, a este esto le funcionó, vamos a probar a ver!”) y para alertar de nuevas enfermedades, sirven principalmente para identificar observaciones interesantes que merezcan ser investigadas. Ejemplo 2.2 Lo que más tarde se reconocería como la epidemia de SIDA se presentó en sociedad en unas primeras series de casos publicadas a principios de los años 1980. En ellos se describían casos de jóvenes homosexuales sanos que habían desarrollado enfermedades relacionadas con una deficiencia grave del sistema inmunitario, como por ejemplo infecciones oportunistas o el sarcoma de Kaposi (un tipo de cáncer de piel asociado a una infección vírica que hasta entonces solo se había detectado básicamente en ancianos de ascendencia judía o mediterránea y en jóvenes en África). Cuando el número de publicaciones de casos similares fue abrumador, se llevó a cabo un estudio de casos y controles (casos: enfermos de lo que fuera esa enfermedad; controles: personas sanas de características similares a los casos; explicaremos los estudios de casos y controles en la próxima sección) para determinar cuáles eran las características, hábitos, comportamientos etc. que tenían en común los enfermos y no compartían con los sanos. Ejemplo 2.3 El artículo “Diabetes tipo 2 en niños. Serie de casos” (H. Manrique-Hurtado et al, Revista Médica Herediana 26 (2015), pp. 5-9) es, como indica su título, un ejemplo típico de serie de casos. Se trata de una descripción detallada de las características de todos los niños y adolescentes diagnosticados de diabetes tipo 2 (DM2) en dos hospitales de Lima (Perú) entre 2008 y 2013. En total, se describen 32 sujetos de entre 8 y 19 años. Entre otras características, se observó que, en el momento del diagnóstico, el 85% de ellos presentaban acantosis pigmentaria (un transtorno de la piel); que un 17% tenían cetoacidosis diabética (CAD), que suele ir asociada a diabetes tipo 1 y no 2; y que estos últimos presentaban todos una serie de características comunes, por ejemplo todos tenían acantosis pigmentaria. Todas estas observaciones sirven para confirmar, o contradecir, observaciones realizadas en otros momentos u otros países sobre enfermos de DM2 en esta franja de edad. Además, plantean cuestiones sobre la DM2 en niños y adolescentes que pueden ser susceptibles de responderse mediante estudios analíticos. Por ejemplo: ¿Es la acantosis pigmentaria un síntoma frecuente de DM2 entre niños y adolescentes? ¿Presentar CAD y acantosis pigmentaria es más síntoma de DM2 que de DM1 entre niños y adolescentes? Ejemplo 2.4 En el estudio “Survey of COVID-19 Disease Among Orthopaedic Surgeons in Wuhan, People’s Republic of China” (X. Guo et al, The Journal of Bone and Joint Surgery 102 (2020), pp. 847-854), se pasó un cuestionario a todos los cirujanos ortopédicos del área urbana de Wuhan (China) que no habían sido destinados específicamente a tratar enfermos de COVID-19. El objetivo era identificar cuántos habían tenido COVID-19 antes de finales de febrero de 2020 y recoger una serie de características de interés sobre ellos: sus síntomas, a cuánta gente contagiaron, su estado de salud previo al contagio, la distancia de su hospital al mercado mayorista de mariscos de Huanan (donde se cree que se inició la pandemia) etc. Se encontraron en total 24 infectados, y sus características se describen en el artículo mencionado. Esta parte del estudio es descriptiva: una descripción de todos los casos de COVID-19 en un colectivo concreto. El estudio luego tuvo una segunda parte analítica que clasificaremos como de casos y controles en la próxima sección. Hemos dicho que una serie de casos describe un grupo pequeño de individuos, y que un survey describe un grupo grande. En la serie de casos del Ejemplo 2.3 se describieron 32 pacientes, y en el survey (así es como lo clasifican sus autores en el título) del Ejemplo 2.4 solo 24 infectados. ¿32 es pequeño y 24 es grande? ¡Claro que no! La diferencia aquí está en cómo se obtuvo la información: por medio de historias clínicas en el estudio peruano y por medio de un cuestionario en el estudio chino. Además, en este segundo caso el cuestionario se pasó a 428 médicos, por lo que el número de pacientes “descritos” podría haber sido mucho mayor. 2.4 Estudios de casos y controles En un estudio de casos y controles: Se toma un grupo de individuos con una enfermedad (los casos) y un grupo de individuos sin esta enfermedad (los controles) Se compara retrospectivamente su exposición a factores de riesgo en el pasado. Se determinan qué factores de riesgo fueron más frecuentes entre los casos que entre los controles. Se infiere (mejor dicho, se estudia si se puede inferir) que, en la población general, la exposición a dichos factores está asociada a una mayor probabilidad de enfermar. Figura 2.4: Esquema del estudio de casos y controles del Ejemplo 2.5. Ejemplo 2.5 En uno de los primeros estudios de casos y controles, R. Doll y A. Bradford Hill tomaron 1357 casos de hombres con cáncer de pulmón y 1357 controles, hombres con cáncer de otros tipos. Les preguntaron por el número medio diario de cigarrillos que habían fumado durante los 10 años anteriores al diagnóstico. Los resultados fueron los de la Figura 2.5, donde se observa una clara tendencia a fumar más cigarrillos entre los casos que entre los controles. Figura 2.5: Consumo de tabaco en la muestra analizada por R. Doll y A. Bradford Hill en “Study of the Aetiology of Carcinoma of the Lung”, British Medical Journal 2 (1952), pp. 1271–1286. Los estudios de casos y controles son: Observacionales, porque se recogen datos y se analizan sin influir en las características que se han medido. Analíticos, puesto que el objetivo es deducir la asociación entre los factores de riesgo y la enfermedad a nivel poblacional. Longitudinales, puesto que se analiza información sobre un período de tiempo, que va desde el momento en que los sujetos son declarados casos o controles hacia el pasado. Por lo tanto, son además retrospectivos. Veamos un estudio de casos y controles más reciente. Ejemplo 2.6 En el estudio “Tabaquismo y fracaso del tratamiento de la tuberculosis pulmonar. Un estudio de casos y controles” (J. P. Aguilar et al, Jornal Brasileiro de Pneumologia 45.2 (2019), e20180359) se tomaron todos los pacientes que recibieron tratamiento contra la tuberculosis en una institución brasileña concreta entre 2007 y 2015 y que además cumplían algunas restricciones extra (mayores de 15 años, sin diabetes ni SIDA…). Se definieron como casos aquellos pacientes en los que el tratamiento fracasó (según unos criterios precisos) y como controles aquellos pacientes en los que tuvo éxito. En total fueron 50 casos y 234 controles. Se analizaron un buen número de antecedentes que pudieran influir en el desenlace del tratamiento de la tuberculosis: sexo, edad, historial de tabaquismo, historial de consumo de alcohol, salario etc. La única diferencia “significativa” que encontraron fue en el fumar: un 52% de los casos eran fumadores en el momento del diagnóstico de la tuberculosis o lo habían sido antes, contra solo un 30% de los controles. En cambio, por ejemplo, eran consumidores frecuentes de alcohol en el momento del diagnóstico de la tuberculosis o lo habían sido antes un 59% de los casos y un 52% de los controles, una diferencia que no fue lo suficientemente grande como para poder considerarla “significativa”. El adjetivo significativo (en realidad, estadísticamente significativo, pero por ahora omitiremos el adverbio “estadísticamente” para abreviar), que ha salido dos veces entrecomillado en el párrafo anterior, tiene un significado muy concreto en estadística, sobre el que volveremos más adelante en el curso. Por ahora lo tomaremos en el sentido intuitivo de tan grande que sería muy raro que fuera casualidad, lo que nos hace sospechar que también hay diferencia en la población en general. Por ejemplo: La diferencia entre el 52% de fumadores entre los casos y el 30% de fumadores entre los controles fue tan grande, que hubiera sido muy improbable si, en la población general, la proporción de fumadores entre los pacientes en los que el tratamiento fracasa fuera la misma que entre aquellos en los que tiene éxito. Esto nos lleva a concluir que, en la población de tuberculosos en general, la proporción de fumadores entre los individuos en los que el tratamiento de tuberculosis fracasa es mayor que entre aquellos en los que tiene éxito. La diferencia entre el 59% de consumidores frecuentes de alcohol entre los casos y el 52% entre los controles no fue lo bastante grande como para ser muy improbable si, en la población general, la proporción de consumidores frecuentes de alcohol entre los casos fuera la misma que entre los controles. En este caso, no tenemos base para concluir que la proporción de consumidores frecuentes de alcohol entre los individuos en los que el tratamiento de tuberculosis fracasa sea mayor que entre aquellos en los que tiene éxito. En este estudio, los números de casos y controles no se prefijaron en su diseño, sino que se tomaron “los que encontraron” en un grupo de individuos. Por lo tanto, en principio, su composición en casos y controles refleja la de la población. Diremos en casos como este que el grupo de sujetos analizados forman una muestra transversal de la población. Id con cuidado, que el adjetivo transversal ya ha salido con dos significados diferentes (y aún habrá un tercero): Estudio transversal en el tiempo: Se recogen datos sobre un solo momento. Muestra transversal: Una muestra cuya composición en diferentes clases (por ejemplo, en casos y controles) no está prefijada de ninguna manera, y por lo tanto esperamos que sea representativa de la población. Esto no siempre es así, y a veces se toman números concretos, o al menos relacionados entre si, de casos y controles: tantos casos como controles, el doble de controles que de casos… Llamaremos a una muestra de este estilo estratificada (Sección 3.3.3). Es importante distinguir las muestras transversales de las estratificadas, porque en un estudio de casos y controles hay que tener en cuenta el tipo de muestra que se ha tomado a la hora de realizar el análisis estadístico de los datos y extraer conclusiones. Por ejemplo, tal y como se tomó la muestra en el estudio anterior, tiene sentido calcular la proporción de tuberculosos de la muestra sobre los que el tratamiento tuvo éxito y usar esta proporción para estimar la tasa de éxito del tratamiento entre los tuberculosos en general. En cambio, imaginad que se hubieran tomado a propósito el mismo número de casos que de controles. Ahora la proporción de tuberculosos tratados con éxito en la muestra sería “artificial”, no serviría para nada calcularla y en particular no se podría usar para inferir información sobre la tasa de éxito del tratamiento. Veamos dos ejemplos de estudios de casos y controles con muestras estratificadas. Ejemplo 2.7 Considerad el estudio “Efecto del alcohol y sus metabolitos en el cáncer de pulmón: estudio CAPUA” (S. M. Álvarez-Avellón et al, Medicina Clínica 148 (2017), pp. 531-538). En él se incluyeron 876 casos, enfermos de cáncer de pulmón ingresados en una serie de hospitales asturianos entre 2000 y 2010, y 840 controles, pacientes que fueron atendidos en los mismos hospitales que los casos por patologías no relacionadas con ningún factor de riesgo conocido de cáncer de pulmón. Se les entrevistó para conocer sus hábitos alimentarios y de consumo de alcohol y tabaco y se les realizó un análisis genético de los polimorfismos de algunos genes que codifican enzimas participantes en el metabolismo del alcohol y el folato (un tipo de vitamina B). Copiamos algunas conclusiones: Un consumo de alcohol de 0.1-9.9 g/día disminuye el riesgo de cáncer de pulmón, aunque la diferencia no es significativa. Un consumo de alcohol de ≥ 30 g/día y de tabaco de ≥ 36 paquetes/año aumenta significativamente el riesgo de cáncer de pulmón. Un consumo de alcohol de 10-29.9 g/día en individuos portadores del alelo ADH1B 48His aumenta de manera significativa el riesgo de cáncer de pulmón. Ejemplo 2.8 Volvamos al Ejemplo 2.4. Una vez identificados los 24 cirujanos que habían tenido la COVID-19, se escogieron al azar 48 cirujanos (dos por cada enfermo) que no habían tenido (aún) la COVID-19 de entre los que habían respondido el cuestionario. Se compararon entonces los datos sobre la exposición previa a algunos factores de riesgo entre ambos grupos: grado de fatiga, horas de sueño, uso de mascarilla al tratar con pacientes, etc. Esta segunda parte del estudio es claramente de casos (cirujanos que habían tenido COVID-19) y controles (cirujanos que no habían tenido COVID-19). En este estudio chino se puede observar la gran ventaja de un estudio de casos y controles sobre un estudio descriptivo: el disponer del grupo de control para poder comparar. Por ejemplo, resultó que un 58.7% de los cirujanos que habían tenido COVID-19 no habían recibido formación específica reciente sobre control de infecciones. Son muchos, pero esta cifra aislada no sirve para concluir que no haber recibido formación específica reciente sobre control de infecciones aumenta el riesgo de contraer la COVID-19. A lo mejor el porcentaje global de cirujanos ortopédicos de Wuhan que no habían recibido este tipo de formación era también el 58.7%, en cuyo caso no habría diferencia entre haber tenido o no COVID-19 en este aspecto. El grupo de control es el que nos sirve de referencia y permite comparar este porcentaje con la población “sana”. El porcentaje de controles que no habían recibido formación específica reciente sobre control de infecciones fue solo del 33%. Ahora sí vemos que la proporción de “expuestos al factor de riesgo” (no recibir este tipo de formación) entre los casos es mucho mayor que entre los controles. Al problema de conocer de la proporción de expuestos solo en el grupo de enfermos, sin saber esta proporción en un grupo de control (sea de sanos, sea una muestra transversal representativa de la población) se lo suele denominar problema de falta de denominador. Cuando más adelante hablemos de riesgos relativos y odds ratios (Sección 5.2) se entenderá qué hace aquí la palabra “denominador”. Hemos dicho que la diferencia entre casos y controles es la presencia o no de una “enfermedad” y que se analiza su exposición previa a “factores de riesgo”. Aquí tanto “enfermedad” como “factores de riesgo” se han de tomar en un sentido metafórico. Los casos son individuos a los que “ahora” (en un momento determinado) les pasa “algo”, que puede ser una enfermedad pero también puede ser un embarazo o suspender una asignatura o cualquier otro desenlace (su nombre técnico), y se estudia “qué les ha ocurrido” antes del desenlace (la exposición) para intentar establecer una posible relación de causa-efecto. El motivo por el que usamos “enfermedad” en vez de “desenlace” en la descripción de los casos es que si usáramos desenlace, entonces tendríamos de sustituir en la descripción de los estudios de casos y controles “mayor probabilidad de enfermar” por “mayor probabilidad de … ¿desenlazar?”. Por ejemplo, en el Ejemplo 2.6, tanto los casos como los controles estaban “enfermos”: eran tuberculosos. El desenlace que los distinguía era el éxito (controles) o fracaso (casos) de un tratamiento para la tuberculosis. Por ejemplo: Podemos querer determinar mediante un estudio de casos y controles si los fumadores tienen una mayor probabilidad de fracaso escolar. Entonces, tomamos como casos un grupo de personas que no llegaron a terminar la ESO y como controles un grupo de universitarios, y les pedimos cuánto fumaban en Secundaria. Podemos querer determinar mediante un estudio de casos y controles si las personas con fracaso escolar tienen una mayor probabilidad de volverse fumadores. Entonces, tomamos como casos un grupo de fumadores y como controles un grupo de no fumadores, y consultamos su historial académico. Observad cómo hemos evitado usar, ni siquiera sugerir, la palabra “causa” en los objetivos de los dos puntos anteriores, aun a riesgo de complicar la redacción. Nada de “el fracaso escolar aumenta la probabilidad de fumar” o “fumar aumenta la probabilidad de fracaso escolar”. Volveremos sobre este punto dentro de un rato. Por otro lado, tened presente que una exposición puede ser perjudicial en algún aspecto y beneficiosa en otro. Por ejemplo, tomar el sol está asociado a un incremento del riesgo de cáncer de piel y en este sentido es perjudicial. Pero también está asociado (vía la producción de vitamina D) a una disminución del riesgo de cáncer de colon, por lo que en este sentido es beneficioso. Algunas ventajas de los estudios de casos y controles: Suelen ser fáciles de llevar a cabo y rápidos (todos los datos se pueden recoger sin tener que hacer un seguimiento a los sujetos) y por lo tanto relativamente baratos; también en los estudios médicos el tiempo es oro. Son adecuados para estudiar enfermedades raras, poco frecuentes o de desarrollo muy corto, ya que podemos partir de un grupo de enfermos que tengamos identificados previamente y un grupo de sanos, sin tener necesidad de buscar enfermos en una muestra transversal de individuos. Fijaos en que si los enfermos son muy escasos, para encontrar un número razonablemente grande de ellos en una muestra transversal, muy probablemente tendríamos que tomar una muestra enorme. Esto dificultaría la realización del estudio. Podemos estudiar de golpe la asociación entre la exposición a muchos factores de riesgo y el desenlace que nos ocupa. Y ahora algunos inconvenientes. El primero ya lo hemos advertido hace un instante. Un estudio de casos y controles no puede “demostrar” que la exposición a un riesgo “cause” un desenlace. Ni un estudio de casos y controles, ni ningún otro tipo de estudio observacional. En realidad, si nos apuráis, ningún tipo de estudio médico puede demostrar con total seguridad que la exposición a un riesgo causa un desenlace. Hablaremos un poco sobre cómo detectar causalidad en la Sección 2.11. Por ejemplo, en el estudio de casos y controles sobre consumo de alcohol y cáncer de pulmón del Ejemplo 2.7 observaron que entre los enfermos de cáncer de pulmón había una mayor frecuencia de sujetos que consumían al menos 30 gramos diarios de alcohol y 36 paquetes de tabaco anuales, y de aquí concluyen que “un consumo de alcohol de ≥ 30 g/día y de tabaco de ≥ 36 paquetes/año aumenta significativamente el riesgo de cáncer de pulmón”. Pero esta afirmación hay que entenderla. De ninguna manera están afirmando que un consumo de alcohol de ≥ 30 g/día y de tabaco de ≥ 36 paquetes/año “cause un aumento” del riesgo de cáncer de pulmón. Lo que quieren decir es simplemente que los individuos con estos malos hábitos tienen una mayor probabilidad (en el sentido de que es más frecuente) de cáncer de pulmón que el resto de la población. Esta mayor probabilidad puede ser debida a fumar y beber en exceso, pero también a alguna otra causa desconocida relacionada por un lado con el consumo de tabaco y alcohol y por otro con el cáncer de pulmón. Se trataría de un confundidor, una característica asociada con la exposición que puede causar la enfermedad. Por ejemplo, podríamos encontrar una asociación entre tomar café y tener cáncer de pulmón que fuera debida a que los consumidores de café tienden a ser fumadores y el fumar aumenta la probabilidad de cáncer de pulmón, sin que el café por si mismo aumente dicha probabilidad. Figura 2.6: “-Do you smoke? -Only when I drink [pausa] coffee.” Roberto Benigni en Strange to meet you de Jim Jarmusch; https://www.youtube.com/watch?v=pBa-2nXCc7g Los estudios de casos y controles (y en general todos los estudios observacionales) son muy susceptibles al efecto de confundidores. Veamos un ejemplo famoso. Ejemplo 2.9 En el estudio de casos y controles “Congenital malformations and maternal smoking during pregnancy” (P. Shiono et al, Teratology 34 (1986), pp. 65-71) se observó que las madres fumadoras tenían una frecuencia menor de hijos con síndrome de Down. ¿Se había encontrado por fin un efecto beneficioso del tabaco? No, ¡qué va! Más tarde, en el artículo “Maternal smoking and Down syndrome: the confounding effect of maternal age” (C. L Chen et al, American Journal of Epidemiology 149 (1999), pp. 442-446) se observó que no se había tenido en cuenta la edad de las madres. Las madres jóvenes suelen ser fumadoras con mayor frecuencia que las no tan jóvenes, y las madres de más de 40 años tienen una mayor frecuencia de hijos con síndrome de Down. Aquí la edad es el factor confundidor que hace que parezca que las mujeres fumadoras tienen menor probabilidad de tener hijos con síndrome de Down, cuando en realidad son las madres jóvenes las que son más fumadores y tienen menos hijos con síndrome de Down. Seguimos con los inconvenientes. Los estudios de casos y controles son muy susceptibles a algunos tipos de sesgos concretos relacionados con la manera cómo se recogen los datos. Un sesgo en un estudio es un error sistemático que afecte a los datos recogidos y pueda perjudicar la corrección de las conclusiones obtenidas. Estudiaremos el tema de los sesgos en general con más detalle en la Sección 3.4. Por ahora, vamos a anotar varios sesgos típicos que pueden darse en estudios de casos y controles. Si los datos sobre la exposición a riesgos se recogen mediante entrevistas o cuestionarios, los sujetos pueden mentir (recordad la máxima “Todo el mundo miente” del Dr. G. House y los internistas en general), consciente (para ocultar comportamientos de los que se avergüencen, para contentar el entrevistador,…) o inconscientemente (por haber olvidado detalles relevantes). O al menos puede que no recuerden bien los detalles. En ambos casos diremos que se produce un sesgo de recuerdo. Hay un estudio famoso en el que se preguntó a un grupo de hombres si estaban circuncidados: un 34% de los que contestaron que sí, en realidad no lo estaban, y un 34.6% de los que contestaron que no, en realidad sí que lo estaban. En particular, se puede dar un sesgo de recuerdo diferencial, ya que los casos y los controles pueden recordar datos relevantes de manera diferente. Si uno tiene un percance, suele recordar con más frecuencia los detalles previos al mismo para buscar “qué hizo mal” que una persona que no lo haya tenido. También se puede dar un sesgo de supervivencia, si solo se estudian individuos “vivos”. Por ejemplo, si queremos llevar a cabo un estudio de casos y controles para una enfermedad rara con una tasa de mortalidad a corto plazo muy alta y tomamos como casos enfermos diagnosticados que estén vivos, puede que bastantes de ellos hayan sobrevivido más tiempo de lo normal a la enfermedad y por lo tanto no sean casos representativos. Pero si se quiere incluir casos ya fallecidos, seguramente habrá que entrevistar a familiares para conocer detalles de su exposición a factores de riesgo y aumenta el peligro de sesgo de recuerdo. Si uno ya ha difuminado en su memoria los riesgos que corría hace 10 años, mucho menos los recordarán sus familiares. En estudios de casos y controles para enfermedades raras con tasa de mortalidad a corto plazo muy alta, lo adecuado es tomar como casos enfermos recién diagnosticados y esperar que sean representativos del conjunto de todos los enfermos. Por otro lado, hay que tener mucho cuidado en la selección de controles. En teoría, para poder concluir que hay asociación entre la exposición y la enfermedad, sería necesario que: Los controles fueran similares a los casos en todos los aspectos salvo en la exposición. Los controles fueran representativos de la población de sanos. En la práctica es muy difícil conseguir ambas condiciones, sobre todo si la población de sanos no está bien definida. Así por ejemplo, en el estudio sobre alcoholismo y cáncer de pulmón del Ejemplo 2.7, la elección de los controles entre individuos hospitalizados podría haber sesgado este grupo. La ingesta desmesurada de alcohol aumenta el riesgo de patologías que no sean cáncer de pulmón pero que impliquen ingreso hospitalario. Por lo tanto, podría ser que el alcoholismo fuera más frecuente entre personas hospitalizadas que en la población en general. Los autores tuvieron que tener mucho cuidado en este aspecto, eligiendo hospitalizados de algo que a priori no tuviera nada que ver con el consumo de alcohol. O en el ejemplo sobre el fracaso del tratamiento de la tuberculosis del Ejemplo 2.6, hubiera sido un error tomar como controles pacientes tratados con éxito de otras clínicas, que pudieran seguir protocolos de tratamiento diferentes, ya que entonces los controles no serían comparables a los casos. El siguiente es un ejemplo famoso de la importancia de elegir bien los controles: Ejemplo 2.10 En el artículo “Association Between Malaria and Invasive Nontyphoidal Salmonella Infection in a Hospital Study: Accounting for Berkson’s Bias” (R. Krumkamp et al, Clinical Infectious Diseases 62 (2016), pp. S83–S89), se explica un estudio de casos y controles que en realidad fueron dos. El objetivo era determinar si la malaria es un factor de riesgo para la salmonelosis. Bueno, no, de hecho ese era un objetivo secundario: el principal era estudiar si tomar un grupo de controles no adecuado podía cambiar las conclusiones. Se tomaron como casos todos los niños ingresados en dos hospitales de Ghana con salmonelosis no-tifóidea invasiva (INTS). Entonces: En primer lugar, los controles fueron un grupo de niños sin ninguna enfermedad bacteriana. Se obtuvo que la frecuencia de infecciones previas de malaria entre los controles fue significativamente mayor que entre los casos. En segundo lugar, los controles fueron todos los niños hospitalizados en los mismos hospitales con otras enfermedades bacterianas. Se obtuvo que la frecuencia de infecciones previas de malaria entre los casos fue significativamente mayor que entre los controles. Naturalmente, el enfoque correcto es el primero, o mejor aún, tomar como controles un grupo de niños sin INTS, sin distinguir si tenían o no otras enfermedades bacterianas. Los autores concluyen que: “El estudio muestra cómo un sesgo de selección puede revertir los resultados si se utiliza un grupo de control inadecuado y añade evidencia sobre la asociación entre la malaria y la INTS.” En todo caso, es conveniente siempre preguntarse si la exposición observada en los controles es la esperada en la población sana, o si por el contrario hay algún motivo por el que no tenga por qué serlo. Hemos dejado para el final un inconveniente muy específico de los estudios de casos y controles en el que igual ya habéis caído. Fijaos en que el objetivo de un estudio de casos y controles es determinar si la exposición a un factor de riesgo aumenta la probabilidad de padecer una enfermedad y estimar en cuánto la aumenta. Por tanto, lo que se querría comparar son las proporciones de enfermos entre los expuestos y entre los no expuestos, para ver si la primera es mayor que la segunda y cuánto mayor es. Pero las proporciones que se observan son justamente las contrarias de las que nos interesan. En un estudio de casos y controles, medimos las proporciones de expuestos y no expuestos entre enfermos y sanos: En el estudio sobre consumo de alcohol y cáncer de pulmón, en realidad se observó que entre los enfermos de cáncer de pulmón hubo una mayor frecuencia de consumo de 30 gramos diarios o más de alcohol y 36 paquetes de tabaco anuales o más. Pero lo que queremos saber es si se da más frecuentemente el cáncer de pulmón entre las personas con estos malos hábitos que en el resto de la población. En la parte de casos y controles del estudio chino sobre cirujanos ortopédicos y COVID-19, se observó que la proporción de sujetos que no recibieron formación específica reciente sobre control de infecciones fue superior entre los enfermos de COVID-19 que entre los sanos. Pero lo que queremos saber es si la proporción de infectados entre los que no reciben esta formación es superior a la de infectados entre los que sí la reciben. Pues bien, por un lado estamos de suerte: la conclusión global es correcta. Teorema 2.1 Si la proporción de expuestos entre los casos es mayor que entre los controles, la proporción de casos entre los expuestos es mayor que entre los no expuestos. Hagamos los cálculos. Supongamos que en nuestra muestra hay \\(N\\) casos y \\(M\\) controles. De los \\(N\\) casos, \\(n_1\\) estuvieron expuestos al factor de riesgo y \\(n_0\\) no. Entre los \\(M\\) controles, sean estos números \\(m_1\\) y \\(m_0\\), respectivamente. Llamemos \\(E_1=n_1+m_1\\) al total de expuestos en la muestra y \\(E_0=n_0+m_0\\) al de no expuestos. Estos números se resumen en la tabla siguiente: \\[ \\begin{array}{r|c|c|c} &amp; \\text{Casos} &amp; \\text{Controles} &amp; \\text{Total} \\\\ \\hline \\text{Expuestos} &amp; n_1 &amp; m_1 &amp; E_1\\\\ \\hline \\text{No expuestos} &amp; n_0 &amp; m_0 &amp; E_0\\\\ \\hline \\text{Total} &amp; N &amp; M &amp; N+M \\end{array} \\] Ahora, en términos de estos valores: Que haya una mayor proporción de expuestos entre los casos que entre los controles significa que \\[ \\begin{array}{rl} \\displaystyle \\frac{n_1}{N}&gt;\\frac{m_1}{M} &amp; \\Longleftrightarrow \\displaystyle \\frac{n_1}{n_1+n_0}&gt;\\frac{m_1}{m_1+m_0}\\\\ &amp; \\Longleftrightarrow n_1(m_1+m_0)&gt;m_1(n_1+n_0) \\\\ &amp; \\Longleftrightarrow n_1m_0&gt;m_1n_0 \\end{array} \\] Que haya una mayor proporción de casos entre los expuestos que entre los no expuestos significa que \\[ \\begin{array}{rl} \\displaystyle \\frac{n_1}{E_1}&gt;\\frac{n_0}{E_0} &amp; \\Longleftrightarrow \\displaystyle \\frac{n_1}{n_1+m_1}&gt;\\frac{n_0}{n_0+m_0}\\\\ &amp; \\Longleftrightarrow n_1(n_0+m_0)&gt;n_0(n_1+m_1) \\\\ &amp; \\Longleftrightarrow n_1m_0&gt;n_0m_1 \\end{array} \\] Como podemos ver, ambas condiciones son equivalentes. Pero aquí se acaba nuestra suerte. En un estudio de casos y controles, saber cuántas veces es mayor la fracción de expuestos entre los casos que entre los controles, no nos permite saber en general cuántas veces es mayor la fracción de enfermos entre los expuestos que entre los no expuestos. Ejemplo 2.11 Supongamos que tomamos un grupo de 100 enfermos de cáncer de pulmón (casos) y un grupo de 100 no enfermos de cáncer de pulmón (controles), y que entre los casos hay el triple de fumadores que entre los controles. Supongamos en primer lugar que entre los casos hay 30 fumadores y entre los controles 10. La tabla de frecuencias es \\[ \\begin{array}{r|c|c|c} &amp; \\text{Casos} &amp; \\text{Controles} &amp; \\text{Total} \\\\ \\hline \\text{Fumadores} &amp; 30 &amp; 10 &amp; 40\\\\ \\hline \\text{No fumadores} &amp; 70 &amp; 90 &amp; 160\\\\ \\hline \\text{Total} &amp; 100 &amp; 100 &amp; 200 \\end{array} \\] Entonces, la proporción de enfermos entre los fumadores es de 3/4, es decir, el 75%, y entre los no fumadores es de 7/16, es decir, el 43.80%: la primera es 1.71 veces la segunda. Supongamos ahora que entre los casos hay 90 fumadores y entre los controles 30; observad que sigue habiendo el triple de fumadores entre los casos que entre los controles. La tabla de frecuencias ahora es \\[ \\begin{array}{r|c|c|c} &amp; \\text{Casos} &amp; \\text{Controles} &amp; \\text{Total} \\\\ \\hline \\text{Fumadores} &amp; 90 &amp; 30 &amp; 120\\\\ \\hline \\text{No fumadores} &amp; 10 &amp; 70 &amp; 80\\\\ \\hline \\text{Total} &amp; 100 &amp; 100 &amp; 200 \\end{array} \\] La proporción de enfermos entre los fumadores sigue siendo del 75% (3 fumadores por cada no fumador), pero ahora entre los no fumadores es de 1/8, es decir, el 12.5%: la primera es 6 veces la segunda. En ambos casos había el triple de fumadores entre los casos que entre los controles, pero al invertir las proporciones, han dado cocientes diferentes de las proporciones de enfermos entre fumadores y no fumadores. Por suerte, como veremos más adelante (Sección 4.3), un pequeño truco nos permitirá capear este escollo. El problema que no nos permitía estimar las fracciones de enfermos entre expuestos y no expuestos en el ejemplo anterior era que tomábamos la muestra de casos y controles estratificada, con números “artificiales” de casos y controles. Si hubiéramos tomado la muestra transversal, esperaríamos que fuera representativa de la población y en particular esperaríamos que las proporciones observadas de enfermos entre expuestos y no expuestos fueran representativas de la población y las podríamos usar sin problema para estimar estas últimas. Si tomamos una muestra estratificada de casos y controles, con unos números prefijados de casos y de controles que no representen las proporciones de enfermos y sanos en la población, ni las proporciones de casos entre los expuestos y no expuestos en nuestra muestra ni la proporción de expuestos en nuestra muestra no tienen por qué ser representativas de estas proporciones en el total de la población. Ejemplo 2.12 Supongamos de nuevo que tomamos un grupo de 100 enfermos de cáncer de pulmón (casos) y un grupo de 100 no enfermos de cáncer de pulmón (controles). Esta muestra no es representativa de la población, contiene muchos más enfermos de cáncer de pulmón de lo que cabría esperar en una muestra representativa de 200 personas (no es cierto que la mitad de la población tenga cáncer de pulmón, ¿verdad?). Por lo tanto, es de esperar que las proporciones de casos entre los expuestos y los no expuestos no sean representativas de la población, ya que en la muestra hay más casos de los que “tocaría”. Y también es de esperar que la proporción de fumadores en la muestra tampoco sea representativa de la población, porque hay más casos de lo que tocaría, y la proporción de fumadores entre los casos es mayor, por lo que la cantidad de fumadores es seguramente mayor de lo que cabría esperar en una muestra transversal de 200 personas. 2.5 Estudios de cohorte En un estudio de cohorte: Se toma un grupo de individuos expuestos a un factor de riesgo y un grupo de individuos no expuestos a dicho factor de riesgo, o más en general, varios grupos de individuos expuestos a diferentes factores de riesgo o a un mismo factor de riesgo pero con diferentes niveles de exposición. Se les realiza un seguimiento durante un período de tiempo para comparar prospectivamente (en el futuro) la aparición de una enfermedad en ambos grupos. Se determina si es significativamente más frecuente la aparición de la enfermedad entre los expuestos que entre los no expuestos. En caso afirmativo, se infiere que, en la población general, la exposición a dichos factores está asociada a una mayor probabilidad de sufrir la enfermedad. Como el objetivo es estudiar la aparición de la enfermedad tras la exposición, los individuos participantes han de estar sanos (es decir, sin la enfermedad de interés) en el momento de iniciar su seguimiento. El término “cohorte” del nombre refiere al grupo completo de individuos al que se realiza el seguimiento, aunque también a veces se llama “cohortes” a los subgrupos de la cohorte global definidos por las diferentes exposiciones a factores de riesgo. Por este motivo, a veces se habla de estudio de cohortes, en plural. A nosotros se nos escapará más de una vez, no nos lo tengáis en cuenta. Figura 2.7: No, esto no es una cohorte en el sentido de esta sección. De nuevo, los términos “factores de riesgo” y “enfermedad” se han de tomar en un sentido metafórico. Por ejemplo, podríamos comparar grupos de pacientes con una cierta enfermedad bajo diferentes tratamientos para comparar las tasas de curación. En este caso, los “factores de riesgo” son los tratamientos, y la “enfermedad” la curación. Ejemplo 2.13 Se han llevado a cabo muchos estudios de cohorte para analizar la asociación entre el hábito tabáquico y el desarrollo de enfermedades pulmonares como la EPOC (Enfermedad Pulmonar Obstructiva Crónica). Por ejemplo, el realizado en el marco del estudio de Rotterdam (“Prevalence and incidence of COPD in smokers and non-smokers: the Rotterdam Study”; N. Terzikhan et al, European Journal of Epidemiology 31 (2016), pp. 785–792). En este estudio se realizó un seguimiento entre 1989 y 2009 a un grupo (variable, puesto que en algunos momentos se amplió la cohorte, pero vamos a expicar solo la idea general) de unos 14000 sujetos. De ellos, en el momento de incorporarse al estudio un 21.7% eran fumadores, un 43% habían sido fumadores pero ya no lo eran, y un 35.3% nunca habían fumado. En el primer grupo, un 26% desarrolló EPOC durante el seguimiento; entre el segundo grupo, un 13.6%, y en el tercero, un 6.4%. Las diferencias fueron significativas. Figura 2.8: Esquema de un estudio de cohorte. Los estudios de cohorte son también observacionales, analíticos y longitudinales, por exactamente los mismos motivos que los de casos y controles. La información que se analiza va desde el momento en que los sujetos son clasificados según su exposición a factores de riesgo hacia adelante, para ver si desarrollan la enfermedad, y por tanto siempre es prospectiva. Sin embargo, se suele distinguir entre estudios de cohorte prospectivos y retrospectivos según el momento (presente o pasado) en que se realiza la clasificación en expuestos y no expuestos: Estudios de cohorte prospectivos: se toman los expuestos y no expuestos a día de hoy, y se estudia su evolución futura (por tanto, esperando a que pase un cierto período de tiempo). El estudio de Rotterdam fue prospectivo. Veamos otro ejemplo de estudio de cohorte prospectivo. Ejemplo 2.14 Como su título indica, en el artículo “Increased risk of irritable bowel syndrome after bacterial gastroenteritis: cohort study” (L. A. García Rodríguez y A Ruigómez, British Medical Journal 318 (1999), 565-566) se publican los resultados de un estudio de cohorte destinado a determinar si tener una gastroenteritis bacteriana aumenta el riesgo de padecer posteriormente síndrome de colon irritable (SCI). Para ello, los autores realizaron un seguimiento a un grupo de pacientes que sufrieron un episodio de gastroenteritis bacteriana y a un grupo de individuos sin gastroenteritis bacteriana. De ambos grupos se excluyeron los pacientes que ya tenían un historial de SCI; recordad que en el inicio del estudio los sujetos han de estar libres de la enfermedad que se quiere ver aparecer. Además también se excluyeron los que tenían algún factor de riesgo conocido del SCI (cáncer de colon, alcoholismo…), para poder “garantizar” que su riesgo de aparición del SCI fuera similar, salvo por la gastroenteritis. Se realizó un seguimiento a ambos grupos durante un año, al cabo del cual un 0.3% de la cohorte sana y un 4.4% de la cohorte con gastroenteritis habían sido diagnosticados de SCI. Estudios de cohorte retrospectivos o históricos: se toman los expuestos y no expuestos en un cierto momento del pasado, y se estudia su evolución hasta el día de hoy (sin tener que esperar nada de tiempo). Figura 2.9: Estudios de cohorte prospectivos y retrospectivos. Veamos un ejemplo de estudio de cohorte retrospectivo. Ejemplo 2.15 En el estudio “Mortalidad en pacientes con psoriasis. Análisis de una cohorte retrospectiva” (W. Masson et al, Medicina Clínica 148 (2017), pp. 483-488), llevado a cabo en 2016, se tomó una cohorte formada, por un lado, por todos los pacientes del Sistema de Salud de Buenos Aires que a día 1/1/2010 tenían diagnóstico activo de psoriasis, en total 1500, y por otro, por un grupo de control formado por 1500 pacientes elegidos al azar entre el resto de personas del mismo Sistema de Salud. Se anotaron los sujetos de ambos grupos que fallecieron antes del 30/6/2015. La tasa de mortalidad en el grupo de enfermos de psoriasis fue significativamente más alta que en el grupo de control. La conclusión fue, por lo tanto, que los enfermos de psoriaris tienen un mayor riesgo de defunción a 5 años vista. Observad las diferencia entre un estudio de casos y controles y un estudio de cohorte. Aunque ambos sean observacionales, analíticos y longitudinales: En un estudio de casos y controles, se clasifica el grupo de sujetos en sanos y enfermos y se estudia su exposición anterior a esta clasificación a los factores de riesgo objeto de estudio. En un estudio de cohorte, se clasifica el grupo de sujetos sanos en expuestos y no expuestos y se estudia el desarrollo posterior a esta clasificación de la enfermedad objeto de estudio. Si el estudio es de cohorte retrospectivo, la clasificación se realiza en el pasado, pero igualmente se determina si la enfermedad aparece en algún momento posterior a dicha clasificación. En una nota de prensa de la Universidad de Michigan podemos leer: El peso al nacer tiene efectos importantes y duraderos, según revela un estudio difundido por la Universidad de Michigan. Pesar menos de 2.5 kg al nacer aumenta en un tercio las posibilidades de abandonar la escuela secundaria, reduce las ganancias anuales en alrededor de un 15% […]. Considerad la pregunta de investigación siguiente: Las personas con bajo peso al nacer, ¿tienen una mayor probabilidad de fracaso académico? Diseñad un estudio de casos y controles cuyo objetivo sea responder a esta pregunta. Diseñad un estudio de cohorte prospectivo cuyo objetivo sea responder a esta pregunta. Diseñad un estudio de cohorte retrospectivo cuyo objetivo sea responder a esta pregunta. ¿Cuál de los tres escogeríais llevar a cabo? ¿Por qué? Leed la nota de prensa y decidid qué calificativo describe mejor el estudio realizado por los científicos de la Universidad de Michigan: casos y controles, cohorte prospectivo, cohorte retrospectivo o ninguno de los anteriores. Algunas ventajas de los estudios de cohorte: Los estudios de cohorte son adecuados para estudiar factores de riesgo raros, por el mismo motivo que los de casos y controles lo son para estudiar enfermedades raras. Permiten estimar las probabilidades en el sentido que nos interesa: siempre tiene sentido calcular las proporciones de expuestos y no expuestos que desarrollan una enfermedad, mientras que en un estudio de casos y controles en principio solo tiene sentido calcular las proporciones de enfermos y sanos que previamente estuvieron expuestos al factor de riesgo. Los estudios de cohorte retrospectivos suelen ser, como los de casos y controles, relativamente fáciles de llevar a cabo, rápidos y baratos. Al hacer un seguimiento desde el momento de la exposición en adelante, son útiles no solo para estimar la proporción de expuestos y no expuestos que desarrollan la enfermedad, sino también la incidencia de la enfermedad en ambos grupos. La incidencia de una enfermedad en una población mide el número de casos nuevos de dicha enfermedad en un período de tiempo. “Nuevos” quiere decir que no se cuentan en la incidencia los sujetos que ya estaban enfermos en el momento de iniciar el período de tiempo, pero las recaídas de un mismo individuo sí que cuentan como casos nuevos en la incidencia. Hay un poco de jaleo con la terminología precisa relacionada con la incidencia, de manera que si consultáis fuentes diferentes encontraréis definiciones ligeramente diferentes. Para fijar el lenguaje, en este curso vamos a distinguir entre incidencia acumulada y densidad de incidencia. La incidencia acumulada, o simplemente incidencia a secas, es el número, o la proporción, de casos nuevos de la enfermedad durante un período de tiempo concreto. Por ejemplo, las siguientes frases refieren a la incidencia acumulada: “En los últimos siete días las Islas Baleares han contabilizado 1970 contagios de COVID-19.” “En los últimos 14 días se han detectado en las Islas Baleares 249 casos por cada cien mil habitantes.” Para ser precisos, al calcular la incidencia acumulada como proporción, el denominador no tendría que ser el total de la población, sino el número de individuos sanos en la población al principio del período de tiempo considerado. Como podéis imaginar, no es lo mismo que en una población de cien mil personas, todas sin COVID, una la coja, que en una población de cien mil personas, de las que 99,999 tienen COVID, la última que queda sana la coja. Por lo tanto, tendríamos que hablar del número de casos de COVID-19 detectados en los últimos 14 días en las Islas Baleares por cada cien mil habitantes sin COVID-19”. Naturalmente, si el número de enfermos en la población es relativamente pequeño y solo conocemos una aproximación del número de habitantes en ese momento y además vamos a dar el resultado sin mucha precisión, no hay mucha diferencia entre dividir por el total de habitantes y dividir por el número de habitantes sanos. Pero la manera correcta de calcularla es la primera. Por ejemplo, a la hora de calcular en septiembre de 2020 que “en los últimos 14 días se han detectado en las Islas Baleares 249 casos por cada cien mil habitantes”: Se conoce la población de las Baleares solo aproximadamente. En realidad, se maneja una estimación de su población a 1 de enero de 2020. Esta estimación era de 1,149,460 habitantes según el padrón de la CAIB. El número de casos activos diagnosticados de COVID-19 (su prevalencia, concepto que trataremos en detalle en la próxima sección) era de algo menos de 2500 enfermos. Está claro que no va a haber mucha diferencia entre dividir el número de casos nuevos por 11.4946 (para obtener el número aproximado de casos nuevos por cien mil habitantes) o por 11.4696 (para obtener el número aproximado de casos nuevos por cien mil habitantes sanos). Sobre todo si no estamos seguros de la exactitud del denominador en ninguno de los dos casos. Por otro lado, la densidad de incidencia es el número medio de casos nuevos de la enfermedad por unidad de tiempo (durante un cierto período de tiempo). Por ejemplo: “La densidad de incidencia de la COVID-19 en las Baleares durante la última semana ha sido de 461 contagios diarios.” Por lo tanto, La incidencia acumulada mide el número de casos nuevos durante un cierto período de tiempo La densidad de incidencia mide la velocidad media con la que han aparecido casos nuevos durante un cierto período de tiempo Volviendo a los estudios de cohorte, algunos de sus inconvenientes son: Se puede dar el mismo problema con los confundidores que en los estudios de casos y controles. Por ejemplo, en el estudio de la mortalidad y la psoriasis del Ejemplo 2.15, se especula con que la causa del aumento de mortalidad sea que “las modificaciones inmunológicas e inflamatorias observadas en la psoriasis podrían favorecer el desarrollo de la aterosclerosis”, pero no está claro si la causa de las modificaciones inmunológicas e inflamatorias es la psoriasis misma, o si la psoriasis y estas modificaciones se deben a una tercera causa. Son poco adecuados para estudiar enfermedades raras, ya que entonces habrá que tomar una cohorte muy grande o realizar el seguimiento durante un período muy largo de tiempo para poder observar una cantidad razonable de enfermos. Por el mismo motivo, los estudios de cohorte prospectivos son poco adecuados para estudiar enfermedades de desarrollo lento. Hay que tener en cuenta los abandonos: sujetos de la cohorte inicial a los que se les pierde la pista durante el seguimiento (en los estudios prospectivos) o sobre los que no se tiene información en el momento final del período de tiempo estudiado (en los estudios retrospectivos). Hay técnicas estadísticas específicas para tratarlos. Además, los estudios de cohorte prospectivos tienen los siguientes inconvenientes específicos: Puede ser difícil, o al menos costoso, realizar el seguimiento durante un período largo de tiempo de un grupo grande de sujetos. Se puede dar entre los sujetos seguidos un sesgo de conocimiento, que sucede cuando los individuos modifican su comportamiento habitual al saber que son observados (si los sujetos de la cohorte saben que se les realiza un seguimiento). Los estudios de cohorte retrospectivos resuelven estos inconvenientes, pero presentan uno de propio: Se usan datos históricos sobre la exposición, que casi siempre fueron anotados por personas diferentes a las que realizan el estudio y con otros fines (historias clínicas, otros estudios médicos). Esto puede hacer que esos datos no se recogieran de la manera más adecuada para los intereses del estudio presente. 2.6 Estudios transversales En un estudio transversal se toma un grupo de individuos en principio representativo de una población (una muestra transversal de la población) y se miden en un momento concreto varias características de todos ellos: por ejemplo, una enfermedad y los factores de riesgo presentes en ese momento. El objetivo es inferir qué asociación hay entre estas condiciones en la población general. Para que un estudio sea transversal en el sentido de esta sección, es necesario que: Sea transversal en el tiempo: la información refiera a un solo momento, o al menos que el paso del tiempo no sea relevante en el estudio. La muestra sea transversal: sin composición prefijada en clases definidas por las características que se quiere estudiar ni por características que puedan tener relación con las que queremos estudiar (no estratificada en el sentido de la Sección 3.3.3). Una de las utilidades de los estudios transversales es poder estimar la prevalencia de una enfermedad (o de cualquier otra característica): la proporción, o el número, de individuos con la enfermedad en una población en un momento determinado. No confundáis la prevalencia con la incidencia: La prevalencia representa el número total de enfermos en una población en un momento determinado. La incidencia representa el número de enfermos nuevos en una población en un período de tiempo determinado. Ejemplo 2.16 En “Estimates of global, regional, and national incidence, prevalence, and mortality of HIV, 1980-2015: the Global Burden of Disease Study 2015” (H. Wang et al, The Lancet. HIV 3 (2016), e361-87) se afirma que: Desde 2005, la incidencia global del VIH se ha mantenido relativamente constante alrededor de 2.6 millones por año. La prevalencia global del VIH en 2015 era de 38.8 millones. Estos 38.8 millones son el total de personas que estuvieron infectadas con VIH en algún momento de 2015, contando los que ya venían infectados de 2014 y los que se infectaron en 2015. Ejemplo 2.17 En el estudio “Prevalencia de factores de riesgo cardiovascular en las Islas Baleares (estudio CORSAIB)” (F. Rigo Carratalà et al, Revista Española de Cardiología 58 (2005), pp. 1411-1419) se tomó una muestra aleatoria de habitantes de las Islas Baleares de la manera siguiente. Se dividió la comunidad en 14 sectores y participaron 3 o 4 médicos de familia por sector (50 en total). A continuación, se seleccionó aleatoriamente a 40 personas entre las adscritas a cada médico participante. A partir de las frecuencias de diversos factores de riesgo cardiovascular en las personas de la muestra, se estimó su prevalencia en el total de nuestra comunidad. Por ejemplo: “Las prevalencias estimadas fueron: tabaquismo del 27% (el 36.9% en varones y el 18.7% en mujeres); hipertensión del 47.8% (el 52.3% en varones y el 43.4% en mujeres); hipercolesterolemia del 24.2% (el 24.4% en varones y el 24.1% en mujeres); diabetes del 11.7% (el 15.3% en varones y el 8.4% en mujeres); obesidad del 27% (el 24.8% en varones y el 29% en mujeres), sobrepeso del 40.1% (el 48.3% en varones y el 33.4% en mujeres) […]” Este ejemplo es un estudio transversal de prevalencia: Se tomó una muestra transversal de la población (la que salió, sin especificar su composición según alguna clasificación de los individuos por factores de riesgo o enfermedades). Se midieron algunas características de los sujetos en un solo momento. El objetivo era estimar la prevalencia de estas características entre la población de nuestra comunidad. En otros estudios transversales se estima la asociación entre factores de riesgo y enfermedades. Ejemplo 2.18 En el estudio “Relación entre el mes de nacimiento y la prevalencia de enfermedades crónicas” (J. A. Quesada y A. Nolasco, Medicina Clínica 148 (2017), pp. 489-494), se escogió al azar una muestra de 29,478 españoles adultos y se anotó de cada uno de ellos su sexo y mes de nacimiento y si a 1 de enero de 2017 sufrían, o habían sufrido, alguna enfermedad crónica de una lista de veintisiete. Para ambos sexos se encontraron asociaciones significativas entre el mes de nacimiento y algunas enfermedades crónicas. Por ejemplo, los hombres nacidos en noviembre parecen tener un mayor riesgo de sufrir cataratas. Vamos a ver, en este estudio se tomó una muestra de sujetos y se anotó, por un lado, si tenían o no una serie de enfermedades en un momento determinado y por otro su “exposición previa a un factor de riesgo” (su mes de nacimiento). ¿No sería un estudio de casos y controles? ¿Y de cohorte retrospectivo? Porque también podríamos entender que se tomó una muestra de sujetos, se clasificaron según su exposición previa a un factor de riesgo (el mes de nacimiento) y se anotó si desarrollaron posteriormente alguna enfermedad de una lista, ¿no? Pues sí, podríamos considerarlo como de casos y controles, aunque anotar no solo si los sujetos tenían las enfermedades a día 1/1/2017, sino también si las habían tenido en el pasado, no encaja del todo con un diseño de casos y controles. Pero como la “exposición”, es decir, en este caso, el nacimiento, es anterior a cualquier enfermedad que pudieran desarrollar los sujetos, es aceptable. Y seguramente también podríamos considerarlo de cohorte retrospectivo, aunque, de nuevo, para clasificarlo como tal es necesario que los sujetos no tuvieran las enfermedades en el momento de nacer. Recordad que en los estudios de cohorte, en el momento en el que se clasifican los sujetos según su exposición a factores de riesgo han de estar sanos. De hecho, los autores dicen que es un estudio transversal, y para nuestro gusto esta sería la clasificación más adecuada, ya que se toma una muestra transversal de la población española y se anotan varias características actuales de los sujetos de la muestra. Pero en cambio el análisis estadístico que realizan sus autores es el típico de un estudio de casos y controles (ya trataremos esta cuestión en la Sección 5.2 del tema de Probabilidades). Eso ya es entonces un error. ¿Cuál es entonces la respuesta correcta? Ya hemos dicho que nuestra respuesta preferida sería que transversal, pero la verdad es que cualquiera de las tres sería correcta. Lo importante no es tanto poner una etiqueta a un estudio como razonar correctamente qué tipo de estudio “puede ser” y luego llevar a cabo el análisis estadístico de los datos recogidos de manera consistente con el tipo elegido. Ejemplo 2.19 Consideremos el estudio “Prevalencia de hipertensión arterial y otros factores de riesgo cardiovascular en la población con hipotiroidismo subclínico” (L. G. Gil y A. de la Sierra, Medicina Clínica 148 (2017), pp. 351-353). En él, se tomó un grupo de 240 pacientes con hipotiroidismo subclínico (HS) visitados en un CAP de Terrassa, y un grupo de 480 pacientes del mismo CAP sin HS (dos por cada uno con HS). Se evaluó en todos estos sujetos la presencia de hipertensión arterial, diabetes etc. El objetivo era comparar la prevalencia de estas patologías entre los pacientes con y sin HS. Aunque toda la información se recogió simultáneamente y el objetivo es estudiar prevalencias, desde el punto de vista del diseño no se trata de un estudio transversal. Fijaos en que no se tomó una muestra “transversal” de sujetos al azar, se analizó si tenían HS o no y se evaluó la presencia de las diferentes condiciones de interés. La muestra que tomaron tenía una composición concreta en términos de una de las características objeto de estudio (HS): dos sujetos sanos por cada enfermo. Esta composición no refleja la de la población (no es cierto que un tercio de la población tenga HS: su prevalencia está entre el 4% y el 8%, pudiendo llegar al 16% entre la población mayor de 60 años). Como lo que interesa es comparar la frecuencia de diversas condiciones entre enfermos de HS y sujetos sin HS, el estudio podría considerarse de cohorte, tomando como expuestos los enfermos de HS. O de casos (los enfermos de HS) y controles (los no enfermos de HS), también sería correcto. Lo importante es analizar los datos consecuentemente En este caso los autores del estudio lo clasifican como de casos y controles y analizaron los datos de manera correcta según esta clasificación. Como veremos en el tema de Probabilidades, haberlo considerado de cohorte hubiera dado lugar a conclusiones más fáciles de entender, así que nosotros seguramente hubiéramos optado por clasificarlo como de cohorte. ¿De cohorte? ¿Y qué pasa con la condición de que los individuos han de estar “sanos” en el momento de clasificarlos en expuestos y no expuestos? Sí, tenéis razón, estamos forzando un poco la definición de estudio de cohorte. Pero la condición de que los individuos de la cohorte han de estar sanos al empezar a correr el tiempo de seguimiento es para poder estudiar la aparición posterior de la enfermedad, con el objetivo final de encontrar evidencias de que la exposición causa la enfermedad. En este estudio no les interesaba la aparición posterior de nada, sino lo que pasaba en ese momento. Por ejemplo, qué proporciones de sujetos con y sin HS son hipertensos. ¿Cómo hubiera sido un estudio transversal? Pues si los investigadores hubieran tomado una muestra al azar de 720 pacientes del CAP y por pura casualidad hubieran salido 240 pacientes con HS y 480 sin HS. Entonces se podría estimar que un tercio de la población de Terrassa asignada a ese CAP sufre de HS y tocaría investigar las causas de esta anomalía. Es importante observar la diferencia entre un estudio transversal y un estudio descriptivo de tipo serie de casos o survey. En ambos casos se toma un grupo de sujetos y se miden una serie de características de los mismos en un momento concreto. Pero: Los estudios transversales son analíticos: El objetivo de la descripción de los individuos de la muestra es inferir asociaciones entre características en el total de la población de la que se ha obtenido la muestra. Las series de casos y los surveys son descriptivos: El objetivo de la descripción de los individuos es exclusivamente ese, describir las características de este grupo de individuos, sin pretender generalizar las observaciones a una población mayor. En el ejemplo anterior sobre HS, un estudio descriptivo hubiera consistido en describir (y solo describir) las características de todos los pacientes con HS asignados a ese CAP. Es los que se hizo en el próximo ejemplo, sobre el mismo tema. Ejemplo 2.20 En el estudio “Hipotiroidismo subclínico en la consulta de atención primaria” (M. Torné-Coll et al, Atención Primaria 37 (2006), pp. 175-176) se tomaron todos los pacientes de 11 consultas de un CAP de un pueblo de Barcelona a los que les habían realizado analísis de sangre relacionados con la función tiroidea en algún momento de 2001 y se describieron diversas características de los mismos, con especial atención a cuántos fueron diagnosticados de hipotiroidismo subclínico y sus características. Los autores indican que no se pueden extrapolar los resultados a la población general, porque la muestra estaba formada por individuos a los que se había prescrito un tipo de análisis de sangre concreto, señal de que presentaban síntomas que lo hicieran recomendable. Se trata de un estudio descriptivo, no un estudio analítico transversal. Como la información se obtuvo a partir de las historias clínicas, se podría considerar como una serie de casos. Para curarse en salud, los autores dicen que es un “estudio transversal descriptivo.” La ventaja principal de los estudios transversales es que, como los de casos y controles y los de cohorte retrospectivos, son relativamente fáciles de llevar a cabo. Además, son el tipo de estudio adecuado para estimar prevalencias. Los inconvenientes que comparten con los otros estudios observacionales son que puede haber confundidores y que se pueden dar diferentes sesgos en la recogida de datos. Además, al basarse en una muestra “transversal” tomada en un momento concreto, es complicado usar un estudio transversal para estudiar enfermedades poco frecuentes o de desarrollo rápido o exposiciones a riesgos poco frecuentes, ya que serían necesarias muestras muy grandes para poder esperar un número suficiente de enfermos o de expuestos. Tampoco permiten estimar incidencias, ya que para ello se necesita contar enfermos en diferentes momentos. Además, son muy susceptibles al sesgo de supervivencia que comentábamos en los estudios de casos y controles, ya que solo muestreamos individuos vivos. Pero de entre todos sus inconvenientes, el más destacable es que, al usar información sobre un momento concreto, a partir de un estudio transversal en principio es imposible obtener ninguna información sobre relaciones temporales tipo antecedente/desenlace. Si en una muestra de individuos anotamos, por ejemplo, si en ese momento tienen caries o no y si usan inhaladores para el asma o no, no obtenemos ninguna información sobre si alguna de esas dos condiciones es anterior a la otra y por lo tanto no podemos deducir nada sobre si una podría ser susceptible de “causar” la otra. O por ejemplo, en el estudio del Ejemplo 2.19, se observó que los enfermos de HS tenían un nivel de colesterol significativamente más alto que los controles. Pero la manera como se recogieron los datos no permite saber si el HS precede a la hipercolesterolemia, o si es el colesterol alto el que precede al HS, y por lo tanto no nos podemos ni plantear usarlos para investigar si uno de ellos aumenta el riesgo del otro. Volviendo a la prevalencia, para liar más las cosas los epidemiólogos distinguen entre: Prevalencia puntual: lo que nosotros hemos definido como prevalencia, es decir, el número (o la proporción) de personas que tienen la enfermedad en un momento concreto. Prevalencia de período: el número (o la proporción) de personas que en algún momento de un período de tiempo concreto han tenido la enfermedad, incluidos los que ya estaban enfermos al inicio del período de tiempo considerado. Si una persona ha tenido varias veces la enfermedad durante el período de tiempo considerado, solo cuenta una vez en este valor. Prevalencia de vida: el número (o la proporción) de personas que en algún momento de su vida han tenido la enfermedad. De nuevo, si una persona ha sufrido varias veces la enfermedad a lo largo de su vida, solo cuenta una vez en este valor. En el examen MIR de 2020 se preguntó lo siguiente: En una población se produjeron 2000 accidentes mortales de tráfico desde el 1 de enero al 31 de diciembre de 2019. ¿Qué medida de frecuencia de accidentes se ha utilizado?: Prevalencia puntual. Prevalencia de período. Letalidad. Incidencia. Está claro que la respuesta ha de ser (2) o (4); no es una prevalencia puntual, porque no es el número de casos en un momento concreto sino durante un período de tiempo, y no es una letalidad porque no se trata de la proporción de personas involucradas en accidentes de tráfico que hayan fallecido por esa causa (esa sería la tasa de letalidad de los accidentes de tráfico). ¿Qué responderíais, (2) o (4)? ¿Por qué esa y no la otra? En un estudio llevado a cabo en 1928, R. Pearl quiso contrastar la hipótesis de que la tuberculosis previene el cáncer. Para ello, de un grupo de 7500 pacientes fallecidos en un hospital concreto, identificó a partir de sus autopsias todos los que tenían cáncer en el momento de fallecer. En total, fueron 816. A continuación, seleccionó al azar otro grupo de 816 de entre los restantes, emparejados con los primeros por edades, raza y sexo. Encontró que un 6.6% de los enfermos de cáncer y un 16.3% de los sujetos del otro grupo tenían tuberculosis en el momento de fallecer. Pearl concluyó que la tuberculosis previene el cáncer. (a) ¿De qué tipo de estudio se trata? ¿Cuál es la “exposición” y cuál el “desenlace” de interés? (b) Teniendo en cuenta que la tuberculosis era una de las causas principales de ingreso en el hospital donde se llevaron a cabo las autopsias, ¿creéis que su conclusión estaba justificada? (c) En caso negativo, ¿se os ocurre alguna manera de usar estas 7500 autopsias para estudiar de manera más concluyente la relación entre cáncer y tuberculosis? 2.7 Estudios ecológicos En un estudio ecológico se miden las características de interés a nivel de comunidades (países, ciudades, barrios…), no en individuos concretos. Por ejemplo, se comparan las prevalencias de una enfermedad en países con diferentes niveles medios de exposición de sus habitantes a un factor de riesgo. Ejemplo 2.21 En el estudio “Radón residencial y cáncer de pulmón. Un estudio ecológico en Galicia” (R. Barbosa-Lorenzo et al, Medicina Clínica 144 (2015), pp. 304-348) se consideraron 192 municipios de Galicia en los que se hubieran tomado varias mediciones de radón en domicilios entre 1993 y 2011, y se obtuvieron los números de muertes por cáncer de pulmón en esos municipios durante el período 1980-2009 del Registro de Mortalidad de Galicia. Se observó una asociación positiva entre la mortalidad por cáncer de pulmón y la concentración de radón en domicilios, que fue significativa para los varones pero no para las mujeres. Se concluyó que “Estos datos evidencian que el radón residencial puede aumentar el riesgo de cáncer de pulmón en varones, aunque en las mujeres no se puede establecer ninguna conclusión”. ¿Es correcta la conclusión? Que se observe una tendencia a que la tasa de mortalidad por cáncer de pulmón entre los varones sea mayor en los municipios con mayor concentración media de radón residencial, ¿aporta evidencia de que el radón residencial aumenta el riesgo de cáncer de pulmón en hombres? (Pista: los autores usan el verbo “puede aumentar”, no “aumenta”.) No. Este tipo de conclusión es lo que se conoce como falacia ecológica: tomar una asociación positiva entre dos características a nivel de comunidades e inferir una asociación positiva a nivel individual. En general, la asociación a nivel de comunidades no tiene por qué corresponder a una asociación a nivel de individuos. Por ejemplo, este estudio ecológico no aporta ninguna evidencia directa de que los hombres expuestos a una concentración alta de radón en su domicilio tengan mayor probabilidad de cáncer de pulmón. A lo mejor ningún hombre con cáncer de pulmón en los municipios considerados estuvo expuesto a radón residencial. La asociación solo se observó a nivel de municipios. Veamos otro ejemplo. Ejemplo 2.22 En “Environmental factors and cancer incidence and mortality in different countries, with special reference to dietary practices” (B. Armstrong y R. Doll, International Journal of Cancer 15 (1975), pp. 617-631) se compararon las incidencias y tasas de mortalidad de varios tipos de cáncer con el consumo medio de diferentes tipos de alimentos en 23 países (aquellos para los que pudieron obtener estos datos). Se obtuvo, entre otros, el gráfico de la Figura 2.10, que muestra que la incidencia de cáncer de colon entre las mujeres de un país tiende a ser mayor cuanto mayor es el consumo diario medio de carne roja en el país. Figura 2.10: Incidencia del cáncer de colon entre mujeres en función del consumo diario de carne roja per capita en el estudio sobre factores ambientales y cáncer en diferentes países. ¿Se puede concluir que las mujeres que consumen más carne roja tienen un riesgo mayor de tener cáncer de colon? No, la tendencia observada es a nivel de países, no a nivel individual. Para poder deducir una asociación a nivel de mujeres, sería necesario un estudio en el que se tomara una muestra de mujeres y de cada una se anotara su consumo de carne roja y si desarrolla, o ha desarrollado, cáncer de colon. ¿Para qué sirve entonces un estudio ecológico? Básicamente, para aportar evidencia indirecta de la veracidad de una hipótesis. Esta evidencia indirecta puede reforzar la evidencia obtenida de otras maneras o motivar estudios posteriores. Como además los estudios ecológicos son muy fáciles de llevar a cabo, ya que en general los datos en los que se basan son públicos en bases de datos al alcance de todos y con algo de habilidad se recogen en una tarde, son bastante comunes en epidemiología. 2.8 Ensayos clínicos En todos los tipos de estudios explicados hasta ahora, el investigador se limitaba a medir algunas características de un grupo de personas, sin que su participación en el estudio influyera para nada en dichas características. Es decir, las acciones llevadas a cabo por los investigadores en el paso de recogida de datos eran escoger la muestra y medir sus características, pero, por ejemplo, la exposición a factores de riesgo de los sujetos se debía a razones que no tenían nada que ver con el estudio. En cambio, en los estudios intervencionistas el investigador influye de manera planificada en las características de los sujetos analizados. Por ejemplo decidiendo quién va a tomar un medicamento y quién no, o quién se va exponer a un riesgo y quién no, y en principio controla todos los aspectos relevantes del proceso (o al menos lo intenta). En este curso vamos a distinguir entre dos tipos de estudios intervencionistas: Estudio experimental (o intervencionista aleatorizado y controlado): En él, los individuos se distribuyen al azar (aleatorizado) en al menos dos grupos (controlado) que son sometidos a tratamientos diferentes para luego comparar los resultados. Usualmente, uno de los grupos sirve como grupo de control, por ejemplo porque no se les administra ningún tratamiento, o se les administra un placebo (explicamos qué es esto dentro de un rato) o el tratamiento de referencia con el que se quiere comparar un nuevo tratamiento. Estudio casi-experimental: Todos los otros estudios intervencionistas. Por ejemplo, el estudio sobre marcha nórdica que usábamos en la Sección 2.1 es casi-experimental, puesto que no hay un grupo de control, solo el grupo a los que se “administró” marcha nórdica durante un año. El adjetivo “controlado” en la descripción de los estudios experimentales no significa que el investigador “controle” todos los aspectos del estudio: eso ya está (o tendría que estar) incluido en el adjetivo “intervencionista”. A lo que hace referencia es a la existencia de al menos dos grupos de participantes, uno de los cuales normalmente juega el papel de “control” con el que se comparan los resultados de los otros grupos. Como comentaremos más adelante, los estudios intervencionistas suelen aportar una mayor evidencia de la veracidad de sus conclusiones que los estudios observacionales. Pero a menudo es imposible llevarlos a cabo, o al menos no sería ético hacerlo. Por ejemplo, si queremos estudiar si la obesidad aumenta el riesgo de ingreso en UCI en caso de tener COVID-19, ¿cómo podríamos “intervenir” para que unos pacientes fueran obesos y otros no? O, retomando el ejemplo del radón y el cáncer de pulmón, no sería de ninguna manera ético exponer a propósito un grupo de personas al radón para ver si desarrollan más cáncer de pulmón que los no expuestos. En teoría, lo estudios experimentales tendrían que permitir establecer una asociación causal entre las variables, porque en teoría el investigador controla completamente las características de los sujetos del estudio, de manera que las diferencias que se den entre los diferentes grupos solo puedan deberse a los diferentes tratamientos. Pero esto es solo en teoría, porque en la práctica es imposible controlarlo todo. Se suele llamar ensayo clínico (o simplemente ensayo) a un estudio médico intervencionista con humanos. Un estudio médico en el que se pruebe un tratamiento sobre animales de laboratorio o sobre cultivos de células humanas en placas de Petri no se considera un ensayo clínico (a veces se los llama ensayos pre-clínicos). En la ejecución de un ensayo clínico, vamos distinguir tres tipos de personas involucradas, o partes: Los participantes, es decir, los individuos que forman la muestra que se estudia, a los que se administran (o no) los diferentes tratamientos. Las personas encargadas de recoger los datos sobre estos sujetos. Las personas encargadas de analizar los datos recogidos, que pueden coincidir o no con las que los recogen. Los ensayos clínicos se clasifican según el nivel de enmascaramiento de sus partes, es decir, según a quién se le oculta información, en: Abiertos: Todas las partes del ensayo conocen toda la información sobre qué tratamiento recibe cada sujeto. Simple ciegos: Una de las partes del ensayo, normalmente los participantes o el personal encargado de recoger los datos, no conoce el tratamiento que recibe cada sujeto. Doble ciegos: Dos partes del ensayo, usualmente los participantes y los encargados de recoger los datos, desconocen el tratamiento que recibe cada sujeto. Triple ciegos: Ni los participantes, ni los encargados de recoger los datos, ni los encargados de su análisis estadístico, conocen el tratamiento que recibe cada sujeto. El objetivo del enmascaramiento es evitar sesgos en la recogida o el análisis de los datos. Imaginad por ejemplo que estamos comparando un tratamiento nuevo del dolor articular crónico en el que tenemos muchas esperanzas con simplemente administrar el paracetamol de toda la vida. Si el paciente sabe que está tomando el tratamiento nuevo, puede autosugestionarse y sentir menos dolor. Si el que entrevista a los pacientes sabe qué está tomando cada uno, puede favorecer los datos sobre el tratamiento nuevo (“De 0 a 10, ¿cómo está hoy de dolor?” “Ay, no sé, un 5 o un 6.” “¿Ponemos un 5?”). Si el que analiza los datos sabe cada individuo de su tabla de datos a qué grupo pertenece, puede escoger de entre todas las técnicas correctas para analizarlos una que favorezca el tratamiento nuevo. A menudo se usan los calificativos “simple ciego” o “doble ciego” en el sentido más general de que se esconde “algo” a una o dos partes, pero no tiene por qué ser el tratamiento. Por ejemplo, puede ser que los sujetos sepan perfectamente qué tratamiento reciben, pero que no sepan el objetivo final del estudio para que su conocimiento no influya en su comportamiento. En este último caso se habla a veces de ensayo con engaño (deception trial). Hemos hablado hace un rato de placebo. Un placebo es una substancia similar en todos los aspectos a un tratamiento concreto excepto que es farmacológicamente inactiva. El típico ejemplo son las pastillas de azúcar exactamente con la misma forma y color que las pastillas del tratamiento, pero puede ser algo más exagerado: operar sin hacer nada, solo abrir y cerrar pero siguiendo el ceremonial de las operaciones quirúrgicas, como placebo de la operación quirúrgica “de verdad” que se está estudiando. Usar placebo en un ensayo clínico puede tener varias finalidades: Enmascarar el ensayo. Si el grupo de control recibe algo físicamente idéntico al tratamiento pero que no sirve para nada, se puede ocultar a los participantes (y a los que recogen los datos) quién está tomando el tratamiento activo y quién no. En cambio, si a un grupo se les administra un tratamiento y a otro no se les administra nada, es imposible enmascarar el tipo de tratamiento a los participantes. Evaluar la tasa de curación espontánea. Al tratar pacientes con algo farmacológicamente inactivo, tenemos un grupo con el que estimar qué proporción de los enfermos se curan sin tratamiento. Evaluar el efecto placebo. Se trata de la alteración en la respuesta de un paciente por el mero hecho de recibir tratamiento. Por ejemplo, en un estudio sobre el tratamiento del dolor crónico, puede ser que el paciente note un cierto alivio del dolor simplemente porque “toma algo”, aunque sea azúcar. Muchas pseudoterapias se basan en este efecto. Ejemplo 2.23 Considerad el estudio “Effect of Zhubin (KI9) acupuncture in reducing alcohol craving in patients with alcohol dependence: a randomized placebo-controlled trial” (J. S. Lee et al, Chinese Journal of Integrative Medicine 21 (2015), pp. 307-311). Su objetivo era examinar el efecto de la acupuntura en un determinado punto para reducir el ansia de ingesta de alcohol en alcohólicos. Para ello, se repartieron de manera aleatoria 20 pacientes alcohólicos en dos grupos de 10. El grupo de tratamiento recibió acupuntura con agujas reales dos veces por semana durante 4 semanas, y el grupo de control recibió el mismo régimen de acupuntura pero con agujas de placebo (de punta roma, que no perforan la piel). El doctor que practicó la acupuntura conocía qué tipo de aguja usaba, pero los pacientes y el personal encargado de realizarles el seguimiento, no. Como veis, se trata de un estudio experimental (hay intervención, aleatorización y dos grupos) y es doble ciego. Los resultados del ensayo se resumen en el gráfico siguiente, extraído del artículo: En él, observamos que el ansia por tomar alcohol en el grupo de tratamiento (línea uniendo puntos rellenos) disminuyó mucho más que en el grupo de control, pero que en este último también disminuyó en las primeras sesiones, seguramente debido al efecto placebo. Otra clasificación importante de los estudios controlados depende de cómo se forman los grupos: Grupos paralelos: El grupo de participantes se divide en los diferentes grupos que recibirán los diferentes tratamientos. Figura 2.11: Esquema de un estudio con dos grupos paralelos. Grupos cruzados: Los diferentes tratamientos son administrados a cada sujeto en momentos diferentes, en un orden elegido al azar si queremos que haya aleatorización. Figura 2.12: Esquema de un estudio con dos grupos cruzados. El estudio de acupuntura mencionado hace un rato fue de grupos paralelos: cada grupo recibió un único tratamiento, diferente en un grupo del otro. Veamos otro ejemplo de estudio con grupos paralelos. Ejemplo 2.24 En el estudio “Efectos de un programa de terapia de baile en la calidad de vida, el sueño y la presión arterial en mujeres de mediana edad: un ensayo controlado aleatorizado” (M. Serrano-Guzmán et al, Medicina Clínica 147 (2016), pp. 334-339) participaron 67 mujeres de mediana edad prehipertensas e hipertensas. Se asignó cada una al azar a un grupo de intervención (donde siguieron un programa de terapia de baile específico durante 8 semanas, además de su medicación) o a un grupo control (donde continuaron con sus actividades y medicación habitual). 35 mujeres fueron a parar al grupo de intervención y 32 al grupo de control. Se midieron en ambos grupos la presión arterial, la calidad del sueño y la calidad de vida (estas dos últimas mediante indicadores específicos) al principio del estudio y tras las 8 semanas. El grupo de intervención mejoró significativamente sus valores de presión arterial, calidad del sueño y calidad de vida en comparación con el grupo control. Veamos ahora un ensayo con grupos cruzados. Ejemplo 2.25 En el estudio “Digestión deficiente e intolerancia a lactosa en un grupo de enfermos con colitis ulcerativa crónica inespecífica, Ensayo clínico controlado, cruzado y doblemente a ciegas” (G. A. Cabrera-Acosta et al, Revista de Gastroenterología de México 77 (2012), 26-30) participaron 39 pacientes diagnosticados de colitis ulcerativa crónica inespecífica (CUCI). Cada uno de ellos recibió, de forma aleatoria, 12.5 g de lactosa o de maltosa en 250 ml de agua, tras un ayuno de 12 horas. Al cabo de tres días de dieta habitual, cada participante recibió el preparado que no había recibido en la primera prueba. Tras cada sesión, se les realizó un test de intolerancia a la lactosa, siempre el mismo (cantidad de hidrógeno en aire aspirado). Ni los participantes ni el personal que realizó los tests conocía el orden asignado de los productos consumidos. 18 enfermos (un 46% del total) presentaron digestión deficiente de lactosa. Observad algunos aspectos de este estudio: El ensayo fue controlado, ya que cada sujeto fue el control de si mismo. Se comparó para cada participante su digestión de la lactosa y de la “no-lactosa”, que es el papel que juega la maltosa en este estudio. El ensayo fue aleatorizado, ya que el orden de los productos administrados a cada sujeto fue decidido al azar. De esta manera, se intentó evitar posibles sesgos que podrían haberse dado si todos hubieran consumido cada producto en el mismo día. Por ejemplo, si hubiera algún factor desconocido que influyera en la digestión de la lactosa y que se hubiera dado el día que tocara lactosa a todos. Las dos tomas se separaron 72 horas para disminuir el efecto residual del azúcar consumido en la primera prueba. La maltosa en agua tiene un aspecto y sabor similar al de la lactosa, por lo que sirvió de placebo. El ensayo fue doble ciego: los participantes no sabían qué bebían en cada toma y el personal que realizó los tests de intolerancia a la lactosa y midió sus resultados tampoco sabían qué habían tomado. Es importante recalcar las similitudes y diferencias entre los diseños de cohorte y experimental en estudios para determinar la asociación entre una exposición y un desenlace. En ambos estudios se toma un grupo de expuestos y uno de no expuestos. En el estudio de cohorte, los sujetos pertenecen a un grupo u otro por motivos externos al estudio: por decisión propia, por criterio clínico, por motivos ambientales, geográficos, genéticos… Esto puede hacer que los sujetos con algunas características concretas sean más abundantes en un grupo que en otro. En el estudio experimental, los sujetos son asignados por el investigador de manera aleatoria a un grupo u otro. De esta manera se intenta evitar que los sujetos con algunas características concretas tiendan a aparecer más en un grupo que en otro. Comparad las dos situaciones siguientes. En un estudio sobre la eficacia de dos tratamientos, A y B, para una enfermedad, se tomó un grupo de pacientes con esta enfermedad. A cada uno de ellos se le administró A o B según el criterio clínico del médico que los atendió, y se comparó la eficacia de ambos tratamientos. En un estudio sobre la eficacia de dos tratamientos, A y B, para una enfermedad, se tomó un grupo de pacientes con esta enfermedad. A cada uno de ellos se les administró A o B al azar, y se comparó la eficacia de ambos tratamientos. El primero sería observacional, más en concreto de cohorte; el segundo, experimental. En un famoso estudio, el Dr. Norman Gregg estudió 78 casos de recién nacidos con cataratas congénitas de toda Australia, y observó que en 68 de ellos se había diagnosticado que la madre había tenido la rubeola durante la primera parte del embarazo (de los 10 restantes, solo en 2 se descartaba explícitamente que hubieran pasado la rubeola durante el embarazo). Concluyó que había asociación entre la rubeola materna y las cataratas congénitas. Por su diseño, ¿de qué tipo de estudio se trata? ¿Creéis que la conclusión de Gregg estaba justificada basándose solo en los datos de los 78 neonatos con cataratas? Si sí, ¿por qué? Si no, ¿qué información haría falta para poder llegar a una conclusión? Si el estudio de Gregg no fue de casos y controles, diseñad (en detalle: cómo elegiríais los casos y los controles, cómo obtendríais la información etc.) un estudio de este tipo cuyo objetivo sea detectar la posible asociación entre la rubeola materna y las cataratas congénitas. Repetid la pregunta anterior con un estudio de cohorte prospectivo. Y ahora con un estudio de cohorte retrospectivo. Pensad en algún confundidor que pudiera aparecer en estos estudios observacionales. ¿Qué haríais para descartarlo? ¿Sería posible o ético llevar a cabo un estudio experimental cuyo objetivo fuera detectar la posible asociación entre la rubeola materna y las cataratas congénitas? Para terminar esta sección sobre estudios intervencionistas, vamos a describir los diferentes tipos, o fases, de los ensayos farmacológicos, en los que se investiga el efecto de un nuevo fármaco o vacuna. Figura 2.13: Fases de los ensayos farmacológicos; fuente: https://clinicalinfo.hiv.gov/es/glossary/ensayo-clinico Los ensayos de fase I se centran en la pregunta ¿Es seguro el tratamiento?. En ellos se prueba el fármaco en grupos pequeños (digamos, de decenas) de voluntarios no necesariamente enfermos, sin grupo de control. Estos ensayos aportan datos preliminares sobre su toxicidad y efectividad en diferentes dosis. Los ensayos de fase II se centran en la pregunta ¿Es efectivo el tratamiento?. En ellos se prueba el fármaco sobre un grupo de tamaño medio (digamos, de centenares) de enfermos y se comparan los resultados con un grupo de control, pero posiblemente sin aleatorizar los tratamientos. En los ensayos de una vacuna, se prueba sobre todos los sujetos de la muestra, sin grupo de control. Se estudia la eficacia del medicamento (relación dosis/respuesta, dosis óptima, margen de seguridad….) y los efectos adversos a corto plazo en diferentes condiciones “de laboratorio”, seguramente diferentes de lo que va a ser su administración habitual si se aprueba el fármaco. Los ensayos de fase III se centran en la pregunta ¿Es mejor el nuevo tratamiento que el convencional? Se trata de ensayos controlados aleatorizados sobre un grupo de enfermos mucho mayor (digamos, de miles) en los que se evalúa la eficacia del medicamento en condiciones de uso similares a las que se darían cuando se hubiera aprobado, así como su seguridad a más largo plazo, comparándolo con las alternativas terapéuticas disponibles. Los ensayos de fase IV se llevan a cabo tras la comercialización y varios años de uso del fármaco. En ellos se reevalúa su efectividad y se estudian sus posibles nuevas indicaciones y su seguridad a largo plazo. 2.9 A modo de resumen El gráfico siguiente presenta un diagrama de flujo para clasificar un estudio médico en los diferentes tipos explicados hasta el momento. Figura 2.14: Algoritmo para la clasificación básica de un estudio médico. Hay muchos más tipos de estudios médicos: estudios híbridos que mezclan aspectos de diferentes tipos (casos-cohorte, casos y controles anidados en una cohorte, estudios casi-experimentales con un control externo,…), estudios secuenciales (en los que se analizan cada cierto tiempo los resultados obtenidos y se decide si se continúa el estudio ampliando la muestra o si se para antes de su final previsto), etc. No los vamos a estudiar en este curso. 2.10 Revisiones sistemáticas y metaanálisis Hay un último tipo de estudios que queremos comentar, en los que las muestras que se estudian están formadas por … estudios médicos previos sobre un tema. Se trata de las revisiones sistemáticas: Resúmenes de todo lo publicado sobre un tema específico. Entre las revisiones sistemáticas, aquí destacamos los metaanálisis, que usan técnicas estadísticas para analizar conjuntamente los resultados publicados en una serie de estudios previos sobre un tema concreto. Observad que si se han efectuado, digamos, 25 estudios sobre un tema y en cada uno han participado, pongamos, 40 sujetos, al analizar conjuntamente los datos generados es como si se tratara de un estudio con 1000 sujetos. Como os podéis imaginar, las conclusiones que se obtienen a partir de 1000 sujetos son más fiables que las que se obtienen con 40. De hecho, son más fiables que las que se obtienen en 25 estudios con 40 participantes cada uno, como veremos más adelante en el tema de Contrastes de Hipótesis. Figura 2.15: Esquema de un metaanálisis. Ejemplo 2.26 En el estudio “¿Resistencia en el acné? Un metaanálisis a propósito de la controversia” (M. Álvarez-Sánchez et al, Cirugía y Cirujanos 84 (2016), pp. 190-195), se presenta un metaanálisis de las publicaciones de los 10 años anteriores a su aparición sobre la resistencia bacteriana del Propionibacterium acnes a los antibióticos tópicos usados habitualmente en el tratamiento del acné. En primer lugar, se hizo una selección sistemática de aquellos estudios que iban a ser incorporados al metaanálisis, que al final fueron solo 13 de 501 candidatos, según el proceso descrito en el flujograma siguiente: Figura 2.16: Proceso de selección de los artículos en el estudio sobre resistencia en el acné (Figura 2 en el artículo). De los 13 estudios analizados, en 8 se había obtenido evidencia de un aumento en la resistencia del P. acnes a la eritromicina y clindamicina tópicas usadas en tratamientos anti acné, de los cuales solo en 1 fue significativo, y en 5 se obtuvo evidencia de un aumento en su sensibilidad, de los cuales en 2 fue significativo. Al analizar conjuntamente los datos de los 13 estudios, se obtuvo evidencia de que ha habido un aumento en la resistencia del P. acnes a estos antibióticos, pero el aumento detectado no fue significativo. Figura 2.17: Forest plot del estudio sobre resistencia en el acné (Figura 1 en el artículo). Los resultados de un metaanálisis se suelen representar mediante un forest plot (o también diagrama de efectos o blobograma) como el de la Figura 2.17. Sobre este diagrama conviene saber que: Los segmentos con un cuadrado en su centro representan los estudios analizados. Para cada uno de estos estudios y segmentos: El tamaño del cuadrado representa (en este ejemplo) el tamaño de la muestra usada La posición del centro del cuadrado representa el valor estimado del aumento del riesgo de resistencia (medido mediante la odds ratio, o razón de momios, del título del gráfico, de la que hablaremos en la Sección 4.3). Si el centro está en la zona “Sensible” (a la izquierda de 1), en el estudio se observó un aumento de la sensibilidad, mientras que si el centro está en de la zona “Resistente” (a la derecha de 1), se observó un aumento de la resistencia. La longitud del segmento representa la incertidumbre de la generalización de esta estimación al total de la población (fijaos en que a mayor tamaño de la muestra, menor incertidumbre); formalmente, se tratan de intervalos de confianza del 95% (Sección 13.1) Si el segmento está totalmente contenido de la zona “Sensible”, se obtuvo evidencia significativa de aumento de la sensibilidad, mientras que si el intervalo está totalmente contenido de la zona “Resistente”, se obtuvo evidencia significativa de aumento de la resistencia. Si el segmento curta la línea vertical del 1, la evidencia obtenida no fue significativa. El segmento inferior con un rombo en su centro representa el resultado del metaanálisis. Su interpretación es la misma que para los anteriores. Como su centro está en la zona “Resistente”, se obtuvo evidencia de aumento en la resistencia, pero como cruza la línea vertical del 1, la evidencia no fue significativa. La Figura 2.18 representa la llamada pirámide de la evidencia, que ordena los tipos de estudio, de la base hacia la cúspide, en función de la calidad de la evidencia científica que, en general, aportan. Cuanto más arriba en la pirámide está un tipo de estudio, en principio con más seguridad se pueden adoptar sus conclusiones en la práctica médica. Si reflexionáis un poco, veréis que el orden que describe es muy razonable. Figura 2.18: Pirámide de la evidencia. Los metaanálisis representan la cúspide de la evidencia en estudios médicos, pero no están exentos de problemas: Son sensibles al sesgo de publicación. Se tiende a publicar en revistas científicas solo aquellos estudios que presentan resultados positivos o al menos “interesantes”; las revistas científicas son un negocio, y la mayoría solo publican los artículos que puedan hacer crecer su prestigio y con él las ventas. Por este motivo, si solo se tienen en cuenta estudios publicados en revistas, las conclusiones pueden estar sesgadas. Es imprescindible buscar, e incluir, posibles estudios que hayan quedado sin publicar porque no obtuviesen evidencia significativa de nada. Si los estudios analizados son defectuosos, el metaanálisis no los salva, y las conclusiones pueden ser erróneas. Por ello es necesario establecer unos criterios precisos de calidad de los estudios cuyos datos se vayan a tener en cuenta. 2.11 (Bonus track) Unos criterios de causalidad El objetivo final de la mayoría de estudios médicos es establecer una relación de causalidad, de causa/efecto: Esta medicina cura esta enfermedad. La exposición a tal riesgo aumenta el riesgo de padecer esta enfermedad. Esta vacuna previene esta enfermedad. Etc. Por desgracia, como ya hemos comentado, es virtualmente imposible establecer sin ninguna duda una relación de causalidad entre dos eventos por medio de un estudio médico. Por ejemplo, ¿cómo podríamos estar absolutamente seguros de que hemos obtenido evidencia de que fumar aumente el riesgo de cáncer de pulmón? Pues la única manera sería tomar un grupo de personas, hacerles fumar cantidades fijas de cigarrillos diarios y anotar quiénes de ellos desarrollan cáncer de pulmón a lo largo de su vida. A continuación, volver atrás en el tiempo, impedirles totalmente que fumen, hacerles revivir su vida exactamente como en la primera ronda salvo por el hecho de que ahora no fuman (su vida, y la del resto del universo, fluctuaciones cuánticas incluidas), y anotar quiénes desarrollan cáncer de pulmón en esta segunda oportunidad. Solo de esta manera garantizaríamos que cualquier diferencia en los números de cáncer de pulmón se debe al fumar. Como no podemos usar esta técnica, hemos de echar mano a estudios como los explicados en las secciones anteriores, que en general solo muestran una asociación entre una exposición y un desenlace y en los que no podemos controlar todas las variables que puedan influir en el desenlace, incluyendo confundidores. Cierto es que en los estudios experimentales las controlamos más que en el resto, pero no al cien por cien. En estas condiciones, está claro que la asociación que se observe no tiene por qué implicar causalidad. Ejemplo 2.27 En el estudio “Socioeconomic position and the risk of brain tumour: a Swedish national population-based cohort study” (A. Khanolkar et al, Journal of Epidemiology and Community Health 70 (2016), pp. 1222-1228) se realizó un seguimiento durante 17 años a más de 4 millones de suecos, y se observó una asociación sorprendente: los que habían cursado al menos 3 años de estudios universitarios tenían un 22% más de probabilidad de tener un glioma (un tipo de tumor cerebral) que los que solo tenían educación primaria. La diferencia fue además estadísticamente significativa. ¿Creéis que puede ser verdad que tener estudios universitarios cause un aumento de la probabilidad de tener un glioma? Seguramente no. Incluso los autores lo reconocen en sus Conclusiones. En lo que se detectó una diferencia significativa fue en el número de diagnósticos de glioma, que pudo deberse a que las personas con estudios superiores tienen una mayor probabilidad de que su glioma sea detectado, por ejemplo porque acudan al médico antes, y que sea registrado en el Registro Nacional de Cáncer, que es de donde se extrajo la información sobre los cánceres. Naturalmente, en el periódico solo vais a encontrar la parte llamativa del estudio, como muestra el titular de la noticia del ABC sobre el tema. Figura 2.19: Noticia publicada en el ABC el 21 junio de 2016. El texto completo está disponible en https://www.abc.es/salud/enfermedades/abci-estudios-universitarios-podrian-aumentar-riesgo-tumores-cerebrales-201606201751_noticia.html. El estadístico Austin Bradford Hill (que ya ha aparecido en esta lección como coautor del estudio pionero sobre cáncer y tabaco del Ejemplo 2.5) enunció la lista más popular de criterios de causalidad para poder aceptar que una asociación observada entre una exposición y un desenlace sea en realidad una relación causal. El primer criterio es obvio, y el único que es necesario que se cumpla: Temporalidad: La pretendida causa tiene que preceder temporalmente al efecto. El resto de criterios son optativos, pero cuantos más se cumplan, más fuerza tiene el argumento en favor de la relación causa/efecto. Vamos a ilustrarlos con argumentos en favor de que niveles altos de colesterol en sangre aumentan el riesgo de enfermedad coronaria. Fuerza de la asociación estadística: Cuanto mayor sea la asociación observada (en el sentido, por ejemplo, de cuántas veces mayor es la frecuencia observada del desenlace entre los expuestos que entre los no expuestos), más creíble es que la exposición sea la causa del desenlace. Por ejemplo, ha habido estudios de cohorte en los que se ha observado un aumento de casi un 300% en la incidencia de enfermedades coronarias entre los sujetos con nivel muy alto de colesterol respecto de los sujetos con niveles normales. Consistencia o reproducibilidad: Si cada vez que se llevan a cabo estudios similares se obtienen conclusiones similares, es más creíble que la relación causal sea verdadera. La asociación entre niveles altos de colesterol y enfermedades coronarias se ha observado en multitud de estudios tanto de casos y controles como de cohorte sobre poblaciones de características diferentes. Plausibilidad biológica: La existencia de una explicación biológica plausible de la relación causa/efecto hace más creíble que esta relación sea verdadera. Se ha comprobado que el colesterol LDL promueve el desarrollo de placas arterioescleróticas, y estas aparecen en las enfermedades cardíacas. Coherencia: Si la relación causa/efecto propuesta no va contra el conocimiento científico sobre el tema, es más creíble que sea verdadera. Fijaos en que no es lo mismo tener una explicación biológica para la causalidad (el criterio anterior) que la ausencia de teorías o estudios que la contradigan. En nuestro caso, la asociación entre el colesterol y la enfermedad cardíaca no contradice ningún estudio conocido ni ningún mecanismo biológico conocido. Especificidad: Si se han descartado mediante otros estudios otras posibles causas del desenlace, aumenta la verosimilitud de que la exposición para la que sí se ha encontrado una asociación lo cause. La asociación entre colesterol alto y el desarrollo de enfermedades cardíacas se ha mantenido cuando se han descartado los efectos de posibles confundidores como el tabaco, el alcohol, la edad, la tensión arterial etc. Relación dosis-respuesta: Si a mayor exposición se observa una mayor frecuencia de aparición del desenlace, es más creíble que la exposición sea la causa del desenlace. En el ejemplo que nos ocupa, se ha observado en muchos estudios que la probabilidad de tener una enfermedad cardíaca crece con el nivel de colesterol. Reversibilidad: Si se observa que el desenlace tiende a desaparecer al eliminar la exposición, es más creíble que la exposición sea la causa del desenlace. Se han realizado estudios experimentales en los que se ha observado que si se reduce el nivel de colesterol por medio de la administración de fármacos, se reduce la riesgo de enfermedad coronaria. Calidad del estudio: La relación causa/efecto es más creíble si la asociación se ha establecido en un estudio experimental que si lo ha sido en estudios inferiores en la pirámide de la evidencia. Naturalmente, en nuestro ejemplo no se han llevado a cabo estudios experimentales en los que a sujetos se les aumentara el nivel de colesterol para ver si tenían un infarto, pero como hemos comentado sí que se han realizado en el sentido contrario. Analogía: Si se ha aceptado que exposiciones similares causan desenlaces similares, es más fácil de aceptar que esta relación causa/efecto se dé también en nuestro caso. Se han descrito mecanismos similares al relacionado con el colesterol LDL que producen placas arterioescleróticas. 2.12 (Bonus track) Preguntas clínicas en formato PICO Al buscar información sobre un tema médico específico, es importante formular la pregunta de manera adecuada. Un esquema muy usado para estructurar este tipo de preguntas es el PICO, acrónimo de Paciente-Intervención-Comparación-Outcome (resultado): ¿Sobre qué tipo de Paciente? Se trata de especificar con precisión el tipo de paciente (o de Persona, si está sano) sobre el que nos interesa obtener información. ¿Qué Intervención? Aquí intervención puede referir a un tratamiento de una enfermedad, la exposición a un factor de riesgo, una prueba diagnóstica… ¿Comparado con qué otra intervención? A veces esta parte no se tiene en cuenta, si no se quiere comparar el resultado de la intervención con nada sino simplemente saber su resultado. Hablaríamos entonces del formato PIO. ¿Qué resultado (Outcome) nos interesa? Aquí resultado refiere a las consecuencias de la intervención en la salud del paciente. Ejemplo 2.28 Vamos a traducir al formato PICO la pregunta “¿El uso de ácido acetil salicílico (AAS), aumenta la supervivencia en el infarto agudo de miocardio?” Paciente. ¿Ante qué tipo de pacientes se nos plantea el problema? No vale “las personas en general”. Por ejemplo, podría ser: En los pacientes mayores de 60 años con síndrome coronario agudo con elevación del ST… Intervención. ¿De qué tipo de acción queremos saber las consecuencias? … la administración de AAS… Comparación. ¿Con respecto a qué queremos comparar la intervención? … con respecto a no administrarles nada… Outcome (Resultado). ¿En qué efecto estamos interesados? Como a la larga nadie sobrevive a la vida, podría ser, por ejemplo … ¿aumenta la tasa de supervivencia a 30 días vista? Nos quedaría: En los pacientes mayores de 60 años con síndrome coronario agudo con elevación del ST, ¿la administración de AAS aumenta la tasa de supervivencia a los 30 días con respecto a no administrarles nada? Ejemplo 2.29 Considerad la situación siguiente. X es una nueva paciente de 76 años que acude a vuestra consulta para hacerse un examen físico periódico. X se encuentra en buen estado de salud aunque sufre de hipertensión desde hace muchos años. Su hipertensión está controlada con éxito mediante beta-bloqueantes y nos ha expresado su satisfacción con esta terapia. Sin embargo, su hijo ha sido diagnosticado recientemente de hipertensión y se le ha recetado un inhibidor de la ECA. X os pregunta si este tratamiento sería una mejor opción para ella. Vamos a traducir la pregunta planteada por X al formato PICO. P: mujer, edad avanzada, hipertensa, por lo demás en buen estado de salud I: administrar un inhibidor de la ECA C: administrar beta-bloqueantes O: eficacia en la reducción de la presión arterial, efectos secundarios. Como resultado, la pregunta PICO podría ser: En mujeres hipertensas de edad avanzada, ¿un inhibidor de la ECA es más eficaz que un beta-bloqueante para controlar la presión arterial alta y minimizar los efectos secundarios adversos? 2.13 Test (1) Un estudio publicado describe varias características de los pacientes ingresados con neumonía en un hospital durante un año, incluidos el sexo, la edad, el historial de tabaquismo y el historial de ingresos previos por neumonía. ¿De qué tipo de estudio se trata? Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles (2) En un artículo publicado se estudió a pacientes atendidos en una clínica por apendicitis aguda tratada con apendicectomía laparoscópica. Se tomaron 50 de ellos que presentaron infección de la herida una semana después del alta y 50 que no la presentaron. El estudio comparó entre ambos grupos los factores que se anotaron en el ingreso, como la edad, el sexo, la presencia de dolor en el cuadrante inferior derecho, la temperatura, entre otros. El objetivo era determinar cuáles influyen en la aparición de la infección. ¿De qué tipo de estudio se trata? Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles (3) Si identificamos pacientes con bronquitis crónica obstructiva en el año 2010 tratados y no tratados con corticoides por vía inhalatoria, y comparamos su función respiratoria a día de hoy, se trata de un estudio: Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles (4) Se ha llevado a cabo un estudio con el fin de determinar el riesgo de hemorragia digestiva alta (HDA) asociado al uso de diferentes antiinflamatorios no esteroideos (AINE). Para ello se incluyeron 2777 pacientes con HDA y 5532 pacientes emparejados con los anteriores por edad y mes de ingreso o consulta en los mismos hospitales, pero por otras razones que no tuvieran que ver con el uso de AINE. Se comparó la exposición previa a diferentes AINE en ambos grupos. ¿De qué tipo de estudio se trata? Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles Intervencionista Ecológico (5) Que un ensayo clínico sea “abierto” significa que: No requiere ingreso. Pueden incluirse sujetos en el ensayo una vez iniciado. No existe grupo control. No es enmascarado. Sus resultados son extrapolables a la población general. (6) En un centro de salud se está realizando un estudio para determinar el efecto de la exposición al humo del tabaco en hijos de padres fumadores. Para ello, se selecciona a un grupo de niños sanos entre 3 y 7 años cuyos padres son fumadores y al mismo tiempo se selecciona en el mismo centro un número igual de niños cuyos padres no son fumadores. Un año después se investigará en ambos grupos la aparición de enfermedades respiratorias durante ese año. ¿De qué tipo de estudio se trata? Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles Experimental Casi-experimental Ecológico (7) En un estudio de fase III destinado a confirmar la eficacia bacteriológica de un nuevo antibiótico para el tratamiento de pacientes con pielonefritis aguda (una infección bacteriana de las vías urinarias que puede desembocar en insuficiencia renal, sepsis…) grave, ¿cuál de los siguientes diseños de ensayo clínico es el más apropiado? Paralelo, abierto, controlado con placebo Paralelo, aleatorizado, doble ciego, controlado con otro antibiótico Paralelo, aleatorizado, doble ciego, controlado con placebo Cruzado, abierto, controlado con otro antibiótico Cruzado, aleatorizado, doble ciego, controlado con otro antibiótico Cruzado, aleatorizado, doble ciego, controlado con placebo (8) La medicina basada en la evidencia propone integrar las mejores evidencias con la experiencia clínica y las circunstancias de los pacientes en la toma de las decisiones clínicas. En relación a la calidad de la evidencia, ¿cuál de los siguientes tipos de estudio proporciona evidencias de mayor calidad?: Revisiones sistemáticas Estudios de cohorte Estudios de casos y controles Ensayos clínicos aleatorizados y controlados Ensayos clínicos doble ciegos, aleatorizados y controlados con placebo (9) Seleccionamos una muestra aleatoria entre los pacientes que acuden a vacunarse de la gripe durante la campaña anual en un centro de salud. Se registra en los pacientes seleccionados si están utilizando fármacos hipolipemiantes y si están diagnosticados de diabetes mellitus, entre otros datos. Se obtiene que la diabetes mellitus es más frecuente entre los pacientes que toman hipolipemiantes que entre los que no los toman. ¿A cuál de los siguientes corresponde el diseño de este estudio? Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles Experimental Ecológico (10) ¿Qué tipos de estudios permiten estimar la incidencia de una enfermedad? Marca todas las respuestas correctas: Series de casos De casos y controles De cohorte Transversales Ninguno de los anteriores (11) El servicio de dermatología de un hospital ha registrado durante los últimos 20 años todos los casos diagnosticados de necrosis epidérmica tóxica en el centro. Se encuentra que un 20% de estos pacientes habían estado expuestos a carbamazepina en las 6 semanas previas al diagnóstico, mientras que un 10% habían estado expuestos a fenitoína. ¿A cuál de los siguientes corresponde el diseño de este estudio? Serie de casos Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles Experimental Ecológico Revisión sistemática (12) En un estudio epidemiológico se comparó el consumo de vino per cápita en distintos países en el año 2012 con la tasa de mortalidad por infarto de miocardio en ese mismo año en dichos países. ¿De qué tipo de estudio se trata? Descriptivo Transversal De cohorte prospectivo De cohorte retrospectivo De casos y controles Experimental Ecológico (13) Informamos a la gerencia de nuestro hospital de que la densidad de incidencia de infección en la Unidad de Cuidados Intensivos (UCI) es de 15 por mil diarios y nos preguntan qué significa esa cifra. Nuestra contestación debería ser: Si hubiera 1000 pacientes ingresados en la UCI, cada día habría 15 infecciones nuevas. Si hubiera 1000 pacientes ingresados en la UCI sin infección, cada día habría 15 infecciones nuevas. De cada 1000 ingresos en el hospital, 15 diarios se infectan en la UCI. El riesgo diario de ingresar en la UCI es de 15 cada 1000 habitantes en la población de referencia. Se infectan 15 pacientes de cada 1000 que ingresan en la UCI en un día. (14) Los ensayos clínicos en fase II tienen como objetivo: La estimación inicial de la seguridad y tolerancia Demostrar el efecto terapéutico Obtener información sobre la eficacia Evaluar la aparición de efectos secundarios Estimar la relación eficacia/coste del tratamiento (15) De los siguientes criterios de causalidad en una asociación estadística entre una exposición y un desenlace, ¿cuál es el único necesario?: Plausibilidad biológica: Que se conozca una explicación biológica plausible de la asociación. Consistencia: Que se observe dicha asociación cada vez que se repita el estudio. Relación temporal adecuada: Que la exposición preceda en el tiempo al desenlace. Fuerza de la asociación: Que la asociación observada sea muy grande. Este et al significa “y otros” y se utiliza para no dar toda la lista de autores de un artículo.↩︎ "],["algunos-conceptos-básicos-más.html", "Lección 3 Algunos conceptos básicos más 3.1 Unidad de observación 3.2 Población y muestra 3.3 Tipos básicos de muestreo 3.4 Sesgos 3.5 Test", " Lección 3 Algunos conceptos básicos más 3.1 Unidad de observación En un estudio estadístico, la unidad de observación es, para entendernos, el tipo de qué o de quiénes que son objeto de medición durante la investigación. En los estudios médicos normalmente serán personas, pero no siempre. Por ejemplo, pueden ser sucesos que les pasen a personas, de manera que una misma persona pueda ser observada varias veces: embarazos, operaciones quirúrgicas… O recordad los estudios ecológicos (Sección 2.7), en los que la unidad de observación son las comunidades de las que se mide algún dato global. Por ejemplo, podemos medir en diferentes centros de educación primaria de una ciudad el gasto medio diario en sus máquinas expendedoras de alimentos procesados y la proporción de miopes entre sus alumnos, para estimar si hay alguna relación entre el consumo de alimentos procesados y la miopía. Aquí, la unidad de observación son los centros de educación primaria, no los alumnos. 3.2 Población y muestra En un estudio inferencial queremos deducir (inferir) información sobre una población a partir de una muestra. Figura 3.1: Población versus muestra Ejemplo 3.1 Si queremos saber si un guiso nos ha quedado soso, no nos lo comemos todo, porque entonces nos quedaríamos sin guiso y ya no valdría la pena saber si está soso o no. Lo que hacemos es probar solo una cucharada. El guiso es la población, la cucharada la muestra. A partir del sabor de la cucharada, “inferimos” cómo nos ha quedado el guiso. En general, una población es simplemente un conjunto de individuos u objetos (genéricamente, de sujetos) sobre los que queremos conocer alguna información. Esta población puede estar perfectamente definida en un lugar y tiempo: por ejemplo, los empadronados en Mallorca a día de hoy. Pero normalmente su definición será difusa. Si, por ejemplo, queremos estimar algo sobre “los españoles diabéticos mayores de 65 años”, ¿de quiénes estamos hablando exactamente? ¿De los que están vivos justo ahora? ¿De todos los que ha habido en España desde su fundación? ¿Incluimos los que aún no han nacido? ¿Qué hacemos con los que son diabéticos pero no han sido diagnosticados, ni lo serán nunca? Tranquilos, no nos vamos a romper mucho la cabeza con esto. Pero al menos tenéis que ser conscientes de que una población puede contener sujetos que en realidad no existen ni hayan existido ni vayan a existir, sino simplemente que “podrían existir”. Y en medicina especialmente, cuando queremos estimar si un tratamiento será efectivo para tratar una cierta enfermedad… incluyendo los casos que aún no han contraído la enfermedad. Hablaremos entonces de una población virtual (en otros lugares la califican de población metafórica). Por ejemplo, cuando decimos que “La probabilidad de que salga Cara al lanzar una moneda equilibrada es 1/2”, lo que significa es que “Si tomamos la población formada por todos los posibles lanzamientos de todas las posibles monedas equilibradas, en la mitad de estos lanzamientos el resultado es Cara.” Los sujetos de esta población son todos los “posibles” lanzamientos de monedas equilibradas, los que se han realizado a lo largo de la historia, los que se realizarán en el futuro, y los que se podrían haber realizado o se podrían realizar en el futuro pero en realidad no han tenido lugar ni lo tendrán. Otro ejemplo. Imaginad que comparamos las notas que (vosotros, estudiantes de primer curso del grado de Medicina de la UIB de este año académico) sacáis en dos cuestionarios diferentes sobre un mismo tema, uno sobre conceptos y el otro de cálculos, y que en el primero obtenéis una nota media mucho mayor que en el segundo. Usamos este dato para inferir que los estudiantes de primer curso de Medicina sacan de media mejor nota en tests de conceptos que en tests calculísticos. ¿Quiénes son estos “estudiantes de primer curso de Medicina”? ¿Sobre qué población “inferimos” información a partir de este resultado? No sobre solo vosotros para estos dos tests concretos, ya que entonces no estaríamos infiriendo nada, simplemente calificaríamos, constataríamos que una nota media ha sido más alta que la otra, y pararíamos aquí. La población a la que podríamos querer generalizar los resultados podríais ser vosotros, pero para “siempre que hicierais” tests calculísticos y de conceptos. O podrían ser las personas matriculadas en alguna asignatura de primer curso del grado de Medicina de España en este curso académico, que es una población bien definida. O podría ser la población virtual de “estudiantes de primer curso de Medicina”, pasados, presentes y futuros y con una noción imprecisa de lo que entendemos por “estudiante de primer curso”. Hasta ahora hemos hablado de la población, a menudo virtual, sobre la que queremos obtener información. Está será nuestra población objetivo, que hay que distinguir de la muestra: Población objetivo: un conjunto de sujetos con una o varias características sobre las que deseamos obtener información. Muestra: el grupo de unidades de observación en las que medimos las características de interés. Normalmente, la muestra es un subconjunto de la población objetivo, pero ya hemos visto en la sección anterior que esto no siempre es así: pensad en los estudios ecológicos. Ejemplo 3.2 Una serie de 10 lanzamientos de una moneda equilibrada concreta es una muestra de la población de “los posibles lanzamientos de monedas equilibradas”. Ejemplo 3.3 ¿Y vosotros qué sois: una población o una muestra? Pues depende: Sois una población cuando lo que nos interesa es saber algo sobre vosotros y solo sobre vosotros. Sois una muestra si a partir de información sobre vosotros queremos inferir información sobre un grupo más grande de sujetos: Sobre los estudiantes de primer curso de Medicina en España Sobre los estudiantes de la UIB de este curso Sobre los jóvenes europeos Sobre los mamíferos bípedos Sobre … Procurad tener siempre presente que, por mucho cuidado que pongamos en obtener una muestra de una población, nunca será nada más que una aproximación imperfecta de ella. Si podemos medir todos los individuos de la población objetivo, no nos hace falta usar estadística inferencial para intentar adivinar lo que queremos saber sobre la población: lo medimos sobre todo el mundo y ya está. Pero lo más normal es que no podamos medir todos los individuos de la población. La población puede ser demasiado grande. Por ejemplo, si queremos calcular la altura media de los europeos que hoy tienen 18 años, es prácticamente imposible medirlos todos. Como ya hemos comentado, la población puede ser virtual en el sentido de que puede contener miembros que en este momento ni existan, o que no podamos saber si pertenecen o no a dicha población. Puede ser que para obtener la información de un sujeto lo tengamos que sacrificar (por ejemplo, si la información solo se puede recoger con una autopsia). En este caso, para medir toda la población la tendríamos que exterminar. Puede ser simplemente que sea difícil acceder a toda la población: por ejemplo, los estudiantes de la UIB son relativamente pocos, unos 12000, pero sería complicado conseguir mediros a todos. A la hora de determinar la validez de un estudio, es muy importante comparar la población objetivo con la: Población muestreada: el conjunto de sujetos (unidades de observación) del que se extrae la muestra. Figura 3.2: Población objetivo, población muestrada y muestra. En la mayoría de las ocasiones, la población muestreada será un subconjunto de la población objetivo definido por una serie de restricciones, pero puede no serlo: pensad de nuevo en los estudios ecológicos, donde la población objetivo son individuos y la población muestreada son grupos de individuos. Ejemplo 3.4 Dad un vistazo al artículo “Risk factors for pulmonary tuberculosis in Russia: case-control study” (R. Coker et al, British Medical Journal 332 (2006), pp. 85-87). Su objetivo es “Determinar los factores de riesgo para la tuberculosis pulmonar en Rusia”. Por lo tanto: La población objetivo es “toda la población de Rusia”, sea lo que sea lo que signifique esto. Ahora bien, la muestra se tomó solo entre los adultos de la ciudad de Samara y durante 2003. Por lo tanto: La población muestreada fueron los adultos que vivían en Samara en 2003. Finalmente, leemos que los casos fueron todos los adultos de esta ciudad diagnosticados de tuberculosis pulmonar a los que se administró un DOTS (Tratamiento Acortado Directamente Observado), en total 334. Como controles se tomó al azar el mismo número de personas entre la población adulta de la ciudad sin historial de tuberculosis. La muestra fueron estas 668 personas. Ejemplo 3.5 Para conocer la opinión de sus lectores sobre la familia real española, una conocida revista del corazón propuso una encuesta en línea en su web y analizó las respuestas. En este estudio transversal: La población objetivo es la formada por “los lectores de esta revista”. La población muestreada es la formada por los lectores de esta revista con acceso a Internet el año en que se realizó la encuesta. La muestra es el grupo de personas concretas que voluntariamente respondieron la encuesta. En el Ejemplo 3.4, puede que la población muestreada no fuera representativa de toda Rusia. Los habitantes de Samara, una de las ciudades más pobladas de Rusia, a unos 1500 km al sudeste de Moscú, ¿son representativos de los habitantes de una aldea perdida en mitad de la nada siberiana? Pues no lo sabemos, pero creemos que no. Además, la muestra de casos tampoco representa el colectivo de tuberculosos de Samara, puesto que solo se reclutaron los que reunían las condiciones para un tratamiento concreto (no se suele incluir los tuberculosos con frotis bucal negativo en programas DOTS). En el Ejemplo 3.5 está más claro que la población muestreada no es representativa de la población objetivo: seguramente excluye, por ejemplo, los lectores ancianos o los de zonas rurales con acceso difícil a Internet. Además, la muestra es aún más restrictiva, ya que los participantes fueron voluntarios, y sus características pueden ser diferentes de las de los lectores que prefirieron no opinar sobre este tema (nunca se sabe si el CNI vigila…) o de los lectores que nunca responden encuestas. Si la población muestreada no es representativa de la población objetivo, los resultados del estudio no tienen por qué poderse generalizar a esta última: diremos entonces que se ha dado un sesgo de falta de representatividad. Hablaremos sobre sesgos en la Sección 3.4. Ejemplo 3.6 Al escogeros a vosotros como una muestra de la población de estudiantes de primer curso de Medicina, podríamos entender como población muestreada, por ejemplo, la de “los estudiantes que este año académico cursan alguna asignatura de primer curso de Medicina en una universidad española”. Pero seguramente esta población difiera en algunos aspectos de los estudiantes de primer curso de Medicina de hace unos años, antes de la pandemia. Un estudio médico toma información sobre una muestra de individuos y la generaliza a una población objetivo. Si nos ha interesado leerlo, seguramente será porque su población objetivo contiene, o al menos está relacionada con, la población que nos interesa a nosotros. Pero la muestra habrá sido tomada de una población muestreada que no tiene por qué coincidir con nuestra población de interés. Es muy importante poder decidir entonces si las conclusiones a las que se llega en el estudio se pueden aplicar o no a nuestra población. No es el objetivo de este curso el que podáis tomar esta decisión, ya que la respuesta no va de estadística sino de la experiencia médica que aún os falta. Pero sí que al menos seáis conscientes de que un resultado estimado para una población puede no ser extrapolable a otra población. Ejemplo 3.7 En el estudio “D-dimer as a biomarker for disease severity and mortality in COVID-19 patients: a case control study”(Y. Yao et al, Journal of Intensive Care 8:49 (2020)) se compararon diversas características clínicas, analíticas y radiológicas entre los pacientes que fallecieron (17 en total) y los que no fallecieron (231) en un grupo de enfermos de COVID-19 tratados en el hospital Renmin de la Universidad de Wuhan. Su objetivo era determinar qué características aumentaban el riesgo de defunción entre los enfermos de COVID-19. Se encontró una asociación estadísticamente significativa entre tener un nivel de dímero D en sangre muy alto, superior a 2 mg/l, y un aumento en la letalidad de la COVID-19. Querríamos decidir si esta asociación también es válida para nuestros pacientes. ¿Cuál es el problema? Pues que la población objetivo del estudio es la de todos los enfermos de COVID-19, pero según el artículo la población muestreada fue la de “pacientes con al menos dos síntomas de COVID-19 y PCR positiva tratados en ese hospital concreto de Wuhan”. Así que de entrada, los infectados con un solo síntoma quedan excluidos, por muy grave que sea ese síntoma. Además, habría que valorar si la población asignada a ese hospital se parece o no a la balear. Por ejemplo, la tasa de letalidad de la COVID-19 entre el grupo de pacientes examinados fue del 6.85%, mientras que en las Baleares en esa misma época era de alrededor del 2.4%, aunque este dato refiere al total de infectados, incluyendo los asintomáticos. También habría que tener en cuenta las posibles diferencias en los niveles “normales” de dímero D en sangre entre las personas de origen asiático y las de origen mediterráneo. Y habría que valorar si la asociación observada se debe a algún confundidor. Por ejemplo, la edad media de los sujetos de la muestra con niveles elevados de dímero D era más alta que la de los que tenían un nivel normal, y la COVID-19 es más letal entre los ancianos. ¿Será la edad un factor de confusión en este estudio? En el artículo “Tuberculosis treatment survival of HIV positive TB patients on directly observed treatment short-course in Southern Ethiopia: A retrospective cohort study” (D. Shaweno, BMC Research Notes 5:682 (2012)) se quiso estudiar si la infección por VIH afecta la supervivencia a corto plazo de pacientes con tuberculosis (TB). Para ello, se consideraron todos los pacientes que habían participado en un estudio previo: se trataba de pacientes diagnosticados de TB durante el periodo 2006-2010 a los que se prescribió un tratamiento concreto de quimioterapia de 8 meses de duración y que además pasaron un test de VIH en el momento del diagnóstico positivo de TB. De este grupo de pacientes, se escogieron al azar un subgrupo de 370 VIH-positivos y otro de 370 VIH-negativos, y se anotó el número de pacientes de cada subgrupo que fallecieron antes de finalizar el tratamiento de 8 meses. La conclusión fue que la tasa de mortalidad entre los paciente de TB VIH-positivos es mayor que entre los que son VIH-negativos. (a) ¿De qué tipo de estudio se trata? (b) ¿Cuáles son la población objetivo, la población muestreada y la muestra? (c) ¿Creéis que la población muestreada es representativa de la población objetivo? 3.3 Tipos básicos de muestreo En un estudio estadístico inferencial, se toma una muestra de individuos de una población y se estiman algunas características de la población a partir de las de la muestra. Para que esto tenga sentido, es necesario que la muestra sea razonablemente representativa de la población. Pero, claro, sin conocer las características de la población, no podemos saber si una muestra es representativa o no. Para salir de este impasse, la solución comúnmente aceptada es tomar una muestra aleatoria, es decir, escogiendo sus sujetos de alguna manera al azar. Al hacerlo así: Se evitan preferencias en la elección, por lo que es más probable que la muestra sea representativa de la población. Naturalmente, esto no está garantizado: por pura mala suerte nos puede salir una muestra súper rara, es lo que tiene el azar. Pero al menos hemos hecho “lo que todo el mundo considera que es lo que hay que hacer” para intentar que sea representativa. Figura 3.3: ¿Estás seguro de que la muestra es aleatoria? (http://dilbert.com/strip/2001-10-25) Se pueden usar técnicas estadísticas que permiten acotar errores en la estimación y su probabilidad; por ejemplo, podremos calcular la probabilidad de que nuestra muestra sea súper rara en algún sentido concreto. Ejemplo 3.8 Para probar el guiso, antes de tomar una cucharada lo removemos bien. De este modo esperamos que las moléculas del caldo se organicen de manera aleatoria dentro de la olla y que la cucharada que tomemos sea representativa del guiso. Existen muchos métodos de muestreo. A continuación describimos algunos de forma breve. 3.3.1 Muestreo aleatorio con y sin reposición El muestreo aleatorio consiste en seleccionar una muestra de la población de manera que todas las muestras del mismo tamaño sean equiprobables; es decir, que si fijamos el número de individuos de la muestra, cualquier conjunto de ese número de individuos tenga la misma probabilidad de ser seleccionado. Hay que distinguir entre dos tipos de muestreo aleatorio: con y sin reposición, según permitamos o no que se repitan sujetos en la muestra. Para ilustrarlos, supongamos que disponemos de una urna con 100 bolas numeradas del 1 al 100, de la que queremos extraer una muestra de 15 bolas. La Figura 3.4 representa dicha urna. Figura 3.4: Una urna de 100 bolas. Una manera de hacerlo sería repetir 15 veces el proceso de sacar una bola de la urna, anotar su número y devolverla a la urna. El tipo de muestra obtenida de esta manera recibe el nombre de muestra aleatoria con reposición, o muestra aleatoria simple. Observad que con este procedimiento una misma bola puede aparecer varias veces en una muestra, y que todos los subconjuntos de 15 bolas “con posibles repeticiones” tienen la misma probabilidad de obtenerse. Un posible resultado serían las bolas azules de la Figura 3.5; la bola azul más oscuro ha sido escogida dos veces en la muestra. Figura 3.5: Una muestra aleatoria simple. Otra manera de extraer la muestra sería repetir 15 veces el proceso de sacar una bola de la urna pero ahora sin devolverla. Esto es equivalente a extraer de golpe 15 bolas de la urna. Estas muestras no tienen bolas repetidas, y cualquier selección de 15 bolas diferentes tiene la misma probabilidad de ser la obtenida. En este caso se habla de una muestra aleatoria sin reposición. Un posible resultado serían las bolas azules de la Figura 3.6. Figura 3.6: Una muestra aleatoria sin reposición. Cuando el tamaño de la población es muy grande en relación al de la muestra, como suele suceder en medicina, la probabilidad de que haya repeticiones en una muestra aleatoria simple es muy pequeña. Por ejemplo: Si escogemos 100 individuos de las Baleares (que tiene alrededor de 1,150,000 habitantes) al azar permitiendo repeticiones, la probabilidad de que se escoja más de una vez algún individuo es de 0.004: de media, solo en 1 de cada 250 muestras de 100 individuos de las Baleares elegidos al azar permitiendo repeticiones nos saldría alguien repetido. Si escogemos 100 estudiantes de la UIB (que tiene alrededor de 12000 estudiantes) al azar permitiendo repeticiones, la probabilidad de que se escoja más de una vez algún individuo es de 0.339: de media, en algo más de 1 de cada 3 muestras de 100 estudiantes de la UIB elegidos al azar permitiendo repeticiones habría alguien repetido. En cambio, si escogemos 10 estudiantes de la UIB al azar permitiendo repeticiones, la probabilidad de que se escoja más de una vez algún individuo ya es de 0.004. Ya daremos el detalle de cómo se calculan todas estas probabilidades en el tema siguiente. Esto nos permite considerar que, cuando la población es mucho más grande que la muestra, los muestreos aleatorios con y sin reposición son equivalentes en el sentido siguiente: puesto que si la población es muy, muy grande, una muestra aleatoria con reposición tendría casi seguro todos los elementos diferentes, podemos tomar directamente la muestra sin reposición y aceptar que permitíamos repeticiones, pero que no se han dado y que por tanto la muestra es simple. Una muestra aleatoria de 100 individuos diferentes de las Baleares, o de 10 estudiantes diferentes de la UIB, puede pasar perfectamente por una muestra aleatoria simple, porque aunque permitiéramos repeticiones, sería muy raro que las hubiera. Pero en cambio ya es difícil de creer que una muestra aleatoria de 100 estudiantes diferentes de la UIB haya sido tomada permitiendo repeticiones, porque de media en una de cada tres muestras tomadas permitiendo repeticiones nos saldría alguna repetición. El muestreo aleatorio simple es el estándard de excelencia entre los métodos de muestreo, y la mayoría de los resultados que explicaremos en este curso presuponen que la muestra ha sido tomada aleatoria con reposición. Pero casi nunca es factible hacerlo. El motivo es que para poder tomar una muestra aleatoria de una población en el sentido de este apartado, con o sin reposición, es necesario disponer de una lista completa de todos sus individuos para poder sortear a quién vamos a seleccionar. Esto no siempre es posible. ¿Alguien tiene la lista completa de, pongamos, todos los diabéticos de España? ¿Que incluya los que no saben que lo son? Por lo tanto, en la vida real no siempre podemos tomar muestras aleatorias en este sentido. Muestras aleatorias con R Cualquier paquete estadístico que se precie permite obtener muestras aleatorias de conjuntos. Con R, la función básica es sample(x, n, replace=...) donde: x es un vector que contiene toda la población o un número natural \\(x\\); en este último caso, R entiende que representa el vector 1,2,…,\\(x\\); n es el tamaño de la muestra que deseamos extraer; el parámetro replace puede igualarse a TRUE, y será una muestra aleatoria con reposición, es decir, simple, o a FALSE, y será una muestra aleatoria sin reposición. Si no se especifica este parámetro, R entiende que ha de tomar la muestra sin reposición. Podéis ejecutar las funciones de R que iremos dando en estas notas en la ventana del editor de R de JAMOVI. Para tener acceso a ella, tenéis que instalar el módulo Rj (pulsando en el signo + de la esquina superior derecha de la ventana de JAMOVI y navegando entre las diferentes opciones). Figura 3.7: La ventana de edición de R Así, por ejemplo, para obtener una muestra aleatoria simple de 15 números elegidos entre 1 y 100, podemos entrar:2 sample(100,15,replace=TRUE) ## [1] 100 51 78 55 75 68 6 63 78 92 14 7 93 55 86 Naturalmente, cada ejecución de sample con los mismos parámetros puede dar (y seguramente dé) lugar a muestras diferentes, y todas ellas tienen la misma probabilidad de aparecer. Aquí tenéis tres ejecuciones consecutivas de la instrucción anterior en la ventana del editor de R de JAMOVI: Ejemplo 3.9 En el marco de un estudio experimental, tenemos que asignar al azar 60 pacientes a dos tratamientos, de manera que cada paciente tenga un 50% de probabilidades de caer en uno u otro grupo de tratamiento tratamiento. Si indicamos los dos tratamientos por 1 y 2 (por ejemplo, que 1 sea el tratamiento control y 2 el tratamiento nuevo), podemos numerar los sujetos de 1 a 60 y a continuación tomar una muestra aleatoria simple de tamaño 60 de valores 1 o 2 y a cada sujeto asignarle el tratamiento que le corresponda en esta muestra. Para ello, ejecutamos sample(2,60,replace=TRUE) ## [1] 1 1 1 2 1 2 2 1 1 2 1 2 2 2 1 1 2 1 1 2 1 2 2 2 1 2 1 2 2 2 1 2 1 1 2 1 1 1 ## [39] 1 2 1 2 1 1 2 2 1 1 2 1 2 1 2 2 2 1 2 1 2 2 De esta manera se asignarían 31 pacientes al tratamiento 1 y 29 al tratamiento 2: los tres primeros al tratamiento 1, el cuarto al tratamiento 2, el quinto al tratamiento 1 etc. Si hubiéramos querido forzar que cada grupo de tratamiento tuviera 30 pacientes, hubiéramos podido tomar una muestra aleatoria sin reposición de tamaño 30 de los 60 pacientes, asignar a sus miembros uno de los tratamientos y al resto el otro tratamiento. Así, podríamos asignar el tratamiento 1 a los pacientes sort(sample(60,30,replace=FALSE)) ## [1] 2 5 6 11 12 15 16 17 18 23 24 25 26 29 31 33 40 41 42 44 46 47 50 51 53 ## [26] 55 57 58 59 60 (La función sort, como su nombre en inglés indica, sirve para ordenar vectores.) 3.3.2 Muestreo sistemático Una manera muy sencilla de obtener una muestra de una población cuando disponemos de una lista ordenada de sus individuos y nos da pereza efectuar un sorteo es tomarlos a intervalos constantes: uno de cada cinco individuos, uno de cada diez… Podemos añadir un componente aleatorio escogiendo al azar el primer individuo que elegimos, y a partir del cual empezamos a contar. A esta técnica se la llama muestreo sistemático o a intervalos, añadiendo el adjetivo aleatorio si además el primer sujeto se escoge de manera aleatoria. Así, por ejemplo, si de una clase de 100 estudiantes quisiéramos escoger una muestra de 10, podríamos elegir un estudiante al azar, y a partir de él, por orden alfabético, elegir el décimo estudiante, el vigésimo, el trigésimo, etc.; si al llegar al final de la lista de clase no hubiéramos completado la muestra, volveríamos al principio de la misma. La Figura 3.8 describe una muestra aleatoria sistemática de 15 bolas de nuestra urna de 100 bolas: hemos empezado a escoger por la bola roja oscura, que ha sido elegida al azar, y a partir de ella hemos tomado las bolas a intervalos de 7, volviendo al principio cuando hemos llegado al final de la lista numerada. Figura 3.8: Una muestra aleatoria sistemática. Cuando no disponemos de una lista de toda la población pero sí que tenemos una manera de acceder de manera ordenada a sujetos de la misma (por ejemplo, enfermos que acuden a un hospital), podemos realizar un muestreo sistemático tomando los sujetos a intervalos constantes a medida que los encontramos y hasta completar el tamaño deseado de la muestra. Por ejemplo, para escoger una muestra de 10 pacientes que hayan acudido a Urgencias por traumatismos en la cabeza, podríamos escoger pacientes a intervalos regulares de entre los que acudieran a Urgencias por este motivo hasta llegar a los 10. Si la lista de la población está ordenada al azar y la población es muy grande (tanto que con el muestreo sistemático no llegamos al final de la lista para tener que volver a empezar), o si los sujetos que vamos tomando a intervalos regulares nos aparecen al azar, el resultado del muestreo sistemático es equivalente a una muestra aleatoria sin reposición. 3.3.3 Muestreo aleatorio estratificado Este método de muestreo se utiliza cuando la población está clasificada en estratos que son de interés para la característica que se estudia. Estos estratos serán grupos de individuos definidos por un atributo concreto, de manera que individuos del mismo estrato tengan ese atributo igual (los estratos sean homogéneos internamente) y individuos de estratos diferentes tengan ese atributo diferente. Por ejemplo, la clasificación en estratos puede venir dada por los sexos, franjas de edad, provincias, casos y controles… En este caso, se toma una muestra de un tamaño prefijado de cada estrato y se unen en una muestra global. Este proceso es llamado muestreo estratificado, aleatorio si la muestra de cada estrato es aleatoria (en el sentido de la Sección 3.3.1). Por lo que refiere a los tamaños de las muestras de cada estrato, se suele optar por una de las estrategias siguientes: Imponer que la composición por estratos de la muestra global mantenga las proporciones de la población original, de manera que el tamaño de la muestra de cada estrato represente el mismo porcentaje del total de la muestra que el estrato correspondiente en la población completa. Tomar las muestras de los diferentes estratos del mismo tamaño. Tomar los tamaños de manera que los estratos que representen una fracción muy pequeña de la población (tan pequeña que no esperaríamos que tuvieran representación en una muestra aleatoria transversal de la población, es decir, tomada del total de la población sin tener en cuenta su composición en estratos) tengan una representación en la muestra mucho mayor que la que les tocaría. Figura 3.9: Muestra transversal versus estratificada Por ejemplo, los estratos podrían ser grupos de edad y podríamos tomar la muestra de cada grupo de edad de tamaño proporcional a la fracción que representa dicho grupo de edad en la población total. O podrían ser los sexos y procuraríamos que nuestra muestra estuviera formada por un 50% de hombres y un 50% de mujeres. O, en las Islas Baleares, los estratos podrían ser las islas, y entonces podríamos imponer que el número de representantes de cada isla en la muestra fuera proporcional a su población relativa dentro del conjunto total de la Comunidad Autónoma, o podríamos tomar la misma cantidad de individuos de cada isla, independientemente de su población. Cuando en un estudio de casos y controles escogemos un grupo de casos y uno de controles de tamaños prefijados, o cuando en un estudio de cohorte escogemos un grupo de expuestos y uno de no expuestos de tamaños prefijados, se trata de una muestra estratificada. Para continuar con nuestra urna de 100 bolas, supongamos que contiene 40 bolas de un color y 60 de otro color según muestra la Figura 3.10. Figura 3.10: Nuestra urna ahora tiene dos estratos. Para tomar una muestra aleatoria estratificada de 15 bolas, considerando como estratos los dos colores e imponiendo que la muestra refleje la composición de la urna, tomaríamos una muestra aleatoria de 6 bolas del primer color y una muestra aleatoria de 9 bolas del segundo color. De esta manera, los porcentajes de colores en la muestra serían los mismos que en la urna. La Figura 3.11 describe una muestra obtenida de esta manera. Figura 3.11: Una muestra aleatoria estratificada. Para tomar una muestra aleatoria estratificada de 10 bolas, de nuevo considerando como estratos los dos colores pero ahora imponiendo que cada color aporte la misma cantidad de bolas a la muestra, tomaríamos una muestra aleatoria de 5 bolas del primer color y una muestra aleatoria de 5 bolas del segundo color. La Figura 3.12 describe una muestra obtenida de esta manera. Figura 3.12: Otra muestra aleatoria estratificada. La ventaja del muestreo aleatorio estratificado respecto del transversal es que, como el investigador escoge una muestra de cada estrato de la población del tamaño que considera adecuado: Permite estimar la información de interés para cada estrato por separado, como si se tratara de estudios independientes. Permite estimar la información sobre subpoblaciones minoritarias que en una muestra aleatoria transversal aparecerían subrepresentadas. En todo caso, el muestreo por estratos solo es necesario si esperamos que las características que queremos estudiar varíen según el estrato. Por ejemplo, si queremos tomar una muestra para estimar la altura media de los españoles adultos y no creemos que la altura de un español adulto dependa de su provincia de origen, no hay ninguna necesidad de esforzarse en tomar una muestra de cada provincia de manera que todas estén representadas adecuadamente en la muestra. Observad que el muestreo aleatorio por estratos tiene el mismo inconveniente que el muestreo aleatorio de la Sección 3.3.1: es necesario disponer de una lista completa de los individuos de cada estrato para poder sortearlos. Tenemos una población clasificada en dos estratos, A y B. La subpoblación A representa un 20% de la población y la B el 80% restante. Hemos tomado una muestra aleatoria estratificada formada por 100 sujetos de cada subpoblación. Hemos medido una cierta característica X de estos sujetos. La media de los valores de X de los sujetos A ha dado 5 y la media de los valores de X de los sujetos B ha dado 10. (a) ¿Qué vale la media de los valores de X de toda la muestra de 200 sujetos? (b) A partir de estos datos, ¿qué estimáis que vale la media de X en el total de la población? 3.3.4 Muestreo por conglomerados El proceso de obtener una muestra aleatoria en el sentido de las secciones anteriores puede ser caro o difícil en algunos casos, incluso aunque dispongamos de la lista completa de la población. Imaginad que quisiéramos estudiar la prevalencia y gravedad de la miopía entre los estudiantes de Primaria de las Baleares. Para ello tendríamos que seleccionar una muestra representativa de esta población de escolares. Seguramente, con algo de esfuerzo, podríamos disponer de su lista completa para este curso y por lo tanto podríamos tomar una muestra aleatoria, pero entonces acceder a las niñas y niños que la formasen seguramente significaría visitar muchos centros de primaria para entrevistar unos pocos alumnos de cada uno. Esto volvería el proceso lento y costoso. Y eso si consiguiéramos la lista global de alumnos. Una alternativa posible sería, en vez de elegir una muestra aleatoria de todos los estudiantes de Primaria, escoger primero al azar unas pocas aulas de primaria de colegios de las Baleares, a las que llamamos en este contexto conglomerados o clústers, y formar entonces nuestra muestra con todos los alumnos de estas aulas. Estaréis de acuerdo en que es mucho más fácil disponer de la lista completa de estudiantes de unas pocas aulas que conseguir la lista completa de todos los estudiantes de la Comunidad, y mucho más cómodo ir a unos pocos colegios a entrevistar grupos enteros que ir a muchos colegios a entrevistar a unos pocos estudiantes de cada uno. En un muestreo aleatorio por conglomerados o clústers, tenemos la población repartida en pequeños grupos, los clústers, y lo que hacemos es elegir al azar una muestra de clústers y tomar todos los individuos de los clústers elegidos. Volviendo de nuevo a nuestra urna, supongamos que sus 100 bolas se agrupan en 20 conglomerados de 5 bolas cada uno según las franjas verticales de la Figura 3.13 (donde mantenemos la clasificación en dos colores para poder comparar el resultado del muestreo por conglomerados con el estratificado). Figura 3.13: Nuestra urna ahora tiene 2 estratos y 20 clústers. Para obtener una muestra aleatoria por conglomerados de tamaño 15, escogeríamos al azar 3 conglomerados y la muestra estaría formada por todas sus bolas. La Figura 3.14 describe una muestra obtenida de esta manera: los conglomerados escogidos están marcados en azul. Figura 3.14: Una muestra aleatoria por conglomerados. A menudo una vez elegidos los clústers no se toman todos los sujetos de los mismos, sino una muestra aleatoria de cada uno. Esto ya sería un ejemplo de muestreo polietápico (Sección 3.3.6). El muestreo por conglomerados se suele elegir por ser rápido de realizar, pero puede tener un inconveniente: puede que los sujetos de cada clúster tiendan a parecerse los unos a los otros, lo que puede sesgar la muestra. Este método de muestreo es más efectivo cuando los clústers sean heterogéneos en este sentido. En nuestro ejemplo de los niños de primaria de las Baleares, es más creíble que las clases sean heterogéneas por lo que refiere a la miopía que en lo referente a comportamientos en los que influya la pertenencia a un grupo social, por ejemplo la series de TV preferidas. Revisemos la diferencia entre el muestreo estratificado y el muestreo por conglomerados: Muestreo estratificado: Los estratos forman una clasificación de los sujetos de la población en grupos grandes definidos por una propiedad que consideramos relevante en el estudio estadístico. Por ejemplo, el sexo o la franja de edad. Se escoge una muestra de cada estrato. Muestreo por conglomerados: Los conglomerados forman una clasificación de los sujetos de la población en grupos pequeños definidos por una propiedad que en principio es irrelevante en el estudio estadístico. Por ejemplo, la manzana donde viven o el médico de familia al que están asignados. Se escogen algunos conglomerados y se forma la muestra con todos sus miembros. 3.3.5 Muestreos no aleatorios Cuando la selección de la muestra no es aleatoria, se habla de muestreo no aleatorio. En realidad es el tipo más frecuente de muestreo porque casi siempre nos tenemos que conformar con los sujetos disponibles. Por ejemplo, en la UIB, para estimar la opinión que de un profesor tienen los alumnos de una clase, solo se tiene en cuenta las respuestas de los estudiantes que voluntariamente rellenan la encuesta de opinión, que de ninguna manera forman una muestra aleatoria: el perfil del estudiante que responde voluntariamente una encuesta de este tipo es muy específico y no viene determinado por el azar. En este caso se trataría de una muestra auto-seleccionada. Otro tipo de muestras no aleatorias son las oportunistas. Este es el caso, por ejemplo, si para estimar la opinión que de un profesor tienen los alumnos de una asignatura se visita un día la clase y se pasa la encuesta a los estudiantes presentes ese día. De nuevo, puede que esos alumnos no sean representativos del alumnado de la asignatura (pueden ser los más aplicados, o los menos enfermizos, o los no repetidores). La Figura 3.15 describe una muestra oportunista de nuestra urna: sus 15 primeras bolas. Figura 3.15: Una muestra oportunista. Las técnicas de estadística inferencial no se pueden aplicar a muestras no aleatorias. Pero normalmente solo podemos conseguir muestras no aleatorias. En este caso, lo mejor es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, podría pasar por aleatoria y es razonablemente representativa de la población. Por ejemplo, la muestra oportunista anterior de nuestra urna no es de ninguna manera representativa de su contenido por lo que refiere al color de las bolas. Para conocer la opinión de los estudiantes de Medicina españoles sobre un tema concreto, os la pido a vosotros. ¿Qué tipo de muestreo he realizado de los explicados hasta ahora? 3.3.6 Muestreo polietápico En el ejemplo de los estudiantes de Primaria, la muestra final de estudiantes estaba formada por todos los de las aulas elegidas. Otra opción podría haber sido, tras seleccionar la muestra aleatoria de aulas, entrevistar solo una muestra aleatoria de estudiantes de cada una (si por ejemplo nuestro presupuesto no da para procesar las entrevistas a todos los estudiantes de las aulas elegidas). Otro ejemplo: algunos estudios poblacionales a nivel estatal se realizan solamente en algunas provincias escogidas aleatoriamente, en las que luego se encuesta una muestra aleatoria de habitantes. Los dos son ejemplos de muestreos polietápicos, en los que la muestra no se obtiene en un solo paso, sino mediante diversas elecciones sucesivas. La Figura 3.16 muestra un ejemplo sencillo de muestreo polietápico de nuestra urna: hemos elegido al azar 5 conglomerados (marcados en azul) y de cada uno de ellos hemos elegido 3 bolas al azar sin reposición. Figura 3.16: Una muestra polietápica. Veamos algunos ejemplos más. Recordad el estudio CORSAIB del Ejemplo 2.17. Vamos a detallar algo más el proceso mediante el cual se eligieron los participantes: Se dividieron las Baleares en 14 sectores geográficos. Se ofreció la participación a los médicos de familia para conseguir que colaborasen 3-4 médicos por sector, hasta llegar a los 50 médicos. De la población adscrita a cada médico participante se obtuvo una muestra aleatoria de 40 individuos. Como veis, el muestreo tuvo dos etapas. En la primera se seleccionaron clústers mediante un muestreo no aleatorio estratificado: los estratos fueron los 14 sectores geográficos, los clústers elegidos estaban formados por los grupos de pacientes adscritos a los médicos de familia que voluntariamente participaron en el estudio. La segunda etapa fue un muestreo aleatorio sin reposición dentro de cada clúster. Veamos otro ejemplo más complicado. En el estudio “Factors associated with risk of low folate intake among adolescents” (M. Vitolo et al, Jornal de Pediatria 82 (2006), pp. 121–126) los investigadores tenían que tomar una muestra de adolescentes de San Leopoldo (Brasil). Para ello: En primer lugar, escogieron mediante un muestreo aleatorio sistemático varias secciones censales de las 40 que tiene la ciudad. A continuación, escogieron al azar varias manzanas de cada una de estas secciones censales y una esquina de cada manzana. Luego, eligieron direcciones de cada manzana de manera sistemática: una de cada tres en sentido horario a partir de la esquina seleccionada. Finalmente, se invitó a participar en el estudio a todos los habitantes de 10 a 19 años en las casas o fincas seleccionadas. El total eligible de adolescentes fueron 810, de los que aceptaron participar 722. En este proceso, se realizaron: un muestreo aleatorio sistemático (las secciones censales), dos muestreos aleatorios sin reposición (las manzanas y las esquinas), otro muestreo sistemático (las direcciones) y un muestreo no aleatorio (los voluntarios). Un último ejemplo. Recordad el estudio sobre enfermedades y mes de nacimiento del Ejemplo 2.18, donde “se escogió al azar una muestra de 29,478 españoles”. En realidad, no se tomó una lista de toda la población española a 1 de enero de 2017 y se escogió al azar de manera equiprobable una conjunto de 29,478 personas, sino que se usó la muestra de la Encuesta Nacional de Salud de ese año, que se elige de la manera polietápica siguiente (podéis consultar aquí la metodología en detalle): Se clasifican los municipios españoles en 7 tipos según su población. En cada comunidad autónoma y para cada tipo de municipios, se toma una muestra aleatoria de un número de secciones censales del global de esos municipios proporcional a su población. De cada sección censal elegida, se escogen un número fijo de primeras residencias (en 2017 fueron 15) por muestreo aleatorio sistemático (y previa una ordenación específica de las viviendas según su tamaño). En cada vivienda se escoge equiprobablemente un individuo adulto. Fijaos que, en (2), se toma una muestra aleatoria estratificada de secciones censales: los estratos son las combinaciones de comunidad autónoma y tipo de municipio. Existen otros tipos de muestreo, solo hemos explicado los más comunes. En cualquier caso, lo importante es recordar que el estudio estadístico que se realice tiene que adaptarse al tipo de muestreo usado. Por ejemplo, no se pueden usar las mismas técnicas para analizar una muestra aleatoria simple que una muestra estratificada o una muestra por conglomerados. En este curso nos ocuparemos casi exclusivamente del muestreo aleatorio simple, es decir, al azar y con reposición, o al azar sin reposición si la población es muy grande comparada con la muestra. Deseamos llevar a cabo un estudio para determinar si un diabético tipo 2 en las Baleares tiene una mayor probabilidad de infectarse de COVID-19 que una persona sin esa patología. Además, queremos poder comparar las probabilidades entre los diabéticos de Mallorca, de Menorca y de Ibiza. Hemos calculado que para que las conclusiones sean fiables, necesitamos analizar 50 diabéticos tipo 2 de cada isla. Explicad en detalle cómo obtendríais la muestra de diabéticos; el procedimiento ha de ser fácil de llevar a cabo y ha de dar muestras razonablemente representativas de las poblaciones de diabéticos. 3.4 Sesgos Un sesgo es cualquier tipo de error sistemático en el diseño o la ejecución de un estudio que afecte a los datos recogidos y perjudique la corrección de las conclusiones obtenidas. Ejemplo 3.10 Si en un estudio transversal sobre hipertensión usamos un esfigmomanómetro que sistemáticamente mide una presión arterial más alta que la real, se produce un sesgo que hará que se detecte una prevalencia mayor de hipertensos que la real. Los errores que pueden dar lugar a sesgos no se han de confundir con el error aleatorio inherente a las mediciones. Por ejemplo, no son sesgos los errores de medición debidos a la imprecisión del esfigmomanómetro, que mide la tensión redondeando a mm Hg, o a la variación natural de la presión arterial en un individuo a lo largo del día. La estadística nos proporciona herramientas para tratar el error aleatorio, pero las fuentes de sesgo se han de eliminar al diseñar el estudio o detectarlas al leer un estudio para valorar la validez de sus conclusiones. Un sesgo es un error sistemático que afecta las conclusiones. Si no las afecta, no hay sesgo. Por ejemplo, supongamos que tenemos un esfigmomanómetro que sistemáticamente da un valor 2 mm Hg más alto que el real. Si lo usamos para comparar las tensiones medias de los estudiantes de Medicina y de los estudiantes de Informática, la conclusión va a ser la misma que si usamos un esfigmomanómetro bien calibrado. En efecto, el error de medida va a afectar los dos grupos por igual y al compararlos (por ejemplo, restándolos) se va a compensar. Muchos autores han producido listas larguísimas de tipos de sesgos que muestran la creatividad de los humanos a la hora de fastidiarla y de poner nombres a las diferentes maneras de fastidiarla. Aquí solo vamos a introducir algunos de los más comunes. En este url encontraréis una lista algo más larga, aunque tampoco es exhaustiva. Sesgo de selección: Se produce cuando la muestra seleccionada no es representativa de la población objetivo. Por poner un ejemplo exagerado, sería el caso si quisiéramos saber la incidencia del cáncer de ovario en una comunidad y para ello tomáramos una muestra de solo hombres. Hay varios subtipos que vale la pena distinguir: Sesgo de falta de representatividad: Cuando la muestra no es representativa debido a un defecto en su obtención. Por ejemplo, una muestra de hombres para estimar la incidencia del cáncer de ovario; o una muestra de voluntarios que se ofrezcan para que les hagan unas pruebas dolorosas a cambio de una compensación económica. Un ejemplo frecuente en medicina y con nombre propio (sesgo de Berkson) se produce cuando para estudiar la influencia de algunos factores de riesgo en una enfermedad, se toman como controles pacientes hospitalizados. Los pacientes hospitalizados tendrán unas patologías más severas que la población en general, y puede que ello se deba a que su exposición a factores de riesgo sea mayor que la de la población en general. Sesgo de selección diferencial: Cuando el sesgo de selección se da en unos grupos sí y en otros no, o cuando se da de manera diferente en los diferentes grupos. Siguiendo con el ejemplo de la influencia de algunos factores de riesgo en una enfermedad que en principio no conlleve hospitalización, se daría si tomáramos los casos entre enfermos hospitalizados (que no tienen por qué ser representativos del global de enfermos) y los controles entre individuos no hospitalizados. Sesgo de supervivencia: Cuando se toma una muestra de pacientes vivos de una enfermedad con una alta tasa de mortalidad. En este caso, es muy probable que la muestra incluya una proporción muy elevada de enfermos que hayan sobrevivido más de lo normal, y estos no tienen por qué ser representativos del colectivo de enfermos de esta enfermedad. A veces se usa el término sesgo de supervivencia para describir casos como el de la Fig. 3.17: cuando solo se consideran los sujetos que han tenido éxito en algún proceso con una tasa muy baja de éxitos (es el “a mí me ha funcionado” de los anuncios de remedios milagrosos e increíbles). Figura 3.17: “Sesgo de supervivencia” (https://xkcd.com/1827/ (CC-BI-NC 2.5)) Sesgo de medida: Se produce cuando el método de medición es defectuoso en algún sentido. Incluye, por ejemplo: Sesgo de recuerdo: En estudios en los que recojamos la información sobre exposición por medio de entrevistas o encuestas, existe la posibilidad de que algunos encuestados hayan olvidado información, o simplemente de que mientan en temas delicados. Sesgo de recuerdo diferencial: Es un caso particular del anterior, y se da cuando diferentes grupos de sujetos tienen diferente probabilidad de cometer errores en sus recuerdos (o de mentir). Por ejemplo, en estudios de casos y controles en los que se recoge la información sobre exposición por medio de entrevistas o encuestas, los casos tienen mayor tendencia a recordar su exposición a circunstancias que ellos asocien a la enfermedad que los controles. Sesgo de procedimiento: Cuando el clínico analiza de manera diferente un grupo que otro. Se daría, por ejemplo, en un ensayo clínico si se llevara a cabo un seguimiento más frecuente a los que toman un nuevo tratamiento que a los controles, por si presentan efectos secundarios inesperados. Sesgo de detección: Cuando se usan varios métodos con diferente sensibilidad para detectar una enfermedad o una exposición. Este sesgo también puede ser diferencial si los diferentes métodos se usan sobre grupos diferentes. A modo de ejemplo, se daría un sesgo de detección si para saber si los sujetos de una muestra han tomado un medicamento, a algunos se les pasa una encuesta y a otros se les consulta el historial clínico. Sería diferencial si, además, por ejemplo, los primeros fueran los participantes sanos y los segundos los enfermos. Sesgo de atención: Cuando los participantes en un estudio alteran su comportamiento porque se saben observados o porque participan en el estudio (a veces se lo denomina efecto Hawthorne). Se podría dar, por ejemplo, en un estudio sobre el efecto del ejercicio físico en la salud si los sujetos del grupo de intervención (a los que se ha asignado el hacer ejercicio físico) deciden tomar otros nuevos hábitos saludables porque saben que se les ha asignado al grupo “saludable”. Entonces puede que el efecto que se observe en este grupo no se deba al ejercicio físico sino al cambio en otros comportamientos. El “efecto Hawthorne” refiere al nombre de una fábrica en el que se realizó un estudio sobre qué condiciones aumentaban la productividad, y todos los grupos aumentaron su productividad durante el seguimiento. Este aumento se debió al efecto “motivador” de ser observados, porque cuando terminó el estudio volvieron todos a su productividad normal. Sesgo de error instrumental: Cuando los instrumentos usados para medir alguna característica son defectuosos. Sería el caso, por ejemplo, del esfigmomanómetro del primer párrafo de esta sección. Confusión. Se da cuando el efecto de la exposición a un riesgo A se confunde con el de la exposición a otro factor B (el confundidor) que está asociado a la exposición a A y que es el verdadero causante del desenlace X que estamos estudiando. Hemos explicado varios ejemplos de confundidores al hablar de los problemas de los estudios de casos y controles (Sección 2.4). Por ejemplo, la asociación entre que la madre sea fumadora y una disminución del riesgo de que el hijo tenga síndrome de Down, debida en realidad al factor de confusión dado por la edad de las madres (Ejemplo 2.9). Por poner otro ejemplo, si en un estudio se observa una asociación entre una patología durante el embarazo y un defecto en los recién nacidos, podría ser que la causa del desenlace no fuera la enfermedad de las madres sino el tratamiento que se les hubiera admninistrado relacionado con la misma. Hemos incluido la confusión en la lista de sesgos, pero su naturaleza es diferente de los anteriores. Un sesgo es un error sistemático en la recolección de datos, mientras que no tener en cuenta los posibles confundidores es un error que tanto se puede cometer al diseñar el estudio como al interpretar los resultados. Hay muchos otros tipos de sesgos. No es importante en este curso saber sus nombres, de hecho ni tan siquiera de los que hemos dado aquí. Lo importante es aplicar el sentido común al leer la Metodología de un estudio para entender qué procesos podrían haber desviado los datos recogidos y cómo estos sesgos afectan las conclusiones del estudio. Ejemplo 3.11 Volvamos al Ejemplo 3.5, en el que explicábamos el caso de una revista del corazón que, para conocer la opinión de sus lectores sobre la familia real española, propuso una encuesta en línea en su web. ¿Qué sesgos se pudieron dar? (1.a) ¿Sesgo de falta de representatividad? Sí, claro. Los voluntarios que rellenan encuestas en Internet no tienen por qué ser representativos del total de lectores de la revista. (1.b) ¿Sesgo de selección diferencial? No, porque no se eligieron dos grupos. (1.c) ¿Sesgo de supervivencia? No, se supone que les interesaba conocer la opinión de sus lectores vivos en ese momento, ¿verdad? (2.a) ¿Sesgo de recuerdo? Sí, claro, tenemos que tenerlo en cuenta siempre que se recoja información por medio de cuestionarios o entrevistas. Los participantes podrían haber querido dar una mejor opinión de la familia real española que la que realmente tienen para quedar bien o hacer quedar bien a la revista. (2.b) ¿Sesgo de recuerdo diferencial? De nuevo, no, porque no se eligieron dos grupos. (2.c,d) ¿Sesgo de procedimiento o de detección? No, por el mismo motivo (2.e) ¿Sesgo de atención? No, porque no se hizo un seguimiento a los participantes, por lo que si cambiaron su comportamiento, no afectó al resultado de la encuesta. (2.f) ¿Sesgo de error instrumental? Podría ser, si el cuestionario estuviera amañado en algún sentido. A lo mejor recordáis el famoso caso de la encuesta de satisfacción de Ryanair en 2017 en la que en la pregunta sobre el grado de satisfacción con su experiencia de vuelo con ellos, las únicas respuestas que se ofrecían eran “Excelente”, “Muy buena”, “Buena”, “Aceptable” y “OK”. No hace falta ser tan burdo a la hora de amañar un cuestionario. En una encuesta en el Reino Unido en el 2015, a la pregunta “¿Está usted de acuerdo en permitir a los jóvenes de 16 y 17 años votar en el referéndum del Bréxit?”, un 52% respondió que sí y un 41% que no. Hasta ahí bien. Pero en la misma encuesta, bastantes preguntas después, se les pedía “¿Está usted de acuerdo en reducir la edad de voto de los 18 años a los 16 en el referéndum del Bréxit?”, y a esa pregunta respondieron que sí el 37% y que no el 56%. Figura 3.18: ¿El País marcándose un Ryanair con Felipe VI? Gráfico publicado por El País el 30/08/2020; referencia: https://elpais.com/espana/2020-08-29/los-espanoles-rechazan-la-marcha-de-juan-carlos-i-a-emiratos-arabes.html (3) ¿Confusión? Dado que, por así decirlo, se trataba de un estudio transversal de prevalencia, sin intentar estimar relaciones de causa-efecto, no tiene sentido preguntarse por la existencia de confundidores. Otra cosa sería si se hubiera pretendido estudiar qué características hacen que se opine mejor o peor sobre la familia real española. Entonces sí que podrían entrar en juego confundidores. Para no meternos en berenjenales, no vamos a describirlos. En un famoso estudio publicado en 1981 sobre la asociación entre consumo de café y cáncer de páncreas, se tomó un grupo formado por todos los pacientes diagnosticados de cáncer de páncreas entre 1974 y 1979 en once hospitales. Luego, para cada uno de estos casos, se pidió al médico que lo había diagnosticado que eligiera de entre sus pacientes hospitalizados más o menos al mismo tiempo uno o dos controles de características similares pero sin cáncer de páncreas. En total participaron 369 casos y 644 controles. A todos los participantes se les pidió información sobre su consumo de tabaco, alcohol, te y café. Por lo que refiere al café, se observó que los sujetos sin cáncer de páncreas de la muestra consumían menos café que los sujetos con cáncer, como podéis ver en la Figura 3.19. ¿Creéis que el consumo de café entre los controles es representativo de la población sin cáncer de páncreas? (Va, una pista: La mayoría de los casos de cáncer de páncreas son diagnosticados por digestólogos.) Figura 3.19: Proporciones de sujetos que tomaban diferentes números de tazas diarias de café en la muestra analizada por B. MacMahon et al, “Coffee and cancer of the pancreas”. En un estudio llevado a cabo en Sidney en su verano de 1989-90 (American Journal of Public Health 83 (1993), pp. 1701-1706) se quiso determinar la asociación entre nadar en playas contaminadas y sufrir enfermedades infecciosas agudas. Para ello se visitaron durante varios días de verano doce playas de los alrededores de Sidney y se invitó a participar en el estudio a varios individuos en cada ocasión. Se excluyeron individuos que hubieran nadado o que hubieran sufrido alguna enfermedad infecciosa en algún momento durante los 7 días anteriores. A los que aceptaron participar en el estudio, se los llamó por teléfono al día siguiente para pedirles si habían nadado o no el día anterior y se los volvió a llamar al cabo de una semana para pedirles si habían sufrido alguna enfermedad infecciosa desde el día de playa. Si no contestaron a la primera llamada ya no se realizó la segunda llamada. En total se reclutaron 3989 sujetos, pero solo atendieron las dos llamadas 2968. Por otro lado, se midió el nivel de contaminación del agua de las playas visitadas los días en que se reclutaron bañistas en el estudio. El resultado fue que la proporción de sujetos que sufrieron alguna enfermedad infecciosa entre los que nadaron en aguas contaminadas fue un 33% mayor que entre los que nadaron en aguas no contaminadas, y un 116% mayor que entre los que no nadaron. (a) ¿De qué tipo de estudio creéis que se trata? Justificad vuestra respuesta. (b) ¿Qué sesgos se pudieron dar? ¿Cómo se podrían evitar? 3.5 Test (1) En una población se quiere determinar la prevalencia de pediculosis en niños menores de 12 años. Para ello se divide la población en barrios y en cada uno de ellos se toma una muestra aleatoria de tamaño previamente determinado. ¿De qué tipo de muestreo se trata? Muestreo aleatorio simple. Muestreo aleatorio estratificado. Muestreo aleatorio por conglomerados. Muestreo aleatorio sistemático. Muestreo aleatorio polietápico. (2) Disponemos de las listas de todos los pacientes tratados por hipertensión en todos los centros de salud de una ciudad. Cada lista está ordenada por fecha de nacimiento. Para tomar una muestra de hipertensos, escogemos dos centros de salud al azar, y de cada uno de ellos reclutamos cada décimo paciente en su lista de hipertensos. ¿Qué tipo de muestreo hemos usado? Sistemático. Aleatorio simple. Estratificado. Por conglomerados. Polietápico. (3) Las mujeres que usan anticonceptivos orales acuden a revisiones ginecológicas más a menudo que las que no. Si en un estudio de cohorte retrospectivo se encontrara una asociación entre el uso de anticonceptivos orales y alguna enfermedad ginecológica, ¿a qué tipo de sesgo se podría deber? Sesgo de falta de representatividad. Sesgo de recuerdo. Sesgo de procedimiento. Sesgo de detección. Sesgo de atención. Ninguno de los anteriores. (4) En un estudio de casos y controles para estudiar la asociación entre la radioterapia y el cáncer de tiroides, se estudiaron 50 casos ingresados por cáncer de tiroides y 100 controles ingresados durante el mismo período para el tratamiento de hernias. Se entrevistó a los casos, y de estas entrevistas y sus historiales médicos se obtuvo que 20 de ellos habían sido tratados con radioterapia previamente al desarrollo del cáncer de tiroides. Los controles no fueron entrevistados, pero una revisión de sus historiales médicos reveló que solo 2 de ellos habían estado expuestos a radioterapia en el pasado. ¿Qué tipo de sesgo es imposible que se dé en este estudio? Sesgo de recuerdo. Sesgo de falta de representatividad, debido a que los controles no son representativos de la población sin cáncer de tiroides Sesgo de detección, debido al uso de diferentes métodos de determinación de la exposición en los casos y controles Sesgo de procedimiento porque el grupo de cáncer de tiroides recibirá un seguimiento más exhaustivo por parte de los médicos que el grupo de herniados. Algún confundidor no controlado que causara en los casos la enfermedad por la que recibieron radioterapia y posteriormente el cáncer de tiroides. Cuando damos código de R en el texto y su resultado, este va precedido de ##; si hubiéramos ejecutado la instrucción de R en la ventana del editor de R de JAMOVI, el resultado aparecería en la ventana de resultados a la derecha. Cuando el resultado es un vector, como en este caso, R comienza cada línea del resultado con un número entre corchetes [ ]. No lo tengáis en cuenta. Este número indica la posición de la primera entrada de esa línea dentro del vector que forma el resultado. Así, la primera fila siempre empieza con [1].↩︎ "],["probabilidades-elementales-las-mates.html", "Lección 4 Probabilidades elementales: Las mates 4.1 Álgebra de conjuntos 4.2 Algunas fórmulas básicas 4.3 Odds 4.4 Probabilidad condicionada 4.5 Sucesos independientes 4.6 Odds condicionadas y odds ratios relativas 4.7 El teorema de la probabilidad total 4.8 La fórmula de Bayes 4.9 Test", " Lección 4 Probabilidades elementales: Las mates La probabilidad de un suceso es, básicamente, un número entre 0 y 1 (o, si lo preferís, un porcentaje entre 0% y 100%) que mide la expectativa de que se dé este suceso. En este curso vamos a definir la probabilidad de un suceso como la proporción (la fracción, el porcentaje) de sujetos de una población (o a veces de una muestra, dependerá del contexto) en los que se da el suceso. Esta proporción mide la “probabilidad” de que si escogemos al azar un sujeto de la población, se dé en él el suceso (y de hecho coincide con esta probabilidad, para la definición formal de probabilidad que aquí no veremos). Ejemplo 4.1 La probabilidad de que al lanzar una moneda al aire salga cara es la proporción de la población (virtual y prácticamente infinita) de lanzamientos de esta moneda en los que sale cara. En casos MUY sencillos, cuando todos los resultados posibles tienen la misma probabilidad, esta proporción coincide con la fracción de veces en que se da este suceso en el conjunto de resultados posibles y por lo tanto se puede calcular con la famosa regla de Laplace: \\[ \\text{Probabilidad}=\\frac{\\text{Casos favorables}}{\\text{Casos posibles}} \\] Por ejemplo: La probabilidad de que salga cara al lanzar una moneda equilibrada al aire es 1/2 (casos favorables, 1; casos posibles, 2; los dos resultados tienen la misma probabilidad por definición de moneda equilibrada). Pero la probabilidad de que un hijo sea varón no es 1/2, aunque solo haya dos sexos cromosómicos Es la proporción de hijos varones en el total de todos los hijos, que se estima en alrededor del 51.22%. O más exageradamente, la probabilidad de que una mujer de entre 17 y 27 años sea miope no es 1/2, aunque solo haya dos resultados posibles: ser miope y no serlo. Esta probabilidad es la proporción de miopes en la población formada por todas las mujeres de esa franja de edad, que, en España en 2018, se estimaba en un 65.4% según un informe de la Asociación Visión y Vida. Si lanzamos al aire dos veces seguidas una moneda equilibrada, ¿cuál es la probabilidad de que salga alguna cara? Según el enciclopedista y matemático J. d’Alembert es 2/3. Su argumento era el siguiente. Si en el primer lanzamiento sale cara, ya tenemos una cara. Si sale cruz, volvemos a lanzar otra vez y miramos si sale cara o cruz. Por lo tanto, hay solo 3 resultados posibles: cara en el primer lanzamiento; cruz en el primer lanzamiento y cara en el segundo; cruz en ambos lanzamientos. De estos tres “casos posibles”, solo en los 2 primeros sale alguna cara. Casos favorables partido por casos posibles: 2/3. ¿Es correcto este argumento? La teoría matemática de las probabilidades es la que nos permite valorar lo exacta que es una estimación de un valor para una población a partir de una muestra. Por ejemplo, supongamos que elegimos al azar un grupo de 50 estudiantes de la UIB y observamos que 33 sufren de miopía. A partir de este dato, vamos a estimar que un 66% de los estudiantes de la UIB son miopes. ¿Hasta qué punto nos podemos fiar de esta estimación? La teoría de las probabilidades nos permitirá calcular la probabilidad de acertar con esta estimación más o menos un margen de error fijado. 4.1 Álgebra de conjuntos Vamos a repasar muy rápidamente las notaciones y las propiedades de las operaciones de conjuntos, para poder usar este lenguaje en lo que sigue. Sean \\(A\\) y \\(B\\) subconjuntos (en el contexto de la teoría de probabilidades, se los llama sucesos) de un conjunto \\(\\Omega\\) (nuestra población o, en el lenguaje de la teoría de probabilidades, el espacio muestral). \\(A\\cup B\\) es la unión de \\(A\\) y \\(B\\): el conjunto formado por los elementos de \\(\\Omega\\) que pertenecen a \\(A\\) o a \\(B\\) (o a ambos). Corresponde a la disjunción del lenguaje natural. En este curso la disjunción “o” nunca es exclusiva, salvo cuando digamos explícitamente que lo es mediante expresiones del tipo de “o A o B pero no ambos”. \\(A \\cap B\\) es la intersección de \\(A\\) y \\(B\\): el conjunto formado por los elementos que pertenecen simultáneamente a \\(A\\) y a \\(B\\). Corresponde a la conjunción del lenguaje natural. \\(A^c\\) es el complementario de \\(A\\): el conjunto formado por los elementos de \\(\\Omega\\) que no pertenecen a \\(A\\). Corresponde a la negación del lenguaje natural. \\(A-B=A \\cap B^c\\) es la diferencia “\\(A\\) menos \\(B\\)”: el conjunto formado por los elementos de \\(A\\) que no pertenecen a \\(B\\). Por lo tanto, \\(A^c=\\Omega-A\\). Diremos que \\(A\\) y \\(B\\) son disjuntos, o incompatibles, cuando \\(A\\cap B=\\emptyset\\), donde \\(\\emptyset\\) es el conjunto vacío, el conjunto que no tiene elementos. Diremos que \\(A\\) está contenido, o incluido, en \\(B\\), y lo denotaremos por \\(A\\subseteq B\\), cuando todo elemento de \\(A\\) pertenece a \\(B\\). Para recalcar que \\(A\\) está estrictamente contenido en \\(B\\) (que está contenido en \\(B\\) pero no es igual a \\(B\\)) usaremos \\(A\\subsetneq B\\). Ejemplo 4.2 Consideremos la población \\(\\Omega\\) formada por los estudiantes de una clase, y sean \\(A\\) el subconjunto formado por la mujeres de esa clase y \\(B\\) el subconjunto formado por los estudiantes de esa clase que llevan gafas. Entonces: \\(A\\cup B\\) es el conjunto de los estudiantes de la clase que son mujeres o llevan gafas. \\(A \\cap B\\) es el conjunto de los estudiantes de la clase que son mujeres y llevan gafas, es decir, las mujeres de la clase que llevan gafas. \\(A^c\\) es el conjunto de los estudiantes de la clase que no son mujeres, es decir los hombres de la clase. \\(B^c\\) es el conjunto de los estudiantes de la clase que no llevan gafas. \\(A-B\\) es el conjunto de las mujeres de la clase que no llevan gafas. \\(B-A\\) es el conjunto de los estudiantes de la clase que llevan gafas y no son mujeres, es decir, los hombres de la clase que llevan gafas. \\(A\\) y \\(B\\) serán disjuntos (llevar gafas y ser mujer serán incompatibles en esta clase) si no hay ninguna mujer en la clase que lleve gafas. \\(A\\subseteq B\\) será verdad si todas las mujeres de la clase llevan gafas. \\(B\\subseteq A\\) será verdad si todos los estudiantes de la clase que llevan gafas son mujeres. Las propiedades de estas operaciones son las siguientes, y se corresponden a las propiedades de las conjunciones, disjunciones y negaciones en el lenguaje natural. Absorción: Si \\(A\\subseteq B\\), entonces \\(A\\cap B=A\\) y \\(A\\cup B=B\\). La unión y la intersección son conmutativas: \\(A\\cup B=B\\cup A\\) y \\(A\\cap B=B\\cap A\\). La unión y la intersección son asociativas: \\(A\\cup(B\\cup C)=(A\\cup B)\\cup C\\) y \\(A\\cap(B\\cap C)=(A\\cap B) \\cap C\\). Figura 4.1: Propiedad asociativa de la unión. Figura 4.2: Propiedad asociativa de la intersección. La unión y la intersección son distributivas: \\(A\\cap(B\\cup C)=(A\\cap B)\\cup (A\\cap C)\\) y \\(A\\cup(B\\cap C)=(A\\cup B)\\cap (A\\cup C)\\). Figura 4.3: Propiedad distributiva de la unión respecto de la intersección. Figura 4.4: Propiedad distributiva de la intersección respecto de la unión. Propiedad del doble complementario: \\((A^c)^c=A\\). Corresponde a que, en el lenguaje natural, “No es verdad que no lleve gafas” significa lo mismo que “Lleva gafas”. Figura 4.5: Propiedad del doble complementario. Leyes de De Morgan: \\((A\\cup B)^c=A^c \\cap B^c\\) y \\((A\\cap B)^c=A^c\\cup B^c\\). La primera corresponde a que, en el lenguaje natural, lo contrario de “Ser mujer o llevar gafas” es “No ser mujer Y no llevar gafas”. La segunda, a que lo contrario de “Ser mujer y llevar gafas” es “No ser mujer O no llevar gafas”. Figura 4.6: Una ley de de Morgan. Figura 4.7: La otra ley de de Morgan. Que la unión y la intersección sean asociativas y conmutativas nos permite escribir expresiones del estilo de \\[ A_1\\cap A_2\\cap \\cdots \\cap A_n,\\qquad A_1\\cup A_2\\cup \\cdots \\cup A_n \\] para indicar, respectivamente, la intersección o la unión de los sucesos \\(A_1,\\ldots,A_n\\) agrupándolos como queramos y en el orden que queramos. 4.2 Algunas fórmulas básicas Hemos definido la probabilidad \\(P(A)\\) de un subconjunto (suceso) \\(A\\) de una población (espacio muestral) \\(\\Omega\\) como la fracción de los sujetos de \\(\\Omega\\) que pertenecen a \\(A\\). A partir de esta definición se deducen, por puro conteo, las propiedades siguientes: Para todo suceso \\(A\\), \\(0\\leqslant P(A)\\leqslant 1\\). Un subconjunto \\(A\\) de \\(\\Omega\\) no puede representar ni una fracción negativa ni una fracción mayor que 1 de los sujetos de \\(\\Omega\\). \\(P(\\Omega)=1\\) y \\(P(\\emptyset)=0\\) (recordad que \\(\\emptyset\\) es el conjunto vacío). Si \\(A\\) y \\(B\\) son dos sucesos disjuntos, entonces \\(P(A\\cup B)=P(A)+P(B)\\). Si no hay ningún sujeto que pertenezca simultáneamente a \\(A\\) y a \\(B\\), entonces el número de sujetos que pertenecen a \\(A\\) o a \\(B\\) es la suma de los que pertenecen a \\(A\\) y de los que pertenecen a \\(B\\). Entonces, dividiendo por el número total de individuos de la población \\(\\Omega\\) (su cardinal), obtenemos que la fracción de los sujetos que pertenecen a \\(A\\) o a \\(B\\) es la suma de las fracciones de los que pertenecen a \\(A\\) y de los que pertenecen a \\(B\\). Más en general, si \\(A_1,A_2,\\ldots,A_n\\) son sucesos disjuntos dos a dos, entonces \\[ P(A_1\\cup A_2\\cup \\cdots \\cup A_n)=P(A_1)+P(A_2)+\\cdots +P(A_n). \\] \\(P(A-B)=P(A)-P(A\\cap B)\\). El número de sujetos que pertenecen a \\(A\\) pero no a \\(B\\) se obtiene restando del total de sujetos de \\(A\\) los que pertenecen simultáneamente a \\(A\\) y a \\(B\\), es decir, a \\(A\\cap B\\). Dividiendo por el número total de individuos de la población, obtenemos la correspondiente igualdad de proporciones. Formalmente, como \\(A-B\\) y \\(A\\cap B\\) son disjuntos (ya que ningún elemento de \\(A-B\\) pertenece a \\(B\\) y todos los elementos de \\(A\\cap B\\) pertenecen a \\(B\\)), la propiedad (3) nos dice que \\[ P((A-B)\\cup (A\\cap B))=P(A-B)+P(A\\cap B). \\] Por otro lado, \\((A-B)\\cup (A\\cap B)=A\\) porque \\(A\\) es la unión del conjunto de sus elementos que no pertenecen a \\(B\\) y del conjunto de sus elementos que sí pertenecen a \\(B\\). Figura 4.8: Descomposición de A en dos conjuntos disjuntos. ¡Ojo! En general, es falso que \\(P(A-B)=P(A)-P(B)\\). Si en una población hay un 50% de mujeres y un 60% de miopes, y un 35% del total son mujeres miopes, las mujeres no miopes son un 15% del total de la población, no un -10%, ¿verdad? \\(P(A^c)=1-P(A)\\). Es decir, la fracción de los sujetos que no pertenecen a \\(A\\) es 1 menos la fracción de los que sí pertenecen a \\(A\\). Si \\(A\\subseteq B\\), entonces \\(P(A)\\leqslant P(B)\\). Si \\(A\\) está contenido en \\(B\\), la fracción de los sujetos que pertenecen a \\(A\\) es menor o igual que la de los que pertenecen a \\(B\\). \\(P(A\\cup B)=P(A)+P(B)-P(A \\cap B)\\). Si queréis contar cuántos sujetos hay en \\(A\\cup B\\), tenéis que añadir a los de \\(A\\) los de \\(B-A\\) (mirad la Figura 4.9). Dividiendo por el total de la población para pasar a proporciones, esto nos dice que \\[ P(A\\cup B)=P(A)+P(B-A)=P(A)+P(B)-P(A \\cap B) \\] donde la segunda igualdad se debe a (5). Por ejemplo, si en una población hay un 50% de mujeres y un 60% de miopes, y un 35% del total son mujeres miopes, las personas que son mujeres o miopes (recordad, o ambas cosas) forman un 75% de la población: al 50% de mujeres hay que sumarle el 25% de miopes que no son mujeres. Figura 4.9: Descomposición de la unión en tres conjuntos disjuntos. Otra manera de escribir la ecuación anterior es \\[ P(A\\cap B)=P(A)+P(B)-P(A \\cup B) \\] En general, es falso que \\(P(A\\cap B)=P(A)\\cdot P(B)\\). Por ejemplo, en la población con un 50% de mujeres, un 60% de miopes y un 35% de mujeres miopes que hemos usado antes, 0.6·0.5 no es igual a 0.35. Más adelante veremos cuándo esta igualdad es verdadera. Ejemplo 4.3 Supongamos que el 0.1% de los donantes de sangre dan positivo en el test de VIH, que el 1% dan positivo en el test de herpes simple (VHS) y que el 0.05% dan positivo en ambos tests. ¿Cuál es la probabilidad de que un donante escogido al azar dé positivo en al menos uno de los dos tests? ¿Y la de que un donante escogido al azar dé positivo en VHS pero no en VIH? Vamos a poner nombres a los sucesos involucrados en estas preguntas: \\(A\\): Dar positivo en VIH. Sabemos que \\(P(A)=0.001\\). \\(B\\): Dar positivo en VHS. Sabemos que \\(P(B)=0.01\\). \\(A\\cap B\\): Dar positivo en los dos. Sabemos que \\(P(A\\cap B)=0.0005\\). \\(A\\cup B\\): Dar positivo en al menos uno de los dos. Es lo que queremos calcular en la primera pregunta. Por la propiedad (8): \\[ P(A \\cup B) =P(A)+P(B)-P(A\\cap B)=0.001+0.01-0.0005=0.0105 \\] La probabilidad de que un donante escogido al azar dé positivo en al menos uno de los dos tests es del 1.05%. \\(B-A\\): Dar positivo en VHS pero no en VIH. Es lo que queremos calcular en la segunda pregunta. Por la propiedad (5), \\[ P(B-A)=P(B)-P(A\\cap B)=0.01-0.0005=0.0095 \\] La probabilidad de que un donante escogido al azar dé positivo en VHS pero no en VIH es del 0.95%. Otra manera de calcular estas probabilidades sin necesidad de recordar fórmulas sería: Tomar como referencia una población de un tamaño concreto. Calcular en esta población cuántos individuos pertenecen a \\(A\\cap B\\) (dan positivo en ambos tests), cuántos a \\(A-B\\) (positivos en VIH pero no en VHS), cuántos a \\(B-A\\) (positivos en VHS pero no en VIH) y cuántos a \\(A^c\\cap B^c\\) (negativo en ambos tests) y a partir de ahí calcular todo lo que queramos. A este método se le suele llamar método de frecuencias naturales (“la cuenta de la vieja” no suena lo bastante científico), y así lo llamaremos nosotros. Pongámoslo en práctica en nuestro caso: Vamos a tomar una población de referencia de 10,000 donantes ¿Por qué este número? Veamos, fijaos en que la proporción de sujetos en \\(A\\cap B\\) es del 0.05%, es decir, 0.0005, y para facilitar los cálculos nos gustaría que todos los números que nos salieran fueran enteros, para no liarnos con decimales. Como 0.0005·10000=5, parece que 10,000 nos va a valer. Los sujetos de \\(A\\) son el 0.1% de la población: 10 Los sujetos de \\(B\\) son el 1% de la población: 100 Los sujetos de \\(A\\cap B\\) son el 0.05% de la población: 5 En resumen: \\[ \\begin{array}{r|c|c|c} &amp; A\\ (\\text{VIH}+) &amp; A^c \\ (\\text{VIH}-) &amp; \\text{Total} \\\\ \\hline B\\ (\\text{VHS}+) &amp; 5 &amp; &amp; 100 \\\\ \\hline B^c\\ (\\text{VHS}-) &amp; &amp; &amp; 9900 \\\\ \\hline \\text{Total} &amp; 10&amp; 9990 &amp; 10000 \\\\ \\end{array} \\] Entonces, los sujetos de \\(A-B\\) serán los de \\(A\\) menos los de \\(A\\cap B\\): 5 Y los sujetos de \\(B-A\\) serán los de \\(B\\) menos los de \\(A\\cap B\\): 95 Por ahora ya tenemos: 5 sujetos positivos en VIH y en VHS; 5 positivos en VIH y negativos en VHS; y 95 positivos en VHS y negativos en VIH. En total, 105 sujetos. El resto serán negativos tanto en VIH como en VHS. Por lo tanto, los sujetos de \\(A^c\\cap B^c\\) serán 10000-105=9895. Obtenemos la tabla de frecuencias siguiente: \\[ \\begin{array}{r|c|c|c} &amp; A\\ (\\text{VIH}+) &amp; A^c \\ (\\text{VIH}-) &amp; \\text{Total} \\\\ \\hline B\\ (\\text{VHS}+) &amp; 5 &amp; 95 &amp; 100 \\\\ \\hline B^c\\ (\\text{VHS}-) &amp; 5 &amp; 9895 &amp; 9900 \\\\ \\hline \\text{Total} &amp; 10&amp; 9990 &amp; 10000 \\\\ \\end{array} \\] Y ahora, cambiando “probabilidad” por “proporción”, ya podemos calcular lo que queramos. ¿Cuál es la proporción de sujetos que dan positivo en algún test? Hay 105 sujetos en la tabla que dan positivo en algún test: los 10 positivos en VIH y los 95 positivos en VHS y negativos en VIH. Por lo tanto, su proporción es de 105/10000=0.0105. ¿Cuál es la proporción de sujetos que dan positivo en VHS pero no en VIH? Hay 95 sujetos en la tabla que dan positivo en VHS y negativo en VIH, por lo que su proporción es de 95/10000=0.0095. Seguimos en la situación anterior: el 0.1% de los donantes de sangre dan positivo en el test de VIH, el 1% dan positivo en el test de herpes y el 0.05% dan positivo en los dos tests. ¿Cuál es la probabilidad de que un donante escogido al azar dé positivo en un solo test? Supongamos ahora que el 0.1% de todos los donantes de sangre da positivo en el test de VIH, el 1% da positivo en el test de herpes y el 1.07% da positivo en al menos uno de los dos tests. ¿Cuál es la probabilidad de que un donante escogido al azar dé positivo en ambos tests? ¿Y la de que dé positivo en un solo test? Y supongamos ahora que el 0.1% de todos los donantes de sangre da positivo en el test de VIH, el 1% da positivo en el test de herpes y el 1.2% da positivo en al menos uno de los dos tests. ¿Cuál es la probabilidad de que un donante escogido al azar dé positivo en ambos tests? ¿Y la de que dé positivo en un solo test? Figura 4.10: ¡Cuidado con lo que respondéis! Ejemplo 4.4 En la Sección 3.3.1 hemos dado las probabilidades de que se escoja más de una vez algún individuo en algunas situaciones. Por ejemplo, si escogemos 100 individuos de las Baleares (suponiendo que su población es de 1,150,000 habitantes) al azar permitiendo repeticiones. ¿Cómo se calculan estas probabilidades? Vamos a suponer que escogemos los individuos uno tras otro. El plan va a ser calcular primero la probabilidad \\(p\\) de que todos los individuos de la muestra sean diferentes. Entonces, la probabilidad de que salga al menos uno repetido será \\(1-p\\). Como, en el muestreo aleatorio simple, todos los grupos de 100 baleares (con posibles repeticiones) tienen la misma probabilidad de ser elegidos, podemos usar la fórmula de Laplace “casos favorables partido por casos posibles” para calcular \\(p\\). Solo hay que identificar cuántos casos favorables y cuántos casos posibles hay. Casos favorables. ¿De cuántas maneras podemos elegir 100 baleares, uno tras otro, de manera que todos sean diferentes? El primero puede ser cualquiera: hay 1,150,000 posibilidades. Una vez hemos elegido el primero, como el segundo ha de ser diferente, puede ser cualquiera de los 1,149,999 restantes. Una vez hemos elegido los dos primeros, como el tercero ha de ser diferente de ellos, lo podemos escoger de los 1,149,998 restantes. En general, cuando hemos elegido n sujetos, el siguiente puede ser cualquiera de los 1,150,000-n restantes. Y así, cuando hemos elegido los 99 primeros, para el último, el centésimo, tenemos 1,150,000-99=1,149,901 posibilidades. Por lo tanto hay \\[ 1150000\\times 1149999\\times 1149998\\times \\cdots\\times 1149901 \\] posibles elecciones de 100 baleares diferentes. Casos posibles. ¿De cuántas maneras podemos elegir 100 baleares, uno tras otro, sin ninguna restricción? El primero puede ser cualquiera: hay 1,150,000 posibilidades. Una vez hemos elegido el primero, como el segundo puede ser cualquiera, de nuevo tenemos 1,150,000 posibilidades para él. Una vez hemos elegido los dos primeros, como el tercero puede ser cualquiera, seguimos teniendo 1,150,000 posibilidades. En general, cuando hemos elegido n sujetos, para el siguiente volvemos a tener 1,150,000 posibilidades. Por lo tanto hay \\[ \\overbrace{1150000\\times 1150000\\times 1150000\\times \\cdots\\times 1150000}^{100}=1150000^{100} \\] posibles elecciones de 100 baleares sin ninguna restricción. Por la fórmula de Laplace, la probabilidad \\(p\\) de que al elegir al azar 100 baleares nos salgan todos diferentes es \\[ p=\\frac{1150000\\times 1149999\\times\\cdots\\times 1149901}{1150000^{100}} \\] y, finalmente, la probabilidad de que al elegir al azar 100 baleares nos salga alguno repetido es \\[ 1-p=1-\\frac{1150000\\times 1149999\\times\\cdots\\times 1149901}{1150000^{100}} \\] Naturalmente, os va a costar calcular este número con una calculadora científica sencilla, pero para eso están los ordenadores. Da 0.0042952. R dispone de dos funciones relacionadas con la probabilidad de que se dé alguna repetición en una muestra aleatoria simple de un tamaño dado: La instrucción pbirthday(n,N) nos da la probabilidad de que en una muestra aleatoria simple de tamaño n de una población de tamaño N haya algún elemento repetido. La instrucción qbirthday(p,N) nos da el tamaño mínimo de una muestra aleatoria simple de una población de tamaño N para que la probabilidad de que haya algún elemento repetido sea \\(\\geqslant p\\). El nombre birthday hace referencia a la paradoja del cumpleaños: el típico problema de calcular la probabilidad de que dos estudiantes de una clase celebren el cumpleaños el mismo día y asombrarse de que en una clase de 50 estudiantes haya más de un 95% de probabilidades de que haya algún cumpleaños repetido. En efecto, podemos entender una clase de 50 estudiantes como una muestra aleatoria simple de 50 fechas de nacimiento, escogidas de un conjunto de 366 posibles fechas (los 366 días de un año bisiesto). La probabilidad de que al menos 2 estudiantes celebren el cumpleaños el mismo día es la probabilidad de que se dé al menos una repetición en esta muestra. R lo calcula con: pbirthday(50,366) ## [1] 0.9700731 La probabilidad de que en una muestra aleatoria simple de 100 ciudadanos de las Baleares se dé alguna repetición se puede calcular mediante pbirthday(100,1150000) ## [1] 0.004295221 Comprobad que las otras probabilidades de repeticiones anunciadas en la lección anterior son correctas. ¿Cuál es el número mínimo de estudiantes en la clase para que la probabilidad de que se repita una fecha de cumpleaños sea al menos del 95%? 4.3 Odds En algunos contextos, las probabilidades se presentan en forma de odds. La traducción más común en castellano es momios, pero se usan otras: posibilidades, oportunidades, ocasiones… Aquí usaremos odds. Las odds de un suceso \\(A\\) son \\[ \\text{Odds}(A)=\\frac{P(A)}{P(A^c)}=\\frac{P(A)}{1-P(A)} \\] y por lo tanto nos dicen cuántas veces es más probable \\(A\\) que “no \\(A\\)”. Figura 4.11: Momios de gatitos en el British Museum (fotografía de M. Sánchez). Si \\(\\text{Odds}(A)=q\\), significa que por cada vez que ocurre “no \\(A\\)”, ocurre \\(q\\) veces \\(A\\). Por ejemplo, si las odds de suspender una asignatura son 2/3, significa que: Por cada estudiante que aprueba, hay 2/3 de estudiante que suspenden. Por cada 3 estudiantes que aprueban, hay 2 que suspenden. De cada 5 estudiantes, 3 aprueban y 2 suspenden. 2 de cada 5 estudiantes suspenden. La probabilidad de suspender es de un 40%. A veces, que unas odds valgan \\(a/b\\) se expresa diciendo que son \\(a\\!:\\!b\\), y se lee “\\(a\\) a \\(b\\)”. Por ejemplo, las odds de suspender anteriores son 2:3, es decir, 2 a 3. Ejemplo 4.5 Algunos ejemplos de odds a partir de probabilidades: Si \\(P(A)=0.2\\), \\(\\text{Odds}(A)=0.2/0.8=0.25\\). Si \\(P(A)=0\\), \\(\\text{Odds}(A)=0\\). Si \\(P(A)=0.5\\), \\(\\text{Odds}(A)=1\\). Si \\(P(A)=1\\), \\(\\text{Odds}(A)=\\infty\\). Como son un cociente de dos probabilidades, las odds de un suceso son siempre mayores o iguales que 0 y pueden tomar cualquier valor entre 0 e \\(\\infty\\), ambos incluidos. Si lanzamos un dado equilibrado de 10 caras numeradas del 0 al 9: ¿Qué valen las odds de sacar un 3? ¿Qué valen las odds de sacar un múltiplo de 3? Si sabemos las odds de \\(A\\), podemos calcular la probabilidad \\(P(A)\\): \\[ \\begin{array}{rl} \\text{Odds}(A)=\\dfrac{P(A)}{1-P(A)}\\!\\!\\!\\! &amp; \\Longrightarrow \\text{Odds}(A)-\\text{Odds}(A)P(A)=P(A)\\\\ &amp; \\Longrightarrow P(A)=\\dfrac{\\text{Odds}(A)}{1+\\text{Odds}(A)} \\end{array} \\] Por lo tanto, dos sucesos tienen la misma probabilidad si, y solo si, tienen las mismas odds. Observad que la función \\[ x\\mapsto\\frac{x}{1+x} \\] es creciente en \\(x\\): Figura 4.12: Gráfica de la curva y=x/(1+x). Como esta es la función que transforma \\(\\text{Odds}(A)\\) en \\(P(A)\\), deducimos que \\[ \\text{Odds}(A)&gt;\\text{Odds}(B)\\Longleftrightarrow P(A)&gt;P(B) \\] \\(A\\) es más probable que \\(B\\) si, y solo si, las odds de \\(A\\) son mayores que las de \\(B\\). Como veremos en la Sección 5.2.2, la manera correcta de presentar los resultados en los estudios de casos y controles es en forma de odds ratios. La odds ratio (razón de momios, de oportunidades…) de dos sucesos \\(A\\) y \\(B\\) es el cociente de sus odds: \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)} \\] Es decir, \\(\\text{OR}(A,B)\\) nos dice cuántas veces son mayores (o menores) las odds de \\(A\\) que las de \\(B\\). Su valor es difícil de interpretar en términos de probabilidades excepto por lo que refiere a su relación con 1: \\(\\text{OR}(A,B)=1\\Longleftrightarrow \\text{Odds}(A)=\\text{Odds}(B) \\Longleftrightarrow P(A)=P(B)\\) \\(\\text{OR}(A,B)&gt;1\\Longleftrightarrow \\text{Odds}(A)&gt;\\text{Odds}(B) \\Longleftrightarrow P(A)&gt;P(B)\\) \\(\\text{OR}(A,B)&lt;1\\Longleftrightarrow \\text{Odds}(A)&lt;\\text{Odds}(B) \\Longleftrightarrow P(A)&lt;P(B)\\) Pero, por ejemplo \\[ \\text{OR}(A,B)=2 \\Longleftrightarrow \\text{Odds}(A)= 2\\cdot \\text{Odds}(B) \\hspace{1.2ex} \\not\\hspace{-1.2ex}\\Longleftrightarrow P(A)= 2\\cdot P(B) \\] De hecho, el gráfico siguiente muestra qué vale \\(P(A)\\) en función de \\(P(B)\\) cuando \\(OR(A,B)=2\\) (curva negra) y la línea para la cual \\(P(A)\\) valdría \\(2P(B)\\) (línea roja discontinua): Como veis, \\(P(A)=2P(B)\\) solo cuando \\(P(B)=0\\). En general, si \\(\\text{OR}(A,B)=q\\), es decir, \\(\\text{Odds}(A)=q\\cdot\\text{Odds}(B)\\), entonces \\[ \\begin{array}{l} P(A)=\\dfrac{\\text{Odds}(A)}{1+\\text{Odds}(A)}=\\dfrac{q\\cdot\\text{Odds}(B)}{1+q\\cdot\\text{Odds}(B)}\\\\ \\qquad =\\dfrac{q\\cdot\\frac{ P(B)}{1-P(B)}}{1+q\\cdot\\frac{P(B)}{1-P(B)}}=\\dfrac{q\\cdot P(B)}{1-P(B)+q\\cdot P(B)}\\\\ \\qquad=\\dfrac{q\\cdot P(B)}{1+(q-1)P(B)} \\end{array} \\] y por lo tanto la relación entre \\(P(A)\\) y \\(P(B)\\) es complicada. Ejemplo 4.6 En un estudio de casos y controles (Y. Nobel et al, Gastroenterology 159 (2020), pp. 373-375) se afirma que “la presencia de síntomas gastrointestinales se asoció a un incremento del 70% en el riesgo de dar positivo [en el test de COVID-19]: odds ratio, 1.7.” ¿Qué significa esto? Que la odds ratio valga 1.7 significa que las odds de dar positivo en COVID-19 si se tienen síntomas gastrointestinales son 1.7 veces las de dar positivo si no se tienen síntomas gastrointestinales, es decir un 70% mayores. Pero fijaos que estamos hablando de las odds, no del riesgo entendido en el sentido de probabilidad. No tiene por qué ser cierto que la probabilidad de dar positivo en COVID-19 si se tienen síntomas gastrointestinales sea un 70% mayor que si no se tienen síntomas gastrointestinales. De hecho, en este estudio concreto se obtuvo la tabla de frecuencias siguiente (SG abrevia “síntomas gastrointestinales”) \\[ \\begin{array}{r|c|c|c} &amp; \\text{COVID-19 } + &amp; \\text{COVID-19 } - &amp; \\text{Total}\\\\ \\hline \\text{SG Sí} &amp; 97&amp; 63 &amp; 160\\\\\\hline \\text{SG No} &amp; 181 &amp; 175 &amp; 356\\\\\\hline \\text{Total} &amp; 278 &amp; 238 &amp; 316 \\end{array} \\] Por lo tanto, la proporción de COVID-19 positivos entre los que tuvieron síntomas gastrointestinales fue 97/160=0.606 y la proporción de COVID-19 positivos entre los que no tuvieron síntomas gastrointestinales fue 181/356=0.508. Como 0.606/0.508=1.19, la primera es un 19% mayor que la segunda, no un 70% mayor. Veamos las odds. Las de ser COVID-19 positivo entre los que tuvieron síntomas gastrointestinales son \\[ \\frac{97/160}{63/160}=1.54 \\] Las de ser COVID-19 positivo entre los que no tuvieron síntomas gastrointestinales son \\[ \\frac{181/356}{175/356}=1.03 \\] La odds ratio es, entonces 1.54/1.03=1.495. ¿Pero no habíamos dicho que la odds ratio les había salido 1.7? Bueno, sí, lo que les da 1.7 es la odds ratio ajustada, ORa, una odds ratio que se obtiene al descontar la influencia de confundidores en el desenlace. Explicaremos cómo se calcula más adelante, en el tema de regresión logística. ¿Qué valen las odds de sacar 3 caras en 3 lanzamientos de una moneda equilibrada? Si un suceso pasa 2 veces de cada 10 veces que puede pasar, ¿qué valen sus odds? Si las odds de \\(A\\) son 1/2, ¿qué vale \\(P(A)\\)? Si \\(\\text{OR}(A,B)=0.5\\) y \\(P(A)=1/2\\), ¿qué vale \\(P(B)\\)? Sí \\(\\text{OR}(A,B)=0.5\\) y \\(P(A)=3/4\\), ¿qué vale \\(P(B)\\)? 4.4 Probabilidad condicionada Dados dos sucesos \\(A\\) y \\(B\\), con \\(P(A)&gt;0\\), la probabilidad de \\(B\\) condicionada a \\(A\\) es \\[ P(B|A)=\\frac{P(A\\cap B)}{P(A)} \\] Este valor representa la fracción de los sujetos de \\(A\\) que pertenecen a \\(B\\); es decir, es la probabilidad de que si ocurre \\(A\\), entonces también ocurra \\(B\\). Supongamos que en una población \\(\\Omega\\) de \\(N\\) individuos hay \\(M_A\\) que pertenecen a \\(A\\), y que entre estos hay \\(M_{\\textit{AB}}\\) que también pertenecen a \\(B\\). Entonces, la fracción de sujetos de \\(A\\) que pertenecen a \\(B\\) es \\[ \\frac{M_{\\textit{AB}}}{M_A}=\\frac{M_{\\textit{AB}}/N}{M_A/N}. \\] En la fracción de la derecha, el numerador \\(M_{\\textit{AB}}/N\\) es la proporción de sujetos de \\(\\Omega\\) que pertenecen a \\(A\\cap B\\), es decir, \\(P(A\\cap B)\\), y el denominador \\(M_A/N\\) es la proporción de sujetos de \\(\\Omega\\) que pertenecen a \\(A\\), es decir \\(P(A)\\). Por lo tanto, la fracción de la derecha es \\(P(A\\cap B)/P(A)\\). Esto muestra que, efectivamente, \\(P(B|A)\\) representa la fracción de los sujetos de \\(A\\) que pertenecen a \\(B\\) Ejemplo 4.7 Supongamos que en una clase de 20 hombres y 30 mujeres, 15 hombres y 18 mujeres llevan gafas. La tabla de frecuencias correspondiente es \\[ \\begin{array}{r|c|c|c} &amp; \\text{Gafas} &amp; \\text{No gafas} &amp; \\text{Total}\\\\ \\hline \\text{Mujeres} &amp; 18 &amp;12 &amp; 30\\\\ \\hline \\text{Hombres} &amp; 15 &amp; 5 &amp; 20 \\\\ \\hline \\text{Total} &amp; 33 &amp; 17 &amp; 50 \\\\ \\end{array} \\] ¿Cuál es la probabilidad de que un estudiante sea mujer? Como hay 30 mujeres de un total de 50 estudiantes, esta probabilidad es 30/50=0.6 ¿Cuál es la probabilidad de que un estudiante lleve gafas? Como hay 33 estudiantes con gafas de un total de 50 estudiantes, esta probabilidad es 33/50=0.66 ¿Cuál es la probabilidad de que un estudiante sea mujer y lleve gafas? Como la probabilidad de ser mujer es 0.6 y la probabilidad de llevar gafas es 0.66, la probabilidad de ser mujer y llevar gafas es el producto: 0.6·0.66=0.396. ¡No! En general, la probabilidad de la intersección NO es el producto de las probabilidades. Calculémosla bien. Como hay 18 mujeres que llevan gafas de un total de 50 estudiantes, esta probabilidad es 18/50=0.36 ¿Cuál es la probabilidad de que una mujer lleve gafas? Como hay 18 mujeres que llevan gafas de un total de 30 mujeres, esta probabilidad es 18/30=0.6. Fijaos que este valor es igual a \\[ P(\\text{gafas}|\\text{mujer})=\\frac{P(\\text{mujer y gafas})}{P(\\text{mujer})}=\\frac{18/50}{30/50}=\\frac{18}{30} \\] Escogemos un estudiante al azar. ¿Cuál es la probabilidad de que si es mujer, entonces lleve gafas? Es la misma pregunta que la anterior, por lo que la respuesta es la misma: 18/30=0.6. ¿Cuál es la probabilidad de que un estudiante que lleve gafas sea mujer? Como hay 18 mujeres que llevan gafas de un total de 33 estudiantes que lleven gafas, esta probabilidad es 18/33=0.545. Fijaos, de nuevo, que este valor es igual a \\[ P(\\text{mujer}|\\text{gafas})=\\frac{P(\\text{mujer y gafas})}{P(\\text{gafas})}=\\frac{18/50}{33/50}=\\frac{18}{33} \\] Escogemos un estudiante al azar. ¿Cuál es la probabilidad de si lleva gafas, entonces sea mujer? Es la misma pregunta que la anterior, por lo que la respuesta es la misma: 18/33. No confundáis: \\(P(B)\\): La probabilidad de que un individuo de la población global \\(\\Omega\\) pertenezca a \\(B\\). Por ejemplo, si \\(B\\) es “llevar gafas”, \\(P(B)\\) es la probabilidad de que una persona lleve gafas. La población en la que calculamos probabilidades es la de todas las personas. \\(P(B|A)\\): Probabilidad de que un individuo de \\(A\\) pertenezca a \\(B\\). Por ejemplo, si además \\(A\\) es “ser mujer”, \\(P(B|A)\\) es la probabilidad de que una mujer lleve gafas. La población en la que calculamos probabilidades es la de las mujeres. \\(P(A|B)\\): Probabilidad de que un individuo de \\(B\\) pertenezca a \\(A\\). Por ejemplo, con las notaciones anteriores, \\(P(A|B)\\) es la probabilidad de que una persona que lleva gafas sea mujer. La población en la que calculamos probabilidades es la de las personas que llevan gafas. \\(P(B\\cap A)\\): Probabilidad de que un individuo de la población global pertenezca simultáneamente a \\(A\\) y a \\(B\\). Por ejemplo, con las notaciones anteriores, \\(P(A\\cap B)\\) es la probabilidad de que una persona sea mujer y lleve gafas. La población en la que calculamos probabilidades vuelve a ser todas las personas. En una universidad, los alumnos se distribuyen de la manera siguiente por tipos de estudios y sexos: \\[ \\begin{array}{r|c|c|c|c|c} \\text{Estudio} &amp; \\text{Ciencias} &amp; \\text{Derecho} &amp; \\text{Educación} &amp; \\text{Otros} &amp; \\text{Total}\\\\ \\hline \\text{Hombres} &amp; 1200 &amp; 1300 &amp; 300 &amp; 2000 &amp; 4800\\\\ \\hline \\text{Mujeres} &amp; 1400 &amp; 600 &amp; 1600 &amp; 1600 &amp; 5200\\\\ \\hline \\text{Total} &amp; 2600 &amp;1900 &amp; 1900 &amp; 3600 &amp; 10000\\\\ \\end{array} \\] Si escojo un estudiante al azar, ¿cuál es la probabilidad de que: Sea hombre o mujer? Sea mujer? Estudie Ciencias? No estudie Ciencias? Sea mujer o estudie Derecho? Sea mujer y estudie Derecho? Sea mujer pero no estudie Derecho? Si estudia Educación, sea mujer? Si es mujer, estudie Educación? Si es mujer, no estudie Educación? Si no es mujer, estudie Educación? La probabilidad condicionada a \\(A\\), \\(P(\\ldots|A)\\), es una probabilidad “de verdad”, simplemente hemos cambiado la población de \\(\\Omega\\) a \\(A\\). Es decir, en vez de trabajar con proporciones de la población total \\(\\Omega\\), trabajamos con proporciones de la subpoblación definida por los sujetos de \\(A\\). Por lo tanto, \\(P(\\ldots |A)\\) satisface todas las propiedades de las probabilidades. Por ejemplo, se cumple que: \\(P(B^c|A)=1-P(B|A)\\) \\(P(C-B|A)=P(C|A)-P(B\\cap C|A)\\) \\(P(B\\cup C|A)=P(B|A)+P(C|A)-P(B\\cap C|A)\\) Pero si en \\(P(B|A)\\) fijamos la \\(B\\) y permitimos que \\(A\\) varíe (es decir, si fijamos el suceso que nos interesa y variamos la población en la que calcularemos su probabilidad), ya no se cumplen las propiedades de las probabilidades. Por ejemplo, en general: \\(P(B|A^c)\\neq 1-P(B|A)\\) No podéis esperar que la proporción de hombres que llevan gafas sea 1 menos la proporción de mujeres que llevan gafas, ¿verdad? \\(P(B|A_1\\cup A_2)\\neq P(B|A_1)+P(B|A_2)-P(B|A_1\\cap A_2)\\) Ejercicio: Comprobadlo en el Ejercicio anterior. Ejemplo 4.8 Supongamos que un 15% de los adultos son hipertensos, un 25% de los adultos creen que son hipertensos, y un 9% de los adultos son hipertensos y creen que lo son. Si un adulto cree que es hipertenso, ¿cuál es la probabilidad de que lo sea? Si un adulto es hipertenso, ¿cuál es la probabilidad de que crea que lo es? Si un adulto no cree que sea hipertenso, ¿cuál es la probabilidad de que sí lo sea? Pongamos nombres a los sucesos involucrados en estas preguntas: \\(A\\): Ser hipertenso; \\(P(A)=0.15\\) \\(B\\): Creer ser hipertenso; \\(P(B)=0.25\\) \\(A\\cap B\\): Ser hipertenso y creerlo; \\(P(A \\cap B)=0.09\\) En la primera pregunta nos piden la probabilidad de \\(A\\) condicionada a \\(B\\): \\[ P(A|B)=\\frac{P(A\\cap B)}{P(B)}=\\dfrac{0.09}{0.25}=0.36 \\] Si un adulto cree ser hipertenso, tiene una probabilidad del 36% de serlo. En la segunda pregunta nos piden la probabilidad de \\(B\\) condicionada a \\(A\\): \\[ P(B|A) =\\frac{P(A\\cap B)}{P(A)}=\\frac{0.09}{0.15}=0.6 \\] Si un adulto es hipertenso, tiene una probabilidad del 60% de creer que lo es. Y en la tercera pregunta nos piden la probabilidad de \\(A\\) condicionada a \\(B^c\\): \\[ P(A|B^c) =\\frac{P(A\\cap B^c)}{P(B^c)}=\\frac{P(A)-P(A\\cap B)}{1-P(B)}=\\frac{0.06}{0.75}=0.08 \\] Si un adulto no cree ser hipertenso, tiene una probabilidad del 8% de ser hipertenso. Fijaos en que \\(P(A|B^c)\\neq 1-P(A|B)\\), como anunciábamos que en general sucede. Calculad las probabilidades anteriores mediante el método de las frecuencias naturales. Ejemplo 4.9 Un test para el VIH da positivo en un 99% de los casos en los que el virus está presente. En una población con el 0.5% de infectados por VIH: ¿Cuál es la probabilidad de que si hacemos el test a un infectado, dé positivo? ¿Cuál es la probabilidad de que hagamos el test a un infectado y dé positivo? La respuesta a la primera pregunta nos la dan en el enunciado: “el test da positivo en un 99% de los casos en los que el virus está presente”, por lo que “la probabilidad de que si hacemos el test a un infectado, dé positivo” es 0.99. Pero la segunda pregunta no pide lo mismo que la primera, sino la probabilidad de que pasen dos cosas: que hagamos el test a un infectado Y que dé positivo. Es la probabilidad de una intersección. Pongamos nombres: \\(A\\): Estar infectado; \\(P(A)=0.005\\) \\(B\\): Dar positivo. De este suceso, sabemos solo la probabilidad condicionada \\(P(B|A)=0.99\\) \\(A\\cap B\\): Estar infectado y dar positivo. Es el suceso del que nos piden la probabilidad. \\[ P(B|A)=\\frac{P(A \\cap B)}{P(A)}\\Longrightarrow P(A \\cap B)=P(B|A)\\cdot P(A)=0.99\\cdot 0.005=0.00495 \\] La probabilidad de que, al hacer el test a un individuo al azar, dé positivo y esté infectado es del 0.495%. Ejemplo 4.10 Un amigo cardiólogo nos contó una vez que la mitad de los enfermos que acudían a su consulta por supuestos problemas de corazón tenían en realidad estrés, y dos tercios, depresión. Nosotros vamos a suponer además que sólo un 15% de estos enfermos no sufrían ninguna de estas dos condiciones. ¿Cuál es la probabilidad de que un enfermo de estos tenga estrés si tiene depresión? ¿Cuál es la probabilidad de que un enfermo de estos no tenga estrés si no tiene depresión? Esta vez vamos a usar primero el método de frecuencias naturales. Vamos a suponer que tenemos una población de referencia de 300 personas que acuden al cardiólogo. La mitad, 150, tienen estrés y las otras 150 no. Dos tercios, 200, tienen depresión y 100 no. Hay un 15% de la población, es decir, 45 sujetos que no tienen ninguna de las dos condiciones. En resumen, por ahora tenemos que \\[ \\begin{array}{r|c|c|c} &amp; \\text{Depresión} &amp; \\text{No depresión} &amp; \\text{Total}\\\\ \\hline \\text{Estrés} &amp; &amp; &amp; 150 \\\\ \\hline \\text{No estrés} &amp; &amp; 45 &amp; 150 \\\\ \\hline \\text{Total} &amp; 200 &amp; 100 &amp; 300\\\\ \\end{array} \\] Ahora: De los 150 que no tienen estrés, como 45 tampoco tienen depresión, hay 105 que sí que tienen depresión. De los 100 que no tienen depresión, como 45 tampoco tienen estrés, hay 55 que sí que tienen estrés. De los 150 que tienen estrés, como 55 no tienen depresión, hay 95 que sí tienen estrés. Ya tenemos la tabla de frecuencias completa: \\[ \\begin{array}{r|c|c|c} &amp; \\text{Depresión} &amp; \\text{No depresión} &amp; \\text{Total}\\\\ \\hline \\text{Estrés} &amp; 95 &amp; 55 &amp; 150 \\\\ \\hline \\text{No estrés} &amp; 105 &amp; 45 &amp; 150 \\\\ \\hline \\text{Total} &amp; 200 &amp; 100 &amp; 300\\\\ \\end{array} \\] Y ahora: Como hay 200 pacientes con depresión, de los cuales 95 tienen también estrés, la proporción de pacientes con depresión que tienen estrés es 95/200=0.475. Un 47.5% de los pacientes que tienen depresión, también tienen estrés. Como hay 100 pacientes sin depresión, de los cuales 45 no tienen estrés, la proporción de pacientes sin depresión que tampoco tienen estrés es 45/100=0.45. Un 45% de los pacientes que no tienen depresión, tampoco tienen estrés ¿Cómo lo hubiéramos resuelto usando las propiedades de probabilidades? Pongamos nombres: \\(E\\): Tener estrés; \\(P(E)=0.5\\) \\(D\\): Tener depresión; \\(P(D)=2/3\\) \\(E^c \\cap D^c\\): No tener ni estrés ni depresión; \\(P(E^c\\cap D^c)=0.15\\) Con estas notaciones, en la primera pregunta nos piden \\[ P(E|D)=\\dfrac{P(E\\cap D)}{P(D)} \\] Para calcularla, necesitamos saber \\(P(E\\cap D)\\), que vale: \\[ P(E\\cap D)=P(E)P(D)=0.5\\cdot \\frac{2}{3}=0.3333 \\] ¡Que no! ¡Que la probabilidad de la intersección NO es en general igual al producto de las probabilidades! Habrá que currárselo algo más: \\(P((E\\cup D)^c)=P(E^c\\cap D^c)=0.15\\), por lo tanto \\(P(E\\cup D)=1-P((E\\cup D)^c)=0.85\\) \\(P(E\\cap D)=P(E)+P(D)-P(E\\cup D)=0.5+2/3-0.85=0.31667\\) Ahora sí, finalmente, \\(P(E|D)=P(E\\cap D)/P(D)=0.31667/0.66667=0.475\\) En la segunda pregunta nos piden \\[ P(E^c|D^c)=\\dfrac{P(E^c\\cap D^c)}{P(D^c)} \\] y esta probabilidad ya la podemos calcular, porque sabemos que \\(P(E^c\\cap D^c)=0.15\\) y \\(P(D^c)=1-P(D)=1-2/3=1/3\\), por lo que \\(P(E^c|D^c)=P(E^c\\cap D^c)/P(D^c)=0.15/(1/3)=0.45\\). En la situación del ejemplo anterior, ¿cuál es la probabilidad de que un enfermo de estos tenga depresión si tiene estrés? ¿Y cuál la de que un enfermo de estos no tenga depresión si no tiene estrés? 4.5 Sucesos independientes Dos sucesos \\(A\\) y \\(B\\) (ambos de probabilidad no 0) son independientes cuando \\(P(B|A)=P(B)\\). Es decir: Cuando pertenecer a \\(A\\) no modifica la probabilidad de pertenecer a \\(B\\). Cuando que ocurra \\(A\\) no modifica la probabilidad de que ocurra \\(B\\). Cuando la proporción de sujetos de \\(B\\) dentro de \\(A\\) es la misma que dentro del total de la población. En esta definición los papeles de \\(A\\) y \\(B\\) son intercambiables, como muestra el resultado siguiente que, además, da una caracterización alternativa muy importante. Proposition 4.1 Dados dos sucesos \\(A,B\\), ambos de probabilidad ni 0 ni 1, las cinco condiciones siguientes son equivalentes: \\(P(A \\cap B)=P(A)\\cdot P(B)\\) \\(P(B|A)=P(B)\\) \\(P(A|B)=P(A)\\) \\(P(B|A)=P(B|A^c)\\) \\(P(A|B)=P(A|B^c)\\) En efecto, fijaos en que, por la definición de probabilidad condicionada, \\[ \\begin{array}{l} \\mathbf{P(B|A)=P(B)} \\Longleftrightarrow \\dfrac{P(A\\cap B)}{P(A)}=P(B)\\\\ \\qquad \\Longleftrightarrow \\mathbf{P(A\\cap B)=P(A)\\cdot P(B)} \\\\ \\qquad \\Longleftrightarrow \\dfrac{P(A\\cap B)}{P(B)}=P(A)\\\\ \\qquad \\Longleftrightarrow \\mathbf{P(A|B)=P(A)} \\end{array} \\] Esto demuestra (a) \\(\\Leftrightarrow\\) (b) \\(\\Leftrightarrow\\) (c). Por otro lado \\[ \\begin{array}{l} \\mathbf{P(B|A)=P(B|A^c)}\\Longleftrightarrow \\dfrac{P(A\\cap B)}{P(A)}=\\dfrac{P(A^c\\cap B)}{P(A^c)}\\\\ \\qquad \\Longleftrightarrow P(A\\cap B)P(A^c)=P(A^c\\cap B)P(A)=P(B-A)P(A)\\\\ \\qquad \\Longleftrightarrow P(A\\cap B)(1-P(A))=(P(B)-P(A\\cap B))P(A)\\\\ \\qquad \\Longleftrightarrow P(A\\cap B)-P(A\\cap B)P(A)=P(B)P(A)-P(A\\cap B)P(A)\\\\ \\qquad \\Longleftrightarrow \\mathbf{P(A\\cap B)=P(B)P(A)} \\end{array} \\] lo que demuestra (a) \\(\\Leftrightarrow\\) (d). La equivalencia (a) \\(\\Leftrightarrow\\) (e) se demuestra intercambiando los papeles de \\(A\\) y \\(B\\) en la equivalencia (a) \\(\\Leftrightarrow\\) (d). Es decir, las afirmaciones siguientes son equivalentes entre si, y definen la independencia de \\(A\\) y \\(B\\): La proporción de sujetos de \\(B\\) dentro de \\(A\\) es la misma que dentro del total de la población. La proporción de sujetos de \\(B\\) dentro de \\(A\\) es la misma que dentro del complementario de \\(A\\) La proporción de sujetos de \\(A\\) dentro de \\(B\\) es la misma que dentro del total de la población. La proporción de sujetos de \\(A\\) dentro de \\(B\\) es la misma que dentro del complementario de \\(B\\). La proporción de sujetos que son simultáneamente de \\(A\\) y de \\(B\\) es el producto de la proporción de sujetos de \\(A\\) por la proporción de sujetos de \\(B\\). A partir del resultado anterior, se deduce fácilmente que las condiciones siguientes son equivalentes: \\(A\\) y \\(B\\) son independientes. \\(A^c\\) y \\(B\\) son independientes. \\(A\\) y \\(B^c\\) son independientes. \\(A^c\\) y \\(B^c\\) son independientes. Es razonable. Decir que la probabilidad de que pase \\(A\\) no depende de si pasa \\(B\\) o no (\\(A\\) y \\(B\\) independientes), es lo mismo que decir que la probabilidad de que pase \\(A\\) no depende de que no pase \\(B\\) o sí pase (\\(A\\) y \\(B^c\\) independientes). Y si la probabilidad de que pase \\(A\\) no depende de que pase \\(B\\) o no, la probabilidad de que no pase \\(A\\) tampoco depende de que pase \\(B\\) o no. Hemos dado la definición de independencia para sucesos de probabilidad no nula. Para cubrir todos los casos, un suceso de probabilidad 0 se considera siempre independiente de cualquier otro. Es razonable, porque si \\(P(A)=0\\), entonces, como \\(A\\cap B\\subseteq A\\), también \\(P(A\\cap B)=0\\) para cualquier suceso \\(B\\), y se cumple entonces que \\(P(A\\cap B)=P(A)P(B)\\). La fórmula \\(P(A\\cap B)=P(A)P(B)\\) que tanto os gusta solo es válida cuando \\(A\\) y \\(B\\) son independientes. Más en general, dada una familia de sucesos \\(A_1,\\ldots,A_n\\), diremos que son independientes cuando, para todo subconjunto de índices \\(\\{i_1,\\ldots,i_k\\}\\subseteq \\{1,2,\\ldots,n\\}\\) se tiene que \\[ P(A_{i_1}\\cap\\cdots \\cap A_{i_k})=P(A_{i_1})\\cdots P(A_{i_k}) \\] Ejemplo 4.11 En los EEUU, un 33% de la población es hipertensa. Supongamos que escogemos al azar un estadounidense y le hacemos lanzar una moneda equilibrada. ¿Cuál es la probabilidad de que sea hipertenso y saque cara? Consideremos los sucesos: \\(A\\): Que el estadounidense sea hipertenso; \\(P(A)=0.33\\) \\(B\\): Que saque cara; \\(P(B)=0.5\\) La probabilidad que queremos calcular es \\(P(A\\cap B)\\): la probabilidad de que el sujeto sea hipertenso y saque cara. Naturalmente, ser hipertenso y sacar cara son sucesos independientes: la probabilidad de que salga cara no tiene nada que ver con la tensión arterial de quien la lanza. Por lo tanto \\[ P(A\\cap B)=P(A)\\cdot P(B)=0.33\\cdot 0.5=0.165 \\] La probabilidad de que el estadounidense escogido al azar sea hipertenso y saque cara es del 16.5%. Ejemplo 4.12 En los EEUU, el 36.5% de la población adulta es obesa, el 33% es hipertensa, y el 49.5% es obesa o hipertensa (datos del Centro de Control de Enfermedades, CDC, 2014). ¿Son la obesidad y la hipertensión sucesos independientes? Consideremos los sucesos: \\(A\\): Que un estadounidense adulto sea obeso; \\(P(A)=0.365\\) \\(B\\): Que un estadounidense adulto sea hipertenso; \\(P(B)=0.33\\) Queremos saber si es verdad que \\(P(A\\cap B)=P(A)P(B)\\). Para ello tenemos que calcular \\(P(A\\cap B)\\) a partir de los datos que tenemos: \\[ P(A \\cap B) =P(A)+P(B)-P(A\\cup B)=0.365+0.33-0.495=0.2 \\] Por otro lado, \\(P(A)\\cdot P(B)= 0.365\\cdot 0.33=0.12\\) Por lo tanto, son sucesos dependientes. De hecho, \\(P(B|A)=0.2/0.365=0.55&gt; 0.33=P(B)\\): la probabilidad de ser hipertenso entre los obesos es mayor que en el global de la población estadounidense. Ejemplo 4.13 Un cierto test da positivo en un 10% de los individuos que no tienen una determinada enfermedad. Si a un individuo sano se le realizan dos tests independientes, ¿cuál es la probabilidad de que ambos den positivo? ¿Y la de que alguno dé positivo? Consideremos los sucesos: \\(A_1\\): El primer test da positivo sobre un individuo sano \\(A_2\\): El segundo test da positivo sobre un individuo sano Sabemos que \\(P(A_1)=P(A_2)=0.1\\) y que, como las dos repeticiones del test son independientes, los sucesos \\(A_1\\) y \\(A_2\\) son independientes. Entonces: La probabilidad que los dos den positivo es \\[ P(A_1\\cap A_2) =P(A_1)\\cdot P(A_2) =0.1\\cdot 0.1=0.01 \\] La probabilidad que alguno dé positivo es \\[ \\begin{array}{rl} P(A_1\\cup A_2)\\!\\!\\!\\! &amp; =P(A_1)+P(A_2)-P(A_1\\cap A_2)\\\\ &amp; = 0.1+0.1-0.01=0.19 \\end{array} \\] Tenemos dos tests, A y B, para una determinada enfermedad. Sobre los individuos que tienen dicha enfermedad, el test A da positivo en un 95% de las ocasiones y el test B da positivo en un 90% de las ocasiones. Si a un individuo enfermo se le realizan los dos tests de manera independiente, ¿cuál es la probabilidad de que alguno dé positivo? 4.6 Odds condicionadas y odds ratios relativas En las odds y las odds ratios también podemos condicionar a una subpoblación definida por un suceso. Las odds de \\(B\\) entre los sujetos de \\(A\\) (o las odds de \\(B\\) condicionadas a \\(A\\)) son \\[ \\text{Odds}(B|A)=\\frac{P(B|A)}{P(B^c|A)} \\] Mide cuántas veces es más (o menos) probable \\(B\\) que “no \\(B\\)” entre los sujetos de \\(A\\). La odds ratio de \\(B\\) relativa a \\(A\\) es \\[ \\text{OR}(B|A)=\\frac{\\text{Odds}(B|A)}{\\text{Odds}(B|A^c)} \\] Mide cuántas veces son mayores (o menores) las odds de \\(B\\) entre los sujetos de \\(A\\) que las odds de \\(B\\) entre los sujetos de fuera de \\(A\\). Ejemplo 4.14 Volvamos a la situación del Ejemplo 4.10. Si, entre los pacientes de nuestro amigo cardiólogo, llamamos \\(E\\) al suceso “Tener estrés” y \\(D\\) al suceso “Tener depresión”, habíamos calculado que \\(P(E|D)=0.475\\) y \\(P(E^c|D^c)=0.45\\). Si habéis hecho el ejercicio que hemos propuesto tras el ejemplo habréis calculado \\(P(D|E)=0.6334\\) y \\(P(D^c|E^c)=0.3\\). Entonces: Las odds de tener estrés entre los pacientes que tienen depresión son \\[ \\text{Odds}(E|D)=\\frac{P(E|D)}{P(E^c|D)}=\\frac{0.475}{0.525}=0.905 \\] Entre los pacientes con depresión, la probabilidad de tener estrés es 0.905 veces la de no tenerlo, es decir, un 9.5% menor. Por favor, no digáis que “la probabilidad de tener estrés es 0.905 veces mayor que la de no tenerlo”. Las odds de tener estrés entre los pacientes que no tienen depresión son \\[ \\text{Odds}(E|D^c)=\\frac{P(E|D^c)}{P(E^c|D^c)}=\\frac{0.55}{0.45}=1.22 \\] Entre los pacientes sin depresión, la probabilidad de tener estrés es 1.22 veces la de no tenerlo, es decir, un 22% mayor. Las odds de tener depresión entre los pacientes que tienen estrés son \\[ \\text{Odds}(D|E)=\\frac{P(D|E)}{P(D^c|E)}=\\frac{0.6334}{0.3666}=1.73 \\] Entre los pacientes con estrés, la probabilidad de tener depresión es 1.73 veces la de no tenerla, es decir, un 73% mayor. Las odds de tener depresión entre los pacientes que no tienen estrés son \\[ \\text{Odds}(D|E^c)=\\frac{P(D|E^c)}{P(D^c|E^c)}=\\frac{0.7}{0.3}=2.33 \\] Entre los pacientes sin estrés, la probabilidad de tener depresión es 2.33 veces la de no tenerla, es decir, un 133% mayor. La odds ratio de tener estrés relativa a tener depresión es \\[ \\text{OR}(E|D)=\\frac{\\text{Odds}(E|D)}{\\text{Odds}(E|D^c)}=\\frac{0.905}{1.222}=0.74 \\] Las odds de tener estrés entre los que tienen depresión son 0.74 veces las de tener estrés entre los que no tienen depresión, es decir, un 26% menores. La odds ratio de tener depresión relativa a tener estrés es \\[ \\text{OR}(D|E)=\\frac{\\text{Odds}(D|E)}{\\text{Odds}(D|E^c)}=\\frac{1.73}{2.33}=0.74 \\] Las odds de tener depresión entre los que tienen estrés son 0.74 veces las de tener depresión entre los que no tienen estrés, es decir, de nuevo un 26% menores. Las odds de tener estrés entre los que tienen depresión son 0.74 veces las de tener estrés entre los que no tienen depresión y las odds de tener depresión entre los que tienen estrés son 0.74 veces las de tener depresión entre los que no tienen estrés. Pero no es verdad que la probabilidad de tener estrés entre los que tienen depresión sea 0.74 veces las de tener estrés entre los que no tienen depresión ni que la probabilidad de tener depresión entre los que tienen estrés sea 0.74 veces las de tener depresión entre los que no tienen estrés. Estos cocientes son \\[ \\frac{P(E|D)}{P(E|D^c)}=\\frac{0.475}{0.55}=0.864,\\quad \\frac{P(D|E)}{P(D|E^c)}=\\frac{0.6334}{0.7}=0.905 \\] La odds ratio de tener estrés relativa a tener depresión ha dado lo mismo que la odds ratio de tener depresión relativa a tener estrés. ¿Casualidad? No. El teorema siguiente va a ser muy útil en los estudios de casos y controles. Teorema 4.1 Dados dos sucesos \\(A\\) y \\(B\\), \\(\\text{OR}(A|B)=\\text{OR}(B|A)\\). Para comprobarlo, basta ir operando astutamente: \\[ \\begin{array}{l} \\text{OR}(B|A)\\!\\!\\!\\!\\! &amp;= \\dfrac{\\text{Odds}(B|A)}{\\text{Odds}(B|A^c)} = \\dfrac{P(B|A)/P(B^c|A)}{P(B|A^c)/P(B^c|A^c)}\\\\ &amp;=\\dfrac{P(B|A)\\cdot P(B^c|A^c)}{P(B^c|A)\\cdot P(B|A^c)}\\\\ &amp; =\\dfrac{P(B|A)\\cdot P(B^c|A^c)\\cdot P(A)\\cdot P(A^c)}{P(B^c|A)\\cdot P(B|A^c)\\cdot P(A)\\cdot P(A^c)}\\\\ &amp; =\\dfrac{P(B|A)\\cdot P(A)\\cdot P(B^c|A^c)\\cdot P(A^c)}{P(B^c|A)\\cdot P(A)\\cdot P(B|A^c)\\cdot P(A^c)}\\\\ &amp; =\\dfrac{P(B\\cap A)\\cdot P(B^c\\cap A^c)}{P(B^c\\cap A)\\cdot P(B\\cap A^c)}\\\\ \\text{OR}(A|B) &amp; = \\dfrac{\\text{Odds}(A|B)}{\\text{Odds}(A|B^c)} =\\dfrac{P(A|B)/P(A^c|B)}{P(A|B^c)/P(A^c|B^c)}\\\\ &amp; =\\dfrac{P(A|B)\\cdot P(A^c|B)}{P(A|B^c)\\cdot P(A^c|B)}\\\\ &amp; =\\dfrac{P(A|B)\\cdot P(A^c|B^c)\\cdot P(B)\\cdot P(B^c)}{P(A|B^c)\\cdot P(A^c|B)\\cdot P(B)\\cdot P(B^c)}\\\\ &amp; =\\dfrac{P(A|B)\\cdot P(B)\\cdot P(A^c|B^c)\\cdot P(B^c)}{P(A^c|B)\\cdot P(B)\\cdot P(A|B^c)\\cdot P(B^c)}\\\\ &amp; =\\dfrac{P(B\\cap A)\\cdot P(B^c\\cap A^c)}{P(B\\cap A^c)\\cdot P(B^c\\cap A)} \\end{array} \\] y tenemos que \\(\\text{OR}(A|B)=\\text{OR}(B|A)\\). 4.7 El teorema de la probabilidad total Volvamos a la situación del ejercicio del final de la Sección 3.3.3. Ejemplo 4.15 Tenemos una población clasificada en dos subpoblaciones, A y B; por ejemplo, expuestos y no expuestos a un factor de riesgo. La subpoblación A representa un 20% de la población y la B el 80% restante. Un 50% de la subpoblación A y un 5% de la subpoblación B presentan una cierta característica X; por ejemplo, desarrollan una enfermedad. ¿Qué proporción de la población presenta dicha característica X? Esta pregunta la podemos resolver fácilmente mediante el método de frecuencias naturales. Supongamos que nuestra población de referencia es de 1000 individuos. Entonces: 200 serán de la subpoblación A, de los cuales la mitad, 100, tendrán la característica X y los otros 100 no. 800 serán de la subpoblación B, de los cuales el 5%, 40, tendrán la característica X y los otros 760 no. Obtenemos la tabla de frecuencias siguiente: \\[ \\begin{array}{r|c|c|c} &amp; A &amp; B &amp; \\text{Total}\\\\\\hline X &amp;100 &amp; 40 &amp;140\\\\ \\hline \\text{No }X &amp;100 &amp; 760 &amp;860\\\\\\hline \\text{Total} &amp;200 &amp; 800 &amp; 1000 \\end{array} \\] Entonces la fracción de los sujetos del total de la población con la característica X es 140/1000, un 14%. ¿Cómo podríamos usar las propiedades de las probabilidades para calcular este valor? Pues simplemente teniendo en cuenta que, como los sucesos \\(A\\) y \\(B\\), definidos por las correspondientes subpoblaciones, son disjuntos y recubren toda la población, tenemos que \\[ X=(X\\cap A)\\cup (X\\cap B),\\quad (X\\cap A)\\cap (X\\cap B)=\\emptyset \\] y por lo tanto \\[ P(X)=P(X\\cap A)+P(X\\cap B)=P(X|A)P(A)+P(X|B)P(B). \\] Como \\(P(A)=0.2\\), \\(P(B)=0.8\\), \\(P(X|A)=0.5\\) y \\(P(X|B)=0.05\\) \\[ P(X)=0.5\\cdot 0.2+0.05\\cdot 0.8=0.14. \\] El ejemplo anterior es una aplicación del Teorema de la probabilidad total siguiente: Teorema 4.2 Si \\(A\\) y \\(X\\) son dos sucesos y \\(0&lt;P(A)&lt;1\\), \\[ P(X)= P(X\\cap A) +P(X\\cap A^c)=P(A)\\cdot P(X|A)+ P(A^c)\\cdot P(X|A^c) \\] Algunos de vosotros habréis usado en Bachillerato un diagrama de árbol como el siguiente para representar este teorema: Luego se calcula la probabilidad de cada “hoja” del árbol como el producto de las probabilidades del camino que llega a ella desde \\(\\Omega\\) y se calcula como \\(P(X)\\) la suma de las probabilidades de las hojas cuyo suceso contiene “\\(\\cap X\\)”. En el ejemplo anterior, este diagrama es Más en general, llamaremos una partición (o estratificación, clasificación) de una población \\(\\Omega\\) a una familia (finita) de sucesos no vacíos \\(A_1,\\ldots,A_n\\) tales que Recubren todo \\(\\Omega\\): \\(\\Omega=A_1\\cup\\cdots\\cup A_n\\). Dos a dos son disjuntos: Para cada \\(i,j\\in\\{1,\\ldots,n\\}\\), si \\(i\\neq j\\), se tiene que \\(A_i\\cap A_j=\\emptyset\\). Figura 4.13: Una partición. Por ejemplo, los sucesos \\(A\\) y \\(B\\) del Ejemplo 4.15 forman una partición de la población considerada. Teorema 4.3 Si \\(A_1\\), …, \\(A_n\\) es una partición de la población, entonces, para todo suceso \\(X\\), \\[ \\begin{array}{rl} P(X)\\!\\!\\!\\! &amp; = P(X\\cap A_1) +\\cdots+P(X\\cap A_n)\\\\ &amp; =P(A_1)\\cdot P(X|A_1)+\\cdots+ P(A_n)\\cdot P(X|A_n) \\end{array} \\] En la suma de la derecha, si algún \\(A_i\\) tiene probabilidad \\(P(A_i)=0\\), hay que tomar \\(P(A_i)P(X|A_i)=0\\). Ejemplo 4.16 Un test para el VIH da positivo un 99% de los casos en los que el virus está presente y en un 5% de los casos en los que el virus no está presente. En una población con el 0.5% de infectados por VIH, ¿cuál es la probabilidad de que un individuo escogido al azar dé positivo? En primer lugar vamos a usar el teorema de la probabilidad total para calcular esta probabilidad. Sean los sucesos: \\(A\\): Que un individuo esté infectado de VIH; \\(P(A)=0.005\\). \\(X\\): Que un individuo dé positivo en el test. Sabemos que \\(P(X|A)=0.99\\) y \\(P(X|A^c)= 0.05\\). Entonces \\[ \\begin{array}{rl} P(X) \\!\\!\\!\\! &amp; =P(A)\\cdot P(X|A)+P(A^c)\\cdot P(X|A^c) \\\\ &amp;=0.005\\cdot 0.99+0.995\\cdot 0.05=0.0547 \\end{array} \\] Usemos ahora la técnica de frecuencias naturales. Tomemos una población de referencia de 100,000 individuos. Un 0.05% están infectados: 500 infectados y 99500 no infectados. En un 99% de los infectados el test da positivo, son 495. En los 5 restantes da negativo. En un 5% de los no infectados da positivo, son 4975. En los 94525 restantes da negativo. La tabla de frecuencias resultante es \\[ \\begin{array}{l|c|c|c} &amp; \\text{Test }+ &amp; \\text{Test }- &amp; \\text{Total}\\\\ \\hline \\text{VIH} &amp; 495 &amp; 5 &amp; 500\\\\ \\hline \\text{No VIH} &amp; 4975&amp; 94525 &amp; 99500\\\\\\hline \\text{Total} &amp;5470 &amp; 94530&amp; 100000 \\end{array} \\] La proporción de personas en las que el test da positivo es 5470/100000=0.0547. Ejemplo 4.17 Un test diseñado para diagnosticar una determinada enfermedad da positivo el 94% de las veces en las que existe la enfermedad, y un 4% de las veces en las que no existe la enfermedad. A partir de un estudio masivo se estima que un 15% de la población da positivo en el test. ¿Cuál sería la prevalencia de la enfermedad? Fijaos en que si llamamos \\(E\\) al suceso “Tener la enfermedad” y \\(+\\) al suceso “Dar positivo en el test”, los datos que tenemos son \\(P(+)\\), \\(P(+|E)\\) y \\(P(+|E^c)\\), y queremos saber \\(P(E)\\). Esta cuestión se resuelve fácilmente con el Teorema de la Probabilidad Total usando \\(P(E)\\) como incógnita: \\[ \\begin{array}{l} P(+)=P(+|E)P(E)+(P+|E^c)P(E^c) \\\\ \\qquad\\Longrightarrow 0.15 =0.94 P(E)+0.04(1-P(E)) \\end{array} \\] de donde podemos despejar \\(P(E)\\): \\[ 0.11=0.9P(E)\\Rightarrow P(E)=\\frac{0.11}{0.9}=0.1222 \\] También podemos usar la técnica de frecuencias naturales. Tomamos una población de referencia de 100,000 individuos. De ellos, un 15%, 15,000, dan positivo en el test, y los 85,000 restantes, negativo. Llamemos \\(x\\) al número de enfermos, de manera que \\(100000-x\\) es el número de sanos. Sabemos que un 94% de los enfermos y un 4% de los sanos dan positivo. Por lo tanto, el número de enfermos positivos será igual a \\(0.94x\\) y el número de sanos \\(0.04(100000-x)\\). Completando la tabla para que las sumas de las filas sean correctas, obtenemos: \\[ \\begin{array}{l|c|c|c} &amp; \\text{Test }+ &amp; \\text{Test }- &amp; \\text{Total}\\\\ \\hline \\text{Enfermo} &amp; 0.94x &amp; 0.06x &amp; x \\\\ \\hline \\text{Sano} &amp; 0.04(100000-x) &amp; 0.96(100000-x) &amp; 100000-x \\\\\\hline \\text{Total} &amp; 15000 &amp; 85000 &amp; 100000 \\end{array} \\] Y ahora, por la primera columna, \\[ \\begin{array}{l} 15000=0.94x+0.04(100000-x)=0.9x+4000\\\\ \\qquad\\displaystyle \\Longrightarrow x=\\frac{11000}{0.9}=12222.22 \\end{array} \\] Por lo tanto, la prevalencia de la enfermedad es 12222.22/100000=0.1222: un 12.22%. En el estudio de Rotterdam del Ejemplo 2.13, un 21.7% de la cohorte inicial eran fumadores, un 43% habían sido fumadores pero ya no lo eran, y un 35.3% nunca habían fumado. En el primer grupo, un 26% desarrolló EPOC durante el seguimiento; entre el segundo grupo, un 13.6%, y en el tercero, un 6.4%. ¿Qué porcentaje de la cohorte desarrolló EPOC durante el seguimiento? Vamos a llamar “fumador” a un sujeto de la cohorte que o fumaba al principio del estudio, o había fumado anteriormente pero lo había dejado. ¿Qué porcentaje de estos fumadores desarrolló EPOC durante el seguimiento? El teorema de la probabilidad total se usa de manera implícita en el cálculo de tasas ajustadas: Se divide una población en estratos (sexo, grupos étnicos, franjas de edad…). Se calcula la proporción de algo en cada estrato. Se deduce la proporción ajustada de ese algo en una población que tuviera una composición estándar de esos estratos. Por ejemplo, para obtener la tasa de mortalidad de una enfermedad en España ajustada a la composición en franjas de edad de la Unión Europea: Se obtiene la tasa de mortalidad de la enfermedad por franjas de edad en España. Se toma como composición en franjas de edad la de la Unión Europea. Se calcula la tasa de mortalidad de esa enfermedad en una población cuya composición en franjas de edad fuera la europea y en la que la tasa de mortalidad en cada franja de edad fuera la española. Calculando estas tasas ajustadas para varios países de la UE, se pueden comparar sus tasas de mortalidad evitando el factor de confusión que podría representar la edad. Ejemplo 4.18 Una cierta enfermedad tiene en China una tasa de mortalidad del 0.1% entre los menores de 15 años, del 0.3% entre las personas de 15 a 64 años y de un 0.7% entre los mayores de 65 años. En la Unión Europea, un 15.5% de la población es menor de 15 años, un 65.4% tiene entre 15 y 64 años, y un 19.1% tiene 65 años o más. En China, estas proporciones son del 17.6%, 71.2% y 11.2%, respectivamente ¿Cuál es la tasa de mortalidad de esta enfermedad en China? ¿Cuál sería la tasa de mortalidad de esta enfermedad ajustada a la distribución de edades de la Unión Europea? Pongamos nombres a los sucesos de interés: \\(M\\): Morir de la enfermedad \\(C_1\\): Tener menos de 15 años en China; \\(P(C_1)=0.176\\) \\(C_2\\): Tener entre 15 y 64 años en China; \\(P(C_2)=0.712\\) \\(C_3\\): Tener 65 años o más en China; \\(P(C_3)=0.112\\) \\(E_1\\): Tener menos de 15 años en la UE; \\(P(E_1)=0.115\\) \\(E_2\\): Tener entre 15 y 64 años en la UE; \\(P(E_2)=0.654\\) \\(E_3\\): Tener 65 años o más en la UE; \\(P(E_3)=0.191\\) Tenemos que \\(P(M|C_1)=0.001\\), \\(P(M|C_2)=0.003\\) y \\(P(M|C_3)=0.007\\). Por el teorema de la probabilidad total, la tasa de mortalidad en China es \\[ \\begin{array}{rl} P(M)\\!\\!\\!\\! &amp;=P(M|C_1)\\cdot P(C_1)+P(M|C_2)\\cdot P(C_2)+P(M|C_3)\\cdot P(C_3)\\\\ &amp; =0.001\\cdot 0.176+0.003\\cdot 0.712+0.007\\cdot 0.112=0.0031 \\end{array} \\] O sea, del 0.31%. La tasa de mortalidad de esta enfermedad ajustada a la distribución de edades de la UE, \\(\\mathit{TA}\\), sería la probabilidad de \\(M\\) en una población en la que cada franja de edad tuviera probabilidad como en la UE, \\(P(E_i)\\), y la tasa de mortalidad en cada franja de edad fuera como la de China, \\(P(M|C_i)\\): \\[ \\begin{array}{rl} \\mathit{TA}\\!\\!\\!\\! &amp; =P(M|C_1)\\cdot P(E_1)+P(M|C_2)\\cdot P(E_2)+P(M|C_3)\\cdot P(E_3)\\\\ &amp; =0.001\\cdot 0.115+0.003\\cdot 0.654+0.007\\cdot 0.191=0.0034 \\end{array} \\] Es decir, esta tasa de mortalidad ajustada a la UE es del 0.34%. Es un poco mayor que la “real” en China. Es razonable: vemos que la tasa de mortalidad crece con la edad, y la UE tiene una menor proporción de niños y una mayor proporción de ancianos que China. Supongamos que en los Emiratos Árabes, donde hay 256 hombres por cada 100 mujeres (en serio, datos del CIA Woldfact), un 1% de los hombres y un 2% de las mujeres sufren de una determinada enfermedad. (b) ¿Cuál es la prevalencia de esta enfermedad en esta población? (c) ¿Cuál es la prevalencia de esta enfermedad ajustada a una población con un 50% de cada sexo? ¿Os habéis fijado en que la CIA da la composición por sexos de la población mediante odds (hombres por mujer), no mediante proporciones (hombres por habitante)? 4.8 La fórmula de Bayes A menudo conocemos las probabilidades condicionadas en una dirección pero las que nos interesa saber son precisamente las probabilidades condicionadas en la dirección opuesta. Por ejemplo: En un estudio de casos y controles hemos estimado las probabilidades de que individuos sanos y enfermos hayan estado expuestos al factor de riesgo, pero lo que queremos saber son las probabilidades de que individuos expuestos y no expuestos enfermen. Podemos conocer las proporciones de individuos sanos y enfermos que dan positivo en un test diagnóstico, pero lo interesante es la probabilidad de estar enfermo si das positivo en el test (o de estar sano si das negativo). Ejemplo 4.19 Una mujer de 45 años da positivo en una mamografía anual de cribado. Si una mujer tiene cáncer de mama, la probabilidad de dar positivo en dicha prueba es del 99%, y si no lo tiene, esta probabilidad es aún del 9%. Os pide cuáles son sus probabilidades de tener cáncer de mama. ¿Qué contestaríais? Casi seguro, lo siento mucho. Del orden de un 50%. Del orden de un 10%. Tranquila, del orden de un 1%. Casi seguro de que no, del orden de un 0.1%. ¡Señora, yo estudié medicina, no matemáticas! Las preguntas de este tipo no pueden responderse sin alguna información extra. Por ejemplo, la probabilidad global de haber estado expuestos al riesgo o la prevalencia de la enfermedad en el ejemplo de los estudios de casos y controles, o la prevalencia de la enfermedad o la proporción global de positivos en el ejemplo del test diagnóstico. Ejemplo 4.20 Volved a la situación del Ejemplo 4.19. Descartada la respuesta (f), buscáis por Internet y encontráis que, según el informe “Las cifras del cáncer en España 2020” de la Sociedad Española de Oncología Médica, la prevalencia del cáncer de mama en España en el período 2013-2018 fue de 130,000 casos de cáncer de mama entre los cerca de 24,000,000 de mujeres españolas. Eso os lleva a concluir que la prevalencia del cáncer de mama entre las mujeres españolas es de alrededor del 0.5%? ¿Qué responderíais a la pregunta de la mujer? Este tipo de cuestiones se resuelve fácilmente por el método de frecuencias naturales. Ejemplo 4.21 Volvamos a la pregunta de los dos ejemplos anteriores, pero para no hacer spoilers, vamos a resolverla con otro números. Vamos a suponer que la probabilidad de dar positivo en la mamografía si se tiene cáncer es del 90% y si no se tiene, del 10%, y que la prevalencia del cáncer de mama es del 1%. Tomamos una población de referencia de 100,000 mujeres y calculamos la tabla de frecuencias en esta población correspondiente a la situación planteada. Un 1% de la población tiene cáncer de mama: 1,000 mujeres. Las 99,000 restantes, no. De las 1,000 mujeres con cáncer de mama, un 90% dan positivo en la mamografía: 900. Las 100 restantes, dan negativo De las 99,000 mujeres sin cáncer de mama, un 10% dan positivo en la mamografía: 9,900. Las 89,100 restantes dan negativo. La tabla de frecuencias resultante (donde “Test” indica la mamografía) es \\[ \\begin{array}{l|c|c|c} &amp; \\text{Test }+ &amp; \\text{Test }- &amp; \\text{Total}\\\\ \\hline \\text{Cáncer Sí} &amp; 900 &amp; 100 &amp; 1000\\\\ \\hline \\text{Cáncer No} &amp; 9900&amp; 89100 &amp; 99000\\\\\\hline \\text{Total} &amp;10800 &amp; 89200&amp; 100000 \\end{array} \\] Entonces, la proporción de mujeres con cáncer de mama entre las que dan positivo en la mamografía es de 900/10800= 0.0833: un 8.33%. La fórmula de Bayes siguiente permite resolver este tipo de problemas sin tener que recurrir a las frecuencias naturales. Teorema 4.4 Sean \\(A\\) y \\(B\\) dos sucesos. Si \\(P(A),P(B)&gt;0\\), entonces \\[ P(A|B) =\\dfrac{P(A)\\cdot P(B|A)}{P(A)\\cdot P(B|A)+P(A^c)\\cdot P(B|A^c)} \\] Esta fórmula se obtiene de \\[ P(A|B) =\\dfrac{P(A \\cap B)}{P(B)} \\] donde \\[ P(A \\cap B)=P(A)\\cdot P(B|A) \\] y, por el teorema de la probabilidad total, \\[ P(B)=P(A)\\cdot P(B|A)+P(A^c)\\cdot P(B|A^c). \\] Ejemplo 4.22 Con los números del Ejemplo 4.21, si llamamos \\(C\\) al suceso “Tener cáncer de mama” y \\(M\\) al suceso “Dar positivo en la mamografía”, tenemos que \\(P(C)=0.01\\), \\(P(M|C)=0.9\\) y \\(P(M|C^c)=0.1\\), y por lo tanto \\[ \\begin{array}{rl} P(C|M)\\!\\!\\!\\! &amp; =\\dfrac{P(C)\\cdot P(M|C)}{P(C)\\cdot P(M|C)+P(C^c)\\cdot P(M|C^c)}\\\\ &amp; =\\dfrac{0.01\\cdot 0.9}{0.01\\cdot 0.9+0.99\\cdot 0.1}=0.0833 \\end{array} \\] Más en general, si \\(A_1,A_2,\\ldots,A_n\\) es una partición de \\(\\Omega\\) y \\(X\\) un suceso y todos estos sucesos tienen probabilidad no nula, entonces \\[ P(A_i|X) =\\dfrac{P(A_i)\\cdot P(X|A_i)}{P(A_1)\\cdot P(X|A_1)+\\cdots+P(A_n)\\cdot P(X|A_n)} \\] Ejemplo 4.23 Volvemos a la situación del Ejemplo 4.16. Tenemos un test para el VIH que da positivo en un 99% de las personas en las que el virus está presente y en un 5% de las personas en las que el virus no está presente. En una población con el 0.5% de infectados por VIH, ¿cuál es la probabilidad de que un individuo que haya dado positivo en el test esté infectado? ¿Y cuál es la probabilidad de que un individuo que haya dado negativo en el test no esté infectado? Si llamamos \\(A\\) al suceso “Estar infectado por VIH” y \\(B\\) al suceso “Dar positivo en el test”, entonces: La probabilidad de que un individuo que dé positivo en el test esté infectado es \\[ \\begin{array}{rl} P(A|B)\\!\\!\\!\\! &amp; =\\dfrac{P(B|A)\\cdot P(A)}{P(B|A)\\cdot P(A)+P(B|A^c)\\cdot P(A^c)}\\\\ &amp;=\\dfrac{0.99\\cdot 0.005}{0.99\\cdot 0.005+0.05\\cdot 0.995}=0.09 \\end{array} \\] Solo un 9% de los positivos están realmente infectados. La probabilidad de que un individuo que dé negativo en el test no esté infectado es \\[ \\begin{array}{rl} P(A^c|B^c)\\!\\!\\!\\!&amp; =\\dfrac{P(B^c|A^c)\\cdot P(A^c)}{P(B^c|A)\\cdot P(A)+P(B^c|A^c)\\cdot P(A^c)}\\\\ &amp; =\\dfrac{0.95\\cdot 0.995}{0.01\\cdot 0.005+0.95\\cdot 0.995}=0.99995 \\end{array} \\] Un 99.995% de los negativos no están infectados. Ejemplo 4.24 Seguimos con el test para el VIH en una población con el 0.5% de infectados por VIH del ejemplo anterior. Supongamos ahora que a un individuo que da positivo le repetimos el test y vuelve a dar positivo. Si los resultados de las dos repeticiones del test son independientes ¿cuál es la probabilidad de que este individuo esté infectado? Sea \\(A\\) al suceso “Estar infectado por VIH” y llamemos ahora \\(B_2\\) al suceso “Dar positivo en dos repeticiones independientes del test”. Si la probabilidad de que un infectado dé positivo en un test es 0.99, la probabilidad de que dé positivo en dos tests independientes será 0.99·0.99=0.9801 (el producto de la probabilidad de dar positivo en el primero por la probabilidad de dar positivo en el segundo). Y si la probabilidad de que un no infectado dé positivo en un test es 0.05, la probabilidad de que dé positivo en dos tests independientes será 0.05·0.05=0.0025. Es decir, \\(P(B_2|A)=0.9801\\) y \\(P(B_2|A^c)=0.0025\\). Apliquemos de nuevo la fórmula de Bayes: \\[ \\begin{array}{rl} P(A|B_2)\\!\\!\\!\\! &amp; =\\dfrac{P(B_2|A)\\cdot P(A)}{P(B_2|A)\\cdot P(A)+P(B_2|A^c)\\cdot P(A^c)}\\\\ &amp;=\\dfrac{0.9801\\cdot 0.005}{0.9801\\cdot 0.005+0.0025\\cdot 0.995}=0.6633 \\end{array} \\] Con el segundo positivo, la probabilidad de infección ha subido del 9% al 66.33%. En la vida real, esta segunda probabilidad seguramente sea menor, porque algunos pacientes libres de VIH tienen moléculas en la sangre similares a los anticuerpos del VIH que detecta el test y que dan lugar a falsos positivos; por ejemplo, personas con enfermedades autoinmunes como el lupus. En estos pacientes la repeticiones de los tests no se pueden considerar independientes. Un test de detección precoz de una enfermedad da positivo el 97.5% de las veces en que existe la enfermedad, y un 12% de las veces en que no existe la enfermedad. La probabilidad de que un individuo escogido al azar tenga esta enfermedad es de un 2%. ¿Cuál es la probabilidad de que un individuo escogido al azar dé positivo en el test? ¿Cuál es la probabilidad de que un individuo escogido al azar tenga la enfermedad y dé positivo en el test? ¿Cuál es la probabilidad de que un individuo que dé positivo en el test, tenga esta enfermedad? El dar positivo en el test y el tener la enfermedad, ¿son sucesos independientes? 4.9 Test (1) Sean \\(A\\) el suceso “Ser alérgico a los gatos” y \\(B\\) el suceso “Ser asmático”. La probabilidad de que un alérgico a los gatos sea asmático es del 63%. ¿Cuál de las expresiones matemáticas siguientes representa esta afirmación? \\(P(A|B)=0.63\\) \\(P(B|A)=0.63\\) \\(P(A\\cap B)=0.63\\) \\(P(A\\cup B)=0.63\\) Ninguna de las anteriores. (2) Supongamos que la probabilidad de que un individuo de una comunidad tenga una determinada enfermedad es de 0.23. ¿Cuál o cuáles de las afirmaciones siguientes son verdaderas? Cada vez que tomemos 100 individuos al azar de esta comunidad, exactamente 23 tendrán esta enfermedad. Si observamos muchos individuos de esta comunidad, esperamos encontrar un 2.3% de individuos con esta enfermedad. Si observamos muchos individuos de esta comunidad, esperamos encontrar un 23% de individuos con esta enfermedad. Si tomamos una muestra suficientemente grande al azar de esta comunidad, encontraremos exactamente 23 individuos con esta enfermedad. (3) Si un 40% de los pacientes que tienen alguna enfermedad sobreviven un año y, de los supervivientes, un 30% muere antes de cinco años, ¿cuál es la probabilidad de que un paciente sobreviva a dicha enfermedad más de cinco años? 0.33 0.10 0.12 0.30 0.28 Ninguna de las anteriores (4) Si nos dicen que en una determinada población infantil, un 36% han tenido la varicela, un 80%, paperas, y un 70%, el sarampión, ¿cuál o cuáles de las afirmaciones siguientes sobre esta población seguro que son falsas? Nos mienten, porque la suma de estos tres porcentajes es mayor que el 100% Un 40% de esta población han pasado las tres enfermedades Un 15% de esta población han pasado la varicela y las paperas Un 25% de esta población han pasado la varicela y las paperas Un 50% de los que han pasado el sarampión, han tenido las paperas Un 75% de los que han pasado el sarampión, han tenido las paperas Ninguno de los que han tenido las paperas y el sarampión también ha pasado la varicela Todos los que han tenido las paperas y el sarampión también han pasado la varicela (5) La odds ratio de tener asma relativa a tener gato es 0.7. ¿Cuál o cuáles de las afirmaciones siguientes se deducen de este hecho? La probabilidad de tener asma si se tiene un gato es 0.7 veces la de tener asma si no se tiene un gato. La probabilidad de tener asma si se tiene un gato es menor que si no se tiene un gato. La probabilidad de tener asma si se tiene un gato es mayor que si no se tiene un gato. Las odds de tener asma si se tiene un gato son 7 a 10. La odds ratio de tener gato relativa a tener asma también es 0.7. Ninguna de las afirmaciones anteriores se puede deducir de la odds ratio que hemos dado. "],["probabilidades-elementales-aplicaciones-en-medicina.html", "Lección 5 Probabilidades elementales: Aplicaciones en medicina 5.1 Pruebas diagnósticas 5.2 Riesgos 5.3 Tratamientos 5.4 Test", " Lección 5 Probabilidades elementales: Aplicaciones en medicina En medicina, las probabilidades (recordad, las proporciones de sujetos de una población con una determinada característica) aparecen bajo diferentes términos. Por ejemplo: Riesgo de algo: La probabilidad de que pase ese algo (seguramente negativo, por la connotación de la palabra “riesgo”). Prevalencia de algo: La probabilidad de que un individuo de una población tenga ese algo en un momento determinado. Tasa de algo: Sinónimo de la “proporción” o la “fracción” de ese algo en algún “total” (por ejemplo, en una población durante un período de tiempo). Así: Al hablar de incidencia, a veces se usa el término tasa de incidencia de una enfermedad para indicar la proporción de casos nuevos de esa enfermedad en una población (sana) en un periodo determinado de tiempo, y por lo tanto es la probabilidad de que un individuo sano coja esa enfermedad durante ese período. La tasa de mortalidad de una enfermedad es la proporción de individuos de una población que mueren a causa de esa enfermedad en un período determinado de tiempo, y por tanto la probabilidad de que un individuo de esa población muera por esa enfermedad en ese período. La tasa de letalidad de una enfermedad es la proporción de enfermos (de esa enfermedad) en una población que mueren a causa de esa enfermedad en un período determinado de tiempo, y por tanto la probabilidad de que un enfermo muera por esa enfermedad en ese período. La tasa de letalidad es la tasa de mortalidad condicionada a tener la enfermedad. Ejemplo 5.1 En el artículo “Incidencia, prevalencia y mortalidad del cáncer renal en España: estimaciones y proyecciones para el período 1998-2022” (Actas Urológicas Españolas 36 (2012), pp. 521-526) se puede leer: En hombres se espera un aumento de la tasa de incidencia [del cáncer de riñón] de 11.92 casos por 100,000 habitantes/año a 15.7. La prevalencia aumentaría de 72.842 a 94.47 y la mortalidad de 5.77 a 7.29. En todos los casos se trata de estimaciones de probabilidades. Se estima que: La probabilidad de que un hombre español sano enfermara de cáncer de riñón en 1998 fue de 11.92/100000=0.0001192 y en 2022 iba a ser de 0.000157. La probabilidad de que un hombre español tuviera cáncer de riñón en 1998 fue de 0.00072842 y en 2022 iba a ser de 0.0009447. La probabilidad de que un hombre español muriera de cáncer de riñón en 1998 fue de 0.0000577 y en 2022 iba a ser de 0.0000729. Leído en el MallorcaDiario.com: “La tasa de mortalidad a causa del COVID-19 en Baleares fue del 1.06 por ciento frente al 2.17 por ciento a nivel nacional […]. En el caso de personas mayores de 74, la tasa de mortalidad de Baleares (12.74 por ciento) está casi diez puntos porcentuales por debajo que la media nacional de personas de la misma edad, que llegó hasta el 22.34 por ciento.” ¿De qué están hablando realmente, de la tasa de mortalidad de la COVID-19 o de su tasa de letalidad? 5.1 Pruebas diagnósticas Una prueba diagnóstica es cualquier proceso que se use para detectar en un individuo la presencia de una determinada condición, usualmente una patología. Por ejemplo, un test de embarazo, una determinación del nivel de un marcador tumoral, una prueba para detectar la presencia de un virus o una bacteria en el organismo, seleccionar unas cartas del tarot, etc. En la práctica, se suelen distinguir dos tipos de pruebas diagnósticas, de las que se esperan capacidades diagnósticas diferentes: Test de cribado: se realiza sobre individuos asintomáticos, con el objetivo principal de descartar que tengan la enfermedad. Test diagnóstico: se realiza en individuos que muestran síntomas o que han dado positivo en un test de cribado, con el objetivo principal de detectar la presencia de la enfermedad. Por ejemplo, distinguiríamos entre las mamografías de cribado que se realizan periódicamente a las mujeres a partir de una cierta edad, y las mamografías diagnósticas que se realizan a las mujeres a las que se ha detectado un bulto en un seno. Tanto en un caso como el otro, el objetivo de una prueba diagnóstica es diagnosticar una enfermedad. Por ahora vamos a considerar que nuestra prueba es binaria, en el sentido de que da solo dos resultados posibles: positivo o negativo, sin valores intermedios ni matices. Lo deseable sería entonces que: El resultado de la prueba sea positivo exactamente cuando el paciente tiene la enfermedad. El resultado de la prueba sea negativo exactamente cuando el paciente no tiene la enfermedad. Por desgracia, casi nunca se tiene una prueba diagnóstica cien por cien segura en este sentido. Ni tan solo para detectar si un individuo está muerto o no, por lo que parece (cf. Fig. 5.1). Por lo tanto, habrá que evaluar y describir la probabilidad que tiene una prueba de acertar. Figura 5.1: Noticia aparecida en El Comercio el 8/01/2018: https://www.elcomercio.es/asturias/preso-dado-muerto-20180108012648-ntvo.html. En medicina, se llama patognómico (etimológicamente, que permite saber (gnomónico) que se tiene una enfermedad (patos)) a un síntoma que implique con total seguridad que se tiene la enfermedad, es decir, a una prueba diagnóstica tal que todos los que dan positivo están enfermos. Pero cuidado: un síntoma patognómico garantiza la enfermedad, pero se puede tener la enfermedad sin presentar el síntoma patognómico. 5.1.1 Sensibilidad, especificidad, valores predictivos etc. Vamos a poner algunos nombres a sucesos. En una prueba diagnóstica, tenemos dos tipos de sucesos: El resultado de la prueba: \\(+\\), positivo, o \\(-\\), negativo. Como suponemos que la prueba es binaria, \\(-\\) es el complementario de \\(+\\). El estado del sujeto: \\(S\\), sano, o \\(E\\), enfermo. \\(S\\) es el complementario de \\(E\\), no hay términos medios. Es importante tener en cuenta que la clasificación de un sujeto en Enfermo o Sano usualmente se lleva a cabo mediante una prueba de referencia (gold standard), que no siempre existe y que cuando existe, puede dar diagnósticos erróneos. Nosotros vamos a suponer que siempre existe y siempre acierta y que por lo tanto podemos clasificar una persona como “sana” o “enferma”. En todo caso, esta clasificación es la que comparamos con el resultado de la prueba diagnóstica que estudiamos. Entonces, podemos clasificar los sujetos de la población según estos dos pares de sucesos complementarios: Verdaderos positivos: Sujetos enfermos sobre los que la prueba da positivo. Falsos positivos: Sujetos sanos sobre los que la prueba da positivo. Verdaderos negativos: Sujetos sanos sobre los que la prueba da negativo. Falsos negativos: Sujetos enfermos sobre los que la prueba da negativo. \\[ \\begin{array}{l} \\hphantom{TestTestTest}\\textbf{Enfermedad} \\\\ \\begin{array}{c|c|c} \\textbf{Test} &amp; E &amp; S \\\\ \\hline + &amp; \\text{Verdaderos} &amp; \\text{Falsos} \\\\[-0.5ex] &amp; \\text{positivos} &amp; \\text{positivos} \\\\ \\hline - &amp; \\text{Falsos} &amp; \\text{Verdaderos} \\\\[-0.5ex] &amp; \\text{negativos} &amp; \\text{negativos} \\end{array} \\end{array} \\] Por ejemplo, el pobre preso dado por muerto sería un falso positivo en una prueba diagnóstica de muerte (positivo si estás muerto) y un falso negativo en una prueba diagnóstica de vida (positivo si estás vivo). Dada una prueba diagnóstica: Su sensibilidad es la probabilidad de que dé positivo sobre un individuo enfermo. Es decir, \\(P(+|E)\\). Su tasa de falsos negativos es la probabilidad de que dé negativo sobre un individuo enfermo. Es decir, \\(P(-|E)\\). Su especificidad es la probabilidad de que dé negativo sobre un individuo sano. Es decir, \\(P(-|S)\\). Su tasa de falsos positivos es la probabilidad de que dé positivo sobre un individuo sano. Es decir, \\(P(+|S)\\). Observad que, como \\(+\\) y \\(-\\) son sucesos complementarios, La Tasa de falsos negativos es 1 menos la Sensibilidad: \\(P(-|E)=1-P(+|E)\\). La Tasa de falsos positivos es 1 menos la Especificidad: \\(P(+|S)=1-P(-|S)\\). Pero, aunque \\(E\\) y \\(S\\) sean sucesos complementarios, \\(P(+|E)\\neq 1-P(+|S)\\) y \\(P(-|E)\\neq 1-P(-|S)\\). Igual os es útil la regla mnemotécnica siguiente, para recordar qué es la sensibilidad y qué la especificidad: La SeNsibilidad es 1 menos la Tasa de falsos Negativos. La EsPecificidad es 1 menos la Tasa de falsos Positivos Ejemplo 5.2 Recordad el Ejemplo 4.23, en el que teníamos un test para el VIH que daba positivo en un 99% de los infectados y en un 5% de las personas libres del virus. La sensibilidad de este test es la proporción de enfermos en los que da positivo: 99%. La especificidad de este test es la proporción de sanos en los que da negativo: 95%. Y entonces, ¿qué es el 5%? Su tasa de falsos positivos: la proporción de sanos en los que da positivo. Algunas definiciones más. Dada una prueba diagnóstica: Su valor predictivo positivo (VPP) es la probabilidad de que, si da positivo, el individuo esté enfermo. Es decir, \\(P(E|+)\\). Su valor predictivo negativo (VPN) es la probabilidad de que, si da negativo, el individuo esté sano. Es decir, \\(P(S|-)\\). Un examen es una prueba diagnóstica, para determinar si un estudiante sabe (\\(E\\)) o no sabe (\\(S\\)) la materia. Si aprueba da positivo, si suspende negativo. Traducid al contexto de un examen todos los conceptos introducidos hasta ahora para pruebas diagnósticas. Normalmente conocemos estimaciones de la sensibilidad y la especificidad de una prueba, obtenidas tomando una muestra de sanos y una de enfermos y haciéndoles la prueba para ver cuántos dan positivo y cuántos negativo (Ejercicio: ¿De qué tipo de estudio se trata?). Entonces, como hemos visto en la sección sobre la fórmula de Bayes de la lección anterior, conociendo una estimación de la prevalencia \\(P(E)\\) de la enfermedad, podemos estimar los valores predictivos a partir de la especificidad y sensibilidad. Por ejemplo, recordad el enunciado (ahora completo) del Ejemplo 4.23: Un test para el VIH da positivo en un 99% de las personas en las que el virus está presente y en un 5% de las personas en las que el virus no está presente. En una población con el 0.5% de infectados por VIH, ¿cuál es la probabilidad de que un individuo que haya dado positivo en el test esté infectado? ¿Y cuál es la probabilidad de que un individuo que haya dado negativo en el test no esté infectado? Su traducción en la terminología introducida en esta sección es: Un test para el VIH tiene una sensibilidad del 99% y una tasa de falsos positivos del 5%. En una población con una prevalencia del VIH del 0.5%, ¿cuáles son los VPP y VPN del test? Este tipo de cuestiones se pueden resolver usando el método de frecuencias naturales o, si os gusta recordar fórmulas, mediante la fórmula de Bayes: \\[ \\begin{array}{l} \\text{VPP} = P(E|+) =\\dfrac{P(+|E)\\cdot P(E)}{P(+|E)\\cdot P(E)+P(+|S)\\cdot P(S)}\\\\ \\qquad =\\dfrac{\\text{sensibilidad}\\cdot \\text{prevalencia}}{\\text{sensibilidad}\\cdot \\text{prevalencia}+(1-\\text{especificidad})(1-\\text{prevalencia})}\\\\[2ex] \\text{VPN} = P(S|-)=\\dfrac{P(-|S)\\cdot P(S)}{P(-|S)\\cdot P(S)+P(-|E)\\cdot P(E)}\\\\ \\qquad =\\dfrac{\\text{especificidad}\\cdot (1-\\text{prevalencia})}{\\text{especificidad}\\cdot (1-\\text{prevalencia})+(1-\\text{sensibilidad})\\cdot\\text{prevalencia}} \\end{array} \\] Ejemplo 5.3 En el artículo “Sensibilidad y especificidad de los exámenes de anticuerpos antigliadina y antiendomisio” (W. Lozano et al, Archivos de Pediatría del Uruguay 73 (2002), pp. 69-73) se estimaron la sensibilidad y la especificidad de las dos técnicas analíticas mencionadas en su título para diagnosticar la enfermedad celíaca en niños. Para ello se tomaron un grupo de 50 niños celíacos y un grupo de control de 15 niños no celíacos y se les aplicaron dichas pruebas diagnósticas. La clasificación en celíacos y no celíacos se llevó a cabo mediante el diagnóstico de referencia, una biopsia de intestino delgado. En el artículo se incluye la tabla que copiamos en la Figura 5.2. (a) ¿Qué estimamos que valen la especificidad y la sensibilidad de cada una de las dos pruebas de anticuerpos estudiadas? (b) ¿Se pueden estimar los VPP y VPN de estas dos pruebas usando solo los datos de esta tabla? (c) Se estima que en el Uruguay (el país donde se realizó este estudio), de media, 1 de cada 64 niños es celíaco. ¿Qué estimamos que valen el VPP y el VPN de cada una de las dos pruebas de anticuerpos estudiadas para los niños uruguayos? (d) Se estima que en España, de media, 1 de cada 71 niños es celíaco. ¿Qué estimamos que valen el VPP y VPN de cada una de las dos pruebas de anticuerpos estudiadas para los niños españoles? Figura 5.2: Tabla 1 en el artículo “Sensibilidad y especificidad de los exámenes de anticuerpos antigliadina y antiendomisio”. Vamos a responder las preguntas para la prueba de anticuerpos antiendomisio (AAE), os dejamos la otra como ejercicio. Para la prueba AAE, tenemos la tabla de frecuencias siguiente, que es básicamente la de la derecha de la figura anterior: \\[ \\begin{array}{r|cc|c} &amp; \\text{Celíacos}\\ (E) &amp; \\text{No celíacos}\\ (S) &amp; \\text{Total} \\\\ \\hline + &amp; 47 &amp; 1 &amp; 48 \\\\ - &amp; 3 &amp; 14 &amp; 17 \\\\ \\hline \\text{Total} &amp; 50 &amp; 15 &amp; 65 \\end{array} \\] (a) Estimamos que: Su sensibilidad es \\(P(+|E)=47/50=0.94\\) Su especificidad es \\(P(-|S)= 14/15=0.9333\\) Es decir, El test AAE da positivo en un 94% de los niños celíacos. El test AAE da negativo en un 93.33% de los niños no celíacos. (b) No se pueden estimar los VPP y VPN de estas dos pruebas usando solo los datos de esta tabla. Los números de niños celíacos y no celíacos en esta muestra son artificiales, tomados ad hoc por conveniencia del estudio, y no representan las proporciones de niños celíacos y no celíacos en ninguna población. Entonces, las proporciones de celíacos entre los positivos y los negativos también son, en principio, artificiales y no representativas de nada. (c) En primer lugar vamos a calcular los valores predictivos usando la fórmula de Bayes. Como \\(P(+|E)=0.94\\), \\(P(-|S)=14/15\\) y en Uruguay \\(P(E)=1/64\\), por lo que \\(P(S)=63/64\\): \\[ \\begin{array}{rl} \\text{VPP}\\!\\!\\!\\! &amp; =P(E|+)=\\dfrac{P(+|E)\\cdot P(E)}{P(+|E)\\cdot P(E)+P(+|S)\\cdot P(S)}\\\\ &amp;= \\dfrac{0.94\\cdot \\frac{1}{64}}{0.94\\cdot \\frac{1}{64}+\\frac{1}{15}\\cdot \\frac{63}{64}}=0.1829\\\\[1ex] \\text{VPN} \\!\\!\\!\\!&amp; =P(S|-)=\\dfrac{P(-|S)\\cdot P(S)}{P(-|S)\\cdot P(S)+P(-|E)\\cdot P(E)}\\\\ &amp;= \\dfrac{\\frac{14}{15}\\cdot \\frac{63}{64}}{\\frac{14}{15}\\cdot \\frac{63}{64}+0.06\\cdot \\frac{1}{64}}=0.999 \\end{array} \\] Es decir, Estimamos que un 18.29% de los niños uruguayos que dan positivo en el test AAE son celíacos. Estimamos que un 99.9% de los niños uruguayos que dan negativo en el test AAE no son celíacos. Vamos a repetir el cálculo usando frecuencias naturales. Para que nos salgan números redondos, vamos a partir de una población de referencia de 640,000 niños uruguayos. Un 1/64 son celíacos, 10,000. Los 630,000 restantes no lo son. De los 10,000 celíacos, un 94% dan positivo. Por lo tanto, 9,400 dan positivo y 600 negativo. De los 630,000 no celíacos, 14 de cada 15 dan negativo Por lo tanto, 588,000 dan negativo y 42,000 positivo. En resumen: \\[ \\begin{array}{r|c|c|c} &amp; \\text{Celíacos} &amp; \\text{No celíacos} &amp; \\text{Total} \\\\ \\hline + &amp; 9400 &amp; 42000 &amp; 51400 \\\\ \\hline - &amp; 600 &amp; 588000 &amp; 588600 \\\\ \\hline \\text{Total} &amp; 10000 &amp; 630000 &amp; 640000 \\end{array} \\] Y por lo tanto, estimamos que: \\(\\text{VPP}= 9400/51400=0.1829\\) \\(\\text{VPN}= 588000/588600=0.999\\) (d) ¿Y en España? Usando la fórmula de Bayes ahora con \\(P(E)=1/71\\), obtenemos \\[ \\begin{array}{rl} \\text{VPP}\\!\\!\\!\\! &amp; =P(E|+)=\\dfrac{P(+|E)\\cdot P(E)}{P(+|E)\\cdot P(E)+P(+|S)\\cdot P(S)}\\\\ &amp;= \\dfrac{0.94\\cdot \\frac{1}{71}}{0.94\\cdot \\frac{1}{71}+\\frac{1}{15}\\cdot \\frac{70}{71}}=0.1677\\\\[1ex] \\text{VPN} \\!\\!\\!\\!&amp; =P(S|-)=\\dfrac{P(-|S)\\cdot P(S)}{P(-|S)\\cdot P(S)+P(-|E)\\cdot P(E)}\\\\ &amp;= \\dfrac{\\frac{14}{15}\\cdot \\frac{70}{71}}{\\frac{14}{15}\\cdot \\frac{70}{71}+0.06\\cdot \\frac{1}{71}}=0.9991 \\end{array} \\] Estimamos que un 16.77% de los niños españoles que dan positivo en el test AAE son celíacos. Estimamos que un 99.91% de los niños españoles que dan negativo en el test AAE no son celíacos. Con el método de frecuencias naturales a partir de una población de referencia de 710,000 niños españoles, y razonando como antes, obtenemos: \\[ \\begin{array}{r|c|c|c} &amp; \\text{Celíacos} &amp; \\text{No celíacos} &amp; \\text{Total} \\\\ \\hline \\text{Positivos} &amp; 9400 &amp; 46666.67 &amp; 56066.67 \\\\ \\hline \\text{Negativos} &amp; 600 &amp; 653333.33 &amp; 653933.33 \\\\ \\hline \\text{Total} &amp; 10000 &amp; 700000 &amp; 710000 \\end{array} \\] Y por lo tanto, estimamos que: \\(\\text{VPP}= 9400/56066.67=0.1677\\) \\(\\text{VPN}= 653333.33/653933.33=0.9991\\) En resumen: Sensibilidad \\(P(+|E)=0.94\\), Especificidad \\(P(-|S)=14/15\\) Si la prevalencia es \\(P(E)=1/64\\), \\[ VPP=P(E|+)=0.1829,\\quad VPN=P(S|-)=0.9990 \\] Si la prevalencia es \\(P(E)=1/71\\), \\[ VPP=P(E|+)=0.1677,\\quad VPN=P(S|-)=0.9991 \\] La prevalencia de la enfermedad celíaca es menor en España que en Uruguay, y observaréis que, en España, el VPP de la prueba de anticuerpos antiendomisio es menor y su VPN mayor que en Uruguay. No es casualidad: A mayor prevalencia, el VPP es mayor y el VPN es menor. El motivo intuitivo es que si la prevalencia crece: Hay más enfermos, por lo que aumenta la probabilidad de encontrar enfermos y por lo tanto el VPP es mayor. Hay menos sanos, por lo que disminuye la probabilidad de encontrar sanos y por lo tanto el VPN es menor. El motivo matemático es el siguiente. Llamemos \\(x\\in [0,1]\\) a la prevalencia y fijemos los valores de \\(P(+|E)\\), \\(P(+|S)\\), \\(P(-|E)\\) y \\(P(-|S)\\). De esta manera, entendemos el VPP y el VPN como funciones solo en \\(x\\): \\[ \\begin{array}{l} \\text{VPP}(x) =\\dfrac{P(+|E)\\cdot x}{P(+|E)\\cdot x+P(+|S)\\cdot (1-x)}\\\\ \\text{VPN}(x) =\\dfrac{P(-|S)\\cdot (1-x)}{P(-|S)\\cdot (1-x)+P(-|E)\\cdot x} \\end{array} \\] Derivando, podréis comprobar que: La derivada de \\(\\text{VPP}(x)\\) sobre el intervalo [0,1] es positiva, y por tanto \\(\\text{VPP}(x)\\) es creciente en \\(x\\). La derivada de \\(\\text{VPN}(x)\\) sobre el intervalo [0,1] es negativa, y por tanto \\(\\text{VPP}(x)\\) es decreciente en \\(x\\). En cambio, la prevalencia no influye para nada en la sensibilidad y la especificidad de la prueba: La sensibilidad es el porcentaje de enfermos en los que la prueba da positivo, y esto es independiente de cuántos enfermos hay en la población. La especificidad es el porcentaje de sanos en los que la prueba da negativo, y esto también es independiente de cuántos individuos sanos hay en la población. La sensibilidad y la especificidad no dependen de la prevalencia, pero sí que pueden depender de otras características de una población. Por ejemplo, en “Findings From 752 081 Clinical Breast Examinations Reported to a National Screening Program From 1995 Through 1998” (J. Bobo et al, Journal of the National Cancer Institute 92 (2000), pp. 971-976), se estimaron la especificidad y la sensibilidad del examen físico clínico del pecho como prueba diagnóstica del cáncer de mama en diversos grupos de mujeres. En la tabla siguiente recogemos algunos de los datos obtenidos en ese estudio: \\[ \\begin{array}{l|ccc} \\text{Grupo} &amp; \\text{Sensibilidad} &amp; \\text{Especificidad} &amp; \\text{VPP} \\\\ \\hline &lt;40\\text{ años} &amp; 0.885 &amp; 0.860 &amp; 0.014 \\\\ 40-49\\text{ años} &amp; 0.714 &amp; 0.916 &amp; 0.036 \\\\ 50-59\\text{ años} &amp; 0.513 &amp; 0.951 &amp; 0.061 \\\\ 60-69\\text{ años} &amp; 0.572 &amp; 0.960 &amp; 0.074 \\\\ \\geqslant 70\\text{ años} &amp; 0.380 &amp; 0.968 &amp; 0.070 \\\\ \\hline \\text{Global} &amp; 0.588 &amp; 0.934 &amp; 0.043 \\end{array} \\] Las diferencias en la sensibilidad y especificidad entre las diferentes franjas de edad se deben a las diferentes características físicas de los senos a diferentes edades, que facilitan o dificultan la detección de los tumores, no a la prevalencia del cáncer. Una nueva prueba de diagnóstico rápido de una enfermedad rara, de una prevalencia estimada del 0.1%, ha mostrado tener una sensibilidad del 80% y una especificidad del 60%. (a) ¿Cuál es la probabilidad de que un individuo enfermo dé positivo en la prueba? (b) ¿Cuál es la probabilidad de que si escogemos un individuo al azar, esté enfermo y al realizarle la prueba dé positivo? (c) ¿Qué valen los valores predictivos de esta prueba? ¿Qué significan, en lenguaje llano, los valores obtenidos? (d) Si la enfermedad no fuera tan rara, digamos que su prevalencia fuera del 10%, y sin realizar ningún cálculo extra, ¿qué les pasaría a los valores predictivos de la prueba respecto de los calculados en el apartado anterior (aumentarían, disminuirían, se mantendrían igual, no se puede saber)? Justificad brevemente vuestra respuesta. Vamos a añadir algunos términos más sobre probabilidades relacionados con una prueba diagnóstica: Su tasa de positividad es la probabilidad \\(P(+)\\) de que dé positivo, es decir, la proporción de sujetos de la población total en los que da positivo. Por el Teorema de la probabilidad total, esta tasa de positividad es \\[ P(+)=P(+|E)\\cdot P(E)+P(+|S)\\cdot P(S) \\] y por lo tanto depende de la prevalencia de la enfermedad. En efecto, sustituyendo \\(P(S)=1-P(E)\\) tenemos que \\[ P(+)=(P(+|E)-P(+|S))\\cdot P(E)+P(+|S) \\] y si la prueba diagnóstica sirve para algo, tendremos que \\(P(+|E)&gt;P(+|S)\\). En este caso, \\(P(+)\\) crece si la prevalencia crece. Su exactitud (global) es la probabilidad de acertar el diagnóstico, es decir, la proporción de sujetos de la población total en los que el diagnóstico acierta: \\(P(E\\cap +)+P(S\\cap -)\\). Fijaos en que esta exactitud es igual a \\(P(+|E)\\cdot P(E)+P(-|S)\\cdot P(S)\\) y por lo tanto también depende de la prevalencia de la enfermedad. Si sustituimos \\(P(S)=1-P(E)\\) tenemos que la exactitud es \\[ (P(+|E)-P(-|S))\\cdot P(E)+P(+|S) \\] y por lo tanto es creciente en \\(P(E)\\) si la prueba diagnóstica es más sensible que específica y decreciente en \\(P(E)\\) en caso contrario. La exactitud no es \\(P(+|E)+P(-|S)\\) ni \\(P(E|+)+P(S|-)\\). Estas sumas no son la proporción de nada. Su razón de verosimilitud (likelihood ratio, en inglés) positiva, \\(\\text{LR}(+)\\), es cuántas veces es más probable un diagnóstico positivo sobre un enfermo que sobre un sano. Es decir \\[ \\text{LR}(+)=\\dfrac{P(+|E)}{P(+|S)}=\\dfrac{\\text{sensibilidad}}{1-\\text{especificidad}} \\] Un valor de \\(\\text{LR}(+)\\) por encima de 10 se toma como indicador de buen potencial diagnóstico para detectar la enfermedad. Por el contrario, un valor de \\(\\text{LR}(+)\\) cercano a 1 indica una prueba inútil: si dar positivo sobre un enfermo tiene más o menos la misma probabilidad que sobre un sano, los sucesos \\(+\\) y \\(E\\) son aproximadamente independientes. No confundáis la razón de verosimilitud positiva \\(\\text{LR}(+)\\) con las odds de dar positivo entre los enfermos \\[ \\text{Odds}(+|E)= \\dfrac{P(+|E)}{P(-|E)} \\] \\(\\text{LR}(+)\\) nos dice cuántas veces es más probable obtener un positivo en un enfermo que en un sano. \\(\\text{Odds}(+|E)\\) nos dice cuántas veces es más probable obtener un positivo que un negativo en un enfermo. Su razón de verosimilitud negativa, \\(\\text{LR}(-)\\), es cuántas veces es más probable un diagnóstico negativo sobre un enfermo que sobre un sano. Es decir \\[ \\text{LR}(-)=\\dfrac{P(-|E)}{P(-|S)}=\\dfrac{1-\\text{sensibilidad}}{\\text{especificidad}} \\] Un valor de \\(\\text{LR}(-)\\) por debajo de 0.1 se toma como indicador de buen potencial diagnóstico para descartar la enfermedad, y un valor de \\(\\text{LR}(-)\\) cercano a 1 indica de nuevo una prueba inútil en este sentido. Ejemplo 5.4 Volviendo al Ejemplo 5.3, habíamos obtenido que: La sensibilidad del test AAE es \\(P(+|E)=47/50=0.94\\). Por lo tanto, su tasa de falsos negativos es \\(P(-|E)=0.06\\). La especificidad del test AAE es \\(P(-|S)= 14/15\\). Por lo tanto, su tasa de falsos positivos es \\(P(+|S)=1/15\\). En Uruguay teníamos que \\(P(E)=1/64\\), por lo que \\(P(S)=63/64\\). Entonces: Su tasa de positividad en Uruguay es \\[ \\begin{array}{rl} P(+)\\!\\!\\!\\!\\! &amp; =P(+|E)\\cdot P(E)+P(+|S)\\cdot P(S)\\\\ &amp; =0.94\\cdot \\dfrac{1}{64}+\\dfrac{1}{15}\\cdot \\dfrac{63}{64}=0.0803 \\end{array} \\] Un 8.03% de los niños uruguayos dan positivo en el test AAE. Su exactitud en Uruguay es \\[ \\begin{array}{rl} P(E\\cap +)+P(S\\cap -)\\!\\!\\!\\!\\! &amp; =P(+|E)\\cdot P(E)+P(-|S)\\cdot P(S)\\\\ &amp; =0.94\\cdot \\dfrac{1}{64}+\\dfrac{14}{15}\\cdot \\dfrac{63}{64}=0.9334. \\end{array} \\] La prueba de anticuerpos antiendomisio acierta en un 93.34% de los niños uruguayos. Su razón de verosimilitud positiva es \\[ \\text{LR}(+)=\\dfrac{P(+|E)}{P(+|S)}=\\frac{0.94}{1/15}=14.1 \\] y su razón de verosimilitud negativa es \\[ \\text{LR}(-)=\\dfrac{P(-|E)}{P(-|S)}=\\frac{0.06}{14/15}=0.064 \\] Por lo tanto, la prueba de anticuerpos antiendomisio es valiosa tanto para detectar como para descartar la enfermedad celíaca en niños. Los cocientes de verosimilitud se utilizan para transformar las odds de tener la enfermedad a priori (antes de realizar la prueba diagnóstica) en sus odds a posteriori (tras realizar la prueba diagnóstica). En concreto, sean: \\(\\text{Odds}(E)\\): las odds de un individuo de tener la enfermedad, antes de realizar la prueba diagnóstica. \\(\\text{Odds}(E|+)\\): las odds de un individuo de tener la enfermedad si en la prueba da positivo. \\(\\text{Odds}(E|-)\\): las odds de un individuo de tener la enfermedad si en la prueba da negativo. Entonces \\[ \\begin{array}{l} \\text{Odds}(E|+)=\\text{LR}(+)\\cdot \\text{Odds}(E)\\\\ \\text{Odds}(E|-)=\\text{LR}(-)\\cdot \\text{Odds}(E) \\end{array} \\] En efecto \\[ \\begin{array}{rl} \\text{Odds}(E|+)\\!\\!\\!\\!\\! &amp; =\\dfrac{P(E|+)}{P(S|+)}=\\dfrac{P(E|+)P(+)}{P(S|+)P(+)} =\\dfrac{P(E\\cap +)}{P(S\\cap +)}\\\\ &amp; =\\dfrac{P(+|E)P(E)}{P(+|S)P(S)}=\\text{LR}(+)\\text{Odds}(E) \\end{array} \\] Para \\(\\text{Odds}(E|-)\\) el cálculo es similar. Ejemplo 5.5 Se sabe que una mujer con un hermano hemofílico tiene un 50% de probabilidades de ser portadora de una copia defectuosa del gen del factor VIII. Una prueba genética para detectar dicho gen defectuoso tiene una sensibilidad del 90% y una especificidad del 80%. Si una mujer con un hermano hemofílico se hace la prueba y da negativo, ¿cómo modifica este resultado sus odds de ser portadora? Llamemos \\(E\\) al suceso “Ser portadora de una copia defectuosa del gen del factor VIII”. Si la mujer a priori tiene un 50% de probabilidades de serlo, sus odds de serlo valen 1. Ahora sabemos que, para el test genético, \\(P(-|E)=0.1\\) y \\(P(-|S)=0.8\\), por lo que \\(\\text{LR}(-)=P(-|E)/P(-|S)=\\dfrac{1}{8}\\). Entonces, \\(\\text{Odds}(E|-)=\\text{Odds}(E)\\cdot \\text{LR}(-) =\\dfrac{1}{8}\\). Pasan de ser 1:1 a 1:8. Es decir, su “nueva probabilidad” de ser portadora es 1/9. G. Stine, en el libro “AIDS Update 1999” (Prentice Hall, 1999), explica que en 1987 se notificó a 22 donantes de sangre de Florida que habían dado positivo en un test ELISA+Western Blot de VIH, que tenía sensibilidad y especificidad ambas del 99.99%. De ellos, 7 se suicidaron. La prevalencia de VIH en su sector de población (heterosexuales de bajo riesgo) se estimaba en 1 por cada 10000. ¿Cuál era su probabilidad real de infección por VIH, sabiendo que habían dado positivo? Sospechamos que un paciente tiene tuberculosis, y decidimos hacerle un test PCR. El test concreto que vamos a usar se analizó en el estudio “Comparative Study of a Real-Time PCR Assay Targeting senX3-regX3 versus Other Molecular Strategies Commonly Used in the Diagnosis of Tuberculosis”, donde en un grupo de 76 pacientes con tuberculosis confirmada y 69 sujetos de control hubo 58 verdaderos positivos y 9 falsos positivos. (a) Estimad la sensibilidad, especificidad y cocientes de verosimilitud de esta prueba, y a partir de estos últimos valorad su capacidad diagnóstica. (b) Por la sintomatología que presenta y la prevalencia local de la tuberculosis, asignáis a priori a vuestro paciente una probabilidad del 40% de tener tuberculosis. Para esta probabilidad de tener la enfermedad, calculad el VPP y el VPN de esta prueba. (c) ¿Cuáles eran las odds de tener tuberculosis que le asignabais a este enfermo antes de realizar la prueba? Si da positivo en el test PCR, ¿cuáles son las odds de tener tuberculosis que le asignáis tras dicho positivo? Traducidlas a una probabilidad. ¿Coincide con el VPP del apartado anterior? ¿Debería? ¿Nueve palabras para describir aspectos de una prueba diagnóstica? Pues preparaos, que vienen curvas. Literalmente. Lo sentimos, una parte importante de esta asignatura es aprender el vocabulario que se usa al aplicar estadística en medicina. Ya lo dice el autor de Reglas Médicas: Figura 5.3: Los aspirantes a médicos no os podéis perder la magnífica Reglas médicas en Twitter o Facebook. 5.1.2 Curvas ROC En la sección anterior hemos considerado solamente pruebas binarias, que dan positivo o negativo sin ninguna gradación intermedia. Pero muchas veces una prueba diagnóstica puede dar valores en un intervalo de números reales: por ejemplo, la concentración de algún metabolito o el nivel de algún antígeno. En este caso, lo habitual es tomar un valor de corte y definir como positivo todo valor por encima de ese valor de corte (o por debajo, eso va a depender de la prueba concreta) y como negativo lo contrario. Por ejemplo, en el diagnóstico de la diabetes por medio del nivel de glucosa en sangre en ayunas, se toma como positivo un valor por encima de un cierto umbral. En cambio, en el diagnóstico de la anemia por medio del hematocrito, se toma como positivo un valor por debajo de un cierto umbral. De esta manera pasamos de una prueba diagnóstica que puede tomar todo un continuo de valores a una prueba binaria como las de la sección anterior, con su sensibilidad y su especificidad. Pero ¿cómo se ha llegado a definir el valor de corte que se usa para distinguir positivo de negativo? ¿Y cómo hemos de tener en cuenta que la prueba pueda tomar muchos resultados? Para simplificar el lenguaje y fijar ideas, vamos a suponer que los enfermos obtienen un valor anormalmente alto en la prueba diagnóstica, y que por lo tanto queremos definir como positivo cualquier valor por encima de un umbral. La prueba puede dar muchos valores, y para cada valor el test binario asociado tendrá una especificidad y una sensibilidad. La eficacia diagnóstica global de esta prueba diagnóstica se representa gráficamente por medio de una curva ROC (de Receiver Operating Characteristic). Esta curva se obtiene de la manera siguiente: Tomamos varios valores de corte \\(v\\). Para cada uno de estos valores de corte \\(v\\), consideramos el test binario que define. Hemos quedado en que, para fijar ideas, este test da positivo para los valores por encima de \\(v\\) y negativo para los valores por debajo de \\(v\\). Para cada uno de ellos, sean: \\(+_{v}\\): el suceso “Dar positivo en este test” (dar en la prueba un valor \\(\\geqslant v\\)). \\(-_{v}\\): el suceso “Dar negativo en este test” (dar en la prueba un valor \\(&lt; v\\)). Sensibilidad\\({}_{v} = P(+_{v}|E)\\): la sensibilidad de este test, es decir, la probabilidad de que un individuo enfermo dé un valor \\(\\geqslant v\\). Especificidad\\({}_{v} = P(-_{v}|S)\\): la especificidad de este test, es decir, la probabilidad de que un individuo sano dé un valor \\(&lt; v\\). Para cada test asociado a un valor de corte \\(v\\), definimos el punto del plano real de abscisa su tasa de falsos positivos y ordenada su sensibilidad: \\[ \\big(P(+_v|S),P(+_v|E)\\big)=(1-\\text{especificidad}_v,\\text{sensibilidad}_v) \\] Dibujamos estos puntos y los unimos por una recta poligonal (que parecerá una curva si tomamos muchos valores de corte \\(v\\)). El resultado es un gráfico como el siguiente: Figura 5.4: Una curva ROC. Teorema 5.1 Una curva ROC siempre es creciente. Veámoslo en la situación que estábamos considerando en la que definimos positivo cuando el valor obtenido es mayor que un umbral. En este caso, si \\(a&lt;b\\) entonces el test con umbral \\(b\\) da menos positivos que el test con umbral \\(a\\). En efecto, si \\(a&lt;b\\), todos los que dan positivo con valor de corte \\(b\\) también dan positivo con valor de corte \\(a\\), pero un individuo puede dar un resultado entre \\(a\\) e \\(b\\), que será positivo con valor de corte \\(a\\) y negativo con valor de corte \\(b\\). Por lo tanto, si \\(a&lt;b\\), se tiene que, como sucesos, \\[ +_b\\subseteq +_a \\] y por consiguiente \\[ P(+_b|S)\\leqslant P(+_a|S),\\quad P(+_b|E)\\leqslant P(+_a|E) \\] Esto nos dice que el punto de la curva ROC correspondiente al valor de corte \\(b\\), que es \\(\\big(P(+_b|S),P(+_b|E)\\big)\\), estará a la izquierda y por debajo del punto correspondiente al valor de corte \\(a\\), \\(\\big(P(+_a|S),P(+_a|E)\\big)\\). Esto implica que, en este caso la curva ROC es creciente. En efecto, si tenemos dos puntos, correspondientes a valores de corte \\(s\\) y \\(t\\) y \\(P(+_s|S)&lt; P(+_t|S)\\) (la abscisa del primero es más pequeña que la del segundo), entonces, por lo que acabamos de ver, \\(t&lt;s\\) y por lo tanto \\(P(+_s|E)\\leqslant P(+_t|E)\\): la ordenada del primero es menor o igual que la del segundo. Si hubiéramos definido positivo cuando el valor obtenido es menor que un umbral, entonces, cuando \\(a&lt;b\\), el test con umbral \\(b\\) daría más positivos que el test con umbral \\(a\\) y por lo tanto el punto \\(\\big(P(+_b|S),P(+_b|E)\\big)\\) estaría a la derecha y por encima del punto \\(\\big(P(+_a|S),P(+_a|E)\\big)\\). Por el mismo argumento que antes, en este caso también tenemos que la curva ROC es creciente. Ejemplo 5.6 Vamos a dibujar una curva ROC. El artículo “Age-specific reference ranges for serum prostate-specific antigen in black men” (T. Morgan et al, New England Journal of Medicine 335 (1996), pp. 304-310) contiene la tabla que hemos copiado en la Figura 5.5. Esta tabla da la especificidad y la sensibilidad del diagnóstico del cáncer de próstata por medio del nivel de PSA (abreviatura de antígeno prostático específico) en diferentes poblaciones de hombres estadounidenses, definidas por razas y franjas de edad. A los hombres con cáncer de próstata más pronto o más tarde se les dispara el nivel de PSA. Por lo tanto, dado un nivel de corte de PSA, se considera como “positivo” un nivel por encima de él. En particular, en cada fila de esta tabla, se define como “positivo” el tener un nivel de PSA mayor o igual que el valor de su primera columna. Figura 5.5: Tabla 2 en el artículo “Age-specific reference ranges for serum prostate-specific antigen in black men”. La curva ROC se obtiene uniendo puntos de la forma (1-especificidad,sensibilidad). Vamos a calcular estos puntos para la subpoblación de hombres blancos entre 50 y 59 años. Vamos a añadir el nivel PSA 0: como todo el mundo va a dar positivo, tendrá sensibilidad 1 y especificidad 0. \\[ \\begin{array}{c|ccc} \\text{PSA} &amp; \\text{Especificidad}&amp; 1-\\text{Especificidad}&amp; \\text{Sensibilidad}\\\\ \\hline 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 1 &amp; 0.528 &amp; 0.472 &amp; 0.997 \\\\ 2 &amp; 0.834 &amp; 0.166 &amp;0.994\\\\ 3 &amp; 0.932 &amp; 0.068 &amp;0.978\\\\ 4 &amp; 0.974 &amp; 0.026 &amp;0.748\\\\ 5 &amp; 0.987 &amp; 0.013 &amp;0.466\\\\ 6 &amp; 0.991 &amp; 0.009 &amp;0.261\\\\ 7 &amp; 1.000 &amp; 0.000 &amp;0.118\\\\ 8 &amp; 1.000 &amp;0.000 &amp;0.093\\\\ 9 &amp; 1.000 &amp;0.000 &amp;0.078\\\\ 10 &amp; 1.000 &amp; 0.000 &amp;0.075\\\\ 11 &amp; 1.000 &amp; 0.000 &amp;0.053\\\\ 12 &amp; 1.000 &amp; 0.000 &amp; 0.043\\\\ 13 &amp; 1.000 &amp; 0.000 &amp;0.040\\\\ 14 &amp; 1.000 &amp;0.000 &amp; 0.031\\\\ 15 &amp; 1.000 &amp;0.000 &amp; 0.025\\\\ \\end{array} \\] La Figura 5.6 muestra la curva ROC que corresponde a estos valores. En ella los puntos aparecen de izquierda a derecha en orden ascendente en la tabla, es decir en orden descendente del umbral de PSA. Para ayudar a comprender mejor el gráfico, al lado de cada punto hemos anotado el valor de PSA al que corresponde y hemos estirado verticalmente el gráfico para que se puedan leer los valores de corte altos en la esquina inferior izquierda. Figura 5.6: Curva ROC de los niveles de PSA entre 0 y 15 como diagnóstico del cáncer de próstata en hombres blancos de 50 a 59 años. La curva ROC no representa la sensibilidad de la prueba en función del valor de corte. Lo que representa la curva ROC es la sensibilidad en función de la tasa de falsos positivos. Es decir, para cada tasa de falsos positivos \\(x\\), el punto de la curva ROC en la vertical de \\(x\\) nos da la sensibilidad que obtendremos tomando como umbral el valor para el que la tasa de falsos positivos es \\(x\\). Una de las aplicaciones de la curva ROC es ayudar a decidir qué valor de corte tomar para definir el test diagnóstico binario que se va a usar en la práctica. Una estrategia muy común es tomar el valor de corte óptimo: el valor \\(v_o\\) en el que la suma \\[ P(+_{v_o}|E)+P(-_{v_o}|S)=\\text{sensibilidad}_{v_o}+\\text{especificidad}_{v_o} \\] sea máxima. Esta suma menos 1 tiene nombre: es el índice de Youden del test definido por el valor de corte \\(v_0\\). Recordemos que, para cada punto de la curva ROC, Su distancia al eje vertical izquierdo \\(x=0\\) es 1 menos la especificidad. Como su ordenada es la sensibilidad, su distancia a la recta horizontal \\(y=1\\) es 1 menos la sensibilidad. Por lo tanto, el punto que corresponda a la suma máxima de especificidad y sensibilidad será el punto que dé la suma mínima de sus distancias a las rectas \\(x=0\\) e \\(y=1\\). Se trata del punto de la curva más cercano al rincón superior izquierdo \\((0,1)\\) del cuadrado unidad. Por ejemplo, para la curva ROC de la Figura 5.4, es el indicado con una flecha en el gráfico siguiente: Figura 5.7: Una curva ROC y su umbral óptimo. En el ejemplo del PSA para hombres blancos entre 50 y 59 años, tendríamos la tabla siguiente (la columna “Youden” es la suma de las dos anteriores menos 1): \\[ \\begin{array}{c|ccc} \\text{PSA} &amp; \\text{Especificidad}&amp; \\text{Sensibilidad} &amp; \\text{Youden}\\\\ \\hline 1 &amp; 0.528&amp; 0.997&amp; 0.525 \\\\ 2 &amp; 0.834 &amp;0.994&amp; 0.828\\\\ \\mathbf{3} &amp; \\mathbf{0.932} &amp;\\mathbf{0.978}&amp; \\mathbf{0.910} \\\\ 4 &amp; 0.974 &amp;0.748&amp; 0.722\\\\ 5 &amp; 0.987 &amp;0.466&amp;0.453 \\\\ 6 &amp; 0.991 &amp;0.261&amp;0.252 \\\\ 7 &amp; 1.000 &amp;0.118&amp;0.118 \\\\ 8 &amp; 1.000 &amp;0.093&amp; 0.093\\\\ 9 &amp; 1.000 &amp;0.078&amp; 0.078\\\\ 10 &amp; 1.000 &amp;0.075&amp; 0.075\\\\ 11 &amp; 1.000 &amp;0.053&amp; 0.053\\\\ 12 &amp; 1.000 &amp; 0.043&amp; 0.043 \\\\ 13 &amp; 1.000 &amp;0.040&amp; 0.040\\\\ 14 &amp; 1.000 &amp; 0.031&amp; 0.031\\\\ 15 &amp; 1.000 &amp; 0.025&amp; 0.025 \\end{array} \\] El valor de corte óptimo sería entonces tomar un valor de PSA igual a 3. También podéis observarlo en la Figura 5.6: el punto correspondiente al PSA 3 es el más cercano a la esquina superior izquierda. En la práctica, se toma como nivel de PSA a partir del cual uno se ha de preocupar en esa franja de edad el 4. ¿Por qué? Es un compromiso: en las pruebas de cribado se prima la especificidad, ya que se trata de descartar sanos, y la especificidad mejora del PSA 3 al PSA 4 manteniendo aún una sensibilidad aceptable del 75%, es decir, detectando un 75% de los enfermos. La suma de la especificidad y la sensibilidad de una prueba diagnóstica, ¿coincide con su exactitud global que hemos definido en la sección anterior? La curva ROC también se usa para evaluar la capacidad discriminatoria global de la prueba, es decir, su habilidad en general para distinguir sanos de enfermos para el conjunto de posibles umbrales. Para empezar, para que la prueba diagnóstica sirva para detectar enfermos, ha de dar positivo con más frecuencia en enfermos que en sanos, ¿cierto? Por lo tanto, requerimos que, para cada umbral la sensibilidad sea mayor que la tasa de falsos positivos. Esto significa que la curva ROC ha de estar por encima de la diagonal principal \\(y=x\\). Los puntos de esta diagonal corresponden a la situación \\(P(+|E)=P(+|S)\\). Es decir, a que el test dé positivo con la misma frecuencia en sanos que en enfermos y por lo tanto a que “estar enfermo” y “dar positivo” sean sucesos independientes. En este caso el test no sirve para nada. En el contexto de las curvas ROC, a la diagonal principal del cuadrado unidad se la llama la línea de no discriminación por este motivo. Ejemplo 5.7 Imaginaos que queremos diagnosticar una enfermedad mediante el lanzamiento de dados. Lanzas 5 dados, anotas el resultado y si supera un cierto umbral, da positivo. El estar enfermo o sano no influye para nada en el resultado del lanzamiento, por lo que para todo umbral \\(x\\) que consideremos, la probabilidad de superar ese umbral si se está sano y si se está enfermo es la misma: \\(P(+_x|E)=P(+_x|S)\\). La curva ROC de esta prueba diagnóstica sería la diagonal principal del cuadrado unidad, la línea de no discriminación. Como hemos comentado, un valor de la prueba es mejor cuanto más se acerca su punto de la curva ROC al extremo superior izquierdo del cuadrado unidad. Por lo tanto, cuanto más se se separe una curva ROC de la línea de no discriminación por encima de la misma y más se aproxime al ángulo que forman las rectas \\(x=0\\) e \\(y=1\\), mejor es la prueba globalmente. Por ejemplo, en la Figura 5.8, la curva ROC con puntos rellenos corresponde a una prueba diagnóstica con mayor capacidad discriminatoria global que la de los puntos vacíos. Figura 5.8: Dos curvas ROC. La capacidad discriminatoria global de una prueba diagnóstica se mide con su Área Bajo la Curva ROC (abreviada AUC, de area under the curve, en inglés). Este valor es, como su nombre indica, el área comprendida entre la curva ROC y el eje de abscisas \\(y=0\\) entre \\(x=0\\) y \\(x=1\\). Representa el valor promedio de la sensibilidad para todos los valores de corte de la prueba. Los que visteis integrales en Matemáticas II del Bachillerato tendríais que recordar que esta área se obtiene integrando entre 0 y 1 la función que define la curva, y que la integral dividida por la longitud de la base, que en este caso es 1, es el valor promedio de la función sobre el intervalo. Por lo tanto, para ser precisos, el AUC es el valor promedio de la sensibilidad como función de la tasa de falsos positivos, pero tampoco importa hilar tan fino. Así: AUC=0.5 es la de la línea de no discriminación. Si una curva ROC tiene AUC=0.5, consideramos que la prueba diagnóstica es inútil. AUC=1 solo es posible si la curva ROC es la recta \\(y=1\\), es decir, si todos los valores de corte tienen sensibilidad 1, lo que solo puede pasar si la prueba siempre da positivo sobre un enfermo, independientemente del valor de corte. ¿Cómo podría ser una prueba con esta curva ROC? Pues por ejemplo, imaginad que usamos la temperatura corporal para decidir si una persona está viva o muerta: para una temperatura de corte dada \\(t_0\\), diremos que la persona está viva si su temperatura es superior a \\(t_0\\) y muerta en caso contrario. Y como somos algo raros, vamos a considerar solo temperaturas entre 20 y 25 grados. Entonces, para cualquier valor de corte dentro de este rango, este test dará positivo sobre una persona viva. El motivo es que cuando la temperatura corporal es inferior a los 27 grados, se considera que la persona está clínicamente muerta. Por lo tanto, “por definición”, toda persona viva tiene una temperatura corporal superior a 27 grados. Ejemplo 5.8 En el estudio “Proteína C reactiva y lactato deshidrogenasa en el diagnóstico de la obstrucción intestinal en un servicio de urgencias” (R. Rodríguez et al, Anales del Sistema Sanitario de Navarra 39 (2016), pp. 115-122) se compararon dos técnicas analíticas de diagnóstico de la obstrucción intestinal: los niveles de la proteína C reactiva (PCR) y del enzima lactato deshidrogenasa (LDH) en plasma. La Figura 5.9 muestra las curvas ROC de ambos tests, con sus valores de AUC y los valores de corte óptimos marcados. La AUC para la prueba de la PCR es 0.8 y la de la prueba del LDH es 0.86. Por lo tanto, la segunda prueba tiene globalmente una mayor capacidad discriminatoria que la primera. Además, tomando como positivo a partir de los valores de corte óptimos en cada test, el nivel de LDH tiene especificidad y sensibilidad mayores: el punto óptimo de su curva ROC está más arriba y más a la izquierda que el otro. Figura 5.9: Curvas ROC en la Figura 1 del artículo “Proteína C reactiva y lactato deshidrogenasa en el diagnóstico de la obstrucción intestinal en un servicio de urgencias”. En los gráficos de la figura anterior hay un error. ¿Lo veis? 5.1.3 Con JAMOVI El módulo meddecide de JAMOVI (que podéis instalar, como el resto de módulos, accediendo a la Biblioteca jamovi pulsando en el signo + de la esquina superior derecha de la ventana de JAMOVI) permite, entre otras cosas, calcular los diferentes estadísticos asociados a una prueba estadística, bien sea a partir de una tabla de frecuencias como las dadas hasta ahora o a partir de una tabla de datos con el estatus (enfermo/sano) y el resultado de la prueba (positivo/negativo) de todos los sujetos de una muestra. Por ejemplo, considerad de nuevo la prueba AAE para el diagnóstico de la enfermedad celíaca en niños, para la que teníamos la tabla \\[ \\begin{array}{r|cc} &amp; E &amp; S \\\\ \\hline + &amp; 47 &amp; 1 \\\\ - &amp; 3 &amp; 14 \\end{array} \\] Vamos a la sección Medical Decision Calculator del módulo meddecide en Análisis (o, para abreviar, meddecide/Medical Decision Calculator), y entramos los valores de la tabla en las casillas correspondientes, teniendo en cuenta el significado de cada casilla, y obtenemos automáticamente en la ventana la derecha la información siguiente: La primera tabla vuelve a ser la entrada, pero con la filas y la columna totales (“Gold positive” significa que ha dado positivo con la prueba de referencia, lo que nosotros consideramos enfermo, y “Gold negative” significa que ha dado negativo con la prueba de referencia, lo que nosotros consideramos sano). La segunda tabla es un resumen de los Totales de la primera, incluyendo las sumas de las diagonales (tests acertados y tests equivocados). Finalmente, la tercera nos da los valores de la sensibilidad, la especificidad, la exactitud (accuracy), el VPP, el VPN, la LR(+) y la LR(-) estimados a partir de la muestra. Fijaos que da dos veces los valores del VPP y el VPN: como “Positive Predictive Value” y “Negative Predictive Value” y como “Post-test Disease Probability” y “Post-test Health Probability”. Y los dos están mal. Bueno, no mal: son los estimados a partir de la muestra, que en este ejemplo no sirven para nada, porque la muestra tenía números artificiales de niños celíacos y no celíacos. Para obtener los VPP y VPN correctos para una prevalencia dada, hay que marcar la casilla Prior Probability (prevalence) y entrar su valor. Veamos qué pasa si entramos la prevalencia de la enfermedad celíaca infantil en Uruguay, 1/64=0.0156: Los “Positive Predictive Value” y “Negative Predictive Value” son los mismos que antes, los estimados con la muestra, pero ahora los “Post-test Disease Probability” y “Post-test Health Probability” son los VPP y VPN correctos para la prevalencia entrada. Comprobémoslo con la prevalencia en España, que hemos quedado en que era 1/71=0.0141: Marcando la casilla Show Footnote os recuerda el significado de todas las entradas de las dos últimas tablas. Probadlo. Si en vez de los números de falsos positivos, falsos negativos etc. tenemos una tabla de datos donde para cada sujeto se ha anotado si está sano o enfermo y si ha dado positivo o negativo, en vez de meddecide/Medical Decision Calculator tenemos que usar meddecide/Medical Decision. Ejemplo 5.9 En la tabla de datos tabla A1CvsDM.csv, que podéis descargar de https://raw.githubusercontent.com/AprendeR-UIB/INREMDN/master/Dades/A1CvsDM.csv, tenemos, para una muestra de 1030 sujetos, su nivel de hemoglobina glicosilada A1C y si sufren o no de diabetes mellitus (DM). En general, los diabéticos tienen un nivel de A1C superior a las personas sanas, y se diagnostica prediabetes cuando este nivel está entre 5.7 y 6.4999, y diabetes cuando el nivel de A1C es mayor o igual que 6.5. Vamos a usar esta tabla para evaluar la capacidad diagnóstica de esta prueba. En primer lugar, descargamos este fichero y lo importamos abriéndolo con Importar especial. Cuando importamos una tabla de datos, sus columnas siempre se copian tras tres columnas en blanco llamadas A, B, C con las que por defecto se inicializa JAMOVI. Si os molestan, las podéis borrar en Variables, seleccionándolas y pulsando Eliminar. Nosotros las borraremos. Ahora tenemos que añadir una columna con los positivos y negativos de la prueba A1C. Para ello, en Datos clicamos en Agregar/Variable Calculada/Insertar o Añadir: A continuación ponemos nombre a la variable (¿qué tal “Positivo A1C”?) y en el recuadro que define la fórmula escribimos, tras el igual, A1C&gt;=6.5. Esto añadirá una nueva variable con true en los sujetos con A1C≥6.5 y false en los sujetos con A1C&lt;6.5. Finalmente, vamos a meddecide/Medical Decision. En Golden Standard elegimos la variable “DM” y como Positive level el 1 y en New test elegimos la nueva variable “Positivo A1C” y como Positive level el true. En la ventana de la derecha nos aparecen las tres tablas que nos aparecían con meddecide/Medical Decision Calculator, y su mismo significado. En particular, con esta muestra estimamos que la sensibilidad de esta prueba A1C es del 58.6% y su especificidad del 99.6%. Para dibujar curvas ROC con JAMOVI, necesitamos la tabla de datos que describa, para cada sujeto de una muestra, su nivel de la prueba diagnóstica y su clasificación como enfermos y sanos. Como ejemplo, vamos a usar la tabla A1CvsDM.csv para dibujar la curva ROC para el diagnóstico de la DM mediante el nivel de A1C. En Análisis, abrimos Regresión/Regresión logística/2 Resultados (Binomial). Seleccionamos “DM” como Variable Dependiente y “A1C” como covariable. En Niveles de Referencia seleccionamos 0 (no tener diabetes): y en Predicción marcamos Curva ROC y AUC. Entonces, en la ventana de la derecha obtenemos la curva ROC y el AUC: El módulo PsychoPDA también dibuja curvas ROC y además calcula los índices de Youden de los diferentes valores de corte para que podáis determinar el umbral óptimo. En nuestro ejemplo, tras instalarlo, seleccionaríamos PPDA/TestROC, especificaríamos A1C como “Variable dependiente” y DM como “Variable de clases” y 1 como “Clase positiva”. Marcando la casilla ROC Curve obtenemos: En la tabla superior aparecen los índices de Youden de los mejores valores de corte presentes en la tabla de datos: vemos que el máximo se da en 5.976 y que el valor estándar 6.5 no está entre los mejores. 5.2 Riesgos Como ya hemos comentado, en estudios médicos las probabilidades también aparecen como “riesgos” de que pase algo. Recordemos que, si simplificamos mucho, podemos entender que en los estudios analíticos cruzamos información sobre dos sucesos que les pueden pasar a las personas: El desenlace, que para simplificar identificaremos con enfermedad: \\(E\\) será el suceso “estar enfermo” y \\(S\\) “estar sano”, de manera que \\(S=E^c\\). Su exposición a un factor de Riesgo: \\(R\\) será el suceso “haber estado expuesto al factor de riesgo” y \\(R^c\\) su complementario. Podemos clasificar los sujetos de la población según estos dos pares de sucesos complementarios: \\[ \\begin{array}{l} \\hphantom{ExposiciónExposiciónT}\\textbf{Desenlace} \\\\ \\begin{array}{c|c|c} \\textbf{Exposición} &amp; E &amp; S \\\\ \\hline R &amp; \\text{Expuestos} &amp; \\text{Expuestos} \\\\[-0.5ex] &amp; \\text{enfermos} &amp; \\text{sanos} \\\\ \\hline R^c &amp; \\text{No expuestos} &amp; \\text{No expuestos} \\\\[-0.5ex] &amp; \\text{enfermos} &amp; \\text{sanos} \\end{array} \\end{array} \\] Fijaos en que incluso las pruebas diagnósticas se podrían interpretar en términos de exposición y desenlace: el factor de riesgo sería estar enfermo, el desenlace dar positivo en el test. Pero el lenguaje sobre riesgos va a ser muy diferente del de las pruebas diagnósticas, y además es muy lioso que la enfermedad sea la exposición. Así que preferimos no mezclar y vamos a considerar las pruebas diagnósticas y los estudios de asociación entre una exposición y un desenlace como situaciones diferentes. Vamos a llamar: Tasa de riesgo de la enfermedad en expuestos a la probabilidad de enfermar si se ha estado expuesto, es decir, a \\(P(E|R)\\). Tasa de riesgo de la enfermedad en no expuestos a la probabilidad de enfermar si no se ha estado expuesto, es decir, a \\(P(E|R^c)\\). Algunas consideraciones, que ya hemos hecho pero volvemos a repetir, sobre cuándo podemos estimar estas tasas de riesgo y cuándo no a partir de los datos de un estudio: En un estudio de cohorte, partimos de un grupo de expuestos al factor de riesgo y un grupo de no expuestos, y estudiamos la aparición posterior de la enfermedad en ambos grupos. En un estudio intervencionista, la situación es similar: sabemos quién está expuesto al factor de riesgo y quién no, porque nosotros hemos decidido a quién exponemos y a quién no, y estudiamos la aparición posterior de la enfermedad. Por lo tanto, en ambos tipos de estudios, tiene sentido usar las proporciones que observemos de expuestos y no expuestos que enferman para estimar las tasas de riesgo de la enfermedad en expuestos y no expuestos, \\(P(E|R)\\) y \\(P(E|R^c)\\). Pero en un estudio de casos y controles, partimos de un grupo de enfermos y un grupo de sanos, y estudiamos su exposición previa al factor de riesgo. Si tomamos un grupo de casos y un grupo de controles de tamaños fijados a priori y que no representen la composición en enfermos y sanos de la población, NO tiene sentido usar las proporciones que observemos de expuestos y no expuestos que han enfermado para estimar las tasas de riesgo de la enfermedad en expuestos y no expuestos, porque los números de enfermos y sanos serán “artificiales”. En este tipo de estudios, solo tiene sentido estudiar las probabilidades de \\(R\\) (y \\(R^c\\)) condicionadas a \\(E\\) y \\(E^c\\), es decir, \\(P(R|E)\\) y \\(P(R|E^c)\\) y sus complementarios. Si, en cambio, en un estudio de casos y controles la muestra es transversal y las proporciones de enfermos y sanos en la muestra son representativos de la población, entonces, pero solo entonces, sí que tendrá sentido usar las proporciones que observemos de expuestos y no expuestos que han enfermado para estimar los valores de \\(P(E|R)\\) y \\(P(E|R^c)\\). En un estudio transversal la situación es la misma que en un estudio de cohorte, o en un estudio de casos y controles con una muestra transversal. Por lo tanto, tiene sentido estimar las probabilidades \\(P(E|R)\\) y \\(P(E|R^c)\\), aunque con una matiz que puede ser importante. Si medimos la exposición y la enfermedad simultáneamente, las probabilidades \\(P(E|R)\\) y \\(P(E|R^c)\\) que estimemos serán “la probabilidad de que una persona que ahora esté expuesta (o no esté expuesta) al factor de riesgo, ahora esté enferma”. Este no siempre es el significado que nos interesa. 5.2.1 Riesgos relativos y absolutos Vamos a suponer en esta sección que queremos estudiar la asociación entre la exposición a un factor de riesgo y la aparición de una enfermedad, y que con el estudio que hemos llevado a cabo tiene sentido estimar las tasas de riesgo de la enfermedad: la probabilidad \\(P(E|R)\\) de que un expuesto enferme y la probabilidad \\(P(E|R^c)\\) de que un no expuesto enferme. El objetivo del estudio es comparar estas dos probabilidades, para ver si el riesgo de enfermar entre los expuestos es significativamente mayor que entre los no expuestos. ¿Cómo se comparan dos números? Los podemos restar o los podemos dividir. Más vocabulario: Riesgo absoluto atribuible, RA (también llamada en los últimos años Diferencia de Riesgos, DR, por motivos obvios; aquí usaremos RA): Es la diferencia entre la tasa de riesgo de la enfermedad en expuestos y en no expuestos. \\[ RA=P(E|R)-P(E|R^c). \\] Mide el incremento absoluto en la probabilidad de enfermar debido a la exposición. Riesgo relativo, RR: Es el cociente entre la tasa de riesgo de la enfermedad en expuestos y en no expuestos. \\[ RR=\\dfrac{P(E|R)}{P(E|R^c)}. \\] Mide cuántas veces es más probable enfermar entre los expuestos que entre los no expuestos. Número necesario para dañar, NND: Es el número de personas que tendríamos que exponer al factor de riesgo para que, de media, una persona adicional enfermara. Aquí adicional significa que si no hubiera estado expuesta, no habría enfermado. Veamos un ejemplo concreto de RA, RR y, sobre todo, NND, para entender mejor de qué se trata. Ejemplo 5.10 Recordad el estudio de Rotterdam del Ejemplo 2.13, en el que se observó que desarrollaron EPOC un 17.8% de los que eran fumadores al inicio del estudio o lo habían sido pero lo habían dejado, frente al 6.4% de los que nunca habían fumado. Para simplificar, a los primeros los llamaremos fumadores y a los segundos no fumadores. Estos datos nos permiten estimar que si no se es fumador (es decir, si no se fuma ni nunca se ha fumado), se tiene una probabilidad del 6.4% de contraer EPOC, mientras que si se es fumador (ahora o en el pasado), esta probabilidad es del 17.8%. En este caso, si \\(R\\) es el suceso “ser fumador” y \\(E\\) es el suceso “tener EPOC”, entonces estimamos que \\[ P(E|R)=0.178,\\quad P(E|R^c)=0.064 \\] Entonces: RR=0.178/0.064=2.78: el ser fumador multiplica por 2.78 la probabilidad de contraer EPOC, es decir la incrementa un 178%. RA=0.178-0.064=0.114: el ser fumador aumenta la probabilidad de contraer EPOC en 0.114. Como 0.114=11.4%, el ser fumador aumenta la probabilidad de contraer EPOC en un 11.4%. ¿Cómo puede un riesgo ser, al mismo tiempo, un 178% mayor y un 11.4% mayor que el otro? Lo de que “aumenta un 11.4%” es incorrecto. Si el RA es 0.114, el riesgo de EPOC entre los fumadores no es un 11.4% mayor que entre los no fumadores. Que fuera un 11.4% mayor significaría que \\[ P(E|R)=P(E|R^c)+0.114\\cdot P(E|R^c) \\] pero en nuestro caso lo que tenemos es \\[ P(E|R)=P(E|R^c)+0.114. \\] No es lo mismo. ¡Cuidado con cómo os expresáis! El riesgo de EPOC entre los no fumadores es del 6.4% y entre los fumadores es del 17.8%. Por lo tanto, el riesgo entre los fumadores es 11.4 puntos porcentuales mayor que entre los no fumadores. Cuando comparan porcentajes, los RA se expresan en puntos porcentuales. El NND en este contexto sería el número de no fumadores que tendrían que empezar a fumar para añadir 1 caso de EPOC al número esperado de casos. ¿Cómo podemos calcularlo? Veamos, estimamos que, de media, de cada 1000 personas no fumadoras, 64 contraen EPOC, y de cada 1000 personas fumadoras, 178 contraen EPOC. Por lo tanto, si tomáramos 1000 personas no fumadoras y las hiciéramos fumar, el número esperado de casos de EPOC subiría de 64 a 178. Es decir, el número esperado de casos adicionales de EPOC sería de 114. Fijaos en que estos casos de EPOC son los aportados por el fumar, ya que de las 178 personas fumadoras que tendrían EPOC entre estas 1000, 64 habrían tenido EPOC aunque no fumaran. Tenemos por tanto que si 1000 no fumadores empiezan a fumar, esperamos 114 casos adicionales de EPOC. ¿Cuántos no fumadores tendrían que empezar a fumar para que esperáramos tener 1 caso adicional de EPOC? Haced la proporción. Si 1000 no fumadores que empiezan a fumar dan lugar a 114 casos adicionales de EPOC, el número NND de no fumadores que han de empezar a fumar para obtener 1 caso extra de EPOC es \\[ \\left.\\begin{array}{ccc} 1000 &amp; \\longleftrightarrow &amp; 114\\\\ \\mathit{NND} &amp; \\longleftrightarrow &amp; 1 \\end{array}\\right\\} \\Longrightarrow \\mathit{NND}=\\frac{1000}{114}=8.8 \\] De media, por cada 8.8 personas no fumadoras que empiezan a fumar, hay un caso extra de EPOC. Recordad que cuando estimamos estos riesgos en un estudio observacional, solo se trata de asociaciones, de ninguna manera podemos inferir que la exposición cause tal o cual incremento en la probabilidad de enfermar. Aunque a veces lo digamos para simplificar el lenguaje. También nos podríamos haber planteado la pregunta al revés: ¿Cuántos fumadores tendríamos que haber evitado que empezaran a fumar para evitar 1 caso de EPOC? Repetimos el argumento usado para calcular el NND. Estimamos que, de media, de cada 1000 personas no fumadoras, 64 contraen EPOC, y de cada 1000 personas fumadoras, lo contraen 178. Por lo tanto, si tomáramos 1000 fumadores, viajáramos al pasado y les impidiéramos fumar, el número esperado de casos de EPOC bajaría de 178 a 64, es decir, bajaría en 114. Entonces, el número de fumadores que no tendrían que haber fumado nunca para evitar un caso de EPOC se obtiene con la misma proporción que antes y da lo mismo: de media, por cada 8.8 fumadores que no lo hubieran sido, se evita un caso de EPOC. Naturalmente, era de esperar: el número de personas que hay que exponer al riesgo para aumentar en 1 el número de desenlaces negativos ha de ser forzosamente el mismo que el número de personas que hay que evitar que se expongan al riesgo para disminuir en 1 el número de desenlaces negativos. Por eso no se define como un número diferente del NND. Ejemplo 5.11 En el estudio “Exposición prolongada a antibióticos y riesgo de sepsis tardía (ST) en neonatos de 1000 a &lt;1500 g: estudio de cohorte” (E. Briones et al, Gaceta Médica de México 151 (2015), pp. 306-12) se tomó una cohorte de expuestos formada 49 recién nacidos de bajo peso y con infección perinatal que fueron tratados con antibióticos desde su primer día y durante más de 5 días. Como cohorte no expuesta se tomó un grupo de 49 niños en la misma situación, pero con una duración del tratamiento de antibióticos que no superó los 5 días. Tanto unos como otros no tenían síntomas de sepsis al iniciar el tratamiento. Se les realizó un seguimiento para detectar la aparición de sepsis a partir del quinto día de vida (será lo que llamaremos sepsis tardía, ST, para abreviar). Nuestra población de interés son recién nacidos de bajo peso con infección perinatal. Denotemos por \\(R\\) el suceso “estar expuesto”, es decir, recibir el tratamiento de antibióticos durante más de 5 días, y por \\(E\\) el suceso “enfermar”, es decir, desarrollar ST. En este estudio se obtuvo la tabla de frecuencias siguiente: \\[ \\begin{array}{c|cc|c} &amp; E &amp; E^c &amp; \\text{Total}\\\\ \\hline R &amp; 32 &amp; 17 &amp; 49 \\\\ R^c &amp; 4 &amp; 45 &amp; 49\\\\ \\hline \\text{Total} &amp; 36 &amp; 62 &amp; 98 \\end{array} \\] Vamos a estimar el RA, el RR y el NND de ST para la exposición a un tratamiento de más de 5 días de antibióticos. En primer lugar, estimamos los riesgos: \\[ P(E|R)=\\frac{32}{49}=0.653,\\quad P(E|R^c)=\\frac{4}{49}=0.082 \\] Entonces: \\(RA=\\dfrac{32}{49}-\\dfrac{4}{49}=\\dfrac{28}{49}=0.571\\). El tratamiento con antibióticos durante más de 5 días aumenta en un 57.1% el riesgo de ST. ¡Que no! Aumenta 57.1 puntos porcentuales. \\(RR= \\dfrac{32/49}{4/49}=8\\). Entre los neonatos de bajo peso, el tratamiento con antibióticos durante más de 5 días multiplica por 8 el riesgo de ST, es decir, lo aumenta en un 700%. Falta el NND. De media, de cada 100 neonatos de bajo peso tratados con antibióticos ≤ 5 días, 8.2 sufren ST, y de cada 100 neonatos de bajo peso tratados con antibióticos &gt; 5 días, 65.3 sufren ST. Por lo tanto, si tomamos 100 neonatos de bajo peso y en vez de tratarlos ≤ 5 días con antibiótico los tratamos &gt; 5 días, el número esperado de casos de ST sube de 8.2 a 65.3. Es decir, si “exponemos” 100 niños, esperamos 57.1 casos de ST adicionales. Por lo tanto, para esperar 1 caso de ST adicional hay que “exponer” 100/57.1=1.75 recién nacidos. Este es el NND requerido: el número de neonatos de bajo peso con infección perinatal que tendríamos que pasar de tratar 5 días o menos con antibióticos a tratarlos más de 5 días para tener un caso de ST adicional, en el sentido de que no se daría si no se les alargara el tratamiento. De nuevo, seguramente alargar el tatamiento con antibióticos no es la causa de la sepsis tardía, sino que la causa es más bien la gravedad o persistencia de la infección que hacen necesario alargar el tratamiento. Pero lo que hemos estudiado es la relación entre la ST y la duración del tratamiento, y así tenemos que interpretar el NND. Por si no habéis caído en la cuenta: En el ejemplo del estudio de Rotterdam, el NND ha sido 1000/114=1/0.114=1/RA En el ejemplo de la sepsis tardía, el NND ha sido 100/57.1=1/0.571=1/RA. ¿Casualidad? No. Teorema 5.2 \\(NND=1/RA\\). La justificación de esta igualdad es simplemente repetir el argumento que hemos usado para calcular los NND, pero con valores genéricos para \\(P(E|R)\\) y \\(P(E|R^c)\\). Supongamos que \\(P(E|R)=x\\) y \\(P(E|R^c)=y\\), de manera que \\(RA=y-x\\). Esto significa que: Por cada 100 sujetos no expuestos, de media \\(100x\\) enferman. Por cada 100 sujetos expuestos, de media \\(100y\\) enferman. Por cada 100 sujetos que pasemos de no expuestos a expuestos, de media \\(100(y-x)\\) adicionales enfermarán. Por lo tanto, el número de sujetos que hemos de exponer de media al factor de riesgo para tener 1 enfermo adicional es \\[ \\frac{100}{100(y-x)}=\\frac{1}{y-x}=\\frac{1}{RA}. \\] Por lo tanto, la información que aportan el RA y el NND son la misma, solo que presentada de otra manera. Como podéis ver en la Figura 5.10, los autores estimaron un RR de ST de 21.1. A nosotros nos ha salido un RR de 8. ¿Cómo les puede haber salido ese RR=21.1? Continuará. Figura 5.10: Tabla 2 en el artículo “Exposición prolongada a antibióticos y riesgo de sepsis tardía (ST) en neonatos de 1000 a &lt;1500 g: estudio de cohorte”. Muchas veces nos dan los valores del RA o el RR de una exposición, pero no nos dan la tasa de riesgo en los no expuestos. Entonces, solo sabemos cuánto aumenta el riesgo pero no sabemos de qué valor parte, y esto nos impide entender completamente la situación. Aunque, si os dan el RA y el RR, podéis obtener las tasas de riesgo resolviendo un sencillo sistema lineal de ecuaciones \\[ \\left\\{\\begin{array}{l} P(E|R)-P(E|R^c)=RA\\\\ P(E|R)=RR\\cdot P(E|R^c) \\end{array}\\right. \\] Ejemplo 5.12 La página “Terapia hormonal en la menopausia y el riesgo de padecer cáncer” de la American Cancer Society recoge, entre muchos otros, los datos siguientes: Las mujeres sometidas a terapia de reemplazo hormonal reducen su riesgo de cáncer colorectal a 10 años vista en un 50%. Las mujeres sometidas a terapia de reemplazo hormonal aumentan su riesgo de cáncer de mama en los 10 años posteriores en 0.8 puntos porcentuales (8 de cada 1000). Parece que, en el cómputo global, la terapia de reemplazo hormonal previene los casos de cáncer, ¿verdad? Baja el riesgo de uno en un 50% y sube el riesgo de otro 0.8 puntos porcentuales. Pero no. Según los Cancer Stat Facts del Instituto Nacional del Cáncer (de los EEUU), la incidencia del cáncer colorectal en mujeres es de 4 por cada 10,000 anuales. Por lo tanto, de 4 casos por cada 1000 mujeres cada 10 años. La reducción en un 50% significa que baja a 2 por cada 1000. En resumen, por cada 1000 mujeres y 10 años, la terapia de reemplazo hormonal reduce en 2 el número estimado de casos de cáncer colorectal y aumenta en 8 el número estimado de casos de cáncer de mama. Por tanto, por cada 1000 mujeres y 10 años, aumenta en 6 el número esperado de casos de cáncer. ¿Cuántas mujeres hemos de empezar a tratar con terapia de reemplazo hormonal para tener 1 caso adicional de cáncer en 10 años? Insistimos. Ejemplo 5.13 Según la National Cancer Institute’s Breast Cancer tool de 1998, Las mujeres que toman tamoxiflen tienen un 49% menos de diagnósticos de cáncer invasivo de mama. La tasa anual de cáncer uterino entre las mujeres que toman tamoxiflen es de 30 por cada 10,000. En la población femenina general, esta tasa está entre 8 y 10 por cada 10,000. Pero la incidencia anual del cáncer invasivo de mama era de 18 por cada 10,000 mujeres, por lo tanto El tamoxiflen reduce del 0.18% a 0.09% el riesgo de cáncer invasivo de mama Y aumenta el riesgo de cáncer uterino de 0.09% (la media de 8 y 10 por cada 10,000) a 0.3%. Por lo tanto, en términos absolutos, aumenta del 0.27% al 0.39% el riesgo de alguno de los dos cánceres: en algo más de 1 por cada 1000 mujeres Un último ejemplo. Ejemplo 5.14 En octubre de 1995, se publicó en la prensa británica y en circulares a médicos que los anticonceptivos de 3a generación multiplicaban por 2 el riesgo de trombosis venosa (TV). Esta afirmación se basaba en varios estudios publicados o anunciados ese año, como por ejemplo el del grupo World Health Organization Collaborative Study of Cardiovascular Disease and Steroid Hormone Contraception: “Venous thromboembolic disease and combined oral contraceptives: results of international multicentre case-control study” (The Lancet 346 (1996), pp. 1575-1582). El resultado del “susto de la píldora del 1995” fue una reducción en el consumo de la píldora anticonceptiva en el Reino Unido, como muestra la tabla de la Figura 5.11, y como consecuencia que en 1996 hubiera unos 13,600 abortos más y unos 12,400 nacimientos más que en 1995. Encontraréis más detalles de esta historia y su coste social y sanitario en “Social consequences. The public health implications of the 1995 `pill scare’” (A. Furedi, Human Reproduction Update, 5 (1999), pp. 621-626). Figura 5.11: Tabla IV en el artículo “Social consequences. The public health implications of the 1995 pill scare”. Vamos a analizar la afirmación de que “los anticonceptivos de 3a generación multiplican por 2 el riesgo de TV” en términos de riesgos. Según MedSafe, entre las mujeres de entre 15 y 44 años: Entre 5/100,000 y 10/100,000 mujeres anuales padecen una TV: tomaremos la media, 7.5/100,000. Tomar anticonceptivos de 2a generación multiplica por 3.5 este riesgo (es decir, su RR es 3.5): 26.25/100,000 mujeres anuales Entonces, tomar anticonceptivos de 3a generación multiplica por 2 este último riesgo: da 52.5/100,000 mujeres anuales Por tanto, si bien el RR de los anticonceptivos de 3a generación respecto de los de 2a generación es 2, en términos absolutos solo representa un aumento esperado de 26 casos de TV por cada 100,000 mujeres que pasen de anticonceptivos de 2a a 3a generación. Pongamos estos números en perspectiva: El riesgo de TV durante o inmediatamente después del embarazo se estima en Europa de 71/100,000 (según el UpToDate “Deep vein thrombosis in pregnancy: Epidemiology, pathogenesis, and diagnosis”). Es decir, el riesgo de sufrir TV asociado a un embarazo es un 35% mayor que el de tenerla ese mismo año tomando los anticonceptivos de 3a generación. El riesgo de TV durante los 42 días posteriores a un aborto inducido es de 30/100,000 abortos. Si hacéis la proporción, veréis que el riesgo de que una mujer que tome anticonceptivos de 3a generación sufra una TV durante un periodo dado de 42 días es de 6/100,000. Por lo tanto, el aumento de embarazos y abortos por miedo al riesgo de TV si se tomaba un anticonceptivo de 3a generación de hecho aumentó el riesgo de TV en la población femenina. 5.2.2 Odds ratios En los estudios de cohorte, en los que tomamos un grupo de expuestos y uno de no expuestos y observamos en ellos la aparición de la enfermedad, siempre tiene sentido calcular los riesgos en el sentido que nos interesa: \\(P(E|R)\\) y \\(P(E|R^c)\\). Pero en un estudio de casos y controles partiendo de una muestra estratificada no tiene ningún sentido estimar los riesgos \\(P(E|R)\\) y \\(P(E|R^c)\\), y solo tiene sentido estimar las probabilidades \\(P(R|E)\\) y \\(P(R|E^c)\\), y sus complementarias \\(P(R^c|E)\\) y \\(P(R^c|E^c)\\). Si además tenemos una estimación de \\(P(E)\\), podemos girar las probabilidades condicionadas usando la fórmula de Bayes y estimar \\(P(E|R)\\) y \\(P(E|R^c)\\). Pero, ¿y si no? ¿Qué podemos hacer entonces? En este caso, se calcula la odds ratio de la exposición respecto de la enfermedad: el cociente de las odds de haber estado expuestos entre los enfermos y las odds de haber estado expuestos entre los sanos. \\[ OR(R|E)=\\frac{\\mathrm{Odds}(R|E)}{\\mathrm{Odds}(R|E^c)}=\\dfrac{P(R|E)/P(R^c|E)}{P(R|E^c)/P(R^c|E^c)} \\] Este valor tiene sentido estimarlo con los datos obtenidos en un estudio de casos y controles, porque usa las probabilidades que se pueden estimar en estos estudios. ¿Pero qué conseguimos calculándolo? En primer lugar, por el Teorema 4.1: La odds ratio \\(OR(R|E)\\) de la exposición respecto de la enfermedad coincide con la odds ratio de la enfermedad respecto de la exposición, es decir, con el cociente de las odds de enfermar entre los expuestos y las odds de enfermar entre los no expuestos: \\[ OR(E|R)=\\frac{\\mathrm{Odds}(E|R)}{\\mathrm{Odds}(E|R^c)} \\] Por lo tanto, la estimación de la odds ratio de la exposición respecto de la enfermedad también estima la odds ratio de la enfermedad respecto de la exposición. Así pues, en un estudio de casos y controles, calculando la \\(OR(R|E)\\) podemos estimar cuántas veces mayores son las odds de contraer la enfermedad si se está expuesto que si no se está expuesto. Como \\(OR(E|R)=OR(R|E)\\), a partir de ahora la denotaremos simplemente por \\(OR\\). A nosotros nos gustaría tener esta información en términos de riesgos relativos: cuántas veces mayor es la probabilidad de contraer la enfermedad si se está expuesto que si no se está expuesto. Bueno, la vida es dura, en un estudio de casos y controles este cociente no siempre se puede estimar, pero en cambio sí que siempre se puede estimar el “incremento relativo del riesgo” en términos de “incremento relativo de las odds”, mediante la odds ratio. En segundo lugar: Si la enfermedad es muy rara en el sentido de muy poco prevalente, es decir, si \\(P(E)\\) es muy pequeña, entonces la OR es aproximadamente igual al RR. En efecto, si \\(P(E)\\) es tan pequeña que \\(P(E\\cap R)\\) es mucho más pequeña que \\(P(E^c\\cap R)\\) y \\(P(E\\cap R^c)\\) es mucho más pequeña que \\(P(E^c\\cap R^c)\\), entonces \\[ \\begin{array}{rl} RR\\!\\!\\!\\! &amp; =\\dfrac{P(E|R)}{P(E|R^c)} =\\dfrac{P(E\\cap R)/P(R)}{P(E\\cap R^c)/P(R^c)}\\\\ &amp; =\\dfrac{{P(E\\cap R)}/({P(E\\cap R)+P(E^c\\cap R)})}{{P(E\\cap R^c)}/({P(E\\cap R^c)+P(E^c\\cap R^c)})}\\\\ &amp; \\approx \\dfrac{{P(E\\cap R)}/{P(E^c\\cap R)}}{{P(E\\cap R^c)}/{P(E^c\\cap R^c)}}=\\dfrac{P(E\\cap R)P(E^c\\cap R^c)}{P(E^c\\cap R) P(E\\cap R^c)}\\\\ &amp; = \\dfrac{P(E|R)P(R)P(E^c|R^c)P(R^c)}{P(E^c|R)P(R) P(E|R^c)P(R^c)}\\\\ &amp; = \\dfrac{P(E|R)P(E^c|R^c)}{P(E^c|R) P(E|R^c)}=OR \\end{array} \\] En resumen, en un estudio de casos y controles en el que los números de casos y controles no son representativos de las proporciones de enfermos y sanos en la población: No podemos estimar \\(RR=P(E|R)/P(E|R^c)\\) Sí que podemos estimar \\(OR=\\text{Odds}(R|E)/\\text{Odds}(R|E^c)\\) Resulta que \\(OR\\) es igual a la odds ratio \\(OR(E|R)\\) de enfermar relativa a estar expuesto: el cociente entre las odds de enfermar entre los expuestos y las odds de enfermar entre los no expuestos. Algo es algo. Si \\(P(E)\\) es muy pequeña, se tiene que \\(OR\\approx RR\\). En todo caso, recordad que si la muestra de sujetos usados en un estudio de casos y controles es representativa de la población, por ejemplo porque hemos tomado una muestra transversal y considerado como casos los enfermos que hemos encontrado y como controles los sanos, entonces no hace falta que nos compliquemos tanto la vida. Basándonos en esta muestra podemos estimar \\(P(E|R)\\) y \\(P(E|R^c)\\) y con ellas los RA y RR. Dado que siempre es más sencillo entender un riesgo relativo que una odds ratio, lo adecuado es calcular el RR siempre que se pueda, y solo calcular la OR cuando no haya más remedio. Pero en los artículos científicos encontraréis de todo. Antes de pasar a algunos ejemplos, veamos una fórmula sencilla para calcular la \\(OR\\) dada una tabla de frecuencias. Dada la tabla de frecuencias \\[ \\begin{array}{c|cc} &amp; E &amp; E^c \\\\ \\hline R &amp; a &amp; b \\\\ R^c &amp; c &amp; d\\\\ \\hline \\text{Total} &amp; a+c &amp; b+d \\end{array} \\] se tiene que \\(OR=\\dfrac{a\\cdot d}{b\\cdot c}\\). En efecto, \\[ \\begin{array}{l} P(R|E)=\\dfrac{a}{a+c},\\ P(R|E^c)=\\dfrac{b}{b+d}\\\\ P(R^c|E)=\\dfrac{c}{a+c},\\ P(R^c|E^c)=\\dfrac{d}{b+d} \\end{array} \\] y por lo tanto \\[ OR=\\frac{\\dfrac{a}{a+c}\\Big/\\dfrac{c}{a+c}}{\\dfrac{b}{b+d}\\Big/\\dfrac{d}{b+d}}=\\frac{a/c}{b/d}=\\frac{a\\cdot d}{b\\cdot c} \\] Ejemplo 5.15 En el estudio de casos y controles “Factores de riesgo para bacteriemia por Pseudomonas aeruginosa resistente a carbapenémicos adquirida en un hospital colombiano” (S. Valderrama et al, Biomédica 36 (2016), pp. 69-77) se tomó como casos un grupo de pacientes con bacteriemia por P. aeruginosa resistente a carbapenémicos (un determinado tipo de antibióticos) y como controles un grupo de pacientes con bacteriemia por P. aeruginosa sensible a estos antibióticos. Se midieron varias características sobre ellos, como por ejemplo si se les había administrado previamente meropenem (un carbapenémico) o nutrición parenteral. Los resultados sobre estos dos riesgos se recogen en la tabla siguiente: \\[ \\begin{array}{r|cc} &amp;\\text{Casos} &amp;\\text{Controles} \\\\[-0.5ex] \\textbf{Riesgo} &amp; (n=42) &amp; (n=126) \\\\ \\hline \\text{Nutrición parenteral} &amp; 13\\ (31\\%) &amp; 9\\ (7.2\\%) \\\\ \\hline \\text{Uso de meropenem} &amp; 16\\ (38.1\\%) &amp; 14\\ (11.1\\%) \\end{array} \\] El grupo de casos y controles se tomó con una composición específica, tres controles por caso, por lo que no podemos estimar riesgos de la “enfermedad” (resistencia de la P. aeruginosa) en función de la exposición. No hay más remedio que calcular odds ratios. Para ello tenemos que extraer una tabla de frecuencias de expuestos y no expuestos entre sanos y controles. Lo haremos para la nutrición parenteral, dejamos como ejercicio calcularla para el meropenem. La tabla de frecuencias para la nutrición parenteral es \\[ \\begin{array}{r|cc} &amp;E &amp;E^c \\\\ \\hline R &amp; 13 &amp; 9 \\\\ R^c &amp; 29 &amp; 117\\\\ \\hline \\text{Total} &amp; 42 &amp; 126 \\end{array} \\] La odds ratio es \\[ OR=\\frac{13\\cdot 117}{29\\cdot 9}=5.83 \\] Estimamos que las odds de tener una bacteriemia por P. aeruginosa resistente entre los pacientes con bacteriemia por P. aeruginosa a los que se ha administrado nutrición parenteral son 5.8 veces mayores que las de los pacientes con bacteriemia por P. aeruginosa a los que no se ha administrado nutrición parenteral. Ejemplo 5.16 Volvamos al estudio de cohorte sobre la aparición de sepsis tardía en neonatos asociada a tratamientos de más de 5 días con antibióticos del Ejemplo 5.11. Os recordamos la tabla de frecuencias que se obtuvo: \\[ \\begin{array}{c|cc|c} &amp; E &amp; E^c &amp; \\text{Total}\\\\ \\hline R &amp; 32 &amp; 17 &amp; 49 \\\\ R^c &amp; 4 &amp; 45 &amp; 49\\\\ \\hline \\text{Total} &amp; 36 &amp; 62 &amp; 98 \\end{array} \\] Estimábamos el RR: \\[ RR=\\frac{P(E|R)}{P(E|R^c)}=\\frac{32/49}{4/49}=8 \\] y decíamos que en el artículo los autores estimaban que RR=21.1. ¿De dónde sale este valor? Es la odds ratio mal redondeada: \\[ OR= \\dfrac{32\\cdot 45}{17\\cdot 4}=21.176 \\] Por lo tanto, estimamos que, entre los neonatos de bajo peso tratados con antibióticos, las odds de tener sepsis tardía entre los que han tomado antibióticos más de 5 días son 21.2 veces las de los que han recibido antibióticos 5 días o menos De esta manera vemos que los autores del artículo han cometido varios errores que vosotros tenéis que evitar: Los autores calculan la OR y dicen que se trata del RR La sepsis tardía entre neonatos a los que se administran antibióticos no es rara, por lo que es incorrecto aproximar el RR por medio de la OR Con los datos que tenían, podían estimar perfectamente el RR, si era lo que querían. 5.3 Tratamientos Los estudios de cohorte e intervencionistas sobre la efectividad de un tratamiento pueden analizarse como los de la sección anterior, solo que cambia ligeramente el lenguaje, por lo que hemos optado por tratarlos en una sección diferente. En el contexto de los estudios de tratamientos, tenemos dos sucesos básicos: El desenlace en el sujeto. Denotaremos por \\(E\\) el desenlace negativo (no se cura, se muere, recae…) y su complementario será \\(E^c\\): se cura, no se muere, no recae… El tratamiento que recibe el sujeto (que corresponde a la exposición al factor de riesgo en la sección anterior). \\(T\\) indicará que es tratado con el tratamiento objeto de estudio, y \\(T^c\\) que pertenece al grupo de control: no se le da nada, recibe placebo o el tratamiento de referencia… Podemos clasificar los sujetos de la población según estos dos pares de sucesos complementarios: \\[ \\begin{array}{l} \\hphantom{TratamientTratamientooo} \\textbf{Desenlace}\\\\ \\begin{array}{r|c|c} \\textbf{Tratamiento} &amp; E &amp; E^c \\\\ \\hline &amp; \\text{Tratados} &amp; \\text{Tratados} \\\\[-1ex] T &amp; \\text{con desenlace} &amp; \\text{con desenlace} \\\\[-1ex] &amp; \\text{negativo} &amp; \\text{positivo} \\\\ \\hline &amp; \\text{No tratados} &amp; \\text{No tratados} \\\\[-1ex] T^c &amp; \\text{con desenlace} &amp; \\text{con desenlace} \\\\[-1ex] &amp; \\text{negativo} &amp; \\text{positivo} \\end{array} \\end{array} \\] Tenemos entonces las mismas tasas de riesgo que la sección anterior: Tasa de riesgo de desenlace negativo en tratados, \\(P(E|T)\\): La probabilidad de desenlace negativo entre las personas tratadas. Tasa de riesgo de desenlace negativo en no tratados, \\(P(E|T^c)\\): La probabilidad de desenlace negativo entre las personas no tratadas. Tasa de curación (o de desenlace positivo) en tratados, \\(P(E^c|T)\\): La probabilidad de desenlace positivo entre las personas tratadas. Tasa de curación (o de desenlace positivo) en no tratados, \\(P(E^c|T^c)\\): La probabilidad de desenlace positivo entre las personas no tratadas. Para compararlas, podemos dividirlas o restarlas. Riesgo relativo, RR: El cociente entre las probabilidades de desenlace negativo de los tratados y entre los no tratados \\[ RR=\\dfrac{P(E|T)}{P(E|T^c)}. \\] Reducción absoluta del riesgo, RAR: La diferencia entre las probabilidades de desenlace positivo de los tratados y los no tratados, que coincide con la diferencia entre las probabilidades de desenlace negativo de los no tratados y los tratados: \\[ \\begin{array}{rl} RAR\\!\\!\\!\\! &amp; =P(E^c|T)-P(E^c|T^c)\\\\ &amp; =(1-P(E|T))-(1-P(E|T^c))\\\\ &amp; =P(E|T^c)-P(E|T) \\end{array} \\] Fijaos en el cambio de nombre respecto a la sección anterior: en el contexto de exposición y enfermedad, a esta resta la hemos llamado “riesgo absoluto atribuible”, RA, y aquí “reducción absoluta del riesgo”, RAR. En el contexto de los tratamientos a veces se usa el cociente siguiente como alternativa al RR: Reducción relativa del riesgo, RRR: La fracción de la probabilidad de desenlace negativo de los no tratados que representa la reducción absoluta del riesgo \\[ RRR=\\dfrac{P(E|T^c)-P(E|T)}{P(E|T^c)}=1-RR. \\] Además en el contexto de los tratamientos se usa, en vez del NND, el número siguiente: Número necesario que tratar (NNT): El número de pacientes que deberían empezar a recibir el tratamiento \\(T\\) (en lugar del control \\(T^c\\)) para que, de media, un paciente adicional recibiera el beneficio (pasara de \\(E\\) a \\(E^c\\)). Veamos un ejemplo concreto de NNT, para ayudar a entenderlo. Ejemplo 5.17 Imaginad la situación en la que con el tratamiento se cura el 30% de los enfermos y sin el tratamiento solo se cura el 10%. Es decir, \\(P(E|T)=0.7\\) y \\(P(E|T^c)=0.9\\). ¿A cuántos pacientes tendríamos que tratar de media para que se curara 1 paciente adicional (es decir, que no se curaría sin el tratamiento)? De media, por cada 100 pacientes, si los dejamos sin tratar se curan 10 y si los tratamos se curan 30. Por lo tanto, por cada 100 pacientes que tratamos, se añaden de media 20 pacientes al conjunto de los curados. Es decir, cada 100 pacientes que tratamos dan lugar, de media, a 20 curados adicionales (que se suman a los que se curarían sin necesidad de tratamiento). ¿Cuántos hemos de tratar para que tengamos 1 curado adicional? Si 100 pacientes tratados dan 20 curados adicionales, el número NNT de pacientes tratados para obtener 1 curado extra es \\[ NNT=\\frac{100}{20}=5 \\] El mismo argumento que para el NND y que el dado en el ejemplo anterior, prueba la siguiente igualdad: Teorema 5.3 \\(NNT=1/RAR\\). Por lo tanto, en el caso de tratamientos, el RAR y el NNT tienen la misma información. De nuevo, hay que tener cuidado al interpretar los RR, RAR y NNT, ya que solo dan valores “relativos” y por tanto sin saber el riesgo de desenlace negativo en los no tratados, no podemos saber realmente lo beneficioso que es el tratamiento. En el artículo “Helsinki heart study: primary prevention trial with gemfibrozil in middle-aged men with dyslipidemia” (M. Frick et al, The New England Journal of Medicine 317 (1987), pp. 1237-1245) se describe un ensayo clínico en el que se tomó un grupo de pacientes de mediana edad con niveles altos de colesterol no HDL y se dividió al azar en dos grupos. Los de un grupo tomaron gemfibrozil durante 5 años y los del otro grupo tomaron placebo durante el mismo período de tiempo. Se les hizo un seguimiento para determinar si desarrollaban alguna enfermedad coronaria (EC) durante el período de 5 años. Se obtuvo la tabla de frecuencias siguiente \\[ \\begin{array}{l} \\hphantom{ECGemfibro} \\textbf{Tratamiento}\\\\ \\begin{array}{r|cc|c} \\textbf{EC?} &amp; \\text{Gemfibrozil} &amp; \\text{Placebo}&amp; \\text{Total} \\\\ \\hline \\text{Sí} &amp; 56 &amp; 84 &amp; 140\\\\ \\text{No} &amp; 1995 &amp; 1946 &amp; 3941 \\\\ \\hline \\text{Total} &amp; 2051 &amp; 2030 &amp; 4081 \\end{array} \\end{array} \\] Calculad los RR, RAR, RRR y NNT y explicad su significado. Spoiler: Si llamamos \\(E\\) a desarrollar alguna enfermedad coronaria y \\(T\\) a tomar gemfibrozil durante 5 años, \\(P(E|T)=0.027\\) y \\(P(E|T^c)=0.041\\) RR=0.66. La administración de gemfibrozil reduce en un 34% el riesgo de enfermedad coronaria. RAR=0.014. La administración de gemfibrozil reduce en 1.4 puntos porcentuales el riesgo de enfermedad coronaria. RRR=0.34. La administración de gemfibrozil reduce en un 34% el riesgo de enfermedad coronaria. NNT=71. De media, por cada 71 pacientes que tratamos con gemfibrozil evitamos 1 enfermedad coronaria. Ejemplo 5.18 En el estudio “Completeness of reporting trial results: effect on physicians’ willingness to prescribe.”(M. Bobbio et al, The Lancet 343 (1994), pp. 1209-1211) se explicó a 148 médicos los resultados que se habían obtenido en unos ensayos clínicos similares (controlados con placebo) sobre 4 tratamientos para que decidieran para cada uno de ellos si lo recetarían para reducir el colesterol. Se les dijo que: Con el tratamiento A se obtuvo una reducción relativa del 34% en el riesgo de enfermedades coronarias Con el tratamiento B, la reducción absoluta del riesgo de enfermedades coronarias fue de 1.4 puntos porcentuales. Con el tratamiento C, la tasa de pacientes sin enfermedades coronarias subió del 95.9% al 97.3%. Con el tratamiento D, se necesita tratar de media 71 pacientes para evitar una enfermedad coronaria. ¿Habéis reconocido los datos? Los 4 describen los resultados del estudio cardíaco de Helsinki del ejercicio anterior, es decir, el mismo tratamiento: gemfibrozil. Pues bien: Un 77% de los médicos encuestados dijeron que recetarían el tratamiento A. Un 24% de los médicos encuestados dijeron que recetarían el tratamiento B. Un 37% de los médicos encuestados dijeron que recetarían el tratamiento C. Un 33% de los médicos encuestados dijeron que recetarían el tratamiento D. Ningún médico respondió lo mismo a los cuatro tratamientos. Como podéis ver, la manera cómo se presentan los resultados de un estudio sobre un tratamiento influye en nuestra percepción de la bondad del tratamiento. Este tipo de estudio se ha ido repitiendo a lo largo del tiempo, para ver si los nuevos facultativos entrenados en medicina basada en la evidencia eran tan fáciles de engañar como los de 1994. Algo ha mejorado, pero no completamente. Por ejemplo, en “Effects of presenting risk information in different formats to cardiologists. A Latin American survey” (R. Borracci et al, Archivos de Cardiología de México 85 (2015), pp. 3-8) se pasó un cuestionario que contenía resultados de ensayos clínicos expresados en términos de RR, RAR o NNT a 406 cardiólogos. Cuando la misma información se presentaba en términos de RR, los cardiólogos eran más fáciles de convencer de la bondad del tratamiento que si se presentaba como NNT o RAR. En cambio, no hubo diferencias significativas entre estos dos últimos (que, recordemos, son equivalentes). 5.4 Test (1) Una nueva prueba diagnóstica es más específica que la usada hasta el momento. Esta nueva prueba nos asegura: Menos errores en general. Menos falsos positivos. Menos falsos negativos. Menos diagnósticos positivos. Menos diagnósticos negativos. (2) Estáis comparando el diagnóstico clínico de úlcera gastroduodenal y su hallazgo en la autopsia en una serie de 10,000 pacientes. Al comenzar a analizar los datos se construye la siguiente tabla: \\[ \\begin{array}{l} \\ \\, \\textbf{Diagnóstico}\\hphantom{clínico }\\textbf{Autopsia}\\\\[-1ex] \\begin{array}{l|cc} \\textbf{clínico}\\hphantom{clínico} &amp; \\text{Úlcera} &amp; \\text{No úlcera}\\\\ \\hline \\text{Úlcera} &amp; 130 &amp; 20 \\\\ \\text{No úlcera} &amp; 170 &amp; 9680 \\end{array} \\end{array} \\] De las siguientes cifras, ¿cuál es la más cercana a la sensibilidad estimada del diagnóstico clínico de la úlcera?: 3% 43% 87% 98% 100% (3) Estás evaluando una prueba diagnóstica y finalmente llegas a la siguiente tabla: \\[ \\begin{array}{l} \\hphantom{Diagnósticooi}\\textbf{Enfermedad}\\\\ \\begin{array}{l|cc} \\textbf{Prueba} &amp; \\quad\\text{Sí}\\quad &amp; \\quad\\text{No}\\quad\\\\ \\hline \\text{Positiva} &amp; 80 &amp; 100 \\\\ \\text{Negativa} &amp; 20 &amp; 800 \\end{array} \\end{array} \\] A partir de ella y redondeando porcentajes, señala cuál de las siguientes afirmaciones es verdadera: El VPP es del 56% y el VPN del 13%. El VPP es del 44% y el VPN del 98%. El VPP es del 80% y el VPN del 89%. El VPP es del 80% y el VPN del 11%. Ninguna de las anteriores. (4) En el diagnóstico de cardiopatía isquémica, la prueba de esfuerzo tiene mayor valor predictivo positivo cuando (marca una sola respuesta correcta; Pista: es una pregunta de esta asignatura): La probabilidad previa de enfermedad coronaria es baja en el paciente estudiado. La probabilidad previa de enfermedad coronaria es alta en el paciente estudiado. Existe lesión de un solo vaso coronario. Se realiza con tratamiento con nitratos. Se realiza con tratamiento con betabloqueantes. (5) El resultado de un electrocardiograma de esfuerzo, para la predicción de una enfermedad coronaria, cambia si se varían los milímetros de depresión del segmento ST que definen el resultado anormal. Si se considera como resultado anormal a partir de los 2 mm de depresión del segmento ST en lugar de a partir de 0.5 mm (marca la respuesta correcta): La sensibilidad aumenta. Es necesario representar los falsos negativos frente a los verdaderos negativos en una curva ROC. La especificidad aumenta. Los falsos positivos aumentan. Es necesario representar los falsos negativos frente a los falsos positivos en una curva ROC. (6) ¿Cuál o cuáles de la siguientes afirmaciones son VERDADERAS en relación con la evaluación de pruebas diagnósticas?: No es deseable usar una prueba poco específica en diagnósticos que originen un trauma emocional al sujeto. Una prueba muy sensible es sobre todo útil cuando su resultado es positivo. Cuando una prueba presenta una sensibilidad muy alta un resultado positivo hace realmente posible el diagnóstico. Una prueba muy específica es sobre todo útil cuando su resultado es positivo. La sensibilidad de una prueba aumenta en poblaciones donde la enfermedad es poco prevalente La sensibilidad de una prueba aumenta en poblaciones donde la enfermedad es muy prevalente (7) En un estudio sobre la efectividad de una vacuna contra la tosferina, se recolectaron los siguientes datos (tantos por ciento del total): \\[ \\begin{array}{r|cc} &amp; \\text{Vacunado} &amp; \\text{No vacunado}\\\\ \\hline \\text{Tosferina} &amp; 1\\% &amp; 2\\% \\\\ \\text{No tosferina} &amp; 66\\% &amp; 31\\%\\\\ \\end{array} \\] ¿Cuál fue, aproximadamente, el riesgo relativo de contraer tosferina en un niño NO vacunado comparado con los niños vacunados? 0.25 0.5 1.0 2.0 4.0 (8) Hemos realizado usted un estudio en el que hemos seguido a 4000 pacientes con artrosis durante 3 años. De ellos 3000 consumían de manera habitual antiinflamatorios no esteroideos y durante el seguimiento 600 presentaron problemas gastrointestinales graves. De los 1000 que no consumían antiinflamatorios no esteroideos, 20 desarrollaron problemas gastrointestinales graves. ¿Cuál de las siguientes cifras corresponde a la odds ratio del desarrollo de problemas gastrointestinales graves relativa al consumo de AINEs?: 12.25 10 0.1 8.5 0.12 No se puede estimar con los datos de este estudio. (9) ¿En qué circunstancias la odds ratio (OR) se aproxima al valor de riesgo relativo (RR)? (marca todas las respuestas correctas): Cuando la exposición al factor de riesgo es muy poco frecuente. Cuando la exposición al factor de riesgo es muy frecuente. Cuando se trata de una enfermedad muy poco frecuente Cuando se trata de una enfermedad crónica. Cuando el diseño del estudio es de cohorte. Cuando el diseño del estudio es de casos y controles. Nunca. (10) De 143 pacientes que murieron por endocarditis bacteriana, un 2% tenían menos de 10 años de edad. Los autores del estudio concluyen que la endocarditis bacteriana es rara en la infancia. Esta conclusión es falsa o equivocada debido a (marca todas las respuestas correctas): Falta de un grupo de control Falta de seguimiento apropiado Falta de denominadores Han invertido la probabilidad condicional En realidad, la conclusión es correcta (11) En un ensayo clínico aleatorizado, doble ciego y controlado con placebo, se evaluó el efecto sobre la mortalidad de un nuevo fármaco en pacientes con hiperlipidemia y sin antecedentes de cardiopatía isquémica. Después de un seguimiento medio de cinco años se encontró una mortalidad del 10% en el grupo placebo y del 5% en el grupo de tratamiento. ¿Qué vale el NNT, es decir, el número de pacientes que tenemos que tratar con el nuevo fármaco durante 5 años para evitar, de media, una muerte? 5 20 0.5 50 1 (12) En la lección hemos hablado de síntomas patognómicos. ¿Qué implica un síntoma patognómico? Marca todas las respuestas verdaderas. Una sensibilidad del 100%. Una especificidad del 100%. Un área bajo la curva (AUC) de 1. Un valor predictivo positivo del 100%. Un valor predictivo negativo del 100%. Una tasa de falsos positivos del 100%. "],["sec:tiposdatos.html", "Lección 6 Tipos de datos 6.1 Test", " Lección 6 Tipos de datos En las lecciones que siguen explicamos algunas técnicas básicas de estadística descriptiva. Estas técnicas consistirán en una serie de valores y gráficos que nos permitirán resumir y explorar un conjunto de datos, con el objetivo final de entenderlos o describirlos lo mejor posible. Los datos de los que disponemos suelen ser multidimensionales, en el sentido de que observamos varias características (variables) de una serie de individuos. Almacenamos estos datos en tablas de datos como la Tabla 6.1, donde cada columna corresponde a una variable y cada fila son los datos de un individuo concreto. Así, en esta tabla, cada fila representa un niño y cada columna recoge una de las características que hemos anotado: su nombre, su altura (en cm), su número de hermanos, el color de sus cabellos, el número semanal de refrescos que suele tomar, y su grado de satisfacción con un juego para móvil (entre 0 y 5). Tabla 6.1: Tabla 6.2: Una pequeña tabla de datos sobre niños Nombre Altura Hermanos Cabello Refrescos semanales Satisfacción App 1 Marta 135 2 rubio 2-3 4 2 Laura 132 1 negro 2-3 4 3 Xavier 138 0 negro 0-1 3 4 Joan 141 3 castaño 4-5 2 5 Maria 134 2 rojo 0-1 3 6 Maria 136 1 castaño 6 o más 5 En este curso vamos a usar el término variable con dos significados diferentes que esperamos que podáis distinguir según el contexto: Por un lado, llamaremos variable a una característica que puede tomar diferentes valores sobre diferentes individuos; cuando tenga este sentido, a veces le añadiremos el adjetivo poblacional. Por ejemplo, la altura de las personas (de todo el mundo, de un país, de una ciudad…) es una variable poblacional. Por otro lado, también llamaremos una variable a un vector formado por los valores de una variable poblacional sobre los sujetos de una muestra. Por ejemplo, las alturas de los niños recogidas en la Tabla 6.1 forman una variable en este sentido. Los tipos básicos de datos que consideramos en este curso son los siguientes: Datos cualitativos (o categóricos). Son los que expresan una cualidad del individuo, como por ejemplo el sexo cromosómico (macho, hembra), el género de una persona (hombre, mujer, lesbiana, gay, bisexual, transexual, intersexual, asexual, sestosexual…), tipos de cáncer (de mama, de colon, de próstata…)… Si solo pueden tomar dos valores (“Sí” o “No”, “Macho” o “Hembra”…) los llamamos binarios o dicotómicos y si pueden tomar más de dos valores, politómicos o multicotómicos, dependiendo de lo que queramos complicar los adjetivos. Los datos cualitativos pueden ser iguales o distintos, y no admiten ningún otro tipo de comparación. Datos ordinales. Son datos similares a los cualitativos, en el sentido de que expresan una cualidad del individuo, pero con la diferencia de que se pueden ordenar de manera natural. Por ejemplo, los niveles de gravedad de una enfermedad (sano, leve, grave, muy grave, …) o las calificaciones en un examen (suspenso, aprobado, notable, sobresaliente) son datos ordinales. En cambio, no se pueden ordenar de manera significativa los sexos o los tipos de cáncer de los individuos: por eso son datos cualitativos y no ordinales. A menudo a los tipos de datos cualitativos y ordinales se los denomina globalmente nominales. A menudo a una variable de datos nominales (es decir, cualitativos u ordinales) la llamaremos un factor y a sus posibles valores los llamaremos sus niveles. Datos cuantitativos. Son datos que se refieren a medidas que sean números genuinos, con los que tenga sentido operar, tales como edades, longitudes, pesos, tiempos, números de individuos, etc. Distinguimos dos tipos: Discretos: Pueden tomar solo valores que avanzan a saltos y que podemos identificar con números naturales: número de hermanos, número de ingresos en un día en un hospital… Continuos: Podrían tomar cualquier valor real dentro de un intervalo si se pudieran medir con precisión infinita: altura, temperatura, tiempo… Ejemplo 6.1 En la Tabla 6.1: La variable “Nombre” es cualitativa. La variable “Altura” es cuantitativa continua. La variable “Hermanos” es cuantitativa discreta. La variable “Cabello” es cualitativa. La variable “Refrescos semanales” es ordinal. La variable “Satisfacción App” también es ordinal. Dos puntos relevantes a tener en cuenta y que justifican algunas clasificaciones que puede que encontréis dudosas en el ejemplo anterior: No todo número es un dato cuantitativo. Solo los consideramos cuantitativos cuando son números genuinos, “de verdad”. Por ejemplo, si pedimos a un paciente que califique su dolor con un número natural de 0 a 10, no es un dato cuantitativo, sino ordinal: No es una medida precisa del dolor; no son números “de verdad”, sino abreviaturas de “Nada”, “Un poquito”,…, “Matadme”. Tener dolor 6 no significa “tener el doble de dolor” que tener dolor 3 (si lo significara, ¿cuál sería el valor correspondiente “al doble de dolor” que 7?). En cambio, una persona con 6 hermanos sí que tiene el doble de hermanos que si tuviera 3. No tiene sentido sumarlos u operarlos en general. Por ejemplo, si yo tengo dolor de nivel 6 y tú tienes dolor de nivel 5, entre los dos no tenemos dolor de nivel 11. En cambio, si yo tengo 6 hermanos y tú 5, entre los dos sí que tenemos 11 hermanos. Este es justamente el caso de la variable “Satisfacción App” de la tabla anterior. Pese a que sus valores son números, el único contenido real que tienen es su orden: a la María que toma muchos refrescos le ha gustado la app bastante más que a la María que apenas toma refrescos. La distinción discreto-continuo es puramente teórica. En realidad, todo dato es discreto porque no podemos medir nada con precisión infinita, pero las herramientas matemáticas “continuas” (derivadas, integrales, etc.) son mucho más potentes que las discretas, por lo que siempre que tenga sentido, es conveniente considerar una variable como continua. Observad, por ejemplo, la diferencia entre la altura, pongamos que medida en cm y redondeada a unidades como en la tabla anterior, y el número de hermanos. Ambos se presentan como números naturales, pero los números de hermanos no admiten mayor precisión, mientras que las alturas las podríamos medir, con los aparatos adecuados, en mm, en µm, en nm…. Como además las herramientas para tratar datos continuos son mucho más potentes, vamos a considerar las alturas como datos continuos, mientras que los números de hermanos no hay más remedio que tratarlos como discretos. En concreto, es conveniente considerar en la práctica como datos continuos aquellos que dan lugar a números naturales muy grandes, como por ejemplo los números de glóbulos rojos en un litro de sangre, de bases nucléicas en un genoma, o de personas de un país. La diferencia entre diez millones, diez millones uno, diez millones dos… puede considerarse como continua: de hecho, si tomamos el millón como unidad, la diferencia está en la séptima cifra decimal. Hemos dicho que la variable “Cabello” es cualitativa. En principio, el color de los cabellos no tiene ningún orden “natural”. Pero si en un estudio definimos un orden claro para esta variable (por ejemplo, por la longitud de onda correspondiente) y este orden es relevante en nuestro estudio, habrá que considerarla una variable ordinal. La variable “Refrescos semanales” es de un tipo de datos ordinales muy concreto que a veces se califican de cuantitativos agrupados: sus niveles se obtienen agrupando en intervalos los posibles valores de una variable cuantitativa (en este caso, la variable discreta que mide el número preciso de refrescos semanales). Volveremos sobre este tipo de datos en la Sección 9.10. El análisis, tanto descriptivo como inferencial, de un conjunto de datos es diferente según su tipo. Así, para datos cualitativos sólo tiene interés estudiar y representar las frecuencias con que aparecen sus diferentes valores, mientras que el análisis de datos cuantitativos suele involucrar el cálculo de medidas estadísticas, como la media o la desviación típica, que expresen numéricamente sus propiedades. ¿De qué tipo de datos son?: La presión arterial sistólica. El estatus marital. El nivel de gravedad de una enfermedad. El número de ingresos hospitalarios a través de urgencias a lo largo de un día. El nivel de incomodidad de los pacientes sometidos a un tratamiento (debido a sus efectos secundarios). El número de mujeres entre los alumnos de una clase. La proporción de mujeres entre los alumnos de una clase. El grupo sanguíneo (A, B, AB, 0). El número de pulsaciones por minuto. El ser alcohólico (sí o no). El nivel de alcoholismo (crónico, agudo, esporádico, neutro). La concentración de alcohol en sangre (en g/ml). 6.1 Test (1) Se realiza un estudio sobre lesiones en extremidades en infantes. Una de las variables estudiadas es la extremidad lesionada. ¿De qué tipo (estadístico) de datos es esta variable? Cualitativos dicotómicos Cualitativos politómicos Ordinales Cuantitativos discretos Cuantitativos continuos Anatómicos (2) Los diferentes estadios de un cáncer se indican con un número del 0 al 4. Este valor, ¿de qué tipo de dato se trata? Cualitativo dicotómico Cualitativo politómico Ordinal Cuantitativo discreto Cuantitativo continuo "],["descripción-de-datos-cualitativos.html", "Lección 7 Descripción de datos cualitativos 7.1 Frecuencias 7.2 Gráficos 7.3 Tablas de frecuencias multidimensionales 7.4 Diagramas de barras bidimensionales 7.5 Diagramas de mosaico 7.6 Test", " Lección 7 Descripción de datos cualitativos Los datos cualitativos corresponden a observaciones sobre cualidades de un objeto o individuo, tales como su especie o su sexo, que pueden ser iguales o diferentes y no admiten ningún otro tipo de comparación significativa: por ejemplo, datos para los que no tenga ningún sentido preguntarse si uno es más grande que otro, ni efectuar operaciones aritméticas con ellos, aunque estén representados por números. Llamaremos niveles a los diferentes valores que puede tomar una variable cualitativa; por ejemplo, los dos niveles de una variable “Sexo” serían “Macho” y “Hembra”, o sinónimos. 7.1 Frecuencias Lo único que podemos hacer con un conjunto de datos cualitativos es contar cuántas veces aparece cada nivel y presentar estas frecuencias en una tabla o por medio de un gráfico. Distinguiremos entre: Frecuencia absoluta de un nivel: el número de veces que aparece en la muestra. Frecuencia relativa de un nivel: la fracción del total de la muestra que representa este nivel. Además, llamaremos la moda al nivel (o a los niveles, en caso de empate) más frecuente. A veces usaremos adjetivos como unimodal, bimodal, multimodal etc. para referirnos, respectivamente, a una variable con una sola moda, con dos modas, con “varias” modas, etc. Ejemplo 7.1 Hemos recogido información sobre 20 residentes en geriátricos que en el período marzo-mayo de 2020 tuvieron COVID-19. Uno de los datos que hemos recogido sobre estas personas ha sido su sexo. El resultado ha sido una variable cualitativa, que llamaremos “Sexo”, formada por las 20 observaciones siguientes: Mujer, Mujer, Hombre, Mujer, Mujer, Mujer, Mujer, Mujer, Hombre, Mujer, Hombre, Hombre, Mujer, Mujer, Hombre, Mujer, Mujer, Mujer, Mujer, Hombre Sus dos niveles son Hombre y Mujer. En esta variable hay 14 mujeres y 6 hombres. Por lo tanto, éstas son las frecuencias absolutas de estos niveles. Puesto que en total hay 20 individuos, sus frecuencias relativas son: Hombre: 6/20=0.3 Mujer: 14/20=0.7 La moda de la muestra es el nivel Mujer. Resumimos estas frecuencias en la tabla de frecuencias siguiente: Frecuencia absoluta Frecuencia relativa Porcentaje Hombre 6 0.3 30% Mujer 14 0.7 70% Total 20 1.0 100% El término moda y los adjetivos unimodal, bimodal, etc. también se usan en variables poblacionales: dada una variable poblacional cualitativa, su moda es el nivel más frecuente en el total de la población, cuando existe. Pero en el caso poblacional, decimos que la variable es unimodal cuando hay un nivel que es mucho más frecuente que el resto, no basta con que haya uno más frecuente. De manera similar, bimodal no significa que la mayor frecuencia de un nivel en la población se dé en dos niveles que empaten exactamente, sino que hay dos niveles con frecuencias parecidas y mucho mayores que el resto. Por ejemplo, supongamos que tenemos una variable poblacional que puede tomar 4 valores excluyentes: A, B, C, D. Si en el total de la población los niveles A y B se dan, cada uno, en un 25.1% de los individuos, y los niveles C y D cada uno en un 24.9% de los individuos, no diremos que la variable sea bimodal. Si en el total de la población el nivel A se da en un 42% de los individuos, el nivel B en un 41% de los individuos, el nivel C en un 9% y el nivel D en un 8%, sí que diremos que es bimodal, aunque A sea más frecuente que el resto. 7.2 Gráficos Podemos representar una tabla de frecuencias como la de la sección anterior mediante un diagrama de barras, en el que para cada nivel dibujaremos una barra cuya altura represente su frecuencia (absoluta o relativa). Por ejemplo, el diagrama de barras de las frecuencias absolutas de la variable “Sexo” de la sección anterior es: Su diagrama de barras de frecuencias relativas es: Observad que la única diferencia entre estos dos gráficos son las marcas del eje vertical que indican las alturas de las barras. Con JAMOVI, tras entrar los datos en una variable (importando un fichero de datos o entrándolos a mano en Datos), podéis calcular las tablas de frecuencias absolutas y relativas y el diagrama de barras de frecuencias absolutas de una variable cualitativa usando las casillas adecuadas de la sección Exploración/Descriptivas, tal y como se muestra en la imagen siguiente: Antes de continuar, observad que JAMOVI incluye en la tabla de frecuencias una columna “% Acumulado” sin que se la pidamos. Solo la tendremos en cuenta si la variable es ordinal. Un tipo muy popular de representación gráfica de variables cualitativas son los diagramas circulares, donde se representan los niveles de una variable cualitativa como porciones circulares de un círculo, de manera que el ángulo de cada porción (o equivalentemente, su área) sea proporcional a la frecuencia del nivel al que corresponde. Así, el diagrama circular de la variable dicotómica “Sexo” sería el siguiente: Pese a su popularidad, es poco recomendable usar diagramas circulares cuando se manejan más de dos niveles, porque a veces es difícil, a simple vista, comprender las relaciones entre las frecuencias que representan. Para convencerse, basta comparar los diagramas de barras y los diagramas circulares de la figura siguiente, importada de la entrada sobre diagramas circulares de la Wikipedia: Algunos programas ofrecen la posibilidad de dibujar diagramas circulares tridimensionales como el siguiente: Estos diagramas quedan muy bonitos, pero son aún peores que los diagramas circulares planos, puesto que la perspectiva deforma las áreas. A simple vista, en el diagrama anterior, ¿qué frecuencia es mayor: la del nivel representado por el color azul oscuro, o la del correspondiente al verde claro? Y por este motivo, por favor, nunca uséis diagramas circulares para más de dos niveles. Un gráfico ha de servir más que mil palabras, y tiene que explicar de un vistazo las características más relevantes de los datos que representa. Luego ya se pueden añadir detalles que complementen esta primera comprensión básica. En el caso de un diagrama de barras, su objetivo ha de ser mostrar la relación entre las magnitudes de las frecuencias que representa; si nos interesan sus valores concretos, es mejor dar la tabla. Por ejemplo, en los diagramas de barras de la variable “Sexo” dados más arriba se ve a simple vista que hay aproximadamente el doble de mujeres que de hombres. Por ese motivo es un pecado mortal modificar un gráfico para que el primer vistazo sea engañoso. En un diagrama de barras, la adulteración más usual, y ante la que hay que estar atentos, es truncarlo de manera que el eje de coordenadas que indique las frecuencias no arranque en el 0. Mirad, por ejemplo, el diagrama de barras siguiente: Este diagrama sigue indicando que en la muestra hay un 30% de hombres y un 70% de mujeres, pero si le dais un vistazo superficial, sin mirar las marcas del eje vertical, parece que la proporción de mujeres es cinco veces la de los hombres y no un poco más del doble. Es muy frecuente encontrar diagramas de barras (u otros tipos de gráficos) truncados en medios de comunicación. Por ejemplo mirad el gráfico siguiente, que representa la evolución del uso del catalán en las pruebas de Selectividad en la UIB desde 1992 a 2010: El incremento en la realidad fue menos pronunciado: No podemos dejar este asunto sin la siguiente obra maestra de los diagramas de barra truncados: 7.3 Tablas de frecuencias multidimensionales Cuando medimos más de una variable cualitativa sobre un mismo grupo de individuos, representamos sus frecuencias absolutas o relativas mediante tablas de contingencia multidimensionales. Ejemplo 7.2 Continuemos con nuestra muestra de 20 pacientes en residencias geriátricas. Además de su sexo, hemos anotado otras dos características: una variable “Demencia” que recoge si en el momento del ingreso en la residencia habían sido diagnosticados con algún tipo de demencia senil, con niveles “No”, “Alzheimer” y “Otros” (para indicar otros diagnósticos de demencia no-Alzheimer), y una variable “Cancer” que indica si en algún momento han sufrido o no cáncer de mama. La tabla de datos es la siguiente: Tabla 7.1: Tabla 7.2: Tabla de datos de pacientes de residencias geriátricas Sexo Demencia Cancer 1 Mujer No No 2 Mujer Alzheimer Sí 3 Hombre Alzheimer No 4 Mujer Otros No 5 Mujer Alzheimer No 6 Mujer Otros Sí 7 Mujer No No 8 Mujer Alzheimer No 9 Hombre Otros No 10 Mujer Otros Sí 11 Hombre Alzheimer No 12 Hombre Alzheimer No 13 Mujer No No 14 Mujer No No 15 Hombre Alzheimer No 16 Mujer No Sí 17 Mujer No No 18 Mujer No No 19 Mujer Alzheimer No 20 Hombre No No La tabla bidimensional de frecuencias absolutas de las variables “Sexo” y “Demencia”, que nos da la frecuencia absoluta de cada combinación de sexo y tipo de demencia senil, es: Alzheimer Otros No Hombre 4 1 1 Mujer 4 3 7 y la tabla tridimensional de frecuencias absolutas de las tres variables, que nos da la frecuencia absoluta de cada combinación de sexo, tipo de demencia senil y si se ha sufrido o no cáncer de mama, es: Cancer No Sí Sexo Demencia Hombre Alzheimer 4 0 Otros 1 0 No 1 0 Mujer Alzheimer 3 1 Otros 1 2 No 6 1 Con JAMOVI, estas tablas se obtienen fácilmente separando una variable por la otra (u otras) y marcando las mismas casillas en Exploración/Descriptivas que en el caso unidimensional: Las tablas bidimensionales se pueden obtener de manera más adecuada en Frecuencias/Muestras independientes: lo explicaremos dentro de un rato. A menudo es conveniente añadir a una tabla de contingencia multidimensional, filas y columnas marginales (en los márgenes) con las frecuencias totales de cada nivel dentro de cada variable. De esta manera, también tenemos las tablas de frecuencias de cada una de las variables. Por ejemplo, si añadimos la fila y la columna marginales a la tabla bidimensional anterior obtenemos:   Alzheimer Otros No Total Hombre 4 1 1 6 Mujer 4 3 7 14 Total 8 4 8 20 Las tablas multidimensionales de frecuencias relativas son algo más complicadas porque dichas frecuencias relativas se pueden calcular en el total de la muestra (las llamamos frecuencias relativas globales) o dentro de los niveles de una de las variables (por filas o por columnas, en el caso bidimensional), en función de lo que nos interese medir. Por ejemplo: Si nos interesa la fracción de pacientes de cada combinación de sexo y tipo de demencia senil en el total de la muestra, usaremos la tabla de frecuencias relativas globales de las variables “Sexo” y “Demencia”: Alzheimer Otros No Hombre 0.2 0.05 0.05 Mujer 0.2 0.15 0.35 Observad que la suma de todas las entradas de la tabla es 1, lo que indica que estas frecuencias indican proporciones del total de la muestra. Por ejemplo, la entrada superior izquierda de esta tabla nos dice que los hombres con Alzheimer representan el 20% del total de la muestra. Es decir, si en nuestra muestra $A$ representa el suceso &quot;Tener Alzheimer&quot; y $H$ el suceso &quot;Ser hombre&quot;, esta entrada dice que $P(A\\cap H)=0.2$. Si nos interesa la fracción de pacientes con cada tipo de demencia senil dentro de cada sexo, usaremos la tabla de frecuencias relativas de la variable “Demencia” dentro de la variable “Sexo”: Alzheimer Otros No Hombre 0.6667 0.1667 0.1667 Mujer 0.2857 0.2143 0.5000 En esta tabla, la suma de las entradas de cada fila es 1, lo que indica que las frecuencias son proporciones dentro de cada fila. Por ejemplo, la entrada superior izquierda de esta tabla nos dice que los hombres con Alzheimer representan el 66.67% de los hombres de la muestra. Es decir, con las notaciones anteriores, que $P(A|H)=0.6667$. Si nos interesa la fracción de pacientes de cada sexo dentro del grupo de pacientes con cada tipo de demencia senil, usaremos la tabla de frecuencias relativas de la variable “Sexo” dentro de la variable “Demencia”: Alzheimer Otros No Hombre 0.5 0.25 0.125 Mujer 0.5 0.75 0.875 En esta tabla, la suma de las entradas de cada columna es 1, lo que indica que las frecuencias son proporciones dentro de cada columna. Por ejemplo, la entrada superior izquierda de esta tabla nos dice que los hombres con Alzheimer representan el 50% de los enfermos de Alzheimer de la muestra. O sea, de nuevo con las notaciones anteriores, que $P(H|A)=0.5$. En una tabla de contingencia de frecuencias relativas globales, tiene sentido añadir filas y columnas marginales, que nos darán las frecuencias relativas de los niveles de cada variable.   Alzheimer Otros No Total Hombre 0.2 0.05 0.05 0.3 Mujer 0.2 0.15 0.35 0.7 Total 0.4 0.2 0.4 1 Pero en una tabla de contingencia de frecuencias relativas de una variable respecto de otra no tiene mucho interés. Por ejemplo, añadamos las marginales a la tabla de frecuencias relativas de la variable “Demencia” dentro de la variable “Sexo”:   Alzheimer Otros No Total Hombre 0.6667 0.1667 0.1667 1 Mujer 0.2857 0.2143 0.5 1 Total 0.9524 0.381 0.6667 2 Como hemos calculado las frecuencias relativas dentro de cada fila, la suma de las frecuencias relativas de cada fila ha de ser 1. Ahora fijaos en la fila Total. Nos dice por ejemplo que la suma de la proporción de hombres que tienen Alzheimer, 0.6667, y de la proporción de mujeres que tienen Alzheimer, 0.2857, es 0.9523. ¿Qué significado tiene este número? Ninguno, y en todo caso de ninguna manera significa que la proporción de individuos con Alzheimer en la muestra sea 0.9523, ya que esta proporción es del 40%. Suponemos que tenéis claro que si un 50% de los hombres y un 50% de las mujeres de una población tienen una determinada característica, no es verdad que el 100% de la población tenga esta característica. Y sin embargo a veces se calculan marginales de tablas de frecuencias relativas con el piloto automático puesto colándose tonterías de este estilo. Por desgracia, esto es bastante frecuente en los medios de comunicación, como muestra el gazapo siguiente, donde el periodista encargado de los titulares entendió que un 1.2% de los estudiantes de grado y un 5.8% de los estudiantes de máster representan un 7% del total de estudiantes universitarios. A la hora de decidir qué variable asignamos a las filas y cuál a las columnas en una tabla de contingencia bidimensional, es conveniente recordar que, en los paises occidentales, solemos leer las tablas por filas y de izquierda a derecha. Por ello, si tenemos interés en la distribución de los niveles de una variable dentro de los niveles de una segunda variable, puede facilitar la lectura de la tabla que esta segunda variable defina las filas. Las tablas de contingencia bidimensionales con frecuencias relativas marginales se obtienen con JAMOVI en la sección Frecuencias/Muestras independientes. Por ejemplo, si declaramos la variable “Sexo” como la de las filas y la variable “Demencia” como la de las columnas y marcamos Frecuencias observadas en la pestaña Celdas, entonces podemos pedir en las casillas de la columna Porcentajes que se calculen las frecuencias relativas por filas, por columnas o en el total. Por ejemplo, por filas: Olvidaos por ahora de la tabla “Pruebas de \\(\\chi^2\\)” que aparece en el resultado, ya hablaremos de ella al hablar de contrastes de proporciones. Podéis impedir que aparezca desmarcando la casilla \\(\\chi^2\\) en la pestaña Estadísticas, que sale marcada por defecto. 7.4 Diagramas de barras bidimensionales Una tabla de frecuencias bidimensional se suele representar mediante un diagrama de barras bidimensional, que puede ser: De barras apiladas: Se escoge una variable (la llamaremos principal), se dibuja una barra para cada uno de sus niveles de altura la frecuencia total de dicho nivel, y cada una de estas barras se divide verticalmente en sectores que representan las frecuencias de los niveles de la otra variable dentro de ese nivel. Por ejemplo, el diagrama de barras apiladas de frecuencias absolutas de las variables “Sexo” y “Demencia” de la Tabla 7.1, tomando la variable “Sexo” como principal: De barras yuxtapuestas. Se escoge una variable principal y para cada uno de sus niveles se dibuja un diagrama de barras de las frecuencias de los niveles de la otra variable. Así, el diagrama de barras yuxtapuestas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Sexo” como principal es: Otros dos ejemplos: El diagrama de barras apiladas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Demencia” como principal es: El diagrama de barras yuxtapuestas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Demencia” como principal: Los diagramas de barras tienen que mostrar la información de la manera más adecuada posible. Por ejemplo, si lo que nos interesa es la distribución de los tipos de demencia por sexo, la variable principal ha de ser el “Sexo”. Si nos interesan las frecuencias relativas globales, seguramente sea más conveniente dar un diagrama de barras tomando como niveles las combinaciones de niveles de ambas variables, como el siguiente diagrama de barras de frecuencias relativas globales de las variables “Sexo” y “Demencia”: El usar barras apiladas o yuxtapuestas en un diagrama de barras bidimensional ya va más a gusto de cada uno. Como un diagrama de barras yuxtapuestas usa tantas barras como el producto de los números de niveles de las dos variables, si estos dos números son grandes puede necesitar mucho espacio horizontal para ser comprensible. Por otro lado, en los diagramas de barras apiladas es más fácil comparar las frecuencias de los niveles de la variable principal, mientras que en los diagramas de barras yuxtapuestas es más fácil comparar la distribución de los niveles de la variable secundaria dentro de cada nivel de la variable principal. Lo diagramas de barras bidimensionales se obtienen con las casillas adecuadas de la pestaña Gráficos en Frecuencias/Muestras independientes. Podéis elegir si queréis las barras apiladas (Alineados) o yuxtapuestas (Al lado), si el diagrama de barras ha de ser de frecuencias abolutas o relativas y en este último caso qué tipo de frecuencias relativas (del total, por filas o por columnas) y si la variable principal es la de las filas o las columnas. Por ejemplo, el diagrama de barras yuxtapuestas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Demencia” como principal, se obtiene de la manera siguiente: En un estudio transversal en el que se analizó 75 hombres y 70 mujeres, 40 hombres y 20 mujeres presentaron una determinada enfermedad. Representad estos datos en un diagrama de barras bidimensional de frecuencias relativas que muestre las proporciones de enfermos y sanos en cada sexo. ¿Qué vale la frecuencia relativa de los hombres entre los participantes que no presentaron la enfermedad? 7.5 Diagramas de mosaico Una tabla tridimensional se puede representar mediante un diagrama de mosaico. Estos gráficos se obtienen sustituyendo cada entrada de la tabla de frecuencias por una región rectangular de área proporcional a su valor. Por ejemplo, el diagrama de mosaico de la Tabla 7.1 es el siguiente (donde los “Sí” y “No” de la fila superior corresponden a la variable “Cancer”): 7.6 Test (1) Para comparar el alcance del alcoholismo en Barcelona y en Palma, ¿qué es más adecuado usar? Las frecuencias absolutas de alcohólicos en Palma y en Barcelona. Las frecuencias relativas de alcohólicos en Palma y en Barcelona. Las frecuencias relativas de palmesanos y de barceloneses entre los alcohólicos españoles. Las frecuencias relativas de palmesanos alcohólicos y de barceloneses alcohólicos en el total de los españoles. (2) ¿Qué representa el 0.36 de la tabla de contingencia siguiente? \\[ \\begin{array}{lc} &amp;\\hphantom{YY}\\textbf{Propiedad X} \\\\ \\begin{array}{l} \\textbf{Propiedad Y} \\end{array} &amp;\\!\\!\\!\\!\\! \\begin{array}{r |c|c|} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 0.23 &amp; 0.36\\\\ \\text{No} &amp; 0.17 &amp; 0.24\\\\ \\end{array} \\end{array} \\] La frecuencia relativa de individuos con la propiedad Y en el total de la muestra. La frecuencia relativa de individuos con la propiedad Y entre los que no tienen la propiedad X. La frecuencia relativa de individuos sin la propiedad X entre los que tienen la propiedad Y. La frecuencia relativa de individuos con la propiedad Y y sin la propiedad X en el total de la muestra. No podemos saberlo sin conocer la fila y la columna marginales. "],["descripción-de-datos-ordinales.html", "Lección 8 Descripción de datos ordinales 8.1 Frecuencias y diagramas de barras 8.2 Test", " Lección 8 Descripción de datos ordinales Los datos ordinales son parecidos a los cualitativos, en el sentido de que son cualidades de objetos o individuos. Su diferencia con los datos cualitativos está en que las características que expresan los datos ordinales tienen un orden natural que permite acumular observaciones, es decir, contar cuántas hay por debajo de cada nivel. Un caso frecuente son las escalas tipo Likert, que se usan para expresar el nivel de acuerdo o desacuerdo con una afirmación mediante respuestas cerradas. Ejemplo 8.1 En una encuesta sobre la actitud de personal sanitario frente al dolor (M. E. Zanolin et al, “A questionnaire to evaluate the knowledge and attitudes of health care providers on pain”, Journal of pain and symptom management 33 (2007), pp. 727-736), se pidió el grado de conformidad con afirmaciones como: Como los narcóticos pueden causar depresión respiratoria, no se han de usar en pacientes pediátricos. Es útil dar de entrada un placebo al paciente que se queja de dolor para saber si realmente siente dolor. según la escala Likert siguiente: Nivel Significado 1 Muy en desacuerdo 2 En desacuerdo 3 Neutral 4 De acuerdo 5 Muy de acuerdo Las respuestas a este tipo de cuestionarios son números, pero no son datos cuantitativos, sino ordinales: meras abreviaturas de los diferentes grados de conformidad. Para más información sobre escalas Likert, podéis consultar la correspondiente entrada de la Wikipedia. 8.1 Frecuencias y diagramas de barras Cuando trabajamos con datos ordinales, el orden de los niveles de los datos permite calcular no sólo las frecuencias absolutas y relativas que veíamos en la lección anterior, y que para variables ordinales se definen del mismo modo, sino también frecuencias acumuladas. Es decir, no sólo podemos contar cuántas veces hemos observado un cierto nivel, sino también cuántas veces hemos observado un nivel menor o igual que él. Por lo tanto, su descripción estadística es la misma que para datos cualitativos, más: Frecuencias absolutas acumuladas: El número de veces que aparece en la muestra un nivel menor o igual que el considerado. Frecuencias relativas acumuladas: La fracción del total de la muestra que representan los niveles menores o iguales que el considerado. De nuevo, estas frecuencias acumuladas se pueden recoger en una tabla y representar en forma de diagrama de barras (con los niveles ordenados en orden creciente). Ejemplo 8.2 Tenemos una muestra de 20 estudiantes de quienes sabemos la calificación que han sacado en un examen. Clasificamos estas calificaciones en Suspenso (S), Aprobado (A), Notable (N) y Sobresaliente (E) y consideramos su orden natural S &lt; A &lt; N &lt; E. Las calificaciones que han obtenido son las siguientes: N, A, A, S, S, A, N, E, A, A, S, S, S, A, E, N, N, E, S, A En esta lista hay 6 S, 7 A, 4 N y 3 E: éstas serían las frecuencias absolutas de las calificaciones en esta muestra de estudiantes. Por lo que se refiere a sus frecuencias absolutas acumuladas: Hay 6 estudiantes que han obtenido S o menos: la frecuencia acumulada de S es 6. Hay 13 estudiantes que han obtenido A o menos (6 S y 7 A): la frecuencia acumulada de A es 13. Hay 17 estudiantes que han obtenido N o menos (6 S, 7 A y 4 N): la frecuencia acumulada de N es 17. Hay 20 estudiantes que han obtenido E o menos (todos): la frecuencia acumulada de E es 20. La frecuencia relativa acumulada de cada calificación es la fracción del total de estudiantes que representa su frecuencia absoluta acumulada. Por ejemplo, la frecuencia relativa acumulada de notables es la proporción de estudiantes que han sacado un notable o menos, y, por lo tanto, es igual a la frecuencia absoluta acumulada de N dividida por el número total de estudiantes: 17/20=0.85. También se puede obtener “acumulando” las frecuencias relativas de las calificaciones menores o iguales que N: como hay un 30% de S (6 de 20), un 35% de A (7 de 20) y un 20% de N (4 de 20), la frecuencia relativa acumulada de N es 0.3+0.35+0.2=0.85, es decir, un 85%. Así pues, las frecuencias relativas acumuladas de las calificaciones en esta muestra son: Frecuencia relativa acumulada de S: 6/20=0.3. Frecuencia relativa acumulada de A: 13/20=0.65. Frecuencia relativa acumulada de N: 17/20=0.85. Frecuencia relativa acumulada de E: 20/20=1. Resumimos todos estos valores en la tabla siguiente: Frecuencia absoluta Frecuencia relativa Porcentaje Frecuencia absoluta acumulada Frecuencia relativa acumulada Porcentaje acumulado Suspenso 6 0.30 30% 6 0.30 30% Aprobado 7 0.35 35% 13 0.65 65% Notable 4 0.20 20% 17 0.85 85% Sobresaliente 3 0.15 15% 20 1.00 100% Ejemplo 8.3 Todos los ancianos recogidos en la tabla de datos del Ejemplo 7.2 fueron diagnosticados con COVID-19 entre marzo y mayo de 2020. Vamos a ampliar dicha tabla de datos con información sobre la gravedad de su enfermedad, clasificada en cuatro niveles: Asintomática, Leve, Hospitalización (si requirió hospitalización pero no en UCI) y UCI. Consideraremos esta variable como ordinal, con sus niveles ordenados en orden creciente de gravedad. La tabla de datos ampliada es la siguiente: Tabla 8.1: Tabla 8.2: Tabla de datos de pacientes de residencias geriátricas Sexo Demencia Senil Cáncer de mama COVID-19 1 Mujer No No Leve 2 Mujer Alzheimer Sí UCI 3 Hombre Alzheimer No Leve 4 Mujer Otros No Asintomática 5 Mujer Alzheimer No Leve 6 Mujer Otros Sí Hospitalización 7 Mujer No No UCI 8 Mujer Alzheimer No Leve 9 Hombre Otros No Leve 10 Mujer Otros Sí Leve 11 Hombre Alzheimer No Leve 12 Hombre Alzheimer No Hospitalización 13 Mujer No No Leve 14 Mujer No No Asintomática 15 Hombre Alzheimer No Leve 16 Mujer No Sí Asintomática 17 Mujer No No Leve 18 Mujer No No Hospitalización 19 Mujer Alzheimer No Hospitalización 20 Hombre No No Leve Entonces: La tabla de frecuencias absolutas de la variable COVID-19 es: COVID-19 Frecs. Asintomática 3 Leve 11 Hospitalización 4 UCI 2 Su tabla de frecuencias relativas: COVID-19 Frecs. Asintomática 0.15 Leve 0.55 Hospitalización 0.20 UCI 0.10 Su tabla de frecuencias absolutas acumuladas: COVID-19 Frecs. Acum Asintomática 3 Leve 14 Hospitalización 18 UCI 20 Su tabla de frecuencias relativas acumuladas: COVID-19 Frecs. Acum Asintomática 0.15 Leve 0.70 Hospitalización 0.90 UCI 1.00 Su diagrama de barras de frecuencias absolutas acumuladas: Su diagrama de barras de frecuencias relativas acumuladas: La tabla bidimensional de frecuencias absolutas de las variables Demencia Senil y COVID-19: Asintomática Leve Hospitalización UCI Alzheimer 0 5 2 1 Otros 1 2 1 0 No 2 4 1 1 Su tabla de frecuencias relativas acumuladas dentro de cada nivel de demencia senil: Asintomática Leve Hospitalización UCI Alzheimer 0.00 0.625 0.875 1 Otros 0.25 0.750 1.000 1 No 0.25 0.750 0.875 1 El diagrama de barras yuxtapuestas de esta última tabla: Como vimos en el tema anterior, JAMOVI da las frecuencias acumuladas (si hemos especificado correctamente el orden de los niveles) al calcular tablas de contigencia en Exploración/Descriptivas. En las tablas multidimensionales la acumulación se lleva a cabo en el total, lo que no siempre es conveniente. Para calcular bien tablas bidimensionales acumulando frecuencias por filas o columnas hay que usar R en la ventana de edición R. Por ejemplo, para obtener la tabla de frecuencias relativas acumuladas que hemos dado hace un momento de niveles de gravedad de la COVID dentro de cada nivel de demencia senil podemos usar: Fijaos en la lógica de la sintaxis de esta instrucción. De dentro a fuera: table(data$Demencia, data$COVID) calcula la tabla de frecuencias absolutas de las variables Demencia y COVID, con filas la Demencia. prop.table(..., margin=1) calcula la tabla de frecuencias relativas (de proporciones) por filas (margin=1) de la tabla de frecuencias absolutas a la que se aplica en los puntos suspensivos. apply(..., MARGIN=1, FUN=cumsum) aplica la función cumsum, que calcula las sumas acumuladas, por filas (MARGIN=1) a la tabla entrada en los puntos suspensivos. Esta última función transpone nuestra tabla (siempre da el resultado de manera que la dimensión en la que se acumulan las frecuencias sea la de las columnas); si quisiérais mantener los tipos de demencia en la filas, se aplicaría t(...) al resultado del apply. Calculad la tabla bidimensional de frecuencias relativas acumuladas de los niveles de gravedad de la COVID-19 en cada sexo, y representad esta tabla por medio de un diagrama de barras yuxtapuestas adecuado. En el estudio del ejercicio al final de la Sección 7.4, entre los 60 enfermos hubo 12 de 40 años o menos, 3 entre 41 y 50 años, 15 entre 51 y 60 años y 30 de más de 60 años, mientras que los que no presentaron la enfermedad fueron, en estas franjas de edad, 29, 21, 17 y 18, respectivamente. Dad: Un diagrama de barras bidimensional que muestre las frecuencias relativas de las diferentes franjas de edad en enfermos y en sanos. Un diagrama de barras bidimensional que muestre las frecuencias relativas acumuladas de las diferentes franjas de edad en enfermos y en sanos. 8.2 Test (1) ¿Cuál es el valor con mayor frecuencia relativa acumulada en un conjunto de datos ordinales? La moda del conjunto de datos. El relativamente más frecuente. El primer dato obtenido. El último dato obtenido. El mayor dato obtenido. Ninguna de las respuestas anteriores es correcta. (2) A lo largo de un año se atendieron lesiones en la enfermería de un centro de secundaria con la siguiente distribución de gravedad: 26 muy leves, 28 leves, 15 moderadas, 8 graves y 3 muy graves. ¿Cuál es la frecuencia relativa acumulada del nivel de gravedad “Moderada”? 0.1875 0.8625 0.325 0.2174 0.69 Ninguna de las anteriores. "],["descripción-de-datos-cuantitativos.html", "Lección 9 Descripción de datos cuantitativos 9.1 Frecuencias 9.2 Medidas de tendencia central 9.3 Medidas de posición 9.4 Medidas de dispersión 9.5 Diagramas de puntos y de caja 9.6 Histogramas 9.7 Polígonos de frecuencias 9.8 Asimetría y curtosis 9.9 Estadísticos y gráficos con JAMOVI 9.10 Estadísticos sobre datos agrupados 9.11 Datos cuantitativos bivariantes 9.12 Gráficos en escala logarítmica 9.13 Test", " Lección 9 Descripción de datos cuantitativos Los datos cuantitativos son los que expresan cantidades que se representan mediante números, tales como los resultados de contar objetos o individuos o de medir pesos, distancias, tiempos o concentraciones. 9.1 Frecuencias Como los números reales están ordenados de manera natural, para estudiar una muestra de datos cuantitativos (una variable cuantitativa) podemos usar las frecuencias y las frecuencias acumuladas de sus diferentes valores, como en las variables ordinales. Esto realmente solo es útil cuando en la muestra tenemos pocos valores diferentes. Ejemplo 9.1 Vamos a ampliar la tabla de datos del Ejemplo 8.3 con los números de hijos vivos en el momento del ingreso de los pacientes en sus residencias. Tabla 9.1: Tabla de datos de pacientes de residencias geriátricas Sexo Demencia Senil Cáncer de mama COVID-19 Número de hijos 1 Mujer No No Leve 4 2 Mujer Alzheimer Sí Leve 1 3 Hombre Alzheimer No UCI 8 4 Mujer Otros No Asintomática 0 5 Mujer Alzheimer No Leve 3 6 Mujer Otros Sí Hospitalización 4 7 Mujer No No UCI 2 8 Mujer Alzheimer No Leve 1 9 Hombre Otros No Leve 1 10 Mujer Otros Sí Leve 2 11 Hombre Alzheimer No Leve 6 12 Hombre Alzheimer No Hospitalización 0 13 Mujer No No Leve 0 14 Mujer No No Asintomática 1 15 Hombre Alzheimer No Leve 4 16 Mujer No Sí Asintomática 2 17 Mujer No No Leve 0 18 Mujer No No Hospitalización 3 19 Mujer Alzheimer No Hospitalización 6 20 Hombre No No Leve 3 La tabla siguiente agrupa las diferentes tablas de frecuencias (absolutas y relativas, acumuladas o no) de los números de hijos de estos residentes: Número de hijos Frec. absoluta Frec. relativa Frec. abs. acumulada Frec. rel. acumulada 0 4 0.20 4 0.20 1 4 0.20 8 0.40 2 3 0.15 11 0.55 3 3 0.15 14 0.70 4 3 0.15 17 0.85 6 2 0.10 19 0.95 8 1 0.05 20 1.00 Y a modo de ejemplo, el diagrama de barras de frecuencias relativas de estos números de hijos es: La única diferencia entre estas tablas y diagramas de barras y los de las lecciones anteriores es que, en el caso de datos cuantitativos, se omiten los niveles con frecuencia 0, excepto aquellos que puedan ser relevantes para la comprensión de la muestra. 9.2 Medidas de tendencia central Como los datos cuantitativos son números reales y tienen el significado de números reales, podemos operar con ellos. Esto nos aporta una multitud de estadísticos, expresiones matemáticas que, aplicadas a un vector de datos cuantitativos, producen valores que expresan diferentes características del mismo. Supongamos de ahora en adelante que tenemos una muestra formada por \\(n\\) números, que denotaremos \\(x_1,\\ldots,x_n\\). En primer lugar tenemos los estadísticos de tendencia central, que dan un valor representativo del conjunto de datos de la variable; los más importantes son: La moda, que es el valor, o los valores, de máxima frecuencia (absoluta o relativa, tanto da). Normalmente, solo se usa para variables discretas. La media aritmética: \\[ \\overline{x}=\\frac{x_1+\\cdots+x_n}{n} \\] En este curso, cuando hablemos de la media de unos datos nos referiremos siempre a su media aritmética. Hay otros tipos de media, como por ejemplo la media geométrica o la armónica, que no estudiaremos. La mediana \\(Q_{0.5}\\), que representa el valor central en la lista ordenada de observaciones. Se define de la manera siguiente. Si denotamos por \\[ x_{(1)}\\leqslant x_{(2)}\\leqslant \\cdots \\leqslant x_{(n)} \\] los datos de la variable cuantitativa ordenados de menor a mayor: Si \\(n\\) es impar, su mediana es el dato central: \\(x_{(n+1)/2}\\). Por ejemplo, si una muestra está formada por 7 números, su mediana es el cuarto tras ordenarlos de menor a mayor. Si \\(n\\) es par, su mediana es la media de los dos datos centrales: \\[ \\frac{x_{(n/2)}+x_{(n/2+1)}}{2}. \\] Por ejemplo, si una muestra está formada por 8 números, su mediana es la media del cuarto y el quinto tras ordenarlos de menor a mayor. Ejemplo 9.2 Tomemos la variable “Hijos” de la Tabla 9.1, formada por los números 4, 1, 8, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 3 En su tabla de frecuencias vemos que la moda son los valores 0 y 1, que empatan en la frecuencia máxima. Su media es \\[ \\frac{4+1+8+0+3+\\cdots+0+3+6+3}{20}=2.55 \\] Para calcular su mediana, lo primero que hacemos es ordenar de menor a mayor las observaciones, y marcamos su posición dentro del conjunto ordenado: Posición 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Valor 0 0 0 0 1 1 1 1 2 2 2 3 3 3 4 4 4 6 6 8 Como tenemos 20 datos, la mediana será la media aritmética de sus dos valores centrales, los de las posiciones 10 y 11: \\(Q_{0.5}=(2+2)/2=2\\). Ejemplo 9.3 ¿Qué les pasa a estos estadísticos si eliminamos el paciente con 8 hijos de la muestra? Los datos son ahora 4, 1, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 3 La moda siguen siendo los valores 0 y 1, ya que no hemos modificado sus frecuencias y hemos eliminado observaciones Su media ahora es \\[ \\frac{4+1+0+3+\\cdots+0+3+6+3}{19}=2.263 \\] Como ahora tenemos 19 observaciones, su mediana será la observación central, es decir, la décima tras ordenarlas de menor a mayor: Posición 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Valor 0 0 0 0 1 1 1 1 2 2 2 3 3 3 4 4 4 6 6 Por lo tanto, \\(Q_{0.5}=2\\). Ejemplo 9.4 ¿Y qué les pasaría a estos estadísticos si, en la muestra original, hubiéramos cometido un error y al último paciente le hubiéramos anotado 300 hijos en lugar de 3? Los datos así serían: 4, 1, 8, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 300 La moda no cambia La media ahora sería \\[ \\frac{4+1+8+0+3+\\cdots+0+3+6+300}{20}=17.4 \\] Como volvemos a tener 20 números, la mediana sería otra vez la media de las observaciones décima y undécima tras ordenarlas de menor a mayor: Posición 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Valor 0 0 0 0 1 1 1 1 2 2 2 3 3 4 4 4 6 6 8 300 De nuevo, \\(Q_{0.5}=(2+2)/2=2\\). Figura 9.1: Moda, mediana y media (Stephen K. Campbell: Flaws and Fallacies in Statistical Thinking) Es importante observar que, como ilustran estos ejemplos y el chiste de S. K. Campbell: La moda es el valor más repetido, pero puede ser poco representativa y puede carecer completamente de interés si, por ejemplo, todos los valores de la muestra tienen frecuencias muy parecidas. La media es poco robusta, en el sentido de que los valores extremos pueden afectarla mucho La mediana es muy robusta, en el sentido de que los valores extremos la afectan poco Por este motivo, por ejemplo, a la hora de resumir los salarios españoles, se publican los tres valores: Figura 9.2: Gráfico publicado por el INE (https://www.ine.es/prensa/eces_2018_a.pdf) Es interesante copiar un trozo de la nota de prensa de la que hemos extraído el gráfico de la Figura 9.2, donde se comenta la relación entre la moda, la media y la mediana: “El salario bruto medio anual en España fue de 24.009,12 euros por trabajador en el año 2018, un 1,5% mayor al año anterior. La diferencia entre este salario medio y el salario más frecuente o modal (de 18.468,93 euros) fue de más de 5.500 euros. Esto significa que había pocos trabajadores con salarios muy altos pero que influyeron notablemente en el salario medio. “Por otra parte, el salario mediano (que divide al número de trabajadores en dos partes iguales, los que tienen un salario superior y los que tienen un salario inferior) presentó un valor de 20.078,44 euros en 2018.” ¿En serio que el salario más frecuente fue 18468.93 euros, y no de 18468.94? Bueno, en realidad este valor es una estimación y ciertamente se podrían haber ahorrado los céntimos… Ya volveremos más adelante sobre este punto. Revisad los cálculos de la moda, la media y la mediana efectuados por los agentes comerciales del chiste de la Figura 9.1. Algo falla. 9.3 Medidas de posición Las medidas de posición dividen la variable en unas determinadas proporciones; estos valores reciben el nombre de cuantiles. En este sentido, la mediana es también una medida de posición, puesto que divide la variable en dos mitades. Dada una proporción \\(0&lt;p&lt;1\\), el cuantil de orden \\(p\\), o \\(p\\)-cuantil, de una variable cuantitativa, que denotaremos por \\(Q_p\\), es el valor más pequeño del conjunto de datos cuya frecuencia relativa acumulada es mayor o igual que \\(p\\); o sea, el valor más pequeño de la muestra que es mayor o igual que el \\(100p\\%\\) de los valores de la muestra. Dicho de una tercera manera, si tenemos un conjunto de números \\(x_1, \\ldots, x_n\\) y los ordenamos de menor a mayor, \\[ x_{(1)}\\leqslant x_{(2)}\\leqslant \\cdots \\leqslant x_{(n)}, \\] entonces \\(Q_p\\) es el primer valor \\(x_{(i)}\\) de esta lista ordenada que deja a su izquierda (incluyéndolo a él) como mínimo la fracción \\(p\\) de los datos, es decir, \\(p\\cdot n\\) datos. La excepción a esta regla es el cuantil \\(Q_{0.5}\\), que es la mediana y se calcula como hemos explicado antes. Ejemplo 9.5 Volvamos a la variable “Hijos” de la Tabla 9.1. Sus 20 valores, ordenados de menor a mayor son: Posición 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Valor 0 0 0 0 1 1 1 1 2 2 2 3 3 3 4 4 4 6 6 8 Entonces: El 0.2-cuantil, \\(Q_{0.2}\\), es el primer elemento en esta lista ordenada que es mayor o igual que el 20% de los datos. Como el 20% de 20 es 4, \\(Q_{0.2}\\) es el cuarto elemento de la lista ordenada: 0. El 0.75-cuantil, \\(Q_{0.75}\\), es el primer elemento en esta lista ordenada que es mayor o igual que el 75% de los datos. Como el 75% de 20 es 15, \\(Q_{0.75}\\) es el decimoquinto elemento de la lista ordenada: 4. El cuantil de orden 1/3, \\(Q_{1/3}\\), es el primer elemento en esta lista ordenada que es mayor o igual que un tercio de los datos. Como un tercio de 20 es 6.66 y pico, \\(Q_{1/3}\\) es el séptimo elemento de la lista ordenada: 1. Fijaos en que 6/20=0.3, y por lo tanto el sexto elemento de la lista solo es mayor o igual que el 30% de la muestra, no un tercio. Necesitamos el séptimo elemento para llegar al tercio, aunque entonces nos pasemos. Los cuantiles se calculan a partir de los valores ordenados de la muestra, teniendo en cuenta los valores repetidos. Es decir, si se han observado un 1, un 2, un 3, un 4 y cinco 5, la mediana no es el valor central de 1, 2, 3, 4, 5, sino el de 1, 2, 3, 4, 5, 5, 5, 5, 5, que es 5. En realidad, la definición que hemos dado de cuantil es “orientativa”: no hay una regla única para calcular cuantiles de una muestra (salvo la mediana), y se han propuesto varios métodos que pueden dar resultados diferentes; podéis consultar nueve de estos métodos en la entrada sobre cuantiles de la Wikipedia en inglés. La razón de esta diversidad es que a veces el objetivo final del cálculo de un cuantil no es solo descriptivo (dar el menor valor mayor o igual que una fracción \\(p\\) de la muestra) sino que es inferencial (estimar el menor valor que es mayor o igual que una fracción \\(p\\) del total de la población) y esta inferencia se puede hacer de muchas maneras, según las propiedades que tenga (o que supongamos que tenga) la población. ¿Qué os recomendamos? No os compliquéis la vida: Si calculáis cuantiles a mano, usad la definición que hemos dado, que es la más sencilla de todas Si los calculáis con algún paquete estadístico, usad su método por defecto (que seguramente no sea el que hemos explicado) Algunos cuantiles con nombre propio: La mediana es el cuantil \\(Q_{0.5}\\). Los cuartiles son los cuantiles \\(Q_{0.25}\\), \\(Q_{0.5}\\) y \\(Q_{0.75}\\), y reciben, respectivamente, los nombres de primer cuartil, segundo cuartil (o mediana) y tercer cuartil. \\(Q_{0.25}\\) será, pues, el menor valor que es mayor o igual que una cuarta parte de los datos, y \\(Q_{0.75}\\), el menor valor que es mayor o igual que tres cuartas partes de los datos. Los deciles son los cuantiles \\(Q_{p}\\) con \\(p\\) un múltiplo entero de 0.1: el primer decil es \\(Q_{0.1}\\), el segundo decil es \\(Q_{0.2}\\), y así sucesivamente. Los percentiles son los cuantiles \\(Q_{p}\\) con \\(p\\) un múltiplo entero de 0.01: \\(Q_{0.01}\\) es el primer percentil, \\(Q_{0.02}\\) es el segundo percentil, etc. Se llama intervalo intercuartílico, \\(\\mathit{IQI}\\), al intervalo cerrado \\([Q_{0.25},Q_{0.75}]\\). Fijaos que como un 75% de los datos de la muestra son menores o iguales que \\(Q_{0.75}\\) y, de estos, un 25% son menores o iguales que \\(Q_{0.25}\\), dentro del \\(\\mathit{IQI}\\) caerán más o menos el 50% de los datos de la muestra, a no ser que haya muchas repeticiones en los extremos del intervalo. Ejemplo 9.6 Seguimos con la variable “Hijos” de la Tabla 9.1. Su primer cuartil será su quinto dato tras ordenarlos de menor a mayor; como hay cuatro ceros y cuatro unos, será 1. Su tercer cuartil ya lo hemos calculado antes, es 4. Por lo tanto su intervalo intercuartílico es [1,4]. Este intervalo contiene 14 elementos de la muestra, bastante más de la mitad, porque la muestra contiene muchas repeticiones del 1 y el 4. Las medidas de posición también se pueden, y se suelen, usar en la descripción de datos ordinales. En este caso, la mediana se define como el primer valor de la muestra mayor o igual que (al menos) la mitad de la muestra. El resto de cuantiles se definen como los hemos definido aquí. Aquí tenéis una muestra de 14 niveles de glucosa medidos en niños en ayunas: 56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72 Calculad su: Moda Media Mediana Primer y tercer cuartiles Porcentaje de elementos de la muestra que caen dentro del intervalo intercuartílico 9.4 Medidas de dispersión Las medidas de dispersión evalúan lo desperdigados que están los datos. Las más importantes son (seguimos suponiendo que nuestra muestra está formada por los números \\(x_1,\\ldots,x_n\\)): El recorrido, o rango (del inglés range): la diferencia entre el máximo y el mínimo de las observaciones. El recorrido, o rango, intercuartílico: la diferencia \\(\\mathit{IQR}=Q_{0.75}-Q_{0.25}\\). Id con cuidado, porque también se llama a veces rango intercuartílico a lo que nosotros llamamos intervalo intercuartílico, \\([Q_{0.25},Q_{0.75}]\\). La varianza: la media aritmética de las diferencias al cuadrado entre los datos \\(x_i\\) y su media \\(\\overline{x}\\): \\[ s_x^2=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n} \\] La desviación típica (o estándard): la raíz cuadrada positiva de la varianza: \\(s_x=+\\sqrt{s_x^2}\\). La varianza muestral: se define como la varianza, pero usando \\(n-1\\) en lugar de \\(n\\) en el denominador: \\[ \\tilde{s}_x^2 =\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n-1} \\] La desviación típica muestral: la raíz cuadrada positiva de la varianza muestral: \\(\\tilde{s}_x=+\\sqrt{\\tilde{s}_x^2}\\). El coeficiente de variación: la proporción de la media que representa la desviación típica (se usa solo para conjuntos de datos positivos): \\(CV_x=s_x/\\overline{x}\\) La desviación media respecto de la mediana: la media aritmética de los valores absolutos de las diferencias entre los datos \\(x_i\\) y su mediana \\(Q_{0.5}\\): \\[ MDM(x)=\\frac{\\sum_{i=1}^n |x_i-Q_{0.5}|}{n} \\] Ejemplo 9.7 Calculemos todos estos valores para nuestra variable “Hijos” 4, 1, 8, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 3 Su máximo es 8 y su mínimo 0, por lo tanto su recorrido es 8 Ya hemos calculado en la sección anterior su intervalo intercuartílico, que es [1,4], por lo que su rango intercuartílico es 3. Como su media es 2.55, su varianza es \\[ s^2_x=\\frac{(4-2.55)^2+(1-2.55)^2+(8-2.55)^2+\\cdots+(3-2.55)^2}{20}=4.8475 \\] Su desviación típica es \\[ s_x=\\sqrt{4.8475}=2.202 \\] Su varianza muestral es \\[ \\widetilde{s}^2_x=\\frac{(4-2.65)^2+(1-2.65)^2+(8-2.65)^2+\\cdots+(3-2.65)^2}{19}=5.1026 \\] Su desviación típica muestral es \\[ \\widetilde{s}_x=\\sqrt{5.1026}=2.259 \\] Su coeficiente de variación es \\[ CV_x=\\frac{2.202}{2.55}=0.8634 \\] Como su mediana es 2, su desviación media respecto de la mediana es \\[ MDM_x=\\frac{|4-2|+|1-2|+|8-2|+\\cdots+|3-2|}{20}=1.75 \\] La diferencia entre la varianza y la varianza muestral, aparte de la tilde \\(\\widetilde{\\ }\\) en el símbolo de la muestral, es el denominador, que es \\(n\\) para la primera y \\(n-1\\) para la segunda. Por lo tanto, se puede pasar de una a otra simplemente cambiando el denominador: \\[ \\widetilde{s}^2_x=\\frac{n}{n-1}\\cdot s^2_x. \\] Y tomando raíces cuadradas: \\[ \\widetilde{s}_x=\\sqrt{\\frac{n}{n-1}}\\cdot s_x. \\] ¿Por qué introducimos la varianza y la varianza muestral? ¿No bastaría con una, si además se pasa de una a otra con una simple transformación lineal? ¿No es ya la vida lo suficientemente complicada como para añadir definiciones innecesarias? El motivo de distinguir entre la varianza y la varianza muestral es su aplicación en la estimación de la varianza de la variable poblacional: Por un lado, es natural medir la variabilidad de un conjunto de datos cuantitativos mediante su varianza “a secas”, definida como la media de las distancias (al cuadrado) de los datos a su valor promedio. Por lo tanto, si nuestro objetivo final es puramente la descripción de nuestro conjunto de datos, usar la varianza verdadera es lo correcto. Pero, por otro lado, nuestro conjunto de datos será, normalmente, una muestra de una población, y lo más seguro es que, en realidad, la varianza de nuestra muestra nos interese sobre todo como estimación de la varianza de toda la población, es decir, de la varianza poblacional. Pues bien, como veremos más adelante, resulta que la varianza verdadera de una muestra da valores en promedio más pequeños que la varianza real de la población, mientras que la varianza muestral da valores alrededor de la varianza poblacional. Por lo tanto, si nuestro objetivo es estimar la varianza de la población, lo correcto es usar la varianza muestral. De todas formas, para muestras grandes, la diferencia no es importante: si \\(n\\) es grande, dividir por \\(n\\) o por \\(n-1\\) no significa una gran diferencia, y sobre todo si tenemos en cuenta que se trata de estimar la varianza de la población, no de calcularla exactamente. ¿Y por qué definimos la varianza y desviación típica, si ambas medidas dan una información equivalente, ya que la segunda es la raíz cuadrada de la primera? El motivo es que si los elementos de una variable cuantitativa tienen unidades (metros, años, individuos por metro cuadrado…), sus varianzas (“a secas” y muestral) tienen estas unidades al cuadrado; por ejemplo, si los \\(x_i\\) son años, los valores de \\(s_x^2\\) y \\(\\tilde{s}_x^2\\) representan años al cuadrado. En cambio, las desviaciones típicas tienen las mismas unidades que los datos, por lo que se pueden comparar con ellos, y de ahí su utilidad. ¿Y el coeficiente de variación? ¿Cuándo conviene usarlo? Si queremos comparar la dispersión de dos variables con datos de la misma naturaleza, por ejemplo alturas, pero medidos en unidades diferentes, por ejemplo una en metros y la otra en centímetros, no es correcto usar medidas como la varianza o la desviación típica que dependan de las unidades. En este caso es más recomendable usar el coeficiente de variación \\(CV_x\\). Mirad el ejemplo siguiente. Ejemplo 9.8 Considerad las alturas de los niños recogidos en la Tabla 6.1, que, medidas en cm, eran 135, 132, 138, 141, 134, 136 Su media es \\[ \\overline{x}=\\frac{135+ 132+138+141+134+136}{6}=136\\ \\text{cm} \\] y desviación típica es \\[ s_x=\\sqrt{\\frac{(135-136)^2+(132-136)^2+(138-136)^2+(141-136)^2+(134-136)^2}{6}}=2.887\\ \\text{cm} \\] Si damos estas alturas en metros, 1.35, 1.32, 1.38, 1.41, 1.34, 1.36 su media es \\[ \\overline{x}=\\frac{1.35+ 1.32+1.38+1.41+1.34+1.36}{6}=1.36\\ \\text{m} \\] y desviación típica es \\[ s_x=\\sqrt{\\frac{(1.35-1.36)^2+(1.32-1.36)^2+(1.38-1.36)^2+(1.41-1.36)^2+(1.34-1.36)^2}{6}}=0.02887\\ \\text{m} \\] La desviación típica de las alturas en centímetros es 100 veces mayor que la de las alturas en metros, pero sería incorrecto decir que las primeras son más dispersas que las segundas, ya que en realidad se trata de los mismos datos. La diferencia se debe simplemente a las unidades en las que las hemos medido. En cambio, en ambos casos el coeficiente de variación es el mismo: \\[ \\frac{2.887}{136}=\\frac{0.02887\\cdot 100}{1.36\\cdot 100}=\\frac{0.02887}{1.36}=0.0212 \\] La varianza tiene las propiedades matemáticas siguientes: \\(s_x^2\\geqslant 0\\), porque es una suma de cuadrados de números reales. Si \\(s_x^2=0\\), todos los sumandos \\((x_i-\\overline{x})^2\\) son 0 y, por lo tanto, todos los datos son iguales a su media. La implicación al revés también es cierta: si todos los datos son iguales, su media es igual a este mismo valor común, y por lo tanto todos los sumandos \\((x_i-\\overline{x})^2\\) son 0. Así pues, \\(s_x^2=0\\) significa que todos los datos son iguales. A partir de la fórmula dada para \\(s_x^2\\) y operando astutamente se obtiene la fórmula siguiente, que os puede ser útil: \\[ s_x^2= \\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2 \\] Es decir, la varianza es la media de los cuadrados, menos el cuadrado de la media. Hay que ir con cuidado con la desviación típica y la desviación típica muestral. En los trabajos científicos es frecuente que se utilice una u otra sin especificar cuál es, y se la llame “desviación típica” (standard deviation) y se la denote por \\(s\\) independientemente de cuál sea en realidad. Asimismo, la mayoría de paquetes estadísticos, R incluido, llevan funciones para calcular la varianza y la desviación típica (sin más aclaraciones) que, en realidad, calculan sus versiones muestrales. El motivo es que priman su aspecto inferencial sobre el descriptivo. Seguimos con nuestra muestra de 14 niveles de glucosa medidos en niños en ayunas: 56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72 Calculad su: Recorrido IQR Varianza Desviación típica Varianza muestral Desviación típica muestral Coeficiente de variación ¿Qué varianza y desviación típica calcula vuestra calculadora? 9.5 Diagramas de puntos y de caja En un diagrama de puntos (stripchart) dibujamos todos los valores de una muestra en una columna. Si hay valores repetidos, los separamos horizontalmente, para poder ver su frecuencia. Ejemplo 9.9 Consideremos los 14 niveles de glucosa usados en ejercicios anteriores: 56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72 Su diagrama de puntos es Los diagramas de puntos solo son útiles cuando tenemos pocos valores en la muestra, de manera que valga la pena verlos todos. Cuando la muestra es grande, pongamos de 20 o más números, se suelen reemplazar por un gráfico que resume algunos estadísticos de la muestra llamado un diagrama de caja (boxplot). La estructura básica de un diagrama de caja es la que muestra la Figura 9.3. Figura 9.3: Un diagrama de caja genérico En este gráfico: La línea gruesa que divide la caja marca la mediana Los lados inferior y superior de la caja representan los cuartiles \\(Q_{0.25}\\) y \\(Q_{0.75}\\). Por lo tanto: la altura de la caja es igual al rango intercuartílico \\(\\mathit{IQR}\\) la caja contiene alrededor del 50% de los valores de la muestra Los valores \\(b_{inf}, b_{sup}\\) son los bigotes (whiskers) del gráfico y se calculan de la manera siguiente: El bigote inferior \\(b_{inf}\\) es el menor valor de la muestra que es mayor o igual que \\(Q_{0.25}- 1.5\\cdot \\mathit{IQR}\\) El bigote superior \\(b_{sup}\\) es el mayor valor de la muestra que es menor o igual que \\(Q_{0.75}+1.5\\cdot\\mathit{IQR}\\) Si hay datos más allá de los bigotes, se llaman valores atípicos o anómalos, outliers en inglés, y se marcan como puntos aislados. Como su nombre indica, estos valores atípicos son valores que consideramos “muy raros”. Antes de llevar a cabo un estudio inferencial a partir de una muestra, es conveniente dar un vistazo a sus valores atípicos, si los hay. ¿Son datos legítimos? ¿Son errores? ¿Corresponden a individuos con características especiales que conviene no tener en cuenta en el estudio? El inventor de los diagramas de caja, John Tukey, tomó el 1.5 en la definición de los bigotes como un compromiso entre 1 (salían demasiados valores atípicos) y 2 (demasiado pocos). Volveremos sobre esto más adelante. Ejemplo 9.10 Vamos a dibujar el diagrama de caja de los 14 niveles de glucosa usados en ejercicios anteriores, y que damos ordenados de menor a mayor: 56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72 Tenemos que \\(Q_{0.25}=63\\), \\(Q_{0.5}=65.5\\) y \\(Q_{0.75}=66\\). Esto nos define la caja central. \\(b_{inf}\\) será el primer valor de la muestra ordenada que es mayor o igual que \\(63- 1.5\\cdot 3=58.5\\). Es el 60. \\(b_{sup}\\) será el último valor de la muestra ordenada que es menor o igual que \\(66+ 1.5\\cdot 3=70.5\\). Es el 70. Hay dos valores atípicos: el 56, que es menor que \\(b_{inf}\\), y el 72, que es mayor que \\(b_{sup}\\). El resultado es el siguiente, en el que hemos superpuesto el diagrama de puntos para comprender mejor cómo hemos obtenido el diagrama: Dibujad el diagrama de puntos de la variable “Hijos” y superponedle su diagrama de caja. El resultado debería ser: En los gráficos anteriores hemos superpuesto el diagrama de puntos al diagrama de caja para ayudar a comprender cómo se construye este último, pero en la vida real esto no se hace: se da un gráfico u otro, nunca los dos. Hay paquetes estadísticos que producen diagramas de caja cuyas partes tienen un significado diferente del que hemos explicado. Por ejemplo, en los que la línea central corresponde a la mediana y la caja central representa el intervalo media \\(\\pm\\) desviación típica. Por otro lado, como los lados de la caja son cuartiles, diferentes programas pueden dar diagramas de caja ligeramente diferentes, según la definición de cuantil que calculen por defecto. Los bigotes y los valores atípicos son siempre elementos de la muestra. La mediana no siempre (puede obtenerse como la media de dos valores de la muestra y no pertenecer a la muestra), y con nuestra definición los cuartiles pertenecen a la muestra, pero con otras definiciones no tienen por qué. 9.6 Histogramas Un histograma es una representación gráfica de un conjunto de datos cuantitativos continuos, consistente en dividir el intervalo de valores entre el mínimo y el máximo en intervalos contiguos y disjuntos, llamado clases, y dibujar entonces una especie de diagrama de barras de estas clases con las particularidades siguientes: Las barras se dibujan sin espacios entre ellas (para representar la continuidad de los datos) Si se trata de un histograma de frecuencias absolutas (en el que las barras representan las frecuencias absolutas de las clases) y todas las clases tienen la misma amplitud, las alturas de las barras son las frecuencias de las clases En cualquier otro caso (es decir, si se trata de un histograma de frecuencias relativas o si es un histograma de frecuencias absolutas pero no todas las clases tienen la misma longitud), las alturas de las barras han de ser tales que las áreas de las barras sean iguales a las frecuencias de las clases En realidad: En un histograma lo que representa la frecuencia de la clase es siempre el área de su barra. Pero si todas las clases tienen la misma amplitud, las áreas de las barras serán sus alturas por la longitud común de las bases, y por lo tanto proporcionales a las alturas. En este caso, y solo en este caso, podemos interpretar que las alturas representan las frecuencias. Pero en la práctica, y por motivos que se entenderán al hablar de variables aleatorias en el próximo tema, esta representación de las frecuencias por medio de las alturas solo se lleva a cabo para frecuencias absolutas. Ejemplo 9.11 Consideremos la siguiente muestra de 30 alturas de estudiantes: 1.71,1.62,1.72,1.76,1.78,1.73,1.67,1.64,1.63,1.68,1.68,1.70,1.67,1.56,1.66, 1.57,1.69,1.68,1.67,1.75,1.61,1.60,1.74,1.70,1.65,1.55,1.82,1.70,1.69,1.81 El gráfico siguiente muestra el diagrama de barras de sus frecuencias absolutas, tomando como posibles niveles todas las alturas entre su mínimo y su máximo redondeadas a cm. Todas la barras tienen alturas entre 0 y 3, y salvo una mayor presencia de los valores centrales (entre 1.67 y 1.70), no hay mucho más que salte a la vista en este gráfico. Ahora vamos a agrupar estas alturas en intervalos de 5cm. Como el valor mínimo de la muestra es 1.55 y el máximo es 1.82, vamos a tomar las clases 1.55-1.59, 1.60-1.64, 1.65-1.69,1.70-1.74,1.75-1.79, 1.80-1.84. Dibujando el diagrama de barras de las frecuencias absolutas de estas clases sin dejar espacios entre las barras, obtenemos el histograma siguiente: La distribución de estas alturas es mucho más fácil de entender mediante este gráfico que con el primero. Por sistema, en nuestros histogramas las clases serán siempre cerradas a la izquierda y abiertas a la derecha: es decir, el extremo izquierdo de una barra pertenece a su clase, pero el extremo derecho no. Lo hacemos para que sean consistentes con las distribuciones de variables aleatorias que definiremos en los próximos temas. Pero fuera de estas notas, cada paquete estadístico hace lo que consideraron oportuno sus creadores, y puede que el convenio de sus histogramas sea que el extremo izquierdo de una barra no pertenezca a la clase y el extremo derecho sí. Por ejemplo, así es como los produce JAMOVI por defecto. Hemos dicho que si las clases tienen la misma amplitud, las alturas de las barras han de ser las frecuencias de las clases. Pero si las clases tienen diferente amplitud, las alturas de las barras han de ser tales que las áreas de las barras sean iguales a las frecuencias de las clases. Veamos un ejemplo Ejemplo 9.12 El gráfico siguiente es un histograma de un conjunto de 188 notas finales de una asignatura: En este histograma, hemos tomado las clases [0,1), [1,2),…,[9,10]. Si en cambio hubiéramos tomado las clases [0,5) (suspenso), [5,7) (aprobado), [7,9) (notable) y [9,10] (sobresaliente), el histograma sería el siguiente: Aquí no tiene sentido marcar las frecuencias en el eje de ordenadas, porque, por ejemplo, la altura de la barra de notables es mayor que la de los suspensos, pero su frecuencia es menor. Por este motivo las hemos indicado dentro de las barras. Suponemos que estaréis de acuerdo en que es más fácil entender la distribución de las notas con el primer histograma que con el segundo. Como el objetivo de un gráfico ha de ser ayudar a comprender un conjunto de datos, casi siempre es más conveniente usar clases de la misma amplitud a la hora de dibujar histogramas, y solo las usaremos de diferentes amplitudes cuando no haya más remedio. Ahora bien, el número de clases ya depende de los intereses del investigador; números de clases diferentes muestran efectos diferentes. Una posible regla general para decidir el número de clases que normalmente da buenos resultados es tomar alrededor de \\(\\sqrt{n}\\) clases (donde \\(n\\) indica el tamaño de la muestra) pero no menos de 5 clases ni más de 15. Ejemplo 9.13 Tenemos una muestra de tensiones arteriales medias de 120 adultos. Si tomamos 5 clases, con las frecuencias Clase Frecuencia [80,100) 6 [100,120) 49 [120,140) 45 [140,160) 18 [160,180) 2 obtenemos el histograma Si tomamos 9 clases, con las frecuencias Clase Frecuencia [80,90) 3 [90,100) 3 [100,110) 16 [110,120) 33 [120,130) 23 [130,140) 22 [140,150) 13 [150,160) 5 [160,170) 2 obtenemos el histograma Y si tomamos 15 clases, con las frecuencias Clase Frecuencia [80,85) 1 [85,90) 2 [90,95) 1 [95,100) 2 [100,105) 6 [105,110) 10 [110,115) 13 [115,120) 20 [120,125) 9 [125,130) 14 [130,135) 13 [135,140) 9 [140,145) 9 [145,150) 4 [150,155) 3 [155,160) 2 [160,165) 2 obtenemos el histograma En este último histograma, con más resolución, podemos observar dos picos que en los otros no aparecen. Como hemos comentado, los histogramas también pueden ser de frecuencias relativas: en este caso, tanto si todas las clases tienen la misma amplitud como si no, las alturas de las cajas han de ser los valores tales que el área de la barra sea la frecuencia relativa de la clase. Estas alturas son las densidades de las clases. Es decir: La frecuencia relativa de cada clase es el tamaño de la clase (la base de la barra) por su densidad (la altura de la barra). De esta manera, la suma de las áreas de las barras será 1. Como también ya hemos comentado, veremos la justificación de esta convención en el próximo tema, sobre Variables Aleatorias. Así, en el ejemplo anterior para 9 clases, las frecuencias relativas y las densidades serían Clase Frec. absoluta Frec. relativa Densidad [80,90) 3 0.025 0.0025 [90,100) 3 0.025 0.0025 [100,110) 16 0.133 0.0133 [110,120) 33 0.275 0.0275 [120,130) 23 0.192 0.0192 [130,140) 22 0.183 0.0183 [140,150) 13 0.108 0.0108 [150,160) 5 0.042 0.0042 [160,170) 2 0.017 0.0017 y el histograma de frecuencias relativas a que dan lugar es Recordad que, en un histograma correcto, si las clases tienen amplitud diferente, las alturas de las barras han de ser las que den como áreas de las barras las frecuencias (absolutas o relativas) de las clases. Ejemplo 9.14 El gráfico siguiente, extraído de “Iodine status of UK schoolgirls: a cross-sectional survey” (M. Vanderpump et al, The Lancet 377 (2011), pp. 2007–2012), representa las proporciones de colegialas británicas en una muestra que tuvieron diferentes concentraciones de yodo en la orina. Es un diagrama de barras, no un histograma. A primera vista, parecería que la distribución de estas concentraciones de yodo es bastante simétrica. Pero observad que las clases no tienen la misma amplitud. El histograma de frecuencias relativas correcto con estas clases es el siguiente, donde observamos lo que llamaremos una cola a la derecha: En este último histograma vemos claramente que el conjunto de datos no es de ninguna manera simétrico. 9.7 Polígonos de frecuencias A menudo se substituye un histograma con clases de la misma amplitud por un polígono de frecuencias, en el que Para cada clase, marcamos el punto de abscisa el punto medio de la clase y ordenada la altura de su barra (o sea, el que sería el punto medio del lado superior de la barra) Unimos puntos consecutivos mediante segmentos A modo de ejemplo, recordemos el histograma de un conjunto de notas del Ejemplo 9.12, agrupadas en 10 clases: Su polígono de frecuencias es: Los polígonos de frecuencias son útiles para representar simultáneamente varios histogramas: Aquí tenéis los tiempos (en horas) de los ganadores de la maratón de Nueva York (categorías masculina y femenina) de 1970 a 2015, ordenados de menor a mayor: 2.08, 2.12, 2.13, 2.13, 2.13, 2.13, 2.13, 2.13, 2.13, 2.13, 2.13, 2.13, 2.15, 2.15, 2.15, 2.15, 2.15, 2.15, 2.15, 2.15, 2.15, 2.15, 2.15, 2.17, 2.17, 2.17, 2.17, 2.17, 2.17, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.20, 2.20, 2.23, 2.32, 2.35, 2.37, 2.37, 2.38, 2.38, 2.38, 2.38, 2.40, 2.40, 2.40, 2.40, 2.42, 2.42, 2.42, 2.42, 2.42, 2.42, 2.42, 2.42, 2.42, 2.42, 2.43, 2.43, 2.45, 2.45, 2.45, 2.45, 2.45, 2.45, 2.47, 2.47, 2.47, 2.47, 2.47, 2.47, 2.47, 2.47, 2.48, 2.50, 2.50, 2.52, 2.53, 2.65, 2.72, 2.77, 2.92, 2.95, 3.12, 3.13 Dibujad su histograma usando 6 clases de amplitud 0.2, empezando en 2 horas, y su diagrama de caja. ¿Qué observáis en cada uno de ellos que no podáis observar en el otro? ¿Cuál de los dos os parece más informativo? 9.8 Asimetría y curtosis Terminamos la descripción de variables cuantitativas con otros dos estadísticos que a veces se usan en la literatura médica, y por tanto conviene que conozcáis, pero que nosotros no usaremos, porque son inútiles: las propiedades que describen se ven mejor con un histograma o un diagrama de barras, y no sirven para estimar la correspondiente propiedad de la variable poblacional (que en todo caso es la interesante). Dada una muestra de datos numéricos \\(x_1,\\ldots,x_n\\), de media \\(\\overline{x}\\) y desviación típica \\(s_x\\): El coeficiente de asimetría (skewness) es \\[ \\gamma_1=\\frac{1}{s_x^3}\\cdot \\frac{\\sum_{i=1}^n (x_i-\\overline{x})^3}{n} \\] El coeficiente de curtosis, o apuntamiento, es \\[ \\beta_2=\\frac{1}{s_x^4}\\cdot \\frac{\\sum_{i=1}^n (x_i-\\overline{x})^4}{n}-3 \\] Empecemos con el coeficiente de asimetría. Como su nombre indica, cuantifica la asimetría de la variable. Para definir esta característica, lo más práctico es dibujar un histograma o un diagrama de barras de la variable y considerar el eje vertical pasando por la mediana, que divide la muestra en dos partes del mismo tamaño. Llamaremos colas a los trozos del histograma a ambos lados de este eje. Entonces: La variable es simétrica si ambas colas son similares, como en los dos gráficos siguientes: Esta última diremos que tiene forma de U, por motivos obvios. La variable tiene asimetría negativa o a la izquierda cuando la cola de la izquierda es más larga que la de la derecha, en el sentido de que hay más valores más alejados de la mediana por la izquierda que por la derecha. En este caso se suele decir que la variable presenta una cola a la izquierda (aunque con la definición que hemos dado la variable siempre tiene una cola a cada lado). La variable tiene asimetría positiva o a la derecha cuando la cola de la derecha es más larga que la de la izquierda, en el sentido de que hay más valores más alejados de la mediana por la derecha que por la izquierda. En este caso también diremos que la variable presenta una cola a la derecha. Habréis observado que en los histogramas anteriores hemos dibujado las líneas verticales sobre la media y la mediana. En una variable simétrica, la simetría hace que la media y la mediana sean aproximadamente iguales En una variable asimétrica a la izquierda, la existencia de valores relativamente muy pequeños en el extremo de la cola de la izquierda suele desplazar la media hacia la izquierda de la mediana, de manera que la media suele ser más pequeña que la mediana. Y al revés, en una variable asimétrica a la derecha, la existencia de valores relativamente muy grandes en el extremo de la cola de la derecha suele desplazar la media hacia la derecha de la mediana, de manera que la media suele ser más grande que la mediana. En los puntos anteriores hemos descrito lo que “suele pasar” con la media y la mediana en variables asimétricas, pero no siempre pasa. Así, si la media de un vector de datos es bastante más grande que la mediana, suele ser señal de que la muestra es asimétrica a la derecha, pero solo lo “suele ser”: con un poco de imaginación se puede construir un vector asimétrico a la izquierda con la media a la derecha de la mediana. Pensadlo un poco. Pues bien, el coeficiente de asimetría \\(\\gamma_1\\) indica el tipo de asimetría de la variable: Cuando \\(\\gamma_1\\approx 0\\), la distribución de los datos es simétrica Cuando \\(\\gamma_1&lt; 0\\), la variable es asimétrica negativa, con cola a la izquierda Cuando \\(\\gamma_1&gt; 0\\), la variable es asimétrica positiva, con cola a la derecha La mejor manera de decidir la asimetría de una variable es por medio de un histograma, aunque a menudo también se puede ver en un diagrama de caja, como muestran los gráficos siguientes: Un histograma y diagrama de caja de una variable simétrica: Un histograma y diagrama de caja de una variable asimétrica a la izquierda: Un histograma y diagrama de caja de una variable asimétrica a la derecha: Usar la media y la desviación típica (o la varianza) para describir el “valor central” de una variable y cuantificar su dispersión, respectivamente, es lo adecuado solo cuando la variable es bastante simétrica: más aún, solo cuando es bastante simétrica y su histograma recuerda la forma de una campana de Gauss (Figura 9.4); es decir, por ejemplo, no cuando tiene forma de U. Cuando el histograma es simétrico y con una forma parecida a una campana de Gauss (lo que llamaremos se ajusta a una variable normal en las próximas lecciones), el intervalo \\(\\overline{x}\\pm s_x\\) suele contener aproximadamente unos 2/3 de los datos de la muestra. Pero para variables muy asimétricas o simétricas en forma de U es mejor usar la mediana y el intervalo intercuartílico. Recordad que este último contiene más o menos el 50% de la muestra. Figura 9.4: Una campana de Gauss Ejemplo 9.15 Considerad la variable (asimétrica a la derecha) que tiene el histograma siguiente: Resulta que su media es \\(\\overline{x}=3.1\\) y su desviación típica es \\(s_x=2.5\\), y que el intervalo \\([\\overline{x}-s_x,\\overline{x}+s_x]\\) contiene un 84% de la muestra. Su mediana es \\(Q_{0.5}=2.3\\), a la izquierda de la media, y su intervalo intercuartílico \\(IQI\\) es [1.3,4.2]. Por cierto, su coeficiente de asimetría es \\(\\gamma_1=1.7\\), lo que es consistente con su cola a la derecha. Considerad ahora la variable más o menos simétrica siguiente: Resulta que su media es \\(\\overline{x}=2.9\\) y su desviación típica es \\(s_x=1.1\\), y que el intervalo \\([\\overline{x}-s_x,\\overline{x}+s_x]\\) contiene un 64% de la muestra. Su mediana es \\(Q_{0.5}=3\\), muy cercana a su media, y su \\(IQI\\) es [2.2, 3.7]. Su coeficiente de asimetría es \\(\\gamma_1=-0.03\\), lo que es consistente con su simetría. Considerad finalmente la variable siguiente, que es simétrica pero en forma de U: Resulta que su media es \\(\\overline{x}=3.9\\) y su desviación típica es \\(s_x=2.2\\), pero el intervalo \\([\\overline{x}-s_x,\\overline{x}+s_x]\\) contiene solo el 52% de la muestra. Su mediana es también \\(Q_{0.5}=3.9\\) y su \\(IQI\\) es [1.8,5.9]. Su coeficiente de asimetría es \\(\\gamma_1=0.0007\\). Los tres tipos de simetría/asimetría se generalizan de manera inmediata a variables poblacionales, a partir de alguna representación gráfica de su distribución. Por ejemplo, si recordáis el gráfico de la distribución de los salarios anuales españoles (Figura 9.2), presenta una clara asimetría a la derecha que arrastra el salario medio a la derecha del mediano. Figura 9.5: Los tres tipos de asimetría (adaptado de Statistics from A to Z, de A. Jawlik (Wiley 2016)). El 1.5 en la definición de los bigotes en los diagramas de caja es tal que, si la variable “se ajusta a una variable normal” (su histograma se parece a una campana de Gauss), se espere alrededor de un 0.35% de valores atípicos a cada lado de la caja. En un examen, un 60% de los estudiantes han sacado una nota superior a la media. ¿Cómo esperáis que sea la muestra de notas: simètrica, con cola a la izquierda, con cola a la derecha? No nos hemos olvidado del coeficiente de curtosis, \\(\\beta_2\\). Este estadístico compara la longitud de las colas de la muestra con las que esperaríamos si su histograma se pareciera al de una campana de Gauss. Cuando el histograma se parece al de una campana de Gauss, \\(\\beta_2\\approx 0\\): se dice que la variable es mesocúrtica. Cuando el histograma tiene colas más largas, y en particular más valores atípicos, de lo esperado si tuviera la forma de una campana de Gauss, \\(\\beta_2&gt; 0\\); se dice que la variable es leptocúrtica. Cuando el histograma tiene colas más cortas, y en particular menos valores atípicos, de lo esperado si tuviera la forma de una campana de Gauss, \\(\\beta_2&lt; 0\\); se dice que la variable es platicúrtica. 9.9 Estadísticos y gráficos con JAMOVI En la ventana Descriptivas podéis calcular la mayoría de los estadísticos y gráficos explicados hasta ahora. Por ejemplo, los estadísticos que podéis calcular del vector de alturas usado en secciones anteriores son: La varianza y la desviación típica que calcula son las muestrales y el RIC en la tabla en castellano es el rango intercuartílico, nuestro IQR. Aunque en este caso hayan dado lo mismo, los cuantiles los calcula con una definición diferente de la nuestra. Comprobadlo calculando, como Ejercicio, a mano y con JAMOVI los cuartiles de 1,2,3,…,9,10. Por lo que refiere a gráficos, podéis dibujar, entre otros, histogramas de frecuencias relativas, boxplots y diagramas de puntos. Por el momento no es posible dibujar un polígono de frecuencias si no es usando funciones adecuadas en el editor. Histograma: Como ya hemos comentado, en este histograma las clases son cerradas a la derecha. Boxplot: Los cuartiles los calcula con una definición diferente de la nuestra. Diagrama de puntos: 9.10 Estadísticos sobre datos agrupados En nuestro lenguaje cotidiano, solemos agrupar datos cuantitativos sin que seamos conscientes de ello. Cuando decimos, por ejemplo, que la edad de alguien es de 18 años, no queremos decir que nació justo hoy hace 18 años, sino que ya ha cumplido los 18 años, pero aún no ha cumplido los 19; es decir, que agrupamos todas las edades que caen dentro del intervalo [18,19) en una misma clase, que llamamos “18 años”. Del mismo modo, que alguien mida 1.72 no significa que esta sea su altura exacta, con la precisión del grueso de un cabello, sino que su altura pertenece a un intervalo de valores en torno a 1.72 metros que identificamos con “1.72”. Bajo la calificación de “aprobado” agrupamos todas las notas mayores o iguales que 5 y menores que 7. Y estamos seguros de que se os ocurren otros ejemplos. Muy a menudo, los datos cuantitativos se recogen directamente agrupados, como por ejemplo franjas salariales o el número de refrescos semanales en la tabla de datos 6.1. Aunque estas clases definan un conjunto de datos ordinales (los llamábamos cuantitativos agrupados en una Nota al final de la Sección 6) es muy probable que nos interese interpretarlas como eso: clases resultado de agrupar datos cuantitativos. Su representación gráfica adecuada es claramente un histograma, pero ¿cómo podemos calcular los estadísticos? Está claro que de manera exacta es imposible si no conocemos los datos brutos, sin agrupar. Pero podemos intentar aproximarlos. Substituimos la moda por la clase modal: la clase de mayor frecuencia. Para calcular la media, la varianza, etc., para cada clase tomamos su punto medio, al que en este contexto llamaremos su marca de clase, y consideraremos que nuestra muestra está formada, para cada clase, por tantas copias de su marca como la frecuencia de la clase. Ejemplo 9.16 Volvamos a la muestra de tensiones arteriales medias de 120 adultos del Ejemplo 9.13 y supongamos que nos han dado directamente los datos agrupados en 9 clases de amplitud 10: Clase Frecuencia [80,90) 3 [90,100) 3 [100,110) 16 [110,120) 33 [120,130) 23 [130,140) 22 [140,150) 13 [150,160) 5 [160,170) 2 La clase modal es [110,120). Para aproximar la media y la varianza de la muestra original, tomaremos como marcas de clase los puntos medios de las clases, 85,95,…,165, y supondremos que la muestra está formada por 3 copias del valor 85, 3 copias del valor 95, 16 copias del valor 105, …, 2 copias del valor 165. Entonces: Aproximamos la media de la muestra por \\[ \\frac{3\\times 85+3\\times 95+16\\times 105+\\cdots+2\\times 165}{120}=123.75 \\] Aproximamos la varianza de la muestra por \\[ \\frac{3\\times (85-123.75)^2+3\\times (95-123.75)^2+16\\times (105-123.75)^2+\\cdots+2\\times (165-123.75)^2}{120}=267.6 \\] Por lo que refiere a la mediana y los otros cuantiles de una variable cuantitativa agrupada, se han propuesto varios métodos para intentar aproximarlos a partir de las tablas de frecuencias de sus clases. Aquí explicaremos el más sencillo y lo ilustraremos con el ejemplo anterior. Por comodidad, vamos a añadir las frecuencias absolutas y relativas acumuladas de las clases a la tabla de frecuencias: Clase Frecuencia Frec. acum. Frec. rel. acum. [80,90) 3 3 0.0250 [90,100) 3 6 0.0500 [100,110) 16 22 0.1833 [110,120) 33 55 0.4583 [120,130) 23 78 0.6500 [130,140) 22 100 0.8333 [140,150) 13 113 0.9417 [150,160) 5 118 0.9833 [160,170) 2 120 1.0000 En primer lugar buscamos en qué clase cae la mediana, es decir, qué clase contiene el valor que separa las dos mitades de la muestra: la llamaremos el intervalo crítico para la mediana. En nuestro ejemplo, será la primera clase cuya frecuencia relativa acumulada sea mayor o igual que 0.5. Se trata del intervalo [120,130). La mediana sería la media de los valores en las posiciones 60 y 61 tras ordenarlos. Como hasta justo antes de 120 hay 55 valores, es la media de los valores quinto y sexto de la clase [120,130), en la que hay 23. Lo que haremos será suponer que estos 23 valores están igualmente distribuidos empezando por 120 y sin llegar a 130 (porque nuestras clases son cerradas por la izquierda y abiertas a la derecha). Por lo tanto suponemos que son \\[ 120, 120+\\frac{1}{23}\\cdot 10, 120+\\frac{2}{23}\\cdot 10, 120+\\frac{3}{23}\\cdot 10,\\ldots, 120+\\frac{21}{23}\\cdot 10, 120+\\frac{22}{23}\\cdot 10 \\] Los valores quinto y sexto son \\(120+40/23=121.74\\) y \\(120+50/23=122.17\\) y su media 121.96. Esta es nuestra aproximación de la mediana. Si las clases fueran cerradas a la derecha, tomaríamos los valores \\[ 120+\\frac{1}{23}\\cdot 10, 120+\\frac{2}{23}\\cdot 10, 120+\\frac{3}{23}\\cdot 10,\\ldots, 120+\\frac{21}{23}\\cdot 10, 120+\\frac{22}{23}\\cdot 10, 130 \\] Y si supusiéramos que los extremos no pueden pertenecer a las clases, entonces tomaríamos los valores \\[ 120+\\frac{1}{24}\\cdot 10, 120+\\frac{2}{24}\\cdot 10, 120+\\frac{3}{24}\\cdot 10,\\ldots, 120+\\frac{22}{24}\\cdot 10, 120+\\frac{23}{24}\\cdot 10 \\] En cada caso, luego tomaríamos la media del quinto y el sexto. Un procedimiento similar se puede usar para aproximar cualquier cuantil \\(Q_{p}\\) de orden \\(p\\). Por ejemplo, busquemos el primer cuartil. Es el trigésimo valor de la muestra ordenada, y por lo tanto el octavo de la clase [110,120), que contiene 33 valores. Tomamos estos 33 valores igualmente distribuidos y empezando con 110: \\[ 110, 110+\\frac{1}{33}\\cdot 10, 110+\\frac{2}{33}\\cdot 10, 110+\\frac{3}{33}\\cdot 10,\\ldots, 110+\\frac{31}{33}\\cdot 10, 110+\\frac{32}{33}\\cdot 10 \\] El octavo es \\(110+70/33=112.12\\). Esta es nuestra aproximación del segundo cuartil. Considerad el agrupamiento en 15 clases de la muestra de tensiones arteriales medias de 120 adultos del Ejemplo 9.13. A partir de este agrupamiento, estimad los valores de la media, la varianza y la mediana de la muestra, y comparadlos con los obtenidos a partir de 9 clases. ¿Cuáles creéis que estiman mejor los estadísticos de la muestra original? Figura 9.6: Perímetros braquiales Considerad el diagrama de la Figura 9.6, que muestra los perímetros braquiales derechos de 120 mujeres. ¿Qué tipo de gráfico es? ¿De qué tipo de datos es el perímetro braquial? ¿Cuál es la clase modal? ¿Cómo describiríais la asimetría de la muestra? ¿En qué clase cae la mediana de la muestra? ¿Qué estimáis que vale la mediana? ¿En qué clase cae el primer cuartil de la muestra? ¿Qué estimáis que vale el primer cuartil? ¿Qué estimáis que vale la media? 9.11 Datos cuantitativos bivariantes Si tenemos observaciones de dos variables cuantitativas medidas sobre una misma muestra de \\(n\\) individuos, las recogemos en una tabla de datos bivariante, con las filas representando los individuos y las columnas representando las dos variables: \\[ \\begin{array}{c|c|c} \\textbf{Individuo} &amp;\\textbf{Variable 1} &amp;\\textbf{Variable 2}\\\\ \\hline 1 &amp; x_{1} &amp; y_{1} \\cr 2 &amp; x_{2} &amp; y_{2} \\cr 3 &amp; x_{3} &amp; y_{3} \\cr \\vdots &amp;\\vdots &amp; \\vdots \\cr n &amp; x_{n} &amp; y_{n} \\end{array} \\] Podemos representar esta tabla por medio de un gráfico de dispersión (scatter plot): el gráfico de los puntos \\((x_k,y_k)\\). Ejemplo 9.17 Hemos medido la tensión arterial media (en mmHg) y el nivel de colesterol (en mg/dl) de 10 individuos y recogido estos valores en la tabla siguiente: Tensión Colesterol 1 105.7 169.3 2 117.4 191.7 3 131.9 202.6 4 117.8 218.2 5 133.0 223.2 6 107.9 180.0 7 118.6 230.4 8 123.4 211.8 9 124.1 202.3 10 113.4 185.3 Su diagrama de dispersión es Una serie temporal es un caso particular de tabla de datos cuantitativos bivariante en la que la primera variable representa el paso del tiempo. En este caso, es conveniente unir con segmentos los puntos consecutivos en el tiempo para ayudar a visualizar la evolución de los datos en el tiempo. Ejemplo 9.18 Consideremos la siguiente tabla de los números diarios de defunciones por COVID-19 en la Baleares entre día 16 y día 31 de marzo de 2019: Día Defunciones 16 0 17 0 18 1 19 0 20 2 21 0 22 6 23 0 24 3 25 4 26 5 27 4 28 3 29 8 30 5 31 4 Se trata de una serie temporal. Su gráfico de dispersión es A menudo nos interesará medir la asociación (propensión a variar conjuntamente) de dos variables cuantitativas medidas sobre una misma muestra de individuos: por ejemplo, valorar la tendencia del nivel de colesterol a crecer con la tensión arterial media en la tabla del Ejemplo 9.17. Uno de los estadísticos más usados con este fin es la covarianza. Su definición, para los vectores \\(x=(x_1,\\ldots,x_n)\\) e \\(y=(y_1,\\ldots,y_n)\\), de medias \\(\\overline{x}\\) y \\(\\overline{y}\\), respectivamente, es \\[ s_{x,y}=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})}{n} \\] También hay una versión muestral, dividiendo por \\(n-1\\) en lugar de \\(n\\), que es la que calculan la mayoría de los paquetes estadísticos. El motivo es el mismo que ya explicamos con ocasión de la varianza: la covarianza muestral estima mejor la covarianza de las variables poblacionales que la versión “a secas”. La covarianza de un vector consigo mismo es su varianza: \\[ s_{x,x}=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})(x_i-\\overline{x})}{n}=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\overline{x})^2=s_x^2 \\] El signo de la covarianza mide el signo de la asociación entre los dos vectores: La covarianza es positiva cuando \\(x\\) e \\(y\\) satisfacen la condición siguiente: si una de las dos variables crece, la otra también tiende a crecer; es decir, si \\(x_i&lt;x_j\\), \\(y_j\\) tiende a ser mayor que \\(y_i\\). Figura 9.7: Covarianza positiva La covarianza es negativa cuando \\(x\\) e \\(y\\) satisfacen la condición siguiente: si una de las dos variables crece, la otra tiende a decrecer; es decir, si \\(x_i&lt;x_j\\), \\(y_j\\) tiende a ser menor que \\(y_i\\). Figura 9.8: Covarianza negativa Si la covarianza es muy cercana a 0, es porque no hay una tendencia clara al crecimiento o decrecimiento de \\(y_i\\) en función del de \\(x_i\\). Figura 9.9: Covarianza 0 En particular, si las variables \\(x\\) e \\(y\\) son independientes, en el sentido de que el valor de \\(x\\) no influye para nada en el valor de \\(y\\), la covarianza de \\(x\\) e \\(y\\) es 0. Ejemplo 9.19 Volvamos a la tabla de tensiones arteriales medias y niveles de colesterol del Ejemplo 9.17. Las medias de las variables son \\[ \\begin{array}{l} \\overline{\\text{Tensión}}=\\dfrac{105.7+117.4+131.9+\\cdots+113.4}{10}=119.32\\\\ \\overline{\\text{Colesterol}}=\\dfrac{169.3+191.7+202.6+\\cdots+185.3}{10}=201.48 \\end{array} \\] y su covarianza es \\[ \\begin{array}{l} s_{\\text{Tensión},\\text{Colesterol}}\\\\ \\quad =\\dfrac{(105.7-119.32)(169.3-201.48)+(117.4-119.32)(191.7-201.48)+\\cdots}{10}\\\\ \\quad=110.9164 \\end{array} \\] Como esta covarianza es positiva, deducimos que los valores de la tensión media y el nivel de colesterol en esta muestra tienden a crecer juntos, como ya observamos en el diagrama de dispersión del Ejemplo 9.17. En general, la magnitud de la covarianza mide cuánto varían conjuntamente las variables. Por ejemplo, una covarianza positiva y muy grande no solo indica que cuando la \\(x\\) crece, la \\(y\\) tiende a crecer, sino que también nos indica que cuando la \\(x\\) es mucho más grande que la media, la \\(y\\) tiende a ser mucho más grande que la media. Esto hace que, por ejemplo, la covarianza dependa de las unidades de medida. Si por ejemplo hubiéramos medido los niveles de colesterol del ejemplo anterior en mg/cl, de manera que sus valores se dividieran por 10, la covarianza resultante quedaría dividida por 10. Por ello a menudo se usa una versión normalizada de la covarianza, la correlación de Pearson, cuyo valor no depende de cambios de escala y tiene una interpretación sencilla (aunque no siempre corresponde con lo que queremos saber de nuestra muestra). La correlación de Pearson de dos vectores de datos \\(x\\) e \\(y\\) de la misma longitud se define como su covarianza dividida por el producto de sus desviaciones típicas: \\[ r_{x,y}=\\frac{s_{x,y}}{s_xs_y} \\] Como el signo de \\(r_{x,y}\\) es el mismo que el de \\(s_{x,y}\\) y es 0 exactamente cuando \\(s_{x,y}=0\\), el signo de la correlación de Pearson tiene el mismo significado que el de la covarianza: \\(r_{x,y}&gt;0\\) cuando \\(y\\) tiende a crecer si \\(x\\) crece \\(r_{x,y}&lt;0\\) cuando \\(y\\) tiende a decrecer si \\(x\\) crece \\(r_{x,y}\\approx 0\\) cuando no hay ninguna tendencia en este sentido; decimos entonces que \\(x\\) e \\(y\\) están incorreladas En particular, si \\(x\\) e \\(y\\) son independientes, \\(r_{x,y}=0\\) Pero la correlación de Pearson lleva más información que la covarianza, porque mide la relación lineal entre los dos vectores, en el sentido de las propiedades siguientes: \\(r_{x,y}\\) está siempre entre -1 y 1. Cuanto más cerca está \\(r_{x,y}\\) de -1 o 1, más se aproximan los puntos \\((x_i,y_i)\\) a estar sobre una recta, que será creciente si \\(r_{x,y}&gt;0\\) y decreciente si \\(r_{x,y}&lt;0\\). Y en concreto, Los puntos \\((x_i,y_i)\\) están sobre una recta creciente exactamente si, y solo si, \\(r_{x,y}=1\\). Los puntos \\((x_i,y_i)\\) están sobre una recta decreciente si, y solo si, \\(r_{x,y}=-1\\). Ejemplo 9.20 Seguimos con la tabla de tensiones arteriales medias y niveles de colesterol del Ejemplo 9.17. Ya hemos obtenido su covarianza, \\(s_{\\text{Tensión},\\text{Colesterol}}=110.9164\\). Sus desviaciones típicas son \\[ \\begin{array}{l} s_{\\text{Tensión}}=\\sqrt{\\dfrac{(105.7-119.32)^2+(117.4-119.32)^2+\\cdots+(113.4-119.32)^2}{10}}=8.616\\\\ s_{\\text{Colesterol}}=\\sqrt{\\dfrac{(169.3-201.48)^2+(191.7-201.48)^2+\\cdots+(185.3-201.48)^2}{10}}=18.84 \\end{array} \\] por lo que su correlación de Pearson es \\[ r_{\\text{Tensión},\\text{Colesterol}}=\\frac{110.9164}{8.616\\cdot 18.84}=0.683 \\] Los pares de valores de tensión arterial media y el nivel de colesterol de los individuos de la muestra presentan una tendencia acusada a crecer conjuntamente siguiendo una recta. Si una de las dos variables tiene desviación típica 0, en la fórmula de la correlación aparece un 0 en el denominador y no la podemos calcular. En este caso, se toma \\(r_{x,y}=0\\). El motivo es el siguiente. Supongamos que \\(s_x=0\\). Como ya hemos visto, esto quiere decir que todos los valores de \\(x\\) son iguales, y por lo tanto iguales al valor medio \\(\\overline{x}\\). Pero entonces \\(s_{x,y}=0\\): el numerador de \\(r_{x,y}\\) también es 0. Por lo tanto, si los puntos están sobre una recta horizontal o una recta vertical, la correlación es 0, por mucho que estén sobre una recta. Esto es consistente con el propiedad de que independencia implica correlación nula: si una de las variables es constante, los valores que toma son claramente independientes de los que toma la otra. Gráficamente podemos visualizar la tendencia de los puntos de una tabla bivariante a estar sobre una recta añadiendo a su gráfico de dispersión su recta de regresión (para ser precisos, de regresión lineal por mínimos cuadrados, pero normalmente omitiremos esta apostilla). Se trata de la recta que más se aproxima a los puntos \\((x_i,y_i)\\) en el sentido siguiente. Dada una recta \\(y=ax+b\\), el error que se comete al estimar con esta recta el valor \\(y_i\\) sobre el sujeto correspondiente al par \\((x_i,y_i)\\) es \\(y_i-(ax_i+b)\\). La recta de regresión es la que tiene coeficientes \\(a,b\\) que hacen mínima la suma de los cuadrados de estos errores, \\[ \\sum_{i=1}^n (y_i-(ax_i+b))^2 \\] Resulta que los coeficientes de esta recta de regresión son \\[ a=\\frac{s_{x,y}}{s_x^2},\\quad b = \\overline{y}-a\\cdot \\overline{x}. \\] Ejemplo 9.21 Siguiendo con nuestro ejemplo de tensiones y niveles de colesterol, la recta de regresión del nivel de colesterol en función de la tensión media tiene pendiente \\[ a=\\frac{s_{\\text{Tensión},\\text{Colesterol}}}{s_{\\text{Colesterol}}^2}=\\frac{110.9164}{8.616^2}=1.494 \\] y término independiente \\[ b= \\overline{\\text{Colesterol}}-a\\cdot \\overline{\\text{Tensión}}=201.48-1.494\\cdot 119.32=23.216 \\] El gráfico de dispersión de los puntos junto a esta recta de regresión es el siguiente: Con JAMOVI podéis calcular la correlación de Pearson y dibujar un gráfico de dispersión con la recta de regresión en Regresión/Matriz de correlaciones: Por el momento JAMOVI no ofrece la posibilidad de calcular covarianzas si no es a través del editor. La función que calcula la covarianza muestral es cov y se aplica a los dos vectores. En el módulo Demonstration de JAMOVI tenéis la opción de generar muestras aleatorias de pares de valores y correlación (aproximadamente) la deseada, para haceros una idea de qué representan los diferentes valores de la correlación. Por ejemplo, un conjunto de 100 pares de valores con correlación aproximadamente 0.5: El valor de la correlación de Pearson no siempre es suficiente para valorar el ajuste de los puntos a una recta. Es siempre conveniente dibujar los puntos y la recta de regresión lineal y darles un vistazo. Por ejemplo, F. Anscombe produjo los cuatro conjuntos de puntos descritos en la Figura 9.10. Como podéis, ver, tienen ajustes muy diferentes a una recta, y en cambio resulta que tienen el mismo valor de \\(r\\): 0.816. Para más detalles, consultad la correspondiente entrada de la Wikipedia Figura 9.10: El cuarteto de Anscombe Ser incorrelados no es sinónimo de que no haya ninguna dependencia entre las dos variables. Por ejemplo, los conjuntos de puntos de la Figura 9.11 tienen correlación casi 0 (en concreto -0.004), y es claro que en cada caso hay una fuerte dependencia entre los valores de \\(x\\) y de \\(y\\). Lo que significa que la covarianza, o la correlación, sea 0 es que no hay relación entre el crecimiento de una variable y el de la otra. Figura 9.11: Dos conjuntos de datos incorrelados Como hemos visto, la correlación de Pearson mide la dependencia lineal entre dos variables cuantitativas. Otras medidas de correlación miden otros tipos de dependencia. La alternativa más popular a la correlación de Pearson es la correlación de Spearman, \\(r_S\\), que mide la concordancia en el orden de los individuos según sus valores en las dos variables medidas. Se calcula, grosso modo, de la manera siguiente: A cada individuo de la muestra le asignamos su posición (su rango) según el orden creciente de los valores \\(x_i\\). A cada individuo de la muestra le asignamos su rango según el orden creciente de los valores \\(y_i\\). Calculamos la correlación de Pearson de los vectores de rangos. La correlación de Spearman también se puede usar para variables ordinales. ¡La de Pearson no! Ejemplo 9.22 Volvemos a nuestro ejemplo de tensiones y niveles de colesterol. Ampliamos la tabla de datos con los rangos de los individuos recogidos en la misma para cada variable: Tensión Rango Colesterol Rango 1 105.7 1 169.3 1 2 117.4 4 191.7 4 3 131.9 9 202.6 6 4 117.8 5 218.2 8 5 133.0 10 223.2 9 6 107.9 2 180.0 2 7 118.6 6 230.4 10 8 123.4 7 211.8 7 9 124.1 8 202.3 5 10 113.4 3 185.3 3 La correlación de Spearman de las dos variables será la correlación de Pearson de sus vectores de rangos. Si la calculáis, da \\({r_S}=0.73333\\). Una nota técnica, para los completistas. ¿Qué pasa si, al calcular los rangos, hay valores repetidos? Pues que se les asigna el mismo rango calculado de la manera siguiente: En primer lugar, a cada individuo de la muestra le asignamos un “rango provisional”: su posición según el orden creciente de los valores \\(x_i\\) y, en caso de igualdad de estos valores, según su orden de aparición en la tabla de datos. Entonces, para cada valor del vector, se asigna como rango “definitivo” a todos los individuos cuyo valor \\(x\\) es ese valor la media de sus posiciones. Veamos un ejemplo. Ejemplo 9.23 Vamos a calcular los rangos de los individuos de la tabla de datos siguiente según su valor de la variable \\(x\\). Individuo x 1 1 2 2 3 1 4 1 5 2 6 4 7 4 8 3 Empezamos asignando rangos provisionales a los individuos, ordenándolos según su valor de \\(x\\) y en caso de empate de arriba abajo: Individuo x Posición 1 1 1 2 2 4 3 1 2 4 1 3 5 2 5 6 4 7 7 4 8 8 3 6 Pasamos a asignar los rangos definitivos: A los tres individuos cuya \\(x\\) es 1 les asignamos como rango (1+2+3)/3=2. A los dos individuos cuya \\(x\\) es 2 les asignamos como rango (4+5)/2=4.5. Al único individuo cuya \\(x\\) es 3 le asignamos como rango definitivo su rango provisional: 6. A los dos individuos cuya \\(x\\) es 4 les asignamos como rango (7+8)/2=7.5. Individuo x Posición Rango 1 1 1 2.0 2 2 4 4.5 3 1 2 2.0 4 1 3 2.0 5 2 5 4.5 6 4 7 7.5 7 4 8 7.5 8 3 6 6.0 La correlación de Spearman se calcula con JAMOVI marcando Spearman en vez de Pearson en Regresión/Matriz de correlaciones. 9.12 Gráficos en escala logarítmica Los ejes de todos los gráficos para variables cuantitativas producidos en las secciones anteriores estaban en escala lineal: pares de marcas a misma distancia tienen diferencias de valores iguales. A veces es conveniente dibujar un gráfico con un eje (o ambos) en escala logarítmica: donde pares de marcas a misma distancia tengan cocientes iguales (es decir, diferencias de sus logaritmos iguales, de ahí el nombre). Por ejemplo, el gráfico siguiente representa la serie temporal de números acumulados de muertos por COVID-19 en las Balears entre el 16 de marzo y el 25 de abril de 2020. Podéis comprobar que ambos ejes están en escala lineal. Figura 9.12: Gráfico en escala lineal Vamos ahora a dibujar este gráfico con el eje de las ordenadas en escala logarítmica (lo llamaremos un gráfico en escala semilogarítmica): Figura 9.13: Gráfico en escala semilogarítmica Observad las marcas en el eje de las ordenadas: por ejemplo, la distancia entre 1 y 2 es la misma que entre 10 y 20, y la distancia entre 1 y 5 es la misma que entre 10 y 50. Y ahora vamos a dibujarlo con ambos ejes en escala logarítmica (lo llamaremos un gráfico en escala doble logarítmica): Figura 9.14: Gráfico en escala doble logarítmica Un buen motivo para dibujar un gráfico en escala semilogarítmica puede ser la necesidad de representar en un mismo gráfico varias variables de rangos muy diferentes. Por ejemplo, considerad la figura siguiente: Dibujada en escala lineal, se perdería mucho detalle: la línea inferior casi se identificaría con el eje de abscisas, y las líneas centrales parecerían iguales. Otro motivo puede ser simplemente el hacer aparecer detalles que nos ayuden a entender mejor los datos. Por ejemplo, los dos gráficos siguientes muestran la mortalidad anual específica por tuberculosis en Inglaterra y Gales entre 1871 y 1971, a la izquierda en escala lineal y a la derecha en escala semilogarítmica: El gráfico semilogarítmico permite apreciar mejor el descenso en la mortalidad a partir de mediados de los años cuarenta, con la introducción de la penicilina. 9.13 Test (1) En una asignatura de la UIB hay un 40% de matriculados de Palma, un 35% de matriculados del resto de Mallorca y un 25% de matriculados de fuera de Mallorca. En la encuesta donde los estudiantes anotaron su procedencia, “Palma” estaba identificado con un 1, “el resto de Mallorca” con un 2 y “fuera de Mallorca” con un 3 ¿Cuál o cuáles de las afirmaciones siguientes son correctas? El origen medio de estos estudiantes es “Mallorca.” El origen medio de estos estudiantes es “el resto de Mallorca.” El origen medio de estos estudiantes es 1.85. La mediana de los orígenes de estos estudiantes es “el resto de Mallorca.” El resto de afirmaciones son falsas. (2) Un estudio describe los diagnósticos de ingresados en un servicio de urgencias durante una semana que requirieron hospitalización. Estos valores fueron: 6 admisiones por apendicitis aguda 7 admisiones por colecistitis aguda (infección de la vesícula biliar) 12 admisiones por enfermedad de úlcera péptica (úlceras de estómago) 4 admisiones por gastritis (inflamación del revestimiento del estómago) ¿Cuál de los siguientes estadísticos es el más apropiado para indicar la tendencia central de estos diagnósticos? La moda La media La mediana La varianza (3) Si en un conjunto de datos cuantitativos la media aritmética es estrictamente menor que la mediana (marca todas las respuestas correctas): Esperamos que la muestra sea asimétrica a la izquierda. Esperamos que la muestra sea asimétrica a la derecha. No tenemos ninguna indicación sobre el tipo de simetría o asimetría de la muestra Más del 50% de los valores son menores que la media. Más del 50% de los valores son mayores que la media. Ninguna de las respuestas anteriores es correcta. (4) Un profesor calculó algunas medidas de tendencia central de los resultados de un examen. ¿Cuál de las afirmaciones siguientes no aporta ninguna información específica sobre los resultados de este examen (que no cumplan los resultados de todos los exámenes)? Aproximadamente la mitad de los estudiantes tuvieron una nota por encima de la moda. Aproximadamente la mitad de los estudiantes tuvieron una nota por encima de la mediana. Aproximadamente la mitad de los estudiantes tuvieron una nota por encima de la media. Aproximadamente la mitad de los estudiantes suspendieron el examen. En realidad, todas las respuestas anteriores aportan información nueva sobre los resultados del examen. (5) La desviación típica de un conjunto de datos, ¿puede ser &lt;0? Sí No (6) ¿Qué es el recorrido de un conjunto de datos? La diferencia entre la mediana y la media. El número de datos. La diferencia entre el mayor dato y el menor La diferencia entre el último dato recogido y el primero. La distancia entre el tercer cuartil y el primero. (7) ¿Cuáles de los siguientes estadísticos cambian siempre que se cambia un solo valor en el conjunto de datos? Marca todas las respuestas correctas. La moda La mediana La media El tercer cuartil Ninguno de ellos (8) Con la definición que hemos dado de cuantil, ¿cuál es el tercer cuartil del siguiente conjunto de 20 números (que podían tomar valores entre 1 y 40)? 12, 15, 15, 16, 17, 18, 20, 22, 23, 23, 24, 24, 25, 25, 26, 28, 28, 28, 29, 32 22 26 27 28 30 Ninguno de los anteriores (9) Una correlación de Pearson \\(r=-0.3\\) entre dos variables \\(X\\) e \\(Y\\) medidas sobre una misma muestra de individuos indica (marca una sola respuesta): Un aumento de \\(X\\) va acompañado de un aumento de \\(Y\\), y la relación lineal es fuerte Un aumento de \\(X\\) va acompañado de un aumento de \\(Y\\), y la relación lineal es moderada Un aumento de \\(X\\) va acompañado de una disminución de \\(Y\\), y la relación lineal es fuerte Un aumento de \\(X\\) va acompañado de una disminución de \\(Y\\), y la relación lineal es moderada Los valores de las variables \\(X\\) e \\(Y\\) en la muestra son independientes. (10) Un diagrama de dispersión de dos variables \\(X\\) e \\(Y\\) medidas sobre una misma muestra de individuos sirve para mostrar (marca una sola respuesta): La relación entre las varianzas de estos dos conjuntos de datos La frecuencia con la que cada dato aparece en ambas variables Las medias de los dos conjuntos de datos Los valores de \\(Y\\) en función de los valores de \\(X\\) Las frecuencias relativas de los datos que caen dentro de las diferentes clases (11) En los 10 nacimientos que tuvieron lugar en un hospital en un día determinado, se apuntó el peso del recién nacido (\\(X\\)) y la edad de la madre (\\(Y\\)). Curiosamente, todos los bebés pesaron lo mismo: 2.6 kg. ¿Qué vale la covarianza entre los pesos y las edades? 1 0 2.6 0.26 Imposible saberlo, sin conocer las edades de las madres (12) ¿Qué valores puede tomar la correlación de Pearson de dos vectores? Cualquier valor real Cualquier valor real mayor o igual que 0 Cualquier valor real entre -1 y 1 Cualquier valor real entre 0 y 1 Solamente los valores 0, -1 y 1 Ninguna de las respuestas anteriores es correcta. (13) ¿De qué manera se ven afectadas la media y la varianza de una muestra, si a todos los valores de la muestra se les resta 4? Marca una sola respuesta. La media disminuye y la varianza no varía La media y la varianza disminuyen La media y la varianza no varían La media no varía y la varianza disminuye Ninguna de las afirmaciones anteriores es siempre verdadera, porque depende de la muestra "],["variables-aleatorias-discretas.html", "Lección 10 Variables aleatorias discretas 10.1 Densidad y distribución 10.2 Esperanza 10.3 Varianza y desviación típica 10.4 Cuantiles 10.5 Familias importantes de variables aleatorias discretas 10.6 Test", " Lección 10 Variables aleatorias discretas Una variable aleatoria sobre una población \\(\\Omega\\) es una función \\[ X: \\Omega\\to \\mathbb{R} \\] que asigna a cada sujeto de \\(\\Omega\\) un número real. La idea intuitiva tras esta definición es que una variable aleatoria mide una característica de los sujetos de \\(\\Omega\\) que varía al azar de un sujeto a otro. Por ejemplo: Tomamos una persona de una población y medimos su nivel de colesterol, o su altura, o su número de hijos… En este caso, \\(\\Omega\\) es la población bajo estudio, de la que tomamos la persona que medimos. Lanzamos una moneda equilibrada 3 veces y contamos las caras que obtenemos. En este caso, \\(\\Omega\\) es la población virtual de las secuencias de 3 lanzamientos de una moneda equilibrada. Procurad adquirir la disciplina de describir siempre las variables aleatorias mediante una plantilla del estilo de “Tomamos … y medimos …”, para que os quede claro cuál es la población y cuál la función. Además, añadid las unidades si es necesario. Por ejemplo: “Tomamos una persona de Mallorca y medimos su altura (en cm)”. Fijaos en que esta variable aleatoria no es la misma que “Tomamos una persona de Mallorca y medimos su altura (en m)” porque, aunque mide lo mismo sobre los mismos sujetos, les asigna números diferentes. Y también es diferente de “Tomamos una persona de Suecia y medimos su altura (en cm)” porque ha cambiado la población. En cambio en “Lanzamos una moneda 3 veces al aire y contamos las caras” no hay necesidad de especificar unidades, a no ser que vayáis a usar una unidad inesperada (yo qué sé, que contéis las caras en fracciones de docena). Lo que más nos interesará de una variable aleatoria son las probabilidades de los sucesos que define. ¿Y qué tipo de sucesos son los que nos interesan cuando medimos características numéricas? Pues básicamente sucesos definidos mediante igualdades y desigualdades. Por ejemplo, si \\(X\\) es la variable aleatoria “Tomamos una persona y medimos su nivel de colesterol en plasma (en mg/dl)”, nos pueden interesar sucesos del estilo de: El conjunto de las personas cuyo nivel de colesterol está entre 200 y 240. Lo denotaremos \\[ 200\\leqslant X\\leqslant 240 \\] El conjunto de las personas cuyo nivel de colesterol es menor o igual que 200: \\[ X\\leqslant 200 \\] El conjunto de las personas cuyo nivel de colesterol es mayor que 180: \\[ X&gt;180 \\] El conjunto de las personas cuyo nivel de colesterol es exactamente 180: \\[ X=180 \\] Etc. Normalmente, de estos sucesos lo que nos interesará será su probabilidad, y entonces usaremos notaciones del estilo de las siguientes: \\(P(200\\leqslant X\\leqslant 240)\\). Esto denota la probabilidad de que una persona tenga el nivel de colesterol entre 200 y 240. Para abreviar, lo leeremos “la probabilidad de que \\(X\\) esté entre 200 y 240”. Y recordad que nuestras probabilidades son proporciones. Por lo tanto, esta probabilidad es la proporción de personas (de la población \\(\\Omega\\) donde hayamos definido la variable \\(X\\)) con nivel de colesterol entre 200 y 240. \\(P(X\\leqslant 200)\\): La probabilidad de que una persona tenga el nivel de colesterol menor o igual que 200; o la probabilidad de que \\(X\\) sea menor o igual que 200; o la proporción de personas con nivel de colesterol menor o igual que 200… Etc. En este contexto, indicaremos normalmente la unión con una o y la intersección con una coma. Por ejemplo, si \\(X\\) es la variable aleatoria “Lanzamos una moneda 6 veces y contamos las caras”: \\(P(X\\leqslant 2\\text{ o }X\\geqslant 5)\\): Probabilidad de sacar como máximo 2 caras o como mínimo 5. \\(P(2\\leqslant X, X&lt; 5)\\): Probabilidad de sacar un número de caras que sea mayor o igual que 2 y menor que 5; es decir, \\(P(2\\leqslant X&lt; 5)\\). Dos variables aleatorias \\(X,Y\\) son independientes cuando, para todos los pares de valores \\(a,b\\in \\mathbb{R}\\), los sucesos \\[ X\\leqslant a, Y\\leqslant b \\] son independientes, lo que viene a decir intuitivamente que el valor que toma una de ellas sobre un sujeto no influye en la probabilidad del valor que toma la otra. Recordad que los sucesos \\(X\\leqslant a\\) e \\(Y\\leqslant b\\) son independientes cuando satisfacen las tres condiciones equivalentes siguientes: \\[ \\begin{array}{l} P(X\\leqslant a|Y\\leqslant b)=P(X\\leqslant a)\\\\ P(Y\\leqslant b|X\\leqslant a)=P(Y\\leqslant b)\\\\ P(X\\leqslant a, Y\\leqslant b)=P(X\\leqslant a)\\cdot P(Y\\leqslant b) \\end{array} \\] Por ejemplo, si tomamos una persona y: \\(X\\): le pedimos que lance una moneda 3 veces y contamos las caras \\(Y\\): medimos su nivel de colesterol en plasma (en mg/dl) (seguramente) \\(X\\) e \\(Y\\) son independientes. Más en general, unas variables aleatorias \\(X_1,X_2,\\ldots,X_n\\) son independientes cuando, para cualesquiera \\(a_1,a_2,\\ldots,a_n\\in \\mathbb{R}\\), los sucesos \\[ X_1\\leqslant a_1, X_2\\leqslant a_2,\\ldots, X_n\\leqslant a_n \\] son independientes. Es decir, cuando los valores que toman algunas de estas variables sobre un sujeto nunca influyen en los valores que toman las otras. Vamos a distinguir dos tipos de variables aleatorias: Discretas: Sus posibles valores son datos cuantitativos discretos: Número de caras en 3 lanzamientos de una moneda Número de hijos Número de casos nuevos de COVID-19 en un día en Mallorca Continuas: Sus posibles valores son datos cuantitativos continuos: Peso Nivel de colesterol en sangre Diámetro de un tumor En lo que queda de esta lección trataremos las variables aleatorias discretas. Dejamos las continuas para la próxima lección. 10.1 Densidad y distribución Sea \\(X: \\Omega\\to \\mathbb{R}\\) una variable aleatoria discreta. Su dominio \\(D_X\\) es el conjunto de los valores que puede tomar: más concretamente, el conjunto de los \\(x\\in \\mathbb{R}\\) tales que \\(P(X=x)&gt;0\\). Su función de densidad es la función \\(f_X:\\mathbb{R}\\to [0,1]\\) definida por \\[ f_X(x)=P(X=x) \\] Es decir, la función que asigna a cada \\(x\\in \\mathbb{R}\\) la probabilidad de que \\(X\\) valga \\(x\\) (la proporción de sujetos de la población en los que \\(X\\) vale \\(x\\), la frecuencia relativa del valor \\(x\\) en el total de la población…). Su función de distribución es la función \\(F_X:\\mathbb{R}\\to [0,1]\\) definida por \\[ F_X(x)=P(X\\leqslant x) \\] Es decir, la función que asigna a cada \\(x\\in \\mathbb{R}\\) la probabilidad de que el valor de \\(X\\) sea \\(\\leqslant x\\) (la proporción de sujetos de la población en los que \\(X\\) vale \\(\\leqslant x\\), la frecuencia relativa acumulada de \\(x\\) en el total de la población… También se la suele llamar función de probabilidad acumulada para poner énfasis en esta última interpretación). Ejemplo 10.1 Sea \\(X\\) la variable aleatoria “Lanzamos 3 veces una moneda equilibrada y contamos las caras”. Entonces Su dominio es el conjunto de sus posibles valores: \\(D_X=\\{0,1,2,3\\}\\). Su función de densidad viene definida por \\(f_X(x)=P(X=x)\\): \\(f_X(0)=P(X=0)=1/8\\) (la probabilidad de sacar 0 caras) \\(f_X(1)=P(X=1)=3/8\\) (la probabilidad de sacar 1 cara) \\(f_X(2)=P(X=2)=3/8\\) (la probabilidad de sacar 2 caras) \\(f_X(3)=P(X=3)=1/8\\) (la probabilidad de sacar 3 caras) \\(f_X(x)=P(X=x)=0\\) para cualquier otro valor de \\(x\\) (la probabilidad de sacar \\(x\\) caras es 0 si \\(x\\notin\\{0,1,2,3\\}\\)) En resumen, la función de densidad de \\(X\\) es \\[ f_X(x) =\\left\\{ \\begin{array}{ll} 1/8 &amp; \\text{ si $x=0$}\\\\ 3/8 &amp; \\text{ si $x=1$}\\\\ 3/8 &amp; \\text{ si $x=2$}\\\\ 1/8 &amp; \\text{ si $x=3$}\\\\ 0 &amp; \\text{ si $x\\neq 0,1,2,3$} \\end{array}\\right. \\] Figura 10.1: Función de densidad de la variable aleatoria que cuenta el número de caras en 3 lanzamientos Si \\(X\\) es una variable aleatoria discreta, \\(P(X\\in A)=0\\) para cualquier subconjunto \\(A\\) disjunto de \\(D_X\\), porque \\(X\\) no puede tomar ningún valor de \\(A\\). Por ejemplo, ¿cuál es la probabilidad de sacar entre 2.5 y 2.7 caras al lanzar 3 veces una moneda? 0 ¿Y la de sacar \\(\\pi\\) caras? 0 de nuevo. Veamos su función de distribución \\(F_X\\). Recordad que \\(F_X(x)=P(X\\leqslant x)\\) y que nuestra variable solo puede tomar los valores 0, 1, 2 y 3. Si \\(x&lt;0\\), \\(F_X(x)=P(X\\leqslant x)=0\\) porque \\(X\\) no puede tomar ningún valor estrictamente negativo. Si \\(0\\leqslant x&lt;1\\), el único valor \\(\\leqslant x\\) que puede tomar \\(X\\) es el 0 y por lo tanto \\[ F_X(x)=P(X\\leqslant x)=P(X=0)=f_X(0)=1/8 \\] Si \\(1\\leqslant x&lt;2\\), los únicos valores \\(\\leqslant x\\) que puede tomar \\(X\\) son 0 y 1 y por lo tanto \\[ \\begin{array}{rl} F_X(x)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x)=P(X=0\\text{ o }X=1)\\\\ &amp; =f_X(0)+f_X(1)=4/8=1/2 \\end{array} \\] Si \\(2\\leqslant x&lt;3\\), los únicos valores \\(\\leqslant x\\) que puede tomar \\(X\\) son 0, 1 y 2 y por lo tanto \\[ \\begin{array}{rl} F_X(x)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x)=P(X=0\\text{ o }X=1\\text{ o }X=2)\\\\ &amp; =f_X(0)+f_X(1)+f_X(2)=7/8 \\end{array} \\] Si \\(x\\geqslant 3\\), seguro que obtenemos un número de caras \\(\\leqslant x\\) y por lo tanto \\(F_X(x)=P(X\\leqslant x)=1\\). Así pues, la función \\(F_X\\) es la función \\[ F_X(x) =\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt;0$}\\\\ 1/8 &amp; \\text{ si $0\\leqslant x&lt; 1$}\\\\ 4/8 &amp; \\text{ si $1\\leqslant x&lt; 2$}\\\\ 7/8 &amp; \\text{ si $2\\leqslant x&lt; 3$}\\\\ 1 &amp; \\text{ si $3\\leqslant x$} \\end{array}\\right. \\] Su gráfico es el siguiente: Figura 10.2: Función de distribución de la variable aleatoria que cuenta el número de caras en 3 lanzamientos Observad en este gráfico que esta función de distribución \\(F_X\\) es creciente y escalonada, y el valor en los puntos de escalón es el superior. Esto es general. Si \\(X\\) es una variable aleatoria discreta: \\(F_X\\) es una función escalonada, con saltos en los valores de \\(D_X\\), que son los únicos con probabilidad estrictamente mayor que 0 y por lo tanto los únicos que “suman” probabilidad. \\(F_X\\) es creciente, porque si \\(x\\leqslant y\\), todos los sujetos tales que \\(X\\leqslant x\\) también cumplen que \\(X\\leqslant y\\), y por lo tanto \\[ P(X\\leqslant x)\\leqslant P(X\\leqslant y). \\] Si \\(x_0,y_0\\in D_X\\) y \\(x_0&lt;y_0\\), entonces \\(F_X(x_0)&lt; F_X(y_0)\\), porque \\[ \\begin{array}{rl} F_X(x_0)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x_0)&lt;P(X\\leqslant x_0)+P(X=y_0)\\\\ &amp; =P(X\\leqslant x_0\\text{ o }X=y_0)\\leqslant P(X\\leqslant y_0)=F_X(y_0) \\end{array} \\] Como los valores que toma \\(F_X\\) son probabilidades, no pueden ser ni menores que 0 ni mayores que 1. El conocimiento de \\(f_X\\), más las reglas del cálculo de probabilidades, permite calcular la probabilidad de cualquier suceso relacionado con \\(X\\): \\[ P(X\\in A) =\\sum_{x\\in A} P(X=x) = \\sum_{x\\in A} f_X(x) \\] En particular \\[ F_X(x_0)=P(X\\leqslant x_0)=\\sum_{x\\leqslant x_0} f_X(x) \\] La moda de una variable aleatoria discreta \\(X\\) es el valor (o los valores) \\(x_0\\) tal que \\(f_X(x_0)=P(X=x_0)\\) es máximo. Se trata por lo tanto del “valor más frecuente de \\(X\\)” en la población. Por ejemplo, para nuestra variable aleatoria que cuenta el número de caras en 3 lanzamientos de una moneda equilibrada, la moda son los valores 1 y 2. Hay un aspecto de las variables aleatorias discretas sobre el que queremos llamar la atención, sobre todo por comparación con las variables continuas: Los valores de \\(P(X\\leqslant x)\\) y \\(P(X&lt;x)\\) pueden ser diferentes. De hecho, como \\[ P(X\\leqslant x)=P(X&lt;x)+P(X=x), \\] se tiene que \\(P(X&lt; x)\\neq P(X\\leqslant x)\\) exactamente cuando \\(x\\in D_X\\). Por ejemplo, con la variable \\(X\\) “Lanzamos una moneda equilibrada 3 veces y contamos las caras”: La probabilidad de sacar 2 caras o menos ya la hemos calculado, y es \\(P(X\\leqslant 2)=7/8\\) Pero la probabilidad de sacar menos de 2 caras, \\(P(X&lt;2)\\), es la de sacar 1 cara o menos, por lo tanto \\(P(X&lt;2)=P(X\\leqslant 1)=4/8\\). Considerad la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada al aire tantas veces como sea necesario hasta que salga una cara por primera vez, y contamos cuántas veces la hemos tenido que lanzar”. ¿Cuál es su dominio? ¿Cuál es su función de densidad? ¿Cuál es su moda? ¿Qué significa? ¿Cuál es su función de distribución? 10.2 Esperanza Cuando tomamos una muestra de una variable aleatoria \\(X\\) definida sobre una población, podemos calcular la media y la desviación típica de sus valores para obtener una idea de cuál es su valor central y de la variabilidad de sus valores. También nos podemos preguntar por este tipo de información para el total de la población: ¿cuál es el “valor medio” de \\(X\\) sobre toda la población? ¿\\(X\\) toma valores muy dispersos, o más bien concentrados alrededor de este valor medio? Lo primero lo medimos con la media, o esperanza, de \\(X\\), y lo segundo con su desviación típica. Empecemos con la primera. La media, o esperanza (o valor esperado, valor medio, valor promedio…), de una variable aleatoria discreta \\(X\\) con densidad \\(f_X:D_X\\to [0,1]\\) es \\[ E(X)=\\sum_{x\\in D_X} x\\cdot f_X(x) \\] A veces también la denotaremos por \\(\\mu_X\\). La interpretación natural de \\(E(X)\\) es que es la media de los valores de la variable \\(X\\) en el total de la población \\(\\Omega\\). En efecto, como \\(f_X(x)=P(X=x)\\) es la proporción de los sujetos de \\(\\Omega\\) en los que \\(X\\) vale \\(x\\), entonces \\[ E(X)=\\sum_{x\\in D_X} x\\cdot f_X(x) \\] es el promedio del valor de \\(X\\) sobre todos los elementos de \\(\\Omega\\). Comparadlo con el ejemplo siguiente. Ejemplo 10.2 Si, en una clase, un 10% de los estudiantes han sacado un 4 en un examen, un 20% un 6, un 50% un 8 y un 20% un 10, ¿cuál ha sido la nota media del examen? Suponemos que calcularíais esta media como \\[ 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6 \\] Pues este valor es la media de la variable aleatoria \\(X\\) “Tomo un estudiante de esta clase y miro qué nota ha sacado en este examen”: \\[ \\begin{array}{rl} E(X)\\!\\!\\!\\!\\! &amp;=4\\cdot P(X=4)+6\\cdot P(X=6)+8\\cdot P(X=8)+10\\cdot P(X=10)\\\\ &amp; = 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6 \\end{array} \\] Aparte de su interpretación como “el promedio de \\(X\\) en el total de la población”, \\(E(X)\\) es también el valor esperado de \\(X\\), en el sentido siguiente: Suponed que tomamos una muestra aleatoria de \\(n\\) sujetos de la población, medimos \\(X\\) sobre ellos y calculamos la media aritmética de los \\(n\\) valores obtenidos. Entonces, cuando el tamaño \\(n\\) de la muestra tiende a \\(\\infty\\), esta media aritmética tiende a valer \\(E(X)\\) “casi seguro” (en el sentido de que la probabilidad de que su límite sea \\(E(X)\\) es 1). Aquí probabilidad 1 no significa “total y absolutamente seguro”, porque este límite va a ser una variable aleatoria continua, donde, como veremos en la próxima lección, probabiilidad 0 no significa imposible ni probabilidad 1 significa 100% seguro. Por ejemplo, si repetís muchas veces el proceso de lanzar una moneda equilibrada 3 veces, por pura mala suerte puede pasar que en todas las ocasiones saquéis tres caras. Casi seguro que no pasa, pero no podemos estar 100% seguros de que no pase, no es imposible. Como decimos por aquí, n’hi ha que neixen estrellats. Es decir: si midiéramos \\(X\\) sobre muchos sujetos elegidos al azar, de media casi seguro que obtendríamos un valor muy próximo a \\(E(X)\\). Ejemplo 10.3 Seguimos con la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada al aire 3 veces y contamos las caras”. Su esperanza es \\[ E(X)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2\\cdot \\frac{3}{8}+3\\cdot \\frac{1}{8}=1.5 \\] Esto nos dice que: La media de \\(X\\) es 1.5: El valor medio de la variable \\(X\\) sobre toda la población de secuencias de 3 lanzamientos de una moneda equilibrada es 1.5. El valor esperado de \\(X\\) es 1.5: Si repitiésemos muchas veces el experimento de lanzar la moneda 3 veces y contar las caras, la media de los resultados obtenidos daría, muy probablemente, un valor muy cercano a 1.5. Abreviamos esto diciendo que si lanzamos la moneda 3 veces, de media esperamos sacar 1.5 caras. Más en general, si \\(g:\\mathbb{R}\\to \\mathbb{R}\\) es una aplicación, el valor esperado de la composición \\(\\Omega \\stackrel{X}{\\longrightarrow} \\mathbb{R}\\stackrel{g}{\\longrightarrow}\\mathbb{R}\\) es \\[ E(g(X))=\\sum_{x\\in D_X} g(x)\\cdot f_X(x) \\] De nuevo, su interpretación natural es que es el promedio de \\(g(X)\\) sobre la población en la que medimos \\(X\\), y también es el valor “esperado” de \\(g(X)\\) en el sentido anterior. Ejemplo 10.4 Si lanzamos una moneda equilibrada al aire 3 veces, contamos las caras y elevamos este número de caras al cuadrado, ¿qué valor esperamos obtener, de media? Será la esperanza de \\(X^2\\), siendo \\(X\\) la variable aleatoria “Lanzamos una moneda equilibrada al aire 3 veces y contamos las caras” (o sea, \\(X^2\\) es la variable aleatoria “Lanzamos una moneda equilibrada al aire 3 veces, contamos las caras y elevamos este número al cuadrado”): \\[ E(X^2)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2^2\\cdot \\frac{3}{8}+3^2\\cdot \\frac{1}{8}=3 \\] En los dos últimos ejemplos hemos visto que si \\(X\\) es la variable aleatoria que cuenta el número de caras en 3 lanzamientos de una moneda equilibrada, \\(E(X^2)=3\\) pero \\(E(X)^2=1.5^2=2.25\\). Por lo tanto, puede pasar que \\(E(X^2) \\neq E(X)^2\\). De hecho, es lo más común. Más en general, dada una aplicación \\(g:\\mathbb{R}\\to \\mathbb{R}\\), lo usual es que \\(E(g(X))\\neq g(E(X))\\). La esperanza de las variables aleatorias discretas tiene las propiedades siguientes, todas razonables si las interpretáis en términos del valor promedio de \\(X\\) sobre la población: Sea \\(b\\) una variable aleatoria constante, que sobre todos los individuos de la población toma el mismo valor \\(b\\in \\mathbb{R}\\). Entonces \\(E(b)=b\\). Si en una clase todo el mundo saca un 8 de un examen, la nota media es 8, ¿no? La esperanza es lineal: Si \\(a,b\\in \\mathbb{R}\\), \\(E(aX+b)=aE(X)+b\\) Si en una clase la media de un examen ha sido un 6 y decidimos multiplicar por 1.2 todas las notas y sumarles 1 punto, la nueva nota media será 1.2·6+1=8.2, ¿no? Si \\(Y\\) es otra variable aleatoria, \\(E(X+Y)=E(X)+E(Y)\\). Si en una clase la media de la parte de cuestiones de un examen ha sido un 3.5 (sobre 5) y la de la parte de ejercicios ha sido un 3 (sobre 5) y la nota del examen es la suma sus dos partes, la nota media del examen será un 3.5+3=6.5, ¿no? Más en general, si \\(X_1,\\ldots,X_n\\) son variables aleatorias y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ E(a_1X_1+\\cdots +a_nX_n+b)=a_1E(X_1)+\\cdots +a_nE(X_n)+b \\] La esperanza es monótona creciente: Si \\(X\\leqslant Y\\) (en el sentido de que, para cada sujeto de la población \\(\\Omega\\), su valor de \\(X\\) es menor o igual que su valor de \\(Y\\)), entonces \\(E(X)\\leqslant E(Y)\\). Si todos sacáis mejor nota de Anatomía que de Bioestadística, la nota media de Anatomía será mayor que la de Bioestadística, ¿no? 10.3 Varianza y desviación típica La varianza de una variable aleatoria discreta \\(X\\) es \\[ \\sigma(X)^2 =E((X-\\mu_X)^2) =\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x) \\] Es decir, es el valor medio del cuadrado de la diferencia entre \\(X\\) y su media \\(\\mu_X\\). También la denotaremos \\(\\sigma_X^2\\). Fijaos en que se trata de la traducción “poblacional” de la definición de varianza para una muestra, y por lo tanto sirve para medir lo mismo que aquella: la dispersión de los resultados de \\(X\\) respecto de la media. Solo que ahora para toda la población. La identidad siguiente os puede ser útil para calcular varianzas “a mano”. Ya vimos en la lección anterior esta igualdad para la varianza de una muestra. Teorema 10.1 \\(\\sigma(X)^2=E(X^2)-\\mu_X^2\\). Operemos (y recordad que \\(E(X)=\\mu_X\\)) \\[ \\begin{array}{rl} \\sigma(X)^2\\!\\!\\!\\!\\! &amp; =E((X-\\mu_X)^2)=E(X^2-2\\mu_X\\cdot X+\\mu_X^2)\\\\ &amp; = E(X^2)-2\\mu_X\\cdot E(X)+\\mu_X^2\\\\ &amp; \\text{(por la linealidad de $E$)}\\\\ &amp; = E(X^2)-2\\mu_X^2+\\mu_X^2=E(X^2)-\\mu_X^2 \\end{array} \\] En particular, si \\(X\\) no es una variable constante, \\(\\sigma(X)^2\\) es una suma de cuadrados, algunos de los cuales va a ser diferente de 0 y por lo tanto estrictamente positivo, en cuyo caso \\(E(X^2)-\\mu_X^2=\\sigma(X)^2&gt;0\\): el valor esperado de \\(X^2\\) es mayor que el cuadrado del valor esperado de \\(X\\). La desviación típica (o desviación estándar) de una variable aleatoria discreta \\(X\\) es la raíz cuadrada positiva de su varianza: \\[ \\sigma(X)=+\\sqrt{\\sigma(X)^2} \\] También mide la dispersión de los valores de \\(X\\) respecto de la media. La denotaremos a veces por \\(\\sigma_X\\). En el contexto de las variables aleatorias, no hay “varianza” y “varianza muestral”, solo “varianza”. El mismo nombre os tendría que dar la pista de que la “varianza muestral” está definida solo para muestras. El motivo para introducir la varianza y la desviación típica para medir la dispersión de los valores de \\(X\\) es la misma que en estadística descriptiva: la varianza es más fácil de manejar (no involucra raíces cuadradas) pero sus unidades son las de \\(X\\) al cuadrado, mientras que las unidades de la desviación típica son las de \\(X\\), y por lo tanto su valor es más fácil de interpretar. Ejemplo 10.5 Seguimos con la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada 3 veces y contamos las caras”. Su varianza es: \\[ \\begin{array}{rl} \\sigma(X)^2 \\!\\!\\!\\!\\! &amp; \\displaystyle=(0-1.5)^2\\cdot \\frac{1}{8}+(1-1.5)^2\\cdot \\frac{3}{8}\\\\ &amp;\\displaystyle\\qquad +(2-1.5)^2\\cdot \\frac{3}{8}+(3-1.5)^2\\cdot \\frac{1}{8}=0.75 \\end{array} \\] Si recordamos que \\(\\mu_X=E(X)=1.5\\) y \\(E(X^2)=3\\), podemos ver que \\[ E(X^2)-\\mu_X^2=3-1.5^2=0.75=\\sigma(X)^2 \\] Su desviación típica es \\[ \\sigma(X) =\\sqrt{\\sigma(X)^2}=\\sqrt{0.75}= 0.866 \\] Veamos algunas propiedades de la varianza y la desviación típica: Si \\(b\\) es una variable aleatoria constante que sobre todos los individuos de la población toma el valor \\(b\\in \\mathbb{R}\\), es decir, tal que \\(D_b=\\{b\\}\\), entonces \\(\\mu_b=b\\) y \\(\\sigma(b)^2=(b-b)f_b(b)=0\\).. Una variable aleatoria constante tiene cero dispersión, ¿no? El recíproco también es cierto: si \\(0=\\sigma(X)^2=\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x)\\), entonces todos los sumandos son 0, y como \\(f_X(x)\\neq 0\\) si \\(x\\in D_X\\), concluimos que, para todo \\(x\\in D_X\\), \\(x=\\mu_X\\): es decir, que el dominio está formado por un solo número y la variable aleatoria es constante. \\(\\sigma(aX+b)^2=a^2\\cdot \\sigma(X)^2\\). En efecto \\[ \\begin{array}{l} \\sigma(aX+b)^2 =E((aX+b)^2)-E(aX+b)^2\\\\ \\quad = E(a^2X^2+2abX+b^2)-(aE(X)+b)^2\\\\ \\quad \\text{(por la linealidad de $E$)}\\\\ \\quad = a^2E(X^2)+2abE(X)+b^2-a^2E(X)^2-2abE(X)-b^2\\\\ \\quad \\text{(de nuevo, por la linealidad de $E$)}\\\\ \\quad = a^2(E(X^2)-E(X)^2)=a^2\\sigma(X)^2 \\end{array} \\] Sumar un valor constante \\(b\\) a una variable aleatoria no modifica su dispersión: si en un examen a todos los estudiantes les sumamos 1 punto, la media va a subir 1 punto pero la dispersión de las notas alrededor de esta media va a ser la misma que antes de sumarlo. \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\) (recordad que la desviación típica es positiva y que \\(+\\sqrt{a^2}=|a|\\)). Si \\(X,Y\\) son variables aleatorias independientes, \\[ \\sigma(X+Y)^2=\\sigma(X)^2+\\sigma(Y)^2 \\] y por lo tanto \\[ \\sigma(X+Y)=\\sqrt{\\sigma(X)^2+\\sigma(Y)^2} \\] Si no son independientes, en general esta igualdad es falsa. Por poner un ejemplo extremo, \\[ \\sigma(X+X)^2=4\\sigma(X)^2\\neq \\sigma(X)^2+\\sigma(X)^2. \\] Más en general, si \\(X_1,\\ldots,X_n\\) son variables aleatorias independientes y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ \\sigma(a_1X_1+\\cdots +a_nX_n+b)^2=a_1^2\\sigma(X_1)^2+\\cdots +a_n^2\\sigma(X_n)^2 \\] 10.4 Cuantiles Sea \\(p\\) tal que \\(0&lt;p&lt;1\\). El cuantil de orden \\(p\\) (o \\(p\\)-cuantil) de una variable aleatoria \\(X\\) discreta es el menor valor \\(x_p\\) de su dominio \\(D_X\\) tal que \\(P(X\\leqslant x_p)\\geqslant p\\); es decir, es el valor \\(x_p\\in D_X\\) tal que \\(P(X\\leqslant x_p)\\geqslant p\\) pero \\(P(X&lt; x_p)&lt;p\\). Por ejemplo, que el 0.25-cuantil de una variable aleatoria discreta \\(X\\) sea, pongamos, 8, significa que 8 es el menor valor del dominio de \\(X\\) tal que su probabilidad acumulada llega a (o pasa de) 0.25. En otras palabras, que al menos una cuarta parte de la población tiene un valor de \\(X\\) menor o igual que 8, pero estrictamente menos de un 25% de la población tiene un valor de \\(X\\) estrictamente menor que 8. Si existe algún \\(x_p\\in D_X\\) tal que \\(F_X(x_p)(=P(X\\leqslant x_p))=p\\), entonces el \\(p\\)-cuantil es ese \\(x_p\\), porque si \\(x&lt;x_p\\), \\(P(X\\leqslant x)&lt;P(X\\leqslant x_p)=F_X(x_p)=p\\) y por lo tanto es el menor elemento del dominio con probabilidad acumulada al menos (en este caso, exactamente) \\(p\\). Como en estadística descriptiva, algunos cuantiles de variables aleatorias tienen nombres propios. Por ejemplo: La mediana de \\(X\\) es su 0.5-cuantil El primer y el tercer cuartiles de \\(X\\) son sus \\(0.25\\)-cuantil y \\(0.75\\)-cuantil, respectivamente. Etc. Ejemplo 10.6 Seguimos con la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada 3 veces y contamos las caras”. Recordemos que su función de distribución es \\[ F_X(x)=\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt;0$}\\\\ 0.125 &amp; \\text{ si $0\\leqslant x&lt;1$}\\\\ 0.5 &amp; \\text{ si $1\\leqslant x&lt;2$}\\\\ 0.875 &amp; \\text{ si $2\\leqslant x&lt;3$}\\\\ 1 &amp; \\text{ si $3\\leqslant x $} \\end{array} \\right. \\] Entonces, por ejemplo: Su 0.1-cuantil es 0 Su 0.25-cuantil es 1 Su mediana es 1 Su 0.75-cuantil es 2 Aunque usamos “media”, “varianza”, “cuantiles”, etc. tanto para muestras como para variables aleatorias, no debéis confundirlas. Una variable aleatoria representa una característica númerica de los sujetos de una población. Por ejemplo: “Tomamos un estudiante de medicina y medimos su altura en m.” La media y la varianza de esta variable son las de toda la población de estudiantes de medicina. Una muestra de una variable aleatoria son los valores de la misma sobre un subconjunto (relativamente pequeño) de la población. Por ejemplo: Medimos las alturas (en m) de 50 estudiantes de medicina de este curso. La media y la varianza de esta muestra son solo las de esas 50 alturas. Cuando queramos destacar que una media, una varianza etc. son las de una variable aleatoria y por lo tanto refieren a toda una población, los calificaremos de poblacionales. 10.5 Familias importantes de variables aleatorias discretas En esta sección vamos a describir tres familias de variables aleatorias “distinguidas” que tenéis que conocer: Binomial Hipergeométrica Poisson Cada una de estas familias tienen un tipo específico de función de densidad, que depende de uno o varios parámetros. De estas familias de variables tenéis que saber: Distinguirlas: saber cuando una variable aleatoria es de una de estas familias. Sus propiedades más básicas, como por ejemplo cuáles son sus parámetros, cuál es su valor esperado y si su densidad es simétrica o presenta una cola a algún lado. Usar algún programa o alguna aplicación para calcular cosas con ellas cuando sea necesario. 10.5.1 Variables aleatorias binomiales Un experimento de Bernoulli es una acción con solo dos posibles resultados, que identificamos con “Éxito” (\\(E\\)) y “Fracaso” (\\(F\\)). Por ejemplo, lanzar un dado cúbico y mirar si ha salido un 6 (\\(E\\): sacar un 6; \\(F\\): cualquier otro resultado). La probabilidad de éxito \\(p\\) de un experimento de Bernoulli es la probabilidad de obtener \\(E\\). Es decir, \\(P(E)=p\\). Naturalmente, entonces, \\(P(F)=1-p\\). En el ejemplo del dado, donde \\(E\\) es sacar un 6, \\(p=1/6\\). Otros ejemplos de experimentos de Bernoulli: Lanzar una moneda equilibrada y mirar si da cara: \\(E\\): Sacar cara \\(p=1/2\\) Realizar un test PCR de COVID-19 a una persona y mirar si da positivo: \\(E\\): Dar positivo \\(p\\): La proporción de personas que dan positivo en el test (su tasa de positividad). Pedir a una persona si la estadística le aburre: \\(E\\): Que la estadística le aburra \\(p\\): La proporción de personas a las que aburre la estadística Figura 10.3: ¿Con cuál te identificas? Una variable aleatoria de Bernoulli de parámetro \\(p\\) (abreviadamente, \\(Be(p)\\)) es una variable aleatoria \\(X\\) consistente en efectuar un experimento de Bernoulli y dar 1 si se ha obtenido un éxito y 0 si se ha obtenido un fracaso. Una variable aleatoria binomial de parámetros \\(n\\) y \\(p\\) (abreviadamente, \\(B(n,p)\\)) es una variable aleatoria \\(X\\) que cuenta el número de éxitos \\(E\\) en una secuencia de \\(n\\) repeticiones independientes de un mismo experimento de Bernoulli de probabilidad de éxito \\(p\\). Independientes significa que las \\(n\\) variables aleatorias de Bernoulli, una para cada repetición del experimento de Bernoulli, son independientes; intuitivamente, que el resultado de cada repetición en la secuencia no depende de los resultados de las otras. Llamaremos a \\(n\\) el tamaño de las muestras y a \\(p\\) la probabilidad (poblacional) de éxito. A veces también diremos de una variable \\(X\\) de tipo \\(B(n,p)\\) que tiene distribución binomial de parámetros \\(n\\) y \\(p\\). Por ejemplo: Una variable de Bernoulli \\(Be(p)\\) es una variable binomial \\(B(1,p)\\). Lanzar una moneda equilibrada 10 veces y contar las caras es una variable binomial \\(B(10,0.5)\\) Elegir 20 personas al azar, una tras otra, permitiendo repeticiones y de manera independiente las unas de las otras, realizar sobre ellas un test PCR de COVID-19 y contar cuántos dan positivo, es una variable binomial \\(B(20,p)\\) con \\(p\\) la tasa de positividad del test. El tipo más común de variables binomiales en medicina es este último: Tenemos un subconjunto \\(A\\) de una población \\(\\Omega\\) (por ejemplo, las personas que dan positivo en la PCR). Sea \\(p\\) la proporción poblacional de personas que pertenecen a \\(A\\), es decir \\(p=P(A)\\). Tomamos muestras aleatorias simples de tamaño \\(n\\) de la población y contamos cuántos sujetos de la muestra son de \\(A\\). Esto nos define una variable aleatoria que es binomial \\(B(n,p)\\). Tenemos el resultado siguiente. Teorema 10.2 Si \\(X\\) es una variable \\(B(n,p)\\): Su dominio es \\(D_X=\\{0,1,\\ldots,n\\}\\) Su función de densidad es \\[ f_X(k)=\\left\\{\\begin{array}{ll} \\displaystyle\\binom{n}{k}p^k(1-p)^{n-k} &amp; \\text{ si $k\\in D_X$}\\\\ 0 &amp; \\text{ si $k\\notin D_X$} \\end{array}\\right. \\] Su valor esperado es \\(E(X)=np\\) Su varianza es \\(\\sigma(X)^2=np(1-p)\\) Recordad que: El factorial \\(m!\\) de un número natural \\(m\\) se define como \\(m!=m(m-1)\\cdots 2\\cdot 1\\) si \\(m\\geqslant 1\\). Si \\(m=0\\), se toma \\(0!=1\\). El número combinatorio \\(\\binom{n}{k}\\) se define como \\[ \\binom{n}{k}=\\frac{\\overbrace{n\\cdot (n-1)\\cdots (n-k+1)}^k}{k\\cdot (k-1)\\cdots 2\\cdot 1}=\\frac{n!}{k!(n-k)!} \\] y nos da el número de subconjuntos de \\(k\\) elementos de \\(\\{1,\\ldots,n\\}\\). Si lo pensáis, veréis que el valor de \\(E(X)\\) es el “esperado”. Si tomáis una muestra aleatoria de \\(n\\) sujetos de una población en la que la proporción de sujetos \\(E\\) es \\(p\\), ¿cuántos sujetos \\(E\\) “esperáis” obtener en vuestra muestra? Pues una fracción \\(p\\) de la muestra, es decir \\(p\\cdot n\\), ¿no? Supongamos que efectuamos \\(n\\) repeticiones consecutivas e independientes de un experimento de Bernoulli de probabilidad de éxito \\(p\\) y contamos el número de éxitos \\(E\\); llamaremos \\(X\\) a la variable aleatoria resultante. Para seguir la demostración, si no os sentís muy cómodos con el razonamiento con \\(n\\)’s y \\(k\\)’s abstractos, vosotros id repitiéndolo tomando, por ejemplo, \\(n=4\\). Los posibles resultados son todas las secuencias posibles de \\(n\\) letras formadas por \\(E\\)’s y \\(F\\)’s. Como los experimentos sucesivos son independientes, la probabilidad de cada una de estas palabras es el producto de las probabilidades de sus resultados individuales. Por lo tanto, si una palabra concreta tiene \\(k\\) letras \\(E\\) y \\(n-k\\) letras \\(F\\) (se han obtenido \\(k\\) éxitos y \\(n-k\\) fracasos), su probabilidad es \\(p^k(1-p)^{n-k}\\), independientemente del orden en el que hayamos obtenido los resultados. Para calcular la probabilidad de obtener una secuencia con \\(k\\) éxitos, sumaremos las probabilidades de obtener cada una de las secuencias de \\(n\\) letras con \\(k\\) \\(E\\)’s. Como todas tienen la misma probabilidad, el resultado será la probabilidad de una palabra con \\(k\\) \\(E\\)’s y \\(n-k\\) \\(F\\)’s, que hemos quedado que es \\(p^k(1-p)^{n-k}\\), multiplicada por el número total de palabras diferentes con \\(k\\) \\(E\\)’s y \\(n-k\\) \\(F\\)’s. ¿Cuántas palabras hay con \\(k\\) \\(E\\)’s y \\(n-k\\) \\(F\\)’s? Cada una queda caracterizada por las posiciones de las \\(k\\) \\(E\\)’s, por lo tanto es el número de posibles elecciones de conjuntos de \\(k\\) posiciones para las \\(E\\)’s. Este es el número de posibles subconjuntos de \\(k\\) elementos (las posiciones donde habrá las \\(E\\)’s) de \\(\\{1,\\ldots,n\\}\\), que es el número combinatorio \\(\\binom{n}{k}\\). Por lo tanto ya tenemos \\[ P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}. \\] A partir de aquí, para calcular el valor esperado y la varianza se suman \\[ \\begin{array}{l} \\displaystyle E(X)=\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k}\\\\ \\displaystyle \\sigma(X)^2=\\sum_{k=0}^n k^2\\cdot \\binom{n}{k}p^k(1-p)^{n-k}-\\Big(\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k}\\Big)^2 \\end{array} \\] Os podéis fiar de nosotros, dan \\(np\\) y \\(np(1-p)\\), respectivamente. Es una tontería, pero, por si acaso, queremos hacer hincapié en que si \\(X\\) es \\(B(n,p)\\), \\(P(X=k)\\) no solo depende de \\(k\\) sino también de los parámetros \\(n\\) y \\(p\\). No tiene la misma probabilidad sacar 3 caras en 5 lanzamientos de una moneda equilibrada que en 500 lanzamientos, ni tiene la misma probabilidad sacar 3 caras en 5 lanzamientos de una moneda equilibrada que si la moneda está trucada a favor de cara. Esto será general. Todas las variables aleatorias de una misma familia tienen la función de densidad de la misma forma, y solo varían los valores de los parámetros. El tipo de teorema anterior es el que hace que nos interese conocer algunas familias distinguidas frecuentes de variables aleatorias. Si, por ejemplo, reconocemos que una variable aleatoria es binomial y conocemos sus valores de \\(n\\) y \\(p\\) y sabemos el teorema anterior (o sabemos dónde consultarlo), automáticamente sabemos su función de densidad, y con ella su función de distribución, su valor esperado, su varianza etc., sin necesidad de deducir toda esta información cada vez que encontremos una variable de estas. El conocimiento ahorra tiempo. Conocer las propiedades de las variables aleatorias binomiales solo es útil si sabemos reconocer cuándo estamos ante una de ellas. Fijaos en que en una variable aleatoria binomial \\(B(n,p)\\): Contamos cuántas veces ocurre un suceso (el éxito \\(E\\)) en una secuencia de intentos. En cada intento, el suceso que nos interesa pasa o no pasa, sin términos medios. El número de intentos es fijo, \\(n\\). Cada intento es independiente de los otros. En cada intento, la probabilidad de que pase el suceso que nos interesa es siempre la misma, \\(p\\). Por ejemplo: Una mujer tiene 4 hijos. La probabilidad de que un hijo sea niña es fija, 0.51. El sexo de cada hijo es independiente de los otros. Contamos cuántas hijas tiene. Es una variable binomial \\(B(4,0.51)\\). En una aula hay 5 chicos y 45 chicas. Escogemos 10 estudiantes, uno tras otro y sin repetirlos, para hacerles una pregunta. Cada elección es independiente de las otras. Contamos cuántos chicos hemos interrogado. No es una variable binomial: como no podemos repetir estudiantes, en cada ronda la probabilidad de escoger un chico depende del sexo de los estudiantes elegidos antes que él. Por lo tanto la \\(p\\) no es la misma en cada elección. Por ejemplo, en la primera ronda la probabilidad de elegir un chico es 5/50=0.1. Ahora, si en la primera ronda sale elegido un chico, la probabilidad de que en la segunda ronda volvamos a elegir un chico se reduce a 4/49=0.0816, mientras que si la primera elección sale una chica, la probabilidad de chico en la segunda ronda sube a 5/49=0.102. En una aula hay 5 chicos y 45 chicas. Escogemos 10 estudiantes, uno tras otro pero cada estudiante puede ser elegido más de una vez, para hacerles una pregunta. Cada elección es independiente de las otras. Contamos cuántos chicos hemos interrogado. Ahora sí que es una variable binomial \\(B(10,0.9)\\). En una aula hay 5 chicos y 45 chicas. Escogemos estudiantes uno tras otro y cada estudiante puede ser elegido más de una vez, para hacerles una pregunta. Cada elección es independiente de las otras. Contamos cuántos estudiantes he tenido que elegir para llegar a interrogar 5 chicos. No es una variable binomial: no cuenta el número de éxitos en una secuencia de un número fijo de intentos, sino cuántos intentos se han necesitado para llegar a un número fijo de éxitos. En una aula hay 5 chicos y 45 chicas. Lanzamos una moneda equilibrada: si sale cara escogemos 10 estudiantes y si sale cruz escogemos 20, para hacerles una pregunta. Tanto en un caso como en el otro, los elegimos uno tras otro, cada estudiante puede ser elegido más de una vez y cada elección es independiente de las otras. Contamos cuántos chicos hemos interrogado. No es una variable binomial: el número de intentos no es fijo. La probabilidad de que un día de noviembre llueva es de un 32%. Escogemos una semana de noviembre y contamos cuántos días ha llovido. No es de una variable binomial. Aunque a priori cada día tenga la misma probabilidad de lluvia, que llueva un día no es independiente de que llueva el anterior. Si en cambio escogiéramos 7 días novembrinos, de entre el total de todos los días de todos los noviembres de la historia (y permitiendo que se repitieran), entonces sí que se trataría de una variable binomial. En España hay 46,700,000 personas, de las cuales un 11.7% son diabéticos. Escogemos 100 españoles diferentes al azar (de manera independiente unos de otros) y contamos cuántos son diabéticos. No es binomial, pero prácticamente sí que lo es, porque las probabilidades apenas varían de una elección a la siguiente. En este caso haremos la trampa de considerarla binomial. Recordad que, cuando discutíamos sobre muestras aleatorias, decíamos que si tomamos una muestra aleatoria sin reposición de una población muchísimo más grande que la muestra, a efectos prácticos podíamos considerarla simple, porque, total, si hubiéramos permitido repeticiones, casi seguro que no se habrían dado. Pues aquí igual. Veamos algunos gráficos de la función densidad de variables aleatorias binomiales. Primero, para \\(n=10\\) y diferentes valores de \\(p\\). Ahora para \\(n=100\\): Podréis observar que si \\(p&lt;0.5\\), la distribución \\(B(n,p)\\) presenta una cola a la derecha, y si \\(p&gt;0.5\\), la cola es a la izquierda. Es razonable. Por ejemplo, si \\(p&lt;0.5\\), el valor esperado será \\(pn&lt;n/2\\) y hay más valores posibles a la derecha de \\(pn\\) que a su izquierda (porque una binomial \\(B(n,p)\\) puede llegar a tomar el valor \\(n\\), pero no puede tomar valores negativos). Si \\(p=0.5\\), es simétrica: como \\(E\\) y \\(F\\) tienen la misma probabilidad, 0.5, la probabilidad de sacar \\(k\\) \\(E\\)’s es la misma que la de sacar \\(k\\) \\(F\\)’s, es decir, la de sacar \\(n-k\\) \\(E\\)’s. Para agilizar los tests de COVID-19, se propuso la estrategia siguiente (llamada pooled sample testing o simplemente pooling). Se unen grupos de 10 muestras en una sola muestra y se analizan. Si da negativo, será señal de que todas la muestras originales eran negativas. Se declaran entonces negativos los 10 sujetos de las muestras originales. Si da positivo, será porque al menos una de las muestras originales era positiva. En este caso, se analizan las 10 muestras por separado. Supongamos que el test tiene una especificidad y una sensibilidad del 100%. Observad entonces que si los 10 sujetos están sanos, se hace un solo test, mientras que si alguno está infectado, se hacen 11. Con el enfoque tradicional, un test por muestra, sin complicaciones, se harían siempre 10 tests. Sea \\(p\\) la prevalencia de la COVID-19 en un momento y población dados. Sea p la prevalencia de la COVID-19 en un momento y población dados. Dadas 10 muestras tomadas en ese momento en esa población, ¿cuál es el valor esperado de tests que se tienen que realizar? Para p pequeña, del orden del 5%, ¿significaría el pooling un ahorro considerable de tests? Plan: Considerad la variable aleatoria que cuenta, para cada conjunto de 10 muestras, cuántos tests se realizan. ¿Cuál es su dominio? ¿Qué vale la probabilidad de cada elemento del dominio? (es decir, la densidad de la variable aleatoria) ¿Cuál es su valor esperado? ¿Qué vale este valor esperado cuando p es 5%? ¿Cómo efectuar cálculos con una variable aleatoria de una familia dada? Una posibilidad es usar una aplicación de móvil o tablet. Nuestra favorita es Probability distributions, disponible tanto para Android como para iOS. Figura 10.4: La app Probability Distributions. Otra posibilidad es usar JAMOVI. El módulo distrACTION permite calcular probabilidades y cuantiles de todas las distribuciones que usaremos en este curso salvo una, la hipergeométrica. Ya hablaremos de ella en la próxima sección. Figura 10.5: Distribuciones que permite usar distrACTION Por ejemplo: Si lanzamos 20 veces un dado equilibrado (de 6 caras), ¿cuál es la probabilidad de sacar exactamente 5 unos? Si llamamos \\(X\\) a la variable aleatoria que cuenta el número de unos en secuencias de 20 lanzamientos de un dado equilibrado, se trata de una variable binomial \\(B(20,1/6)=B(20,0.166667)\\). Nos piden \\(P(X=5)\\). Da 0.129: Figura 10.6: Cálculo de P(X=5) Si lanzamos 20 veces un dado equilibrado, ¿cuál es la probabilidad de sacar como máximo 5 unos? Con las notaciones anteriores, nos piden \\(P(X\\leqslant 5)\\). Da 0.898: Figura 10.7: Cálculo de P(X⩽5) Si lanzamos 20 veces un dado equilibrado, ¿cuál es la probabilidad de sacar menos de 5 unos? Con las notaciones anteriores, nos piden \\(P(X&lt; 5)\\), es decir, \\(P(X\\leqslant 4)\\). Da 0.769: Figura 10.8: Cálculo de P(X&lt;5) Si lanzamos 20 veces un dado equilibrado, ¿cuál es el menor número \\(N\\) de unos para el que la probabilidad de sacar como máximo \\(N\\) unos llega al 25%? Nos piden el menor valor \\(N\\) tal que \\(P(X\\leqslant N)\\geqslant 0.25\\), y esto por definición es el 0.25-cuantil de \\(X\\). Da 2: Figura 10.9: Cálculo el primer cuartil de X Podéis comprobar que en efecto \\(N=2\\) cumple lo pedido: si las calculáis, veréis que la probabilidad de sacar como máximo 2 unos es \\(P(X\\leqslant 2)=0.329\\) y la probabilidad de sacar como máximo 1 uno es \\(P(X\\leqslant 1)=0.13\\). Por lo tanto, con 1 uno no llegamos al 25% de probabilidad y con 2 sí. 10.5.2 Variables aleatorias hipergeométricas Recordad que el paradigma de variable aleatoria binomial es: tengo una población con una proporción \\(p\\) de sujetos que satisfacen una condición \\(E\\), tomo una muestra aleatoria simple de tamaño \\(n\\) y cuento el número de sujetos \\(E\\) en mi muestra. Si cambiamos “muestra aleatoria simple” por “muestra aleatoria sin reposición”, la distribución de la variable aleatoria que obtenemos es otra: la hipergeométrica. Una variable aleatoria hipergeométrica (o tiene distribución hipergeométrica) de parámetros \\(N\\), \\(M\\) y \\(n\\) (para abreviar, \\(H(N,M,n)\\)) es cualquier variable aleatoria \\(X\\) que podáis identificar con el proceso siguiente: Tenemos una población formada por \\(N\\) sujetos que satisfacen una condición \\(E\\) y \\(M\\) sujetos que no la satisfacen (por lo tanto, en total, \\(N+M\\) sujetos en la población), tomamos una muestra aleatoria sin reposición de tamaño \\(n\\) y contamos el número de sujetos \\(E\\) en esta muestra. Llamaremos a \\(N\\) el número poblacional de éxitos, a \\(M\\) el número poblacional de fracasos y a \\(n\\) el tamaño de las muestras. Fijaos entonces que \\(N+M\\) es el tamaño total de la población y que \\(N/(N+M)\\) es la probabilidad poblacional de éxito (la fracción de sujetos que satisfacen \\(E\\) en el total de la población), que llamaremos \\(p\\). Ejemplo 10.7 Recordad uno de los ejemplos de variables no binomiales de la sección anterior. En una aula hay 5 chicos y 45 chicas. Escogemos 10 estudiantes, uno tras otro y sin repetirlos, para hacerles una pregunta. Cada elección es independiente de las otras. Contamos cuántos chicos hemos interrogado. Se trata de una variable hipergeométrica \\(H(5,45,10)\\). Teorema 10.3 Si \\(X\\) es una variable \\(H(N,M,n)\\): Su dominio es \\(D_X=\\{0,1,\\ldots,\\text{min}(N,n)\\}\\) Su función de densidad es \\[ f_X(k)=\\left\\{\\begin{array}{ll} \\displaystyle\\dfrac{\\binom{N}{k}\\cdot \\binom{M}{n-k}}{\\binom{N+M}{n}} &amp; \\text{ si $k\\in D_X$}\\\\ 0 &amp; \\text{ si $k\\notin D_X$} \\end{array}\\right. \\] Su valor esperado es \\(E(X)=\\dfrac{nN}{N+M}\\) Su varianza es \\(\\sigma(X)^2=\\dfrac{nNM(N+M-n)}{(N+M)^2(N+M-1)}\\) Fijaos en que si llamamos \\(p\\) a la probabilidad poblacional de éxito, \\(p=N/(N+M)\\), entonces \\[ E(X)=np. \\] Es la misma fórmula que para las variables binomiales \\(B(n,p)\\) (y si lo pensáis un rato veréis que, de nuevo y por el mismo argumento, es lo razonable). Por otro lado, si llamamos \\(\\mathbf{P}\\) al tamaño de la población, \\(\\mathbf{P}=N+M\\), entonces \\[ \\sigma(X)^2=n\\cdot\\dfrac{N}{N+M}\\cdot\\dfrac{M}{N+M}\\cdot\\frac{N+M-n}{N+M-1}=np(1-p)\\cdot\\dfrac{\\mathbf{P}-n}{\\mathbf{P}-1} \\] que es la varianza de una variable \\(B(n,p)\\) multiplicada por un factor de corrección debido a que ahora tomamos muestras sin repeticiones, lo que hace que la dispersión de resultados sea más pequeña que si permitiéramos repeticiones (yendo a un caso extremo, de tamaño \\(N+M\\) hay una sola muestra posible sin repetición, pero muchísimas si permitimos repeticiones). A la raíz cuadrada de este factor, \\[ \\sqrt{\\dfrac{\\mathbf{P}-n}{\\mathbf{P}-1}} \\] se la llama factor (corrector) de población finita. Fijaos en que si \\(\\mathbf{P}\\) es muchísimo mayor que \\(n\\), tendremos que \\(\\mathbf{P}-n\\approx \\mathbf{P}-1\\) y por lo tanto \\((\\mathbf{P}-n)/(\\mathbf{P}-1)\\approx 1\\) y la varianza de la hipergeométrica será aproximadamente la de la binomial. Esto es consistente con lo que ya hemos comentado varias veces: si la población es mucho mayor que la muestra, tomar las muestras con o sin reposición no afecta demasiado a las muestra obtenidas, por lo que la distribución de probabilidad ha de ser muy parecida. Recordad los ejemplos siguientes: En España hay 46,700,000 personas, de las cuales un 11.7% son diabéticos. Escogemos 100 españoles y contamos cuántos son diabéticos. Esta variable es, en realidad, hipergeométrica con \\(N=0.117\\cdot 46700000=5463900\\), \\(M=46700000-N=41236100\\) y \\(n=100\\), pero en la práctica la consideramos binomial \\(B(100,0.117)\\). El factor de población finita es \\[ \\frac{46700000-100}{46700000-1}=0.9999979 \\] De hecho, la probabilidad de alguna repetición en una muestra aleatoria simple de 100 españoles es 0.0001, es decir, de media solo se da alguna repetición en una de cada 10000 muestras de estas, como muestra la aplicación siguiente de la función pbirthday: pbirthday(100,46700000) ## [1] 0.0001059902 Hay otro motivo para considerarla binomial en este ejemplo, y es que, en realidad, no sabemos los valores exactos de \\(N\\) y \\(M\\). Estoy seguro de que no es verdad que el tamaño de la población española sea exactamente de 46,700,000 personas, tan redondo, ni que los diabéticos representen exactamente un 11.7%, sin más cifras decimales. Así que ya puestos a aproximar, tomamos la aproximación binomial, que es más sencilla. Pero cuidado: si la muestra fuera, pongamos, de 10,000 personas, entonces la aproximación binomial sería teóricamente incorrecta, aunque el factor corrector de población finita es de 0.999786: de media, un poco menos de 2 de cada 3 muestras aleatorias simples de 10,000 personas tomadas de una población de 46,700,000 personas contienes alguna repetición, como muestra el cálculo siguiente. pbirthday(10000,46700000) ## [1] 0.6572086 En una aula hay 5 chicos y 45 chicas. Escogemos 10 estudiantes, uno tras otro y sin repetirlos, para hacerles una pregunta. Cada elección es independiente de las otras. Contamos cuántos chicos hemos interrogado. Esta variable es hipergeométrica \\(H(5,45,10)\\). El factor de población finita en esta caso no es aproximadamente 1: da \\[ \\frac{50-10}{50-1}=0.8163 \\] No es correcto aproximarla por una binomial \\(B(10,0.1)\\). El gráfico siguiente compara la función de densidad de una variable \\(B(10,0.1)\\) con las de variables hipergeométricas \\(H(5,45,10)\\), \\(H(50,450,10)\\) y \\(H(5000,45000,10)\\) para que veáis cómo a medida que el tamaño de la población crece (manteniendo constante la proporción poblacional de éxitos), la distribución hipergeométrica se aproxima a la binomial. Veamos algunos gráficos de la función densidad de variables aleatorias hipergeométricas. Fijemos el tamaño de la población en \\(N+M=100\\), y tomaremos \\(n=10\\) y diferentes valores de \\(N\\). Podréis observar que, como en el caso binomial, si \\(p=N/(N+M)&lt;0.5\\), la distribución \\(H(N,M,p)\\) presenta una cola a la derecha, y si \\(p&gt;0.5\\), la cola es a la izquierda. Si \\(p=0.5\\), es simétrica. Hemos comentado en la sección anterior que el módulo distrACTION de JAMOVI no conoce la distribución hipergeométrica. Pero R sí, y podéis usarlo en la ventana del editor de R. Para R la distribución hipergeométrica es hyper (la binomial es binom). Para cada distribución implementada en R: Añadiendo al nombre de la distribución el prefijo d, tenemos su función de densidad: de la binomial será dbinom, de la hipergeomètrica dhyper… Añadiendo al nombre de la distribución el prefijo p, tenemos su función de distribución: de la binomial será pbinom, de la hipergeomètrica phyper… Añadiendo al nombre de la distribución el prefijo q, tenemos sus cuantiles: para la binomial será qbinom, para la hipergeomètrica qhyper… Añadiendo al nombre de la distribución el prefijo r, tenemos una función que produce muestra aleatorias de números con esa distribución de probabilidad: para la binomial será rbinom, para la hipergeomètrica rhyper… Estas funciones se aplican al argumento de la función y los parámetros de la variable aleatoria (todo entre paréntesis y separados por comas). Para la hipergeométrica, y con las notaciones que hemos dado, se aplican a (argumento, \\(N\\), \\(M\\), \\(n\\)). Veamos algunos ejemplos. En una clase de 50 estudiantes, 5 son hombres (y 45 mujeres). Escogemos una muestra aleatoria sin reposiciòn de 10 estudiantes. ¿Cuál es la probabilidad de que exactamente dos de los estudiantes elegidos sean hombres? La variable \\(X\\) que cuenta el número de hombres en estas muestras es hipergeométrica \\(H(5,45,10)\\). Nos piden \\(P(X=2)\\), y esta probabilidad nos la da la función de densidad de \\(X\\). Es \\(f_X(2)\\): dhyper(2,5,45,10) ## [1] 0.2098397 Fijaos en el orden de los argumentos de la función entre los paréntesis. Para calcular \\(f_X(x)\\), aplicamos dhyper a \\((x,N,M,n)\\). Figura 10.10: Cálculo de P(X=2) En la situación anterior, ¿cuál es la probabilidad de la muestra contenga como máximo 2 hombres? Con las notaciones anteriores, nos piden \\(P(X\\leqslant 2)\\), y esta probabilidad nos la da la función de distribución de \\(X\\). Es \\(F_X(2)\\): phyper(2,5,45,10) ## [1] 0.9517397 En la situación anterior, ¿cuál es la probabilidad de la muestra contenga al menos 2 hombres? Con las notaciones anteriores, nos piden \\(P(X\\geqslant 2)\\). Como lo contrario de elegir 2 hombres o más es elegir 1 hombre o menos, tenemos que \\(P(X\\geqslant 2)=1-P(X\\leqslant 1)=1-F_X(1)\\): 1-phyper(1,5,45,10) ## [1] 0.2581 Queremos simular 25 elecciones como la anterior y contar en cada una el número de hombres; es decir, queremos una muestra aleatoria de tamaño 50 de nuestra variable \\(X\\): rhyper(25,5,45,10) ## [1] 1 2 0 1 0 0 1 2 1 1 0 2 1 1 0 1 2 0 3 2 1 2 1 1 2 Cada vez que repitamos esta instrucción seguramente obtendremos una muestra aleatoria diferente: rhyper(25,5,45,10) ## [1] 0 1 1 1 3 2 1 1 2 2 2 2 2 2 0 2 1 0 2 3 0 2 1 0 3 rhyper(25,5,45,10) ## [1] 0 0 1 1 2 0 2 0 4 0 1 0 2 1 1 1 1 1 1 1 4 1 0 1 0 rhyper(25,5,45,10) ## [1] 2 2 2 1 1 1 2 1 0 0 1 0 1 1 1 2 0 2 1 2 0 0 1 1 2 10.5.3 Variables aleatorias de Poisson Una variable aleatoria \\(X\\) es de Poisson (o tiene distribución de Poisson) con parámetro \\(\\lambda&gt;0\\) (para abreviar, \\(Po(\\lambda)\\)) cuando: Su dominio es \\(D_X=\\mathbb{N}\\), el conjunto de todos los números naturales (es decir, teóricamente puede tomar como valor cualquier número natural). Su función de densidad es \\[ f_X(k)=\\left\\{\\begin{array}{ll} e^{-\\lambda}\\cdot \\dfrac{\\lambda^k}{k!} &amp; \\text{ si $k\\in \\mathbb{N}$}\\\\ 0 &amp; \\text{ si $k\\notin \\mathbb{N}$} \\end{array}\\right. \\] Teorema 10.4 Si \\(X\\) es una variable \\(Po(\\lambda)\\), entonces \\(E(X)= \\sigma(X)^2= \\lambda\\). Es decir, el “parámetro” \\(\\lambda\\) de una variable de Poisson es su valor esperado, y coincide con su varianza. ¿Para qué nos sirve definir una variable de Poisson mediante su densidad, si lo que nos interesa es poder clasificar una variable como de Poisson (o binomial, o hipergeométrica etc.) para así saber “gratis” su densidad? La respuesta es que la familia de Poisson incluye un tipo de variables aleatorias muy común en epidemiología. Supongamos que tenemos un tipo de objetos o acontecimientos que pueden darse en una región continua de tiempo o espacio. Por ejemplo, defunciones de personas por una determinada enfermedad en el decurso del tiempo, casos de un tipo de cáncer en diferentes zonas geográficas de un país, o bacterias en una superficie. Para simplificar el lenguaje, vamos a suponer que observamos apariciones de objetos en el tiempo. Si las apariciones de estos objetos satisfacen las propiedades siguientes: Las apariciones de los objetos son aleatorias: en cada instante, un objeto se da, o no, al azar, con una probabilidad fija y constante Las apariciones de los objetos son independientes: que se dé un objeto en un instante concreto, no depende para nada de que se haya dado o no un objeto en otro instante Las apariciones de los objetos no son simultáneas: es prácticamente imposible que dos objetos de estos se den en el mismo instante exacto, medido con precisión infinita entonces, la variable \\(X_t\\) que toma un intervalo de tiempo de duración \\(t\\) y cuenta el número de objetos que se dan en él es de Poisson: \\(Po(\\lambda_t)\\), con \\(\\lambda_t\\) el número esperado de objetos en este intervalo de tiempo (es decir, el número medio de objetos en intervalos de tiempo de este tamaño). Por ejemplo, cuando lo que cuentan ocurre al azar, son variables de Poisson: El número de enfermos admitidos en urgencias en un día (o en 12 horas, o en una semana…) El número de defunciones por una enfermedad concreta en un día (o en una semana, o en un año…) El número de bacterias en un cuadrado de 1 cm de lado (o de 1 m de lado…) Más en concreto, si \\(X\\) es una variable binomial \\(B(n,p)\\) con \\(n\\) MUY grande y \\(p\\) MUY pequeño, entonces \\(X\\) es aproximadamente \\(Po(\\lambda)\\) con \\(\\lambda=p\\cdot n\\). Aquí \\(n\\) es, para entendernos, el número de instantes en un día, o el número de puntos del cuadrado de 1 cm de lado: MUY grande. Para que os hagáis una idea, la instrucción siguiente calcula el máximo (max) de los valores absolutos (abs) de las diferencias entre la densidad de una \\(B(10^6,10^{-5})\\) y una \\(Po(10)\\): esta diferencia máxima es del orden de 0.0000006. max(abs(dbinom(0:10^6,10^6,10^-5)-dpois(0:10^6,10))) ## [1] 6.255548e-07 Podemos aplicar esta información de dos maneras: Si sabemos que una variable es (aproximadamente) de Poisson, conocemos su densidad y por lo tanto podemos calcular lo que queramos para ella. Si los datos que observamos tocarían seguir una distribución de Poisson pero parece que no (por ejemplo, porque su varianza sea muy diferente de su media, tan diferente que sea difícil de creer que la media y la varianza poblacionales sean iguales), entonces es señal de que algo “raro” está pasando en realidad. Ejemplo 10.8 Observad la diferencia entre las dos variables siguientes: Número semanal de defunciones por un tipo de cáncer en un país. El momento exacto de las defunciones se produce al azar, podemos entender que no se dan dos defunciones exactamente en el mismo instante, con precisión infinita, y las defunciones se producen de manera independiente. Es de Poisson. Número semanal de defunciones en accidentes de tráfico en un país. De nuevo, el momento exacto de las defunciones se produce al azar y podemos entender que no se dan dos defunciones exactamente en el mismo instante, con precisión infinita. Pero las muertes en accidentes de tráfico no son independientes: en un mismo accidente mortal se pueden producir varias muertes casi simultáneas. No es buena idea modelarla mediante una distribución de Poisson. En cambio, el número de accidentes de tráfico sí. Como las apariciones de los objetos que cuenta una variable de Poisson son aleatorias e independientes, el número medio de objetos es lineal en el tamaño de la región. Es decir, por ejemplo, en un intervalo de dos días esperamos ver el doble de objetos que en un día. O por ejemplo, si se diagnostican de media 32,240 casos de cáncer de colon anuales en España (y siguen una ley de Poisson), esperamos que de media se diagnostiquen 32240/52=620 casos semanales. Veamos algunos gráficos de funciones de densidad de variables de Poisson. Como podéis ver, la densidad de una variable de Poisson es asimétrica, con un máximo alrededor de \\(\\lambda\\) y una cola a la derecha, pero a medida que \\(\\lambda\\) crece, la asimetría se va atenuando. La incidencia anual de un cierto accidente laboral sigue una distribución de Poisson. A lo largo del tiempo se ha observado que el 55% de los años no se produce ningún accidente. ¿Cuántos accidentes esperas que ocurran en un año? Sea \\(X\\) la variable que cuenta estos accidentes laborales anuales. Nos dicen que es \\(Po(\\lambda)\\), donde \\(\\lambda\\) es su valor esperado, y por lo tanto lo que nos piden. Nos dicen también que \\(P(X=0)=0.55\\). Por la fórmula de la densidad de una variable de Poisson: \\[ 0.55=e^{-\\lambda}\\cdot \\dfrac{\\lambda^0}{0!}=e^{-\\lambda}\\Longrightarrow \\lambda=-\\ln(0.55) \\] 10.6 Test (1) Sea \\(X\\) una variable aleatoria discreta de media \\(\\mu\\) y desviación típica \\(\\sigma\\). ¿Cuál o cuáles de las afirmaciones siguientes son siempre verdaderas? \\(E(X+2)=\\mu+2\\). \\(\\sigma(X+2)=\\sigma+2\\). \\(\\sigma(-X)=-\\sigma\\). \\(\\sigma(-X)=\\sigma\\). \\(\\sigma(X/2)=\\sigma/2\\). Ninguna de las otras afirmaciones es verdadera. (2) La función de distribución \\(F_X(x)\\) de una variable aleatoria discreta \\(X\\) nos da: La probabilidad de obtener el valor \\(x\\). La probabilidad de obtener un valor entre \\(-x\\) y \\(x\\), ambos extremos incluidos. La probabilidad de obtener un valor entre \\(0\\) y \\(x\\), ambos extremos incluidos. La probabilidad de obtener un valor menor o igual que \\(x\\). La probabilidad de obtener un valor estrictamente menor que \\(x\\). (3) Un tratamiento T cura el 20% de los enfermos de una enfermedad X. Marca todas las afirmaciones verdaderas. La distribución del número de individuos que se curan con el tratamiento T en una muestra aleatoria simple de 100 enfermos de X es aproximadamente simétrica. La distribución del número de individuos que se curan con el tratamiento T en una muestra aleatoria simple de 100 enfermos de X es más bien asimétrica a la izquierda. La distribución del número de individuos que se curan con el tratamiento T en una muestra aleatoria simple de 100 enfermos de X es más bien asimétrica a la derecha. La probabilidad de que T cure dos enfermos de X escogidos al azar es 0.4. En una muestra aleatoria simple de 50 enfermos de X, esperamos que T cure 10. Ninguna de las otras afirmaciones es verdadera. (4) ¿Cuál o cuáles de las variables siguientes tienen una distribución binomial? El peso de una persona elegida al azar. Lanzamos un dado cúbico; si sale un resultado par, lanzamos una moneda equilibrada 5 veces y contamos el número de caras, y si sale un resultado impar, lanzamos la moneda equilibrada 10 veces y contamos el número de caras. El número de glóbulos rojos en 1 mm3 de sangre. La proporción de hipertensos en una muestra aleatoria de 50 individuos. Escogemos 10 estudiantes diferentes en una clase de 20, y contamos cuántas mujeres han salido. Ninguna de ellas. (5) ¿Cuál o cuáles de las variables siguientes tienen una distribución de Poisson? El peso de una persona elegida al azar. El número de casos diarios de gripe en Mallorca. El número de glóbulos rojos en 1 mm3 de sangre. La proporción de hipertensos en una muestra aleatoria de 50 individuos. Escogemos 10 estudiantes diferentes en una clase de 20, y contamos cuántas mujeres han salido. Ninguna de ellas. (6) Sean \\(X\\) e \\(Y\\) dos variables aleatorias discretas cualesquiera. ¿Cuál o cuáles de las afirmaciones siguientes son verdaderas? Siempre es cierto que \\(E(2X+3Y)=2E(X)+3E(Y)\\) No siempre es cierto que \\(E(2X+3Y)=2E(X)+3E(Y)\\), pero sí que es cierto si \\(X\\) e \\(Y\\) son independientes Siempre es cierto que \\(\\sigma(2X+3Y)^2=2\\sigma(X)^2+3\\sigma(Y)^2\\) No siempre es cierto que \\(\\sigma(2X+3Y)^2=2\\sigma(X)^2+3\\sigma(Y)^2\\), pero sí que es cierto si \\(X\\) e \\(Y\\) son independientes Siempre es cierto que \\(\\sigma(2X+3Y)^2=4\\sigma(X)^2+9\\sigma(Y)^2\\) No siempre es cierto que \\(\\sigma(2X+3Y)^2=4\\sigma(X)^2+9\\sigma(Y)^2\\), pero sí que es cierto si \\(X\\) e \\(Y\\) son independientes Siempre es cierto que \\(\\sigma(2X+3Y)=2\\sigma(X)+3\\sigma(Y)\\) No siempre es cierto que \\(\\sigma(2X+3Y)=2\\sigma(X)+3\\sigma(Y)\\), pero sí que es cierto si \\(X\\) e \\(Y\\) son independientes Ninguna de las otras afirmaciones es siempre verdadera. (7) Tenéis una población con una proporción \\(0&lt;p&lt;1\\) de individuos que tienen una determinada enfermedad. Tomáis muestras aleatorias de tamaño \\(n\\) de la población y contáis cuántos individuos tienen esta enfermedad. ¿Cuál o cuáles de las afirmaciones siguientes son verdaderas? Si tomáis las muestras sin permitir repeticiones, los resultados salen más variados que si las tomáis permitiendo repeticiones. Si tomáis las muestras sin permitir repeticiones, los resultados salen menos variados que si las tomáis permitiendo repeticiones. Si tomáis las muestras permitiendo repeticiones, cuanto más grandes tomáis las muestras más variados salen los resultados. Si tomáis las muestras permitiendo repeticiones, cuanto más grandes tomáis las muestras menos variados salen los resultados. Si tomáis las muestras sin permitir repeticiones, cuanto más grandes tomáis las muestras más variados salen los resultados. Si tomáis las muestras sin permitir repeticiones, cuanto más grandes tomáis las muestras menos variados salen los resultados. Ninguna de las otras afirmaciones es verdadera. "],["variables-aleatorias-continuas.html", "Lección 11 Variables aleatorias continuas 11.1 Densidad y distribución 11.2 Esperanza, varianza, cuantiles… 11.3 Variables aleatorias normales 11.4 Test", " Lección 11 Variables aleatorias continuas Recordad que una variable aleatoria continua toma valores continuos. Por ejemplo: Peso de una persona Nivel de colesterol en sangre Diámetro de un tumor En este curso vamos a restringirnos a variables aleatorias continuas \\(X: \\Omega\\to \\mathbb{R}\\) que cumplen la siguiente propiedad extra: su función de distribución \\[ \\begin{array}{rcl} F_X: \\mathbb{R} &amp; \\to &amp; [0,1]\\\\ x &amp;\\mapsto &amp;P(X\\leqslant x) \\end{array} \\] es continua. Todas las variables aleatorias continuas que os puedan interesar en algún momento van a tener esta propiedad, así que no perdemos nada imponiéndola. ¿Y qué ganamos? Pues que podemos usar todas las técnicas matemáticas aplicables a funciones continuas para estudiar \\(F_X\\). Por ejemplo, nuestras variables continuas verifican la propiedad siguientes: Teorema 11.1 Si \\(X\\) es una variable aleatoria continua, la probabilidad de que tome un valor concreto siempre es 0: \\[ P(X=a)=0 \\text{ para todo $a\\in \\mathbb{R}$}. \\] Por si pasa por aquí alguien que necesite una demostración: \\[ \\begin{array}{l} \\displaystyle P(X=a) = P(X\\leqslant a)-P(X&lt;a)=P(X\\leqslant a)-P\\Big(\\bigcup_{n\\geqslant 1} \\Big(X\\leqslant a-\\frac{1}{n}\\Big)\\Big)\\\\ \\displaystyle \\qquad= P(X\\leqslant a)-\\lim_{n\\geqslant 1}P\\Big(X\\leqslant a-\\frac{1}{n}\\Big)\\\\ \\displaystyle \\qquad= F_X(a)-\\lim_{n\\geqslant 1}F_X\\Big(a-\\frac{1}{n}\\Big)=0 \\end{array} \\] porque \\(F_X\\) es continua. En particular, para una variable aleatoria continua: Probabilidad 0 no significa imposible. Cada valor de \\(X\\) tiene probabilidad 0, pero cuando tomamos un sujeto, tendrá algún valor de \\(X\\), ¿no?. Por lo tanto, su valor de \\(X\\) es posible, aunque tenga probabilidad 0. De \\(P(X=a)=0\\) se deduce que la probabilidad de un suceso definido con una desigualdad es la misma que la del suceso correspondiente definido con una desigualdad estricta. Por ejemplo, y contrariamente a lo que pasaba en las variables aleatorias discretas, para una variable aleatoria continua siempre tenemos que \\[ P(X\\leqslant a)=P(X&lt;a) \\] porque \\[ P(X\\leqslant a)=P(X&lt;a)+P(X=a)=P(X&lt;a)+0=P(X&lt;a). \\] De manera similar: \\(P(X\\geqslant a)=P(X&gt; a)+P(X=a)=P(X&gt; a)\\) \\(P(a\\leqslant X\\leqslant b)=P(a&lt;X&lt;b)+P(X=a)+P(X=b)\\) \\(=P(a&lt;X&lt;b)\\) 11.1 Densidad y distribución Sea \\(X\\) una variable aleatoria continua. Como ya hemos dicho, su función de distribución \\(F_X\\) se sigue definiendo como \\[ x\\mapsto F_X(x)=P(X\\leqslant x) \\] recordando además que, ahora, también \\[ F_X(x)=P(X&lt; x) \\] Pero puesto que tenemos que \\(P(X=x)=0\\), ahora no podemos definir la función de densidad de \\(X\\) como \\(f_X(x)=P(X=x)\\). ¿Qué podemos hacer? Recordad que, en las variables aleatorias discretas \\[ F_X(a)=\\sum_{x\\leqslant a} f_X(x) \\] En el contexto de matemáticas “continuas”, la suma \\(\\sum\\) se traduce en la integral \\(\\int\\). Se define entonces la función de densidad de una variable aleatoria continua \\(X\\) como la función \\(f_X:\\mathbb{R}\\to \\mathbb{R}\\) tal que: \\(f_X(x)\\geqslant 0\\), para todo \\(x\\in \\mathbb{R}\\) \\(\\displaystyle F_X(a)=\\int_{-\\infty}^a f_{X}(x)\\, dx\\) para todo \\(a\\in \\mathbb{R}\\). Recordad (o aprended por primera vez) que la integral tiene una interpretación sencilla en términos de áreas. En concreto, dados \\(a\\in \\mathbb{R}\\) y una función \\(f(x)\\), la integral \\[ \\int_{-\\infty}^a f(x)\\, dx \\] es igual al área de la región a la izquierda de la recta vertical \\(x=a\\) comprendida entre la curva \\(y=f(x)\\) y el eje de abscisas \\(y=0\\). Por lo tanto, la función de densidad \\(f_X\\) de \\(X\\) es la función positiva tal que para todo \\(a\\in \\mathbb{R}\\), \\(F_X(a)\\) es igual al área bajo la curva \\(y=f_X(x)\\) (entre esta curva y el eje de abscisas) a la izquierda de \\(x=a\\). ¿Cuál es la idea intuitiva que hay detrás de esta definición de densidad? Suponed que dibujamos histogramas de frecuencias relativas de los valores de \\(X\\) sobre toda la población. Como estamos hablando de toda la población, la frecuencia relativa de cada clase es la proporción de individuos de la población cuyo valor de \\(X\\) pertenece a esta clase: es decir, la probabilidad de que \\(X\\) caiga dentro de la clase. Recordad que, en un histograma de frecuencias relativas: La frecuencia relativa (ahora, la probabilidad) de cada clase es el área de su barra, es decir, el ancho de la clase por la altura de la barra. Llamamos a la altura de una barra la densidad de la clase. Si \\(a\\) es un extremo de una clase, la frecuencia relativa acumulada (la probabilidad) de que \\(X&lt;a\\) es la suma de las áreas de las barras a la izquierda de \\(a\\). Si dibujamos los histogramas de \\(X\\) tomando clases cada vez más estrechas, sus polígonos de frecuencias (en rojo) tienden a dibujar una curva: Cuando el ancho de las clases tiende a 0, obtenemos una curva que es el límite de estos polígonos de frecuencias: En el límite, la probabilidad de que \\(X&lt; a\\) (o sea, de que \\(X\\leqslant a\\)) será el límite de las sumas de las áreas de las barras a la izquierda de \\(a\\), y por tanto el área a la izquierda de \\(a\\) bajo esta curva límite. Esto nos dice que esta curva es precisamente la función de densidad \\(y=f_X(x)\\). La función de densidad \\(f_X\\) de una variable aleatoria continua \\(X\\) es la función límite de los polígonos de frecuencias de histogramas de \\(X\\) cuando el ancho de las clases tiende a 0. Veamos algunas propiedades que se deducen de que \\(F_X(a)=P(X\\leqslant a)\\) sea igual al área bajo la curva \\(y=f_X(x)\\) a la izquierda de \\(x=a\\): Como \\(P(X&lt;\\infty)=P(\\Omega)=1\\), el área total bajo la curva \\(y=f_X(x)\\) es 1. \\(P(a\\leqslant X\\leqslant b)=P(X\\leqslant b)-P(X&lt;a)\\) es el área bajo la curva \\(y=f_X(x)\\) a la izquierda de \\(x=b\\) menos el área bajo la curva \\(y=f_X(x)\\) a la izquierda de \\(x=a\\), es decir, \\(P(a\\leqslant X\\leqslant b)\\) es igual al área bajo la curva \\(y=f_X(x)\\) entre \\(x=a\\) y \\(x=b\\). Si \\(\\varepsilon&gt;0\\) es muy, muy pequeño, el área bajo \\(y=f_X(x)\\) entre \\(a-\\varepsilon\\) y \\(a+\\varepsilon\\) es aproximadamente igual a la del rectángulo de base el intervalo \\([a-\\varepsilon,a+\\varepsilon]\\) y altura \\(f_X(a)\\), que vale \\(2\\varepsilon\\cdot f_X(a)\\) (ved la Figura 11.1). Es decir, \\[ P(a-\\varepsilon\\leqslant X\\leqslant a+\\varepsilon)\\approx 2\\varepsilon\\cdot f_X(a). \\] Figura 11.1: El área bajo la curva alrededor de \\(a\\) es aproximadamente igual a la del rectángulo de altura \\(f_X(a)\\) Por lo tanto \\(f_X(a)\\) nos da una indicación de la probabilidad de que \\(X\\) valga aproximadamente \\(a\\) (pero no es \\(P(X=a)\\), que vale 0). Es decir, por ejemplo, si \\(f_X(a)=0.1\\) y \\(f_X(b)=0.5\\), la probabilidad de que \\(X\\) tome un valor muy cercano a \\(b\\) es 5 veces mayor que la probabilidad de que tome un valor muy cercano a \\(a\\). Pero \\(P(X=a)=P(X=b)=0\\), así que, por favor, evitad decir que “la probabilidad de que \\(X\\) valga \\(b\\) es 5 veces mayor que la probabilidad de que valga \\(a\\)”. Sí, ya sabemos que \\(5\\cdot 0=0\\), pero la frase es engañosa. Unas consideraciones finales: Lo hemos dicho en la definición, y lo hemos usado implícitamente en toda la sección, pero lo volvemos a repetir: \\(f_X(x)\\geqslant 0\\) para todo \\(x\\in \\mathbb{R}\\). \\(f_X(x)\\) no es una probabilidad, y por lo tanto puede ser mayor que 1. Por ejemplo, el gráfico siguiente muestra la densidad de una variable normal \\(N(0,0.01)\\) (véase la Sección 11.3), que llega a valer casi 40. Pero el área bajo toda la curva densidad es 1: a partir de \\(\\pm 0.06\\) la densidad vale prácticamente 0. La función de densidad \\(f_X\\) no tiene por qué ser continua, aunque la función de distribución \\(F_X\\) lo sea. Ejemplo 11.1 Sea \\(X\\) una variable aleatoria continua con función de distribución \\[ F_X(x)=P(X\\leqslant x)=\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x\\leqslant 0$}\\\\ x &amp; \\text{ si $x\\in [0,1]$}\\\\ 1 &amp; \\text{ si $x\\geqslant 1$} \\end{array}\\right. \\] Su función de densidad es \\[ f_X(x)\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt; 0$}\\\\ 1 &amp; \\text{ si $x\\in [0,1]$}\\\\ 0 &amp; \\text{ si $x&gt; 1$} \\end{array}\\right. \\] porque la integral de \\(-\\infty\\) hasta \\(a\\) de esta función es (calculadlo como áreas si os cuesta recordar cómo calcular integrales definidas) \\[ \\int_{-\\infty}^a f_X(x)\\,dx=\\left\\{ \\begin{array}{ll} \\int_{-\\infty}^a 0\\,dx =0 &amp; \\text{ si $a&lt; 0$}\\\\ \\int_{-\\infty}^0 0\\,dx+ \\int_{0}^a 1\\,dx=0 + a=a &amp; \\text{ si $a\\in [0,1]$}\\\\ \\int_{-\\infty}^0 0\\,dx+ \\int_{0}^1 1\\,dx+ \\int_{1}^a 0\\,dx=0 + 1+0=1 &amp; \\text{ si $x&gt; 1$} \\end{array}\\right. \\] Observad que \\(f_X(x)\\) es discontinua, con saltos en 0 y 1. Esta densidad representa que \\(X\\) solo puede tomar valores entre 0 y 1 y que entre estos dos valores los toma todos “con la misma probabilidad”. Diremos que \\(X\\) tiene distribución uniforme entre 0 y 1. Más en general, una variable con distribución uniforme entre \\(a\\) y \\(b\\) (con \\(a&lt;b\\)) solo puede tomar valores entre \\(a\\) y \\(b\\) y entre estos dos valores los toma todos “con la misma probabilidad”. ¿Cuál sería su densidad? ¿Cuál sería su distribución? Comprobad que el área bajo la curva de la densidad que hayáis dado es la distribución que hayáis dado. 11.2 Esperanza, varianza, cuantiles… La esperanza y la varianza de una variable aleatoria continua \\(X\\), con función de densidad \\(f_X\\), se definen como en el caso discreto, substituyendo la suma \\(\\sum_{x\\in D_x}\\) por una integral \\(\\int_{-\\infty}^{\\infty}\\). La media, o esperanza (valor medio, valor esperado…), de \\(X\\) es \\[ E(X)=\\int_{-\\infty}^{\\infty}x \\cdot f_{X}(x)\\, dx \\] Es decir, es el área comprendida entre el eje de abscisas y la curva \\(y=xf_X(x)\\). Como en el caso discreto, también la denotaremos a veces por \\(\\mu_X\\). Este valor tiene la misma interpretación que en el caso discreto: Representa el valor medio de \\(X\\) sobre el total de la población. Es (con probabilidad 1) el límite de la media aritmética de los valores de \\(X\\) sobre muestras aleatorias simples de tamaño \\(n\\), cuando \\(n\\to \\infty\\). Ejemplo 11.2 Volvamos a la variable aleatoria \\(X\\) con distribución uniforme entre 0 y 1 del Ejemplo 11.1, que toma todos los valores entre 0 y 1 con la misma probabilidad. ¿Cuál tendría que ser su valor medio? El valor medio del intervalo, 1/2, ¿no?. Veamos: como \\(f_X(x)=1\\) entre 0 y 1 y \\(f_X(x)=0\\) fuera de este intervalo, \\[ \\int_{-\\infty}^{\\infty}x \\cdot f_{X}(x)\\, dx =\\int_{0}^1 x\\,dx=\\left[\\frac{x^2}{2}\\right]^1_0=\\frac{1}{2}-0=\\frac{1}{2} \\] Nuestra intuición era correcta. Si os da pereza calcular la integral del ejemplo anterior, fijaos en que el área bajo la curva \\(y=x\\) entre 0 y 1 es la del triángulo de base (0,0)-(1,0) y altura (1,0)-(1,1), que es la mitad del cuadrado unidad y por lo tanto su área es 1/2 Si \\(g:\\mathbb{R}\\to \\mathbb{R}\\) es una función continua, la esperanza de la composición \\(\\Omega \\stackrel{X}{\\longrightarrow} \\mathbb{R}\\stackrel{g}{\\longrightarrow}\\mathbb{R}\\) es \\[ E(g(X))=\\int_{-\\infty}^{+\\infty} g(x) \\cdot f_X(x)dx \\] La varianza de \\(X\\) es \\[ \\sigma(X)^2=E((X-\\mu_X)^2) \\] y se puede demostrar que es igual a \\[ \\sigma(X)^2=E(X^2)-\\mu_X^2 \\] También se escribe \\(\\sigma_X^2\\). La desviación típica de \\(X\\) es \\[ \\sigma(X)=+\\sqrt{\\sigma(X)^2} \\] y también se escribe \\(\\sigma_X\\). Como en el caso discreto, la varianza y la desviación típica miden la variabilidad de los resultados de \\(X\\) respecto de su valor medio. Estos parámetros de \\(X\\) tienen las mismas propiedades en el caso continuo que en el discreto. Las recordamos: Si \\(b\\) es una variable aleatoria constante, \\(E(b)=b\\) y \\(\\sigma(b)^2=0\\). Si \\(\\sigma(X)^2=0\\), \\(X\\) es constante. Y por supuesto, si \\(X\\) solo puede tomar un valor, ya no es continua, sino discreta. Por lo tanto, por convenio, de ahora en adelante supondremos que nuestras variables aleatorias continuas siempre tienen varianza no nula. Si \\(X_1,\\ldots,X_n\\) son variables aleatorias y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ E(a_1X_1+\\cdots+a_nX_n+b)=a_1E(X_1)+\\cdots+a_nE(X_n)+b \\] En particular: \\(E(a X+b)=a E(X)+b\\). \\(E(X+Y)=E(X)+E(Y)\\). Si \\(X\\leqslant Y\\), entonces \\(E(X)\\leqslant E(Y)\\). Si \\(a,b\\in \\mathbb{R}\\), \\(\\sigma(aX+b)^2=a^2 \\sigma(X)^2\\) y \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\). Si \\(X,Y\\) son independientes, \\(\\sigma(X+Y)^2=\\sigma(X)^2+\\sigma(Y)^2\\). Si no, en principio no. Si \\(X_1,\\ldots,X_n\\) son variables aleatorias independientes y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ \\begin{array}{l} \\sigma(a_1X_1+\\cdots+a_nX_n+b)^2=a_1^2\\cdot\\sigma(X_1)^2+\\cdots+a_n^2\\cdot\\sigma(X_n)^2\\\\ \\sigma(a_1X_1+\\cdots+a_nX_n+b)=\\sqrt{a_1^2\\cdot\\sigma(X_1)^2+\\cdots+a_n^2\\cdot\\sigma(X_n)^2} \\end{array} \\] Si no son independientes, estas igualdades pueden ser falsas. Dado \\(p\\) entre 0 y 1, el cuantil de orden \\(p\\) (o \\(p\\)-cuantil) de una variable aleatoria continua \\(X\\) es el menor valor \\(x_p\\in \\mathbb{R}\\) tal que \\[ F_X(x_p)=P(X\\leqslant x_p)=p \\] Fijaos en que como \\(F_X(x)\\) tiende a 0 (la probabilidad del conjunto vacío) cuando \\(x\\to -\\infty\\) y tiende a 1 (la probabilidad de todo \\(\\Omega\\)) cuando \\(x\\to +\\infty\\) y es continua, por el Teorema del Valor Medio de las funciones continuas (que dice, básicamente, que las funciones continuas no dan saltos) toma todos los valores entre 0 y 1 y por lo tanto dado cualquier \\(p\\) entre 0 y 1 existe algún \\(x\\) tal que \\(F_X(x)=p\\). La mediana de \\(X\\) es su 0.5-cuantil, los primer y tercer cuartiles son su 0.25-cuantil y su 0.75-cuantil, etc. Los coeficientes de asimetría y de curtosis se definen de manera similar a los de una muestra: \\[ \\begin{array}{l} \\displaystyle \\gamma_1=E\\Big(\\Big(\\frac{X-\\mu_X}{\\sigma}\\Big)^3\\Big)\\\\ \\displaystyle \\beta_2=E\\Big(\\Big(\\frac{X-\\mu_X}{\\sigma}\\Big)^4\\Big)-3 \\end{array} \\] Miden para la densidad de la variable lo que medían los de la muestra: el coeficiente de asimetría, si es simétrica o si tiene cola a algún lado; el coeficiente de curtosis, si sus colas son más largas o más cortas que las de una campana de Gauss. 11.3 Variables aleatorias normales Una variable aleatoria continua \\(X\\) es normal (o tiene distribución normal) de parámetros \\(\\mu\\) y \\(\\sigma\\) (es \\(N(\\mu,\\sigma)\\), para abreviar) cuando su función de densidad es \\[ f_{X}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{{-(x-\\mu)^2}/{2\\sigma^{2}}} \\mbox{ para todo } x\\in \\mathbb{R} \\] Naturalmente, no os tenéis que saber esta fórmula. Pero sí que tenéis que saber que: Una variable aleatoria normal \\(X\\) es continua, y por lo tanto \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc. Si \\(X\\) es normal \\(N(\\mu,\\sigma)\\), su valor esperado es \\(E(X)=\\mu\\) y su desviación típica es \\(\\sigma_X=\\sigma\\). Si \\(X\\) es normal, su función de distribución \\(F_X\\) es inyectiva y creciente: si \\(x&lt;y\\), \\(F_X(x)&lt;F_X(y)\\). Una variable aleatoria normal es típica (o estándar) cuando es \\(N(0,1)\\). Usaremos normalmente \\(Z\\) para denotar una variable normal estándar. Por lo tanto, si \\(Z\\) es una normal estándar, \\(E(Z)=0\\) y \\(\\sigma(Z)=1\\). La gráfica de la densidad de una variable aleatoria normal es la famosa campana de Gauss de la que ya hemos hablado varias veces: La distribución normal es una distribución teórica, no la encontraréis exacta en la vida real. Y pese a su nombre, no es más “normal” que otras distribuciones continuas. Pero es muy importante, debido a que muchas distribuciones de la vida real son aproximadamente normales porque: Toda variable aleatoria que consista en tomar \\(n\\) medidas independientes de una o varias variables aleatorias y sumarlas, tiene distribución aproximadamente normal cuando \\(n\\) es muy grande, aunque las variables aleatorias de partida no sean normales. Ejemplo 11.3 Una variable binomial \\(B(n,p)\\) se obtiene tomando \\(n\\) medidas independientes de una variable Bernoulli \\(Be(p)\\) y sumando los resultados. Por lo tanto, por la “regla” anterior, una \\(B(n,p)\\) tendría que ser aproximadamente normal si \\(n\\) es grande. Pues sí, si \\(n\\) es grande (pongamos mayor que 40, aunque si \\(p\\) está muy cerca de 0 o 1 el tamaño de las muestras tiene que ser mayor), la distribución de una variable \\(X\\) binomial \\(B(n,p)\\) se acerca mucho a la de una normal \\(N(np,\\sqrt{np(1-p)})\\), donde, recordad que si \\(X\\) es \\(B(n,p)\\), entonces \\(\\mu_X=np\\) y \\(\\sigma_X=\\sqrt{np(1-p)}\\). Por ejemplo, el gráfico siguiente compara las funciones de distribución de una binomial \\(B(40,0.3)\\) y una normal \\(N(40\\cdot 0.3,\\sqrt{40\\cdot 0.3\\cdot 0.7})\\). En los próximos temas utilizaremos a menudo que una variable \\(B(n,p)\\) con \\(n\\) es grande es aproximadamente \\(N(np,\\sqrt{np(1-p)})\\). Para calcular probabilidades de una \\(N(\\mu,\\sigma)\\), hay que calcular las integrales a mano. O podéis usar JAMOVI, R o alguna aplicación para móvil o tablet. Para R, la normal es norm. Así, por ejemplo, si \\(X\\) es \\(N(1,2)\\) \\(P(X\\leqslant 1.5)\\) es pnorm(1.5,1,2) ## [1] 0.5987063 El 0.4-cuantil de \\(X\\), es decir, el valor \\(q\\) tal que \\(P(X\\leqslant q)=0.4\\) es qnorm(0.4,1,2) ## [1] 0.4933058 \\(P(X=1.5)\\) es dnorm(1.5,1,2) ## [1] 0.1933341 ¡No! Como \\(X\\) es continua, \\(P(X=1.5)=0\\). Lo que os da dnorm(1.5,1,2) es el valor de la función de densidad de \\(X\\) en 1.5. Ejemplo 11.4 La presión sistólica, medida en mm Hg, es una variable aleatoria aproximadamente normal con valor medio \\(\\mu\\) y desviación típica \\(\\sigma\\) que dependen del sexo y la edad. Para la franja de edad 16-24 años, estos valores son: Para hombres, \\(\\mu=124\\) y \\(\\sigma=13.7\\) Para mujeres, \\(\\mu=117\\) y \\(\\sigma=13.7\\) El modelo de hipertensión-hipotensión aceptado es el descrito en la Figura 11.2. Queremos calcular los límites de cada clase para cada sexo en este grupo de edad. Figura 11.2: Modelo de hipertensión-hipotensión. Veamos: El límite superior del grupo de hipotensión será el valor que deja a la izquierda un 5% de las tensiones: el 0.05-cuantil de la distribución. El límite superior del grupo de riesgo de hipotensión será el valor que deja a la izquierda un 10% de las tensiones: el 0.1-cuantil de la distribución. El límite inferior del grupo de riesgo de hipertensión será el valor que deja a la izquierda un 90% de las tensiones: el 0.9-cuantil de la distribución. El límite inferior del grupo de hipertensión será el valor que deja a la izquierda un 95% de las tensiones: el 0.95-cuantil de la distribución. En los hombres, la tensión sistólica es una variable aleatoria \\(N(124,13.7)\\). Si calculamos estos cuantiles, dan: El 0.05-cuantil es 101.5 El 0.1-cuantil es 106.4 El 0.9-cuantil es 141.6 El 0.95-cuantil es 146.5 En resumen, para los hombres de 16 a 24 años: \\[ \\begin{array}{|ll|} \\hline \\text{Grupo} &amp; \\text{Intervalo}\\\\ \\hline \\text{Hipotenso} &amp; &lt;101.5\\\\ \\text{Prehipotenso} &amp; 101.5\\text{ a }106.4\\\\ \\text{Normotenso} &amp; 106.4\\text{ a }141.6\\\\ \\text{Prehipertenso} &amp; 141.6\\text{ a }146.5\\\\ \\text{Hipertenso} &amp; &gt; 146.5\\\\ \\hline \\end{array} \\] Calculad estos límites para las mujeres de 16 a 24 años. 11.3.1 Propiedades básicas Una de las propiedades clave de la distribución normal es la simetría de la campana de Gauss: Si \\(X\\) es \\(N(\\mu,\\sigma)\\), su densidad \\(f_X\\) es simétrica respecto de \\(\\mu\\), es decir, \\[ f_{X}(\\mu-x)=f_{X}(\\mu+x), \\] y tiene el máximo en \\(x=\\mu\\). Decimos entonces que \\(\\mu\\) es la moda de \\(X\\). Recordad que no tiene sentido definir la moda de una variable continua \\(X\\) como el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sea máximo, porque \\(P(X=x)=0\\) para todo \\(x\\in \\mathbb{R}\\). Se define entonces la moda de una variable continua \\(X\\) como el valor (o los valores) \\(x_0\\) tal que \\(f_X(x_0)\\) es máximo. Así, como \\(f_X(x_0)\\) mide la probabilidad de que \\(X\\) valga aproximadamente \\(x_0\\), la moda de \\(X\\) es el valor cerca del cual es más probable que caiga el valor de \\(X\\). En particular, si \\(Z\\) es \\(N(0,1)\\), entonces \\(f_Z\\) es simétrica alrededor de 0, es decir, \\(f_{Z}(-x)=f_{Z}(x)\\), y la moda de \\(Z\\) es \\(x=0\\). Recordad que la función de distribución de una variable aleatoria continua \\(X\\), \\[ F_X(x)=P(X\\leqslant x) \\] es el área comprendida entre la densidad \\(y=f_X(x)\\) y el eje de abscisas a la izquierda de \\(x\\). Entonces, la simetría de \\(f_X\\) alrededor de \\(\\mu\\) hace que, para todo \\(x\\geqslant 0\\), las áreas a la izquierda de \\(\\mu-x\\) y a la derecha de \\(\\mu+x\\) sean iguales. Es decir, \\[ P(X\\leqslant \\mu-x)=P(X\\geqslant \\mu+x)=1-P(X\\leqslant \\mu+x) \\] En particular (tomando \\(x=0\\)) \\[ P(X\\leqslant \\mu)=1-P(X\\leqslant \\mu)\\Rightarrow P(X\\leqslant \\mu)=0.5 \\] y por lo tanto, \\(\\mu\\) es también la mediana de \\(X\\). Si \\(X\\) es \\(N(\\mu,\\sigma)\\), \\(\\mu\\) es la media, la mediana y la moda de \\(X\\). En el caso concreto de la normal estándar \\(Z\\), para cualquier \\(z\\geqslant 0\\) se tiene que las áreas a la izquierda de \\(-z\\) y a la derecha de \\(z\\) son iguales \\[ P(Z\\leqslant -z)=P(Z\\geqslant z)=1-P(Z\\leqslant z) \\] y la mediana de \\(Z\\) es 0. Ahora que sabemos más cosas de la normal, en el Ejemplo 11.4 nos hubiéramos podido ahorrar la mitad del trabajo. Llamemos \\(X\\) a la variable aleatoria que nos da la presión arterial, en mm Hg, de un hombre de entre 16 y 24 años. Nos dicen que \\(X\\) es \\(N(124,13.7)\\). Por la simetría de \\(X\\) alrededor de \\(\\mu=124\\), si escribimos el 0.05-cuantil como \\(124-x\\), entonces \\(P(X\\geqslant 124+x)=P(X\\leqslant 124-x)=0.05\\) y por lo tanto \\(P(X\\leqslant 124+x)=1-P(X\\geqslant 124+x)=0.95\\), es decir, \\(124+x\\) será el 0.95-cuantil de \\(X\\). El 0.05-cuantil ha sido 101.5. Escribiendo \\(101.5=124-x\\), obtenemos \\(x=22.5\\). Por lo tanto, el 0.95-cuantil tiene que ser \\(124+22.5=146.5\\). Lo mismo pasa con el 0.9-cuantil y el 0.1-cuantil, razonadlo y comprobadlo. El argumento que hemos desarrollado en la nota anterior muestra en general que si \\(X\\) es \\(N(\\mu,\\sigma)\\) y su \\(q\\)-cuantil es \\(\\mu-x\\), entonces su \\((1-q)\\)-cuantil es \\(\\mu+x\\). Figura 11.3: Quantils gratis! Si \\(\\mu\\) crece, desplaza a la derecha el máximo de la densidad, y con él toda la curva. Si \\(\\sigma\\) crece, la curva se aplana: al aumentar la desviación típica, los valores se dispersan y se alejan más del valor medio. El gráfico siguiente muestra el efecto combinado: Denotaremos por \\(z_q\\) el \\(q\\)-cuantil de una variable normal estándar \\(Z\\). Es decir, \\(z_q\\) es el valor tal que \\(P(Z\\leqslant z_q)=q\\). Aparte de que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) es 0), hay dos cuantiles más de la normal estándar \\(Z\\) que os conviene recordar: \\(z_{0.95}=1.64\\); es decir, \\(P(Z\\leqslant 1.64)=0.95\\) y por lo tanto \\(P(Z\\leqslant -1.64)=P(Z\\geqslant 1.64)=0.05\\) y \\[ P(-1.64\\leqslant Z\\leqslant 1.64)=0.9. \\] \\(z_{0.975}=1.96\\); es decir, \\(P(Z\\leqslant 1.96)=0.975\\) y por lo tanto \\(P(Z\\leqslant -1.96)=P(Z\\geqslant 1.96)=0.025\\) y \\[ P(-1.96\\leqslant Z\\leqslant 1.96)=0.95. \\] Muy a menudo el valor 1.96 de \\(z_{0.975}\\) se aproxima por 2. Tenéis permiso para hacerlo cuando no dispongáis de medios (R, aplis de móvil) para calcular cuantiles o cuando tengáis que hacer algún cálculo “a ojo” que involucre este cuantil. Ejemplo 11.5 Supongamos que la concentración de un cierto metabolito es una variable aleatoria de distribución normal, pero cuyos parámetros \\(\\mu\\) y \\(\\sigma\\) dependen de si la medimos en personas sanas o en personas con una cierta enfermedad. Sean: \\(X_E\\) la variable aleatoria “Tomo una persona enferma y mido su concentración de este metabolito”, y supongamos que es \\(N(\\mu_E, \\sigma_E)\\). \\(X_S\\) la variable aleatoria “Tomo una persona sana y mido su concentración de este metabolito”, y supongamos que es \\(N(\\mu_S, \\sigma_S)\\). Supongamos, para fijar ideas, que \\(\\mu_E&gt;\\mu_S\\): la concentración media de este metabolito en los enfermos es más alta que en las personas sanas. Podríamos usar como prueba diagnóstica de la enfermedad la concentración del metabolito. Para cada valor de referencia \\(x_0\\), nuestra prueba dará: Positivo, si la concentración es mayor o igual que \\(x_0\\). Negativo, si la concentración es menor que \\(x_0\\). Entonces: La sensibilidad de esta prueba es \\[ P(+|E) =P(X_E\\geqslant x_0)=1-P(X_E&lt; x_0)=1-F_{X_E}(x_0) \\] Su especificidad es \\[ P(-|S)=P(X_S&lt; x_0)=F_{X_S}(x_0) \\] Su tasa de falsos positivos es \\[ P(+|S)=P(X_S\\geqslant x_0)=1-F_{X_S}(x_0) \\] Al variar \\(x_0\\), tenemos valores diferentes de la sensibilidad y la tasa de falsos positivos. Entonces, podemos dibujar su curva ROC y escoger el umbral con algún criterio o valorar su capacidad diagnóstica global con su AUC. Por ejemplo, imaginad que la densidad de \\(X_E\\) es la línea discontinua del gráfico de la izquierda de la figura siguiente y la de \\(X_S\\) la línea continua. Ambas son normales y \\(\\mu_E&gt;\\mu_S\\), porque el pico de la densidad de \\(X_E\\) está a la derecha del de \\(X_S\\). Si para cada \\(x\\) dibujamos los puntos \\((1-F_{X_S}(x),1-F_{X_E}(x))\\), obtenemos la curva ROC de la derecha de dicha figura. Del gráfico de las densidades de \\(X_E\\) i \\(X_S\\), ¿podéis deducir cuál tiene mayor desviación típica? Tenemos también el resultado siguiente: Teorema 11.2 Las variables normales tienen coeficientes de asimetría y de curtosis 0. Una de las propiedades de la distribución normal que nos facilitan mucho la vida es que toda combinación lineal de variables aleatorias normales independientes es normal. En concreto, tenemos los resultados siguientes: Teorema 11.3 Sea \\(X\\) una variable \\(N(\\mu,\\sigma)\\). Para todos \\(a,b\\in \\mathbb{R}\\), \\(aX+b\\) es \\(N(a\\mu+b,|a|\\cdot\\sigma)\\). En particular, la tipificada de \\(X\\) \\[ Z=\\dfrac{X-\\mu}{\\sigma} \\] es \\(N(0,1)\\). Más en general: Teorema 11.4 Si \\(X_1,\\ldots,X_n\\) son variables aleatorias normales independientes, cada \\(X_i\\) de tipo \\(N(\\mu_i,\\sigma_i)\\), y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), entonces \\(a_1X_1+\\cdots +a_nX_n+b\\) es \\(N(\\mu,\\sigma)\\) con \\[ \\mu=a_1\\mu_1+\\cdots +a_n\\mu_n+b,\\ \\sigma=\\sqrt{a_1^2\\sigma^2_1+\\cdots +a_n^2\\sigma^2_n} \\] Que toda combinación lineal de variables normales vuelva a ser del mismo tipo, es decir, normal, es una propiedad muy útil de las variables normales que pocas familias de distribuciones comparten. Por ejemplo, si \\(X\\) es una variable binomial \\(B(n,p)\\) con \\(p\\neq 0\\), la variable \\(2X\\) no es binomial, porque solo toma valores pares, mientras que una variable binomial \\(B(m,q)\\) ha de poder tomar todos los valores entre 0 y \\(m\\). Las probabilidades de la normal tipificada determinan las de la normal original, porque si \\(X\\) es \\(N(\\mu,\\sigma)\\): \\[ \\begin{array}{rl} P(a\\leqslant X\\leqslant b)\\!\\!\\!\\!\\! &amp; \\displaystyle =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{b-\\mu}{\\sigma}\\Big)\\\\ &amp; \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant \\frac{b-\\mu}{\\sigma}\\Big) \\end{array} \\] Esto sirve para deducir fórmulas, y vuestros padres lo usaban para calcular probabilidades (con tablas de probabilidades de la normal estándar); ahora es más cómodo usar una aplicación del móvil. 11.3.2 Intervalos de referencia Un intervalo de referencia del \\(Q\\%\\) para una variable aleatoria \\(X\\) es un intervalo \\([a,b]\\) tal que \\[ P(a\\leqslant X\\leqslant b)=Q\\%(=Q/100). \\] Es decir, un intervalo de referencia del \\(Q\\%\\) para \\(X\\) es un intervalo que contiene los valores de \\(X\\) del \\(Q\\%\\) de los sujetos de la población. Por ejemplo, hemos visto en la sección anterior que [-1.64,1.64] y [-1.96,1.96] son intervalos de referencia del 90% y del 95%, respectivamente, para una variable normal estándar \\(Z\\). Y en el Ejemplo 11.4 hemos visto que un intervalo de referencia del 90% para la presión sistólica de los hombres de 16 a 24 años, medida en mm Hg, es [101.5,146.5]. Los más comunes son los intervalos de referencia del 95%, que satisfacen que \\[ P(a\\leqslant X\\leqslant b)=0.95 \\] y son los, que por ejemplo, os dan como valores de referencia en las analíticas: Cuando se habla de un intervalo de referencia sin dar la probabilidad, se sobreentiende siempre que es el intervalo de referencia del 95%. Un 5% de la población está fuera del intervalo de referencia del 95%, por definición. Cuando \\(X\\) es \\(N(\\mu,\\sigma)\\), estos intervalos de referencia se toman siempre centrados en la media \\(\\mu\\), es decir, de la forma \\([\\mu-\\text{algo},\\mu+\\text{algo}]\\). Para calcularlos se usa el resultado siguiente: Teorema 11.5 Si \\(X\\) es \\(N(\\mu,\\sigma)\\), un intervalo de referencia del \\(Q\\%\\) para \\(X\\) es \\[ [\\mu- z_{(1+q)/2}\\cdot \\sigma, \\mu+ z_{(1+q)/2}\\cdot \\sigma] \\] donde \\(q=Q/100\\) y \\(z_{(1+q)/2}\\) denota el \\((1+q)/2\\)-cuantil de la normal estándar \\(Z\\). Se suele escribir \\[ \\mu\\pm z_{(1+q)/2}\\cdot \\sigma. \\] En efecto: \\[ \\begin{array}{l} P(\\mu-x\\leqslant X\\leqslant \\mu+x)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant {x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-P(Z\\leqslant -{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-P(Z\\geqslant {x}/{\\sigma})=q\\\\ \\qquad \\text{(por la simetría de $f_Z$ alrededor de 0)}\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-(1-P(Z\\leqslant {x}/{\\sigma}))=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant {x}/{\\sigma})=q+1\\\\ \\qquad \\Longleftrightarrow P(Z\\leqslant {x}/{\\sigma})=(1+q)/2\\\\ \\qquad \\Longleftrightarrow x/\\sigma= z_{(1+q)/2}\\\\ \\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma \\end{array} \\] Si \\(q=0.95\\), entonces \\((1+q)/2=0.975\\) y \\(z_{0.975}=1.96\\). Por lo tanto, el intervalo de referencia del 95% para una variable \\(X\\) normal \\(N(\\mu,\\sigma)\\) es \\[ \\mu\\pm 1.96\\sigma. \\] Y como este 1.96 a menudo se aproxima por 2, el intervalo de referencia del 95% se simplifica a \\[ \\mu\\pm 2\\sigma. \\] Esto dice, básicamente, que si una población sigue una distribución normal \\(N(\\mu,\\sigma)\\), alrededor del 95% de sus individuos tienen su valor de \\(X\\) a distancia como máximo \\(2\\sigma\\) (“a dos sigmas”) de \\(\\mu\\). El 5% restante de distribuye a partes iguales a ambos lados del intervalo: un 2.5% por encima de su extremo superior y un 2.5% por debajo de su extremo inferior. Ejemplo 11.6 Según la OMS, las alturas (en cm) de las mujeres europeas de 18 años siguen una ley \\(N(163.1,18.53)\\). ¿Cuál es el intervalo de alturas centrado en la media que contiene a la mitad las europeas de 18 años? Fijaos en que, si llamamos \\(X\\) a la variable aleatoria “Tomo una mujer europea de 18 años y mido su altura en cm”, lo que queremos saber es el intervalo centrado en su media tal que la probabilidad de que la altura de una europea de 18 años escogida al azar pertenezca a este intervalo sea 0.5. Es decir, el intervalo de referencia del 50% para \\(X\\). Nos dicen que \\(X\\) es \\(N(163.1,18.53)\\). Si \\(q=0.5\\), entonces \\((1+q)/2=0.75\\) y si calculamos el 0.75-cuantil de una normal estándar, da \\(z_{0.75}=0.6745\\). Por lo tanto, es el intervalo \\(163.1\\pm 0.6745\\cdot 18.53\\). Redondeando a mm, \\([150.6, 175.6]\\). Esto nos dice que la mitad de las mujeres europeas de 18 años miden entre 150.6 y 175.6 cm. De la otra mitad, la mitad (es decir un cuarto del total) miden menos de 150.6 cm y la otra más de 175.6 cm. El z-score (z-valor, z-puntuación, z-puntaje…) de un valor \\(x_0\\in \\mathbb{R}\\) respecto de una distribución \\(N(\\mu,\\sigma)\\) es \\[ \\frac{x_0-\\mu}{\\sigma} \\] Es decir, el z-score de \\(x_0\\) es el resultado de “tipificar” \\(x_0\\) en el sentido del Teorema 11.3. Si la variable poblacional es normal, cuanto mayor es el valor absoluto del z-score de \\(x_0\\), más “raro” es \\(x_0\\); el signo nos dice si es más grande o más pequeño que el valor esperado \\(\\mu\\). Ejemplo 11.7 Recordad que, según la OMS, las alturas de las mujeres europeas de 18 años siguen una ley \\(N(163.1,18.53)\\). ¿Cuál sería el z-score de una jugadora de baloncesto de 18 años que midiera 191 cm? Sería \\[ \\frac{191-163.1}{18.53}=1.5 \\] Esto se suele leer diciendo que la altura de esta jugadora está 1.5 sigmas por encima de la media (donde, recordad, “sigma” es una abreviatura de “desviación típica poblacional”). 11.4 Test (1) Sea \\(X\\) una variable aleatoria continua de función de densidad: \\[ f_X(x)=\\left\\{\\begin{array}{ll} 0 &amp; \\mbox{si $x&lt;0$}\\\\ \\frac{2\\sqrt{2}}{\\sqrt{\\pi}} e^{-2x^2} &amp; \\mbox{si $x\\geqslant 0$} \\end{array} \\right. \\] ¿Es cierto que \\(P(X=1)=2\\sqrt{2}e^{-2}/\\sqrt{\\pi}\\)? Sí No: en realidad \\(P(X=1)=\\int_{-\\infty}^1 \\frac{2\\sqrt{2}}{\\sqrt{\\pi}} e^{-2x^2}\\,dx\\) pero no sé calcular esta integral, o sí sé calcularla, pero me da pereza hacerlo. Esto no es la función de densidad de una variable aleatoria continua, porque no es una función continua (en el 0 salta de 0 a \\(2\\sqrt{2}/\\sqrt{\\pi}\\)) Todas las otras respuestas son incorrectas (2) \\(X\\) una variable aleatoria continua de media \\(\\mu\\). ¿Qué vale \\(P(X=\\mu)\\)? 0.5 \\(\\mu\\) 0 Depende de la variable aleatoria Todas las otras respuestas son falsas (3) \\(X\\) una variable aleatoria continua de moda \\(M\\). ¿Qué vale \\(P(X=M)\\)? 1 0.5 0 Depende de la variable aleatoria, pero es estrictamente mayor que cualquier otro valor de \\(P(X=x)\\) Depende de la variable aleatoria, pero es el valor máximo de la función de densidad de \\(X\\). Todas las otras respuestas son falsas (4) En una variable aleatoria continua, su función de densidad (marca una única respuesta): Es tal que su integral desde \\(-\\infty\\) es la función de distribución. Mide lo denso que es su dominio. Aplicada a un par de números reales, nos da la probabilidad de obtener valores dentro del intervalo definido por dichos números. Aplicada a un número real, nos da da la probabilidad de obtener dicho número. Aplicada a un número real, nos da la probabilidad de obtener un valor menor o igual que dicho número. (5) Sea \\(Z\\) una variable aleatoria normal estándar. Marca las afirmaciones verdaderas. Es asimétrica a la izquierda. Su media es 1. Su desviación típica es 0. Su varianza es 1. Su mediana es 0. (6) Sea \\(X\\) una variable aleatoria \\(N(\\mu,\\sigma)\\) y \\(f_X\\) su función de densidad. ¿Qué vale el área entre la curva \\(y=f_X(x)\\) y el eje de abscisas? 0 \\(\\mu\\) \\(\\sigma\\) 1 Todas las otras respuestas son falsas (7) Sea \\(X\\) una variable aleatoria \\(N(\\mu,\\sigma)\\) y \\(f_X\\) su función de densidad. ¿Cuál de las afirmaciones siguientes es correcta? \\(\\mu\\) es la media de \\(X\\), pero no su mediana \\(\\mu\\) es la media y la mediana de \\(X\\), pero no su moda \\(\\mu\\) es la media, la mediana y la moda de \\(X\\), pero no es verdad que \\(P(X=\\mu)&gt;P(X=a)\\) para todo \\(a\\neq \\mu\\) \\(\\mu\\) es la media, la mediana y la moda de \\(X\\) y \\(P(X=\\mu)&gt;P(X=a)\\) para todo \\(a\\neq \\mu\\) (8) ¿Qué distribución es la más adecuada para modelar el número anual de fallecimientos entre enfermos de cáncer tratados con una determinada quimioterapia si estas se producen al azar? Marca una única respuesta. Normal Binomial Poisson Uniforme acotada (todos los números de fallecimientos entre 0 y el número \\(N\\) de enfermos de cáncer tratados con esta quimioterapia tienen la misma probabilidad) (9) El FME (Flujo Máximo de Espiración) de las chicas de 11 años sigue una distribución aproximadamente normal de media 300 l/min y desviación típica 20 l/min. Marca las afirmaciones verdaderas: Aproximadamente la mitad de las chicas de 11 años tienen un FME entre 280 l/min y 320 l/min. Alrededor del 95% de las chicas de 11 años tienen un FME entre 280 l/min y 320 l/min. Alrededor del 95% de las chicas de 11 años tienen un FME entre 260 l/min y 340 l/min. Alrededor del 5% de las chicas de 11 años tienen un FME inferior a 260 l/min. Ninguna chica de 11 años tiene FME superior a 360 l/min. (10) En una muestra aleatoria extraída de población sana se encuentra que una variable bioquímica tiene media 90 y desviación típica 10. Si tomamos una muestra de individuos sanos ¿es razonable esperar que aproximadamente el 95% de ellos tengan un valor de esa variable comprendido entre 70 y 110? (marca todas las respuestas correctas): Sí, siempre. No, nunca. Si la variable tiene distribución normal, entonces sí. Si la muestra es muy grande, entonces sí. Si la variable tiene distribución normal y la muestra es muy grande, entonces sí. (11) En un estudio clínico, se midió el nivel de glucosa en sangre en un grupo muy grande de personas de una determinada población y a partir del mismo se estimó el intervalo de referencia del 95% para este nivel de glucosa en esta población. ¿Cuál es la interpretación correcta de este intervalo? Es un intervalo que contiene el 95% de los valores medios del nivel de glucosa en muestras de sujetos de esta población del mismo tamaño que la usada Es un intervalo que tiene una probabilidad del 95% de contener el nivel de glucosa en sangre del 95% de esta población Es un intervalo que contiene el nivel de glucosa en sangre del 95% de las personas de esta población Es un intervalo que, para cada persona de esta población, contiene su nivel de glucosa en sangre en el 95% de las ocasiones que se lo medimos Ninguna de las otras respuestas es correcta (12) El 0.975-cuantil de la altura de las niñas recién nacidas es 0.53 metros. ¿Qué significa esto? Que un 97.5% de las niñas recién nacidas miden exactamente 0.53 metros Que un 97.5% de las niñas recién nacidas miden alrededor de 0.53 metros Que un 97.5% de las niñas recién nacidas miden 0.53 metros o menos Que un 97.5% de las niñas recién nacidas miden 0.53 metros o más Ninguna de las otras respuestas es correcta "],["estimadores.html", "Lección 12 Estimadores 12.1 La media muestral 12.2 La proporción muestral 12.3 La varianza muestral 12.4 La distribución t de Student 12.5 Test", " Lección 12 Estimadores En un problema típico de estadística inferencial: Queremos conocer el valor de una característica en el total de una población, pero no podemos medir esta característica en todos los individuos de la población. Entonces, extraemos una muestra de la población, medimos la característica en los individuos de esta muestra, calculamos algo con los datos obtenidos e inferimos el valor de la característica en el global de la población. Inmediatamente surgen varias preguntas, que responderemos entre esta lección y la próxima: ¿Cómo tiene que ser la muestra? ¿Qué tenemos que calcular? ¿Con qué precisión podemos inferir la característica de la población? ¿Qué tipo de muestra tenemos que tomar? Vamos a suponer de ahora en adelante que tomamos muestras aleatorias simples. Esto incluye las muestras aleatorias sin reposición si la población es mucho más grande que la muestra, ya que entonces no hay diferencia práctica entre permitir y prohibir las repeticiones. En algunos casos muy concretos permitiremos muestras aleatorias sin reposición en general. Sí, ya sabemos que en la práctica casi nunca tomamos muestras aleatorias, sino oportunistas. En este caso, recordad lo que os explicábamos en la Sección 3.3.5. Lo que hay que hacer es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, es razonablemente representativa de la población y podría pasar por aleatoria. ¿Qué calculamos? Pues un estimador: alguna función adecuada aplicada a los valores de la muestra, y que dependerá de lo que queramos estimar. Por ejemplo: Si queremos estimar la altura media de los estudiantes de la UIB, tomaremos una muestra aleatoria de estudiantes de la UIB, mediremos sus alturas y calcularemos su media aritmética. Si queremos estimar la proporción de estudiantes de la UIB que usan lentillas, tomaremos una muestra aleatoria de estudiantes de la UIB y calcularemos la proporción en esta muestra de los que las usan. Si queremos estimar el riesgo relativo para un estudiante de la UIB de suspender alguna asignatura si es fumador, tomaremos una muestra aleatoria de estudiantes de la UIB, anotaremos si fuman o no y si han suspendido alguna asignatura o no, y calcularemos el cociente entre las proporciones muestrales de suspensos entre los fumadores y los no fumadores de la muestra. Un estimador es una variable aleatoria, definida sobre la población formada por las muestras de la población de partida. Por lo tanto, tiene función de densidad, función de distribución, esperanza, desviación típica, etc. 12.1 La media muestral Cuando queremos estimar el valor medio de una variable sobre una población, tomamos una muestra de valores y calculamos su media aritmética, ¿verdad? Pues eso es la media muestral. Dada una variable aleatoria \\(X\\), llamamos media muestral de (muestras de) tamaño \\(n\\) a la variable aleatoria \\(\\overline{X}\\) “Tomamos una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calculamos la media aritmética de sus valores”. Fijaos en que definimos la media muestral solo para muestras aleatorias simples. Naturalmente, tiene sentido definirla para otros tipos de muestras, pero entonces su distribución de probabilidad no cumple las propiedades que damos en esta sección. La misma advertencia vale para los estimadores que definimos en las próximas secciones. Veamos algunas propiedades de la distribución de \\(\\overline{X}\\): Teorema 12.1 Sea \\(X\\) una variable aleatoria cualquiera de media \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\), y sea \\(\\overline{X}\\) la media muestral de tamaño \\(n\\) de \\(X\\). Entonces: \\(E(\\overline{X})=\\mu_X\\) \\(\\sigma(\\overline{X})=\\dfrac{\\sigma_X}{\\sqrt{n}}\\) Formalmente, la media muestral de tamaño \\(n\\) de una variable aleatoria \\(X\\) se define como la variable aleatoria \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] donde \\(X_1,\\ldots,X_n\\) son \\(n\\) copias independientes de la variable \\(X\\). Entonces, por la linealidad de la esperanza \\[ E(\\overline{X})=\\frac{E(X_1)+\\cdots+E(X_n)}{n}=\\frac{n\\cdot \\mu_X}{n}=\\mu_X \\] porque, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(E(X_1)=\\cdots=E(X_n)=\\mu_X\\). Y por la “linealidad” de la varianza de la suma de variables independientes \\[ \\sigma(\\overline{X})^2=\\frac{\\sigma(X_1)^2+\\cdots+\\sigma(X_n)^2}{n^2}=\\frac{n\\cdot \\sigma_X^2}{n^2}=\\frac{\\sigma_X^2}{n} \\] porque, de nuevo, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(\\sigma(X_1)^2=\\cdots=\\sigma(X_n)^2=\\sigma_X^2\\). Que \\(E(\\overline{X})\\) sea \\(\\mu_X\\) nos indica que \\(\\overline{X}\\) sirve para estimar \\(\\mu_X\\), porque su valor esperado es \\(\\mu_X\\): Si calculáramos muchas medias de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a \\(\\mu_X\\). Cuando el valor esperado de un estimador es precisamente el parámetro poblacional que se quiere estimar, se dice que el estimador es insesgado. Así, el primer punto del teorema anterior dice que la media muestral \\(\\overline{X}\\) es un estimador insesgado de la media poblacional \\(\\mu_X\\). Que \\(\\sigma(\\overline{X})\\) sea \\(\\sigma_X/\\sqrt{n}\\) implica que la variabilidad de las medias muestrales crece con la variabilidad de \\(X\\) y decrece si tomamos muestras de mayor tamaño. Esto último es razonable. Aunque la variabilidad de \\(X\\) sea grande, si tomamos muestras grandes, es de esperar que los valores extremos se compensen al calcular sus medias y que estas últimas tengan por lo tanto menos variabilidad que la variable \\(X\\) original. A \\(\\sigma_X/\\sqrt{n}\\) se le llama el error típico de la media muestral (para la variable aleatoria \\(X\\) y muestras de tamaño \\(n\\)). Ejemplo 12.1 Vamos a realizar un experimento. Vamos a tomar una población de 106 sujetos y una variable aleatoria uniforme \\(X\\) que sobre cada sujeto toma un valor real entre 0 y 1, todos estos valores con la misma probabilidad. Llamaremos X al vector con los 106 valores de esta variable aleatoria, y dibujaremos un histograma de este vector de números para que veáis que los valores salen muy dispersos. Mostramos el código de R para que podáis repetir el experimento por vuestra cuenta; como es una simulación, cada vez que lo ejecutéis dará resultados diferentes, pero el mismo efecto global. X=runif(10^6) hist(X,freq=FALSE,main=&quot;Histograma de X&quot;,xlab=&quot;&quot;,ylab=&quot;Densidad&quot;,col=&quot;light blue&quot;) La desviación típica \\(\\sigma_X\\) de la variable \\(X\\) sobre nuestra población es sd(X)*sqrt((10^6-1)/10^6) ## [1] 0.2884943 La función sd (de standard deviation) calcula la desviación típica muestral, con denominador \\(\\sqrt{n-1}\\). Para calcular la desviación típica de verdad, con denominador \\(\\sqrt{n}\\) hay que multiplicarla por \\(\\sqrt{n-1}\\) y dividirla por \\(\\sqrt{n}\\). Ahora vamos a tomar 1000 medias muestrales de tamaño 100 de esta población, las organizaremos en un vector que llamaremos Medias y dibujaremos un histograma de este vector de medias. Medias=replicate(1000,mean(sample(X,100,replace=TRUE))) hist(Medias, breaks=15,freq=FALSE,main=&quot;Histograma de las medias muestrales&quot;,xlab=&quot;&quot;,ylab=&quot;Densidad&quot;,col=&quot;light blue&quot;,xlim=c(0.4,0.6)) Podéis observar cómo los valores de estas medias se concentran alrededor de 0.5. Veamos su desviación típica: sd(Medias)*sqrt((1000-1)/1000) ## [1] 0.02921408 Fijaos cómo se acerca mucho al valor \\(\\sigma_X/\\sqrt{100}=0.0288494\\) predicho por el teorema anterior. No coinciden exactamente, porque \\(\\sigma_X/\\sqrt{100}\\) es el valor de la desviación típica poblacional de \\(\\overline{X}\\), es decir, para toda la “población” de medias muestrales de muestras aleatorias simples de tamaño 100 de nuestra población de partida, y nosotros hemos tomado una muestra de “solo” 1000 medias de estas. La pestaña Teorema Central del Límite del módulo Demonstration de JAMOVI os permite experimentar cómo muestras de diferentes tamaños de medias muestrales de diferentes tamaños y de diferentes distribuciones poblacionales se aproximan más o menos a una distribución normal. Por ejemplo, para 1000 medias de muestras de tamaño 40 de una binomial: La media muestral \\(\\overline{X}\\) de tamaño \\(n\\) de una variable aleatoria \\(X\\) se interpreta formalmente como la variable aleatoria obtenida tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n}. \\] Por lo tanto, es una combinación lineal de \\(n\\) copias independientes de \\(X\\). Recordando que una combinación de variables aleatorias normales independientes es normal, tenemos el resultado siguiente: Teorema 12.2 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\), entonces \\(\\overline{X}\\) es \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\). Si \\(X\\) no es normal, la tesis del teorema anterior sigue siendo cierta “aproximadamente” siempre y cuando \\(n\\) sea grande. Este resultado, llamado el Teorema Central del Límite es, como su nombre indica, uno de los más importantes en estadística y el motivo de la importancia de la distribución normal. Teorema 12.3 Sea \\(X\\) una variable aleatoria cualquiera de esperanza \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\). Si \\(n\\) es muy grande, \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X, {\\sigma_X}/{\\sqrt{n}})\\). Dos observaciones: ¿Cuándo es una muestra lo bastante grande como para poder invocar el Teorema Central del Límite? En realidad, depende de la \\(X\\). Cuánto más se parezca \\(X\\) a una variable normal, más pequeñas pueden ser la muestras. Por fijar un valor, aceptaremos que “muy grande” en este teorema es \\(n\\geqslant 40\\). ¿Qué quiere decir que una variable aleatoria sea “aproximadamente” normal? Pues que su función de distribución \\(F_X\\) toma valores muy cercanos a la función de distribución de una normal. Recordad cómo una \\(B(n,p)\\) con \\(n\\) grande era “aproximadamente normal” en la lección anterior. Si miráis el histograma de las 1000 medias muestrales del Ejemplo 12.1, veréis que se parece al de una muestra de una variable normal. Es que \\(\\overline{X}\\) es aproximadamente normal, por el Teorema Central del Límite, aunque la variable \\(X\\) sea muy diferente de una normal. Para verlo, en la figura que sigue superponemos al histograma de las medias la gráfica de la densidad de una variable normal de media y desviación típica las predichas por el Teorema Central del Límite. En resumen: Si \\(X\\) es normal, \\(\\overline{X}\\) es \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\). Si \\(X\\) no es normal pero \\(n\\) es grande (pongamos \\(n\\geqslant 40\\), aunque puede ser menor si \\(X\\) se parece a una normal y seguramente tendrá que ser mayor si \\(X\\) es muy diferente de una normal), \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\). Las afirmaciones del bloque anterior son verdaderas para medias muestrales de muestras aleatorias simples. Si no podemos suponer que la muestra sea aleatoria simple, ninguno de los dos resultados es válido. 12.2 La proporción muestral Cuando queremos estimar la proporción de sujetos de una población que tienen una determinada característica, tomamos una muestra y calculamos la proporción de sujetos de la muestra con esta característica. Esta será la proporción muestral de sujetos con esta característica en nuestra muestra. Dada una variable aleatoria \\(X\\) de Bernoulli \\(Be(p_X)\\), la proporción muestral de (muestras de) tamaño \\(n\\), \\(\\widehat{p}_X\\), es la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la proporción de éxitos en la muestra: es decir, contar el número total de éxitos y dividir el resultado por \\(n\\). Fijaos en que \\(\\widehat{p}_X\\) es un caso particular de media muestral \\(\\overline{X}\\): estamos calculando medias muestrales de muestras aleatorias simples de la variable de Bernoulli \\(X\\). Por lo tanto, todo lo que hemos dicho para medias muestrales vale también para proporciones muestrales: Teorema 12.4 Si \\(X\\) es una variable aleatoria de Bernoulli con probabilidad poblacional de éxito \\(p_X\\) y \\(\\widehat{p}_X\\) es la proporción muestral de tamaño \\(n\\): \\(E(\\widehat{p}_X)=p_X\\) \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) No hace falta invocar que la proporción muestral sea un caso particular de media muestral para obtener el resultado anterior. Si llamamos \\(S_n\\) a la variable que cuenta el número de éxitos en una muestra aleatoria simple de tamaño \\(n\\) de la variable de Bernoulli \\(X\\), entonces, por un lado, tenemos que \\(\\widehat{p}_X=S_n/n\\) y, por otro, que \\(S_n\\) es \\(B(n,p_X)\\). Entonces: \\(E(\\widehat{p}_X)=E\\Big(\\dfrac{1}{n}S_n\\Big)=\\dfrac{1}{n}\\cdot E(S_n)=\\dfrac{1}{n}\\cdot np_X=p_X\\) \\(\\sigma({\\widehat{p}_X})=\\sigma\\Big(\\dfrac{1}{n}S_n\\Big)=\\dfrac{1}{n}\\cdot \\sigma(S_n)=\\dfrac{1}{n} \\sqrt{np_X(1-p_X)}=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) \\(E(\\widehat{p}_X)=p_X\\) nos dice que \\(\\widehat{p}_X\\) es un estimador insesgado de \\(p_X\\). Si calculáramos muchas proporciones muestrales de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a la proporción poblacional de éxitos \\(p_X\\). \\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) nos dice que, fijada la variable \\(X\\), si tomamos muestras de tamaño mayor, la variabilidad de los resultados de \\(\\widehat{p}_X\\) disminuye. Si tomamos muestras aleatorias simples de tamaño \\(n\\) de una variable aleatoria Bernoulli \\(X\\): \\(\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) es el error típico de la variable aleatoria \\(\\widehat{p}_X\\): su desviación típica. Para cada muestra, \\(\\sqrt{\\dfrac{\\widehat{p}_X(1-\\widehat{p}_X)}{n}}\\) es el error típico de la muestra, que estima el error típico de \\(\\widehat{p}_X\\). Y como la proporción muestral es un caso particular de media muestral, por el Teorema Central del Límite tenemos el resultado siguiente: Teorema 12.5 Si \\(n\\) es grande y las muestras aleatorias son simples, \\(\\widehat{p}_X\\) es aproximadamente \\(N\\big (p_X,\\sqrt{{p_X(1-p_X)}/{n}}\\big)\\) y por lo tanto \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}} \\] es aproximadamente \\(N(0,1)\\). En el caso de la proporción muestral, a veces vamos a permitir tomar muestras aleatorias sin reposición. En este caso, la variable \\(S_n\\) que cuenta el número de éxitos en una muestra aleatoria sin reposición de tamaño \\(n\\) de la variable de Bernoulli \\(X\\), y que verifica que \\(\\widehat{p}_X=S_n/n\\), es hipergeométrica. De aquí deducimos que seguimos teniendo que \\(E(\\widehat{p}_X)=p_X\\), pero ahora, si \\(N\\) es el tamaño de la población, \\[ \\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(p_X}N-n}{N-1}}. \\] El factor \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que transforma \\(\\sigma({\\widehat{p}_X})\\) para muestras aleatorias simples en la desviación típica de \\({\\widehat{p}_X}\\) para muestras aleatorias sin reposición es el factor de población finita que transformaba la desviación típica de una variable binomial (que cuenta éxitos en muestras aleatorias simples) en la desviación típica de una variable hipergeométrica (que cuenta éxitos en muestras aleatorias sin reposición). Y recordad que si el tamaño de la población \\(N\\) es muy grande comparado con \\(n\\), podemos suponer que una muestra aleatoria sin reposición es simple. 12.3 La varianza muestral Dada una variable aleatoria \\(X\\), llamamos: Varianza muestral de (muestras de) tamaño \\(n\\), \\(\\widetilde{S}_{X}^2\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la varianza muestral de sus valores. Desviación típica muestral de (muestras de) tamaño \\(n\\), \\(\\widetilde{S}_{X}\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la desviación típica muestral de sus valores. Formalmente, estas variables se definen tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1},\\quad \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] Tenemos los dos resultados siguientes. El primero nos dice que \\(\\widetilde{S}_{X}^2\\) es un estimador insesgado de la varianza poblacional \\(\\sigma_{X}^2\\). Teorema 12.6 \\(E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2\\). Por lo tanto, esperamos que la varianza muestral de una muestra aleatoria simple de \\(X\\) valga \\(\\sigma_{X}^2\\), en el sentido usual de que si tomamos muestras aleatorias simples de \\(X\\) de tamaño \\(n\\) grande y calculamos sus varianzas muestrales, muy probablemente obtengamos de media un valor muy cercano a \\(\\sigma_{X}^2\\). Y por consiguiente NO esperamos que la varianza “a secas” de una muestra aleatoria simple valga \\(\\sigma_{X}^2\\), porque la varianza muestral y la varianza “a secas” dan valores diferentes (tienen el mismo numerador y denominadores diferentes). El segundo resultado nos dice que si la variable \\(X\\) es normal, un múltiplo adecuado de \\(\\widetilde{S}_{X}^2\\) tiene distribución conocida, lo que nos permitirá calcular probabilidades de sucesos relativos a \\(\\widetilde{S}_{X}^2\\). Teorema 12.7 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras aleatorias simples de tamaño \\(n\\), la variable aleatoria \\[ \\chi^2= \\dfrac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] tiene una distribución conocida, llamada ji cuadrado con \\(n-1\\) grados de libertad, \\(\\chi_{n-1}^2\\). La letra griega \\(\\chi\\) en castellano se lee ji; en catalán, khi; en inglés, chi, pronunciado “chai”. Figura 12.1: Chi es un gatito, la distribución és ji. La distribución \\(\\chi_\\nu^2\\), donde \\(\\nu\\) es un parámetro llamado sus grados de libertad, es la distribución de probabilidad de la suma de los cuadrados de \\(\\nu\\) copias independientes de una variable normal estándar. Para R es chisq. La tenéis también en el módulo distrACTION. Os puede interesar recordar que una variable \\(\\chi_\\nu^2\\) de tipo ji cuadrado con \\(\\nu\\) grados de libertad: Tiene valor esperado \\(E(\\chi_\\nu^2)=\\nu\\) y varianza \\(\\sigma(\\chi_\\nu^2)^2=2 \\nu\\). Su función de distribución es estrictamente creciente. Su densidad es asimétrica a la derecha, como muestra el gráfico siguiente: A medida que el número de grados de libertad \\(\\nu\\) crece, esta asimetría tiende a desaparecer y, por el Teorema Central del Límite, si \\(\\nu\\) es lo bastante grande, la distribución \\(\\chi_\\nu^2\\) se aproxima a la de una variable normal \\(N(\\nu,\\sqrt{2\\nu})\\). Tened cuidado: Si la variable poblacional \\(X\\) no es normal, la conclusión del Teorema 12.7 no es verdadera. Aunque \\(X\\) sea normal, \\(E(\\widetilde{S}_{X})\\neq \\sigma_{X}\\). La desviación típica muestral es un estimador sesgado de \\(\\sigma_{X}\\) (pero tiene otras buenas propiedades que hacen que la usemos igualmente). Ya lo hemos comentado antes. Si \\(S^2_{X}\\) es la varianza “a secas” (dividiendo por \\(n\\) en vez de por \\(n-1\\)), \\(E(S^2_{X})\\neq \\sigma^2_{X}\\). De hecho, como \\(S_X^2\\) se obtiene a partir de \\(\\widetilde{S}_{X}^2\\) cambiando el denominador, \\[ S_X^2=\\frac{n-1}{n} \\widetilde{S}_{X}^2 \\] tenemos que \\[ E(S_X^2)=\\frac{n-1}{n}E(\\widetilde{S}_{X}^2)=\\frac{n-1}{n}\\sigma^2_{X} \\] 12.4 La distribución t de Student Recordad que si la variable poblacional \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras aleatorias simples de tamaño \\(n\\), entonces \\(\\overline{X}\\) es \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\) y por lo tanto, tipificando, la variable \\[ \\frac{\\overline{X}-\\mu_X}{\\sigma_{X}/\\sqrt{n}} \\] es normal estándar. Esto no nos sirve de nada para calcular la probabilidad de que \\(\\overline{X}\\) se aleje mucho de \\(\\mu_X\\) si no sabemos la desviación típica poblacional \\(\\sigma_{X}\\), que será lo habitual. ¿Qué pasa si la estimamos por medio de \\(\\widetilde{S}_{X}\\) con la misma muestra con la que calculamos \\(\\overline{X}\\)? Pues que el resultado siguiente nos salva el día, porque la variable que resulta tiene distribución conocida y por lo tanto podemos calcular probabilidades con ella. Teorema 12.8 Sea \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\). Si tomamos muestras aleatorias simples de tamaño \\(n\\), la variable aleatoria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene una distribución conocida, llamada t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Al denominador \\(\\widetilde{S}_{X}/\\sqrt{n}\\) de la \\(T\\) del teorema anterior se le llama el error típico de la muestra, y estima el error típico \\(\\sigma_X/\\sqrt{n}\\) de la media muestral \\(\\overline{X}\\). Fijaos en que el teorema anterior es solo para variables poblacionales \\(X\\) normales. Si \\(X\\) no es normal, tenemos el resultado siguiente. Teorema 12.9 Sea \\(X\\) una variable de media \\(\\mu_X\\). Si tomamos muestras aleatorias simples de tamaño \\(n\\) muy grande, la variable aleatoria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene distribución aproximadamente \\(t_{n-1}\\). Para R, la distribución t de Student es t, a secas. La tenéis también en el módulo distrACTION. Algunas propiedades que conviene que recordéis de las variables \\(T_\\nu\\) que tienen distribución \\(t\\) de Student con \\(\\nu\\) grados de libertad, \\(t_\\nu\\): Su valor esperado es \\(E(T_\\nu)=0\\) y su varianza es \\(\\sigma(T_\\nu)=\\dfrac{\\nu}{\\nu-2}\\) (en realidad esto solo es verdad si \\(\\nu\\geqslant 3\\), pero no hace falta recordarlo). Su función de distribución es estrictamente creciente. Su densidad es simétrica respecto de 0 (como la de una \\(N(0,1)\\)) y por lo tanto \\[ P(T_\\nu\\leqslant -x)=P(T_\\nu\\geqslant x)=1-P(T_\\nu\\leqslant x) \\] Si \\(\\nu\\) es grande (digamos, de nuevo, \\(\\nu\\geqslant 40\\)), \\(T_\\nu\\) es aproximadamente una \\(N(0,1)\\) (pero con un poco más de varianza, porque \\(\\nu/(\\nu-2)&gt;1\\), y por consiguiente un poco más achatada). Denotaremos por \\(t_{\\nu,q}\\) el \\(q\\)-cuantil de una variable aleatoria \\(T_{\\nu}\\) con distribución \\(t_\\nu\\). Es decir, \\(t_{\\nu,q}\\) es el valor tal que \\[ P(T_{\\nu}\\leqslant t_{\\nu,q})=q \\] Entonces: Por la simetría de la densidad de \\(T_{\\nu}\\), \\[ t_{\\nu,q}=-t_{\\nu,1-q}. \\] Exactamente lo mismo que pasaba con la normal estándar Si \\(\\nu\\) es grande, \\(T_\\nu\\) será aproximadamente una \\(N(0,1)\\) y por lo tanto \\(t_{\\nu,q}\\) es aproximadamente igual a \\(z_q\\). No confundáis: Desviación típica de una variable aleatoria: El parámetro poblacional, normalmente desconocido. Es \\(\\sigma_X\\). Desviación típica (muestral o no) de una muestra: El estadístico que calculamos sobre la muestra. Es \\(\\widetilde{S}_X\\) (la muestral) o \\({S}_X\\) (la “a secas”). Error típico de la media muestral: La desviación típica de la variable \\(\\overline{X}\\). Es \\(\\sigma_X/\\sqrt{n}\\), con \\(n\\) el tamaño de las muestras. Error típico de una muestra: Estimación del error típico de \\(\\overline{X}\\) a partir de la muestra. Es \\(\\widetilde{S}_X/\\sqrt{n}\\), con \\(n\\) el tamaño de la muestra. Fijaos en que el denominador \\(\\sqrt{n}\\) hace que, en general, los errores típicos sean mucho más pequeños que las desviaciones típicas. Id con cuidado, porque esto se usa a menudo en artículos para enmascarar los resultados. Si una muestra ha salido con una dispersión muy grande, se da su error típico en vez de su desviación típica y parece que ha salido más concentrada. 12.5 Test (1) Si el tamaño de una muestra aleatoria simple aumenta (marca todas las afirmaciones correctas): La media muestral siempre disminuye. El error típico de la media muestral siempre disminuye. El error típico de la muestra siempre disminuye. La varianza muestral siempre aumenta. El número de grados de libertad de la variable ji cuadrado asociada a la varianza muestral siempre aumenta. Ninguna de las otras afirmaciones es correcta (2) Si queremos disminuir a la mitad el error típico de la media muestral: Tenemos que aumentar en un 50% el tamaño de las muestras. Tenemos que doblar el tamaño de las muestras. Tenemos que cuadruplicar el tamaño de las muestras. Tenemos que dividir por 2 el tamaño de las muestras. Tenemos que dividir por 4 el tamaño de las muestras. Ninguna de las otras respuestas es correcta. (3) La prevalencia de una afección en una población es del 10%. Si estimamos dicha prevalencia repetidamente mediante las proporciones muestrales de muestras aleatorias simples de tamaño 1000, estas estimaciones siguen una distribución que (marca todas las afirmaciones correctas): Es aproximadamente normal. Es binomial. Tiene media 0.1. Tiene media 900. Ninguna de las otras afirmaciones es correcta (4) Sobre una muestra de 100 mujeres se obtuvo una concentración media de hemoglobina de 10 con una desviación típica de 2. ¿Qué vale el error típico de la muestra (para la media muestral, se entiende)? 0.02 0.04 0.2 0.4 1 Ninguno de los anteriores (5) ¿Cuáles de las afirmaciones siguientes sobre la media muestral son verdaderas? Marca todas las respuestas correctas. Si la distribución poblacional es normal, siempre coincide con la media de la distribución poblacional. Si la distribución poblacional es normal, siempre coincide con la mediana de la distribución poblacional. Siempre sirve para estimar la media poblacional, aunque la distribución poblacional no sea normal. Si la distribución poblacional es normal, sirve para estimar la mediana poblacional. Se calcula sumando todos los valores de la muestra y dividiendo por \\(n-1\\), donde \\(n\\) indica el tamaño de la muestra. Ninguna de las otras respuestas es correcta. (6) La concentración de un determinado metabolito en sangre tiene un valor medio \\(\\mu\\). Si tomamos muestras aleatorias simples de \\(n=20\\) individuos, calculamos su media muestral \\(\\overline{X}\\) y su desviación típica muestral \\(\\widetilde{S}_X\\) (marca la continuación más correcta): El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) tiene siempre distribución normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) tiene siempre distribución t de Student. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) tiene distribución normal si la concentración sigue una ley normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) tiene distribución t de Student si la concentración tiene distribución normal. El estadístico \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) no tiene nunca ni distribución normal ni distribución t de Student, porque \\(n=20\\) no es lo bastante grande. (7) Tenemos una variable aleatoria \\(X\\) normal de media \\(\\mu\\) y desviación típica \\(\\sigma\\). Tomamos muestras aleatorias simples de tamaño \\(n\\), y denotamos por \\(\\widetilde{S}_X\\) su desviación típica muestral. ¿Cuáles de las afirmaciones siguientes son verdaderas? Marca todas las respuestas verdaderas: \\(E(\\widetilde{S}_X^2)=\\sigma^2\\). \\(E(\\widetilde{S}_X)=\\sigma\\). \\(\\widetilde{S}_X^2\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. \\((n-1)\\widetilde{S}_X^2/\\sigma^2\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. \\((n-1)\\widetilde{S}_X/\\sigma\\) sigue una distribución ji cuadrado con \\(n-1\\) grados de libertad. Todas las otras respuestas son falsas. (8) El 0.75-cuantil de una variable t de Student con 49 grados de libertad \\(T\\) vale 0.68. ¿Cuál de las afirmaciones siguientes es verdadera? \\(P(T\\leqslant 0.75)= 0.68\\) \\(P(T\\geqslant 0.75)= 0.68\\) \\(P(T\\leqslant 0.68)= 0.75\\) \\(P(T\\geqslant 0.68)= 0.75\\) \\(P(T= 0.68)= 0.75\\) \\(P(T= 0.75)= 0.68\\) Ninguna de las otras respuestas es correcta. (9) Sabemos que una determinada variable poblacional \\(X\\) sigue una distribución normal de media 2. ¿Cuál de las afirmaciones siguientes es verdadera? El porcentaje de individuos de la población en los que la \\(X\\) vale 2 es del 50% El porcentaje de individuos de la población en los que la \\(X\\) vale menos de 1 es del 70% Si el 0.95-cuantil de \\(X\\) es 3, el 0.05-cuantil de \\(X\\) es 1 Si el 0.95-cuantil de \\(X\\) es 3, el 0.05-cuantil de \\(X\\) es -3 Todas las otras afirmaciones son falsas (10) ¿Qué es el error típico de la proporción muestral? La varianza de la distribución de las proporciones muestrales. La diferencia entre su valor sobre una muestra aleatoria simple y el valor real de la probabilidad poblacional de éxito. La desviación típica de la distribución de las proporciones muestrales. La probabilidad que su valor sobre una muestra aleatoria simple sea diferente de la probabilidad poblacional de éxito. La diferencia entre su valor esperado y el valor real de la probabilidad poblacional de éxito. (11) ¿Cuál de las afirmaciones siguientes es FALSA? La media muestral es un estimador insesgado de la media poblacional La proporción muestral es un estimador insesgado de la proporción poblacional La varianza muestral es un estimador insesgado de la varianza poblacional La desviación típica muestral es un estimador insesgado de la desviación típica poblacional Alguna de las afirmaciones anteriores es falsa. "],["intervalos-de-confianza.html", "Lección 13 Intervalos de confianza 13.1 Definiciones básicas 13.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal 13.3 Intervalo de confianza para la media basado en la t de Student 13.4 Intervalos de confianza para proporciones 13.5 (Bonus track) Otros intervalos de confianza 13.6 Test", " Lección 13 Intervalos de confianza Los estimadores de la lección anterior nos permiten hacer una estimación puntual del valor de un parámetro de una variable poblacional: es decir, intentar adivinar su valor. Pero, naturalmente, es muy difícil que a partir de una muestra podamos acertar exactamente el valor del parámetro. Las técnicas de la estadística inferencial nos permiten entonces cuantificar la precisión de esta estimación. Esto se hace complementando la estimación puntual con un intervalo alrededor de la misma donde “estemos muy seguros de que cae el valor real del parámetro”. Figura 13.1: elEconomista.es, 27/5/2019 Obviamente, no es necesario saber estadística para dar un intervalo donde estemos muy seguros de que cae el valor real del parámetro. Basta dar un intervalo lo bastante grande como para contener todos los valores razonables del parámetro. De lo que se trata es de dar un intervalo lo más estrecho posible donde estemos muy seguros de que cae el valor real del parámetro. El tamaño de este intervalo dependerá: De la variabilidad del estimador: cuánta más variabilidad tenga, menos precisa será la estimación. Normalmente, la variabilidad del estimador crece con la desviación típica de la variable poblacional y decrece con el tamaño de las muestras. Del nivel de confianza, o seguridad: cómo de seguros queremos estar de que el valor real del parámetro pertenece al intervalo que damos. Cuánto más seguros queramos estar, más ancho tendrá que ser el intervalo. 13.1 Definiciones básicas Un intervalo de confianza del Q% (para abreviar, un IC-Q%) de un parámetro poblacional (una media, una desviación típica, uno proporción poblacional…) es un intervalo obtenido aplicando a una muestra aleatoria simple de tamaño \\(n\\) una fórmula, o, más en general, un procedimiento, que satisface la propiedad siguiente: El intervalo obtenido contiene el valor del parámetro poblacional el Q% de las veces que aplicamos la fórmula a muestras aleatorias simples de tamaño \\(n\\) tomadas al azar. Tener una confianza del Q% significa pues que lo calculamos con una fórmula que acierta el Q% de las veces que la aplicamos. Formalmente: La probabilidad de éxito de la variable aleatoria de Bernoulli (definida sobre la “población” formada por todas las muestras con posibles repeticiones de un tamaño \\(n\\) determinado de la población de interés) “Tomamos una muestra aleatoria simple de tamaño \\(n\\) de la población, calculamos a partir de ella un IC-Q% para una cierto parámetro de la población, y consideramos como Éxito que este intervalo contenga dicho parámetro poblacional” es del Q%. Informalmente: El Q% de los IC-Q% contienen el valor real del parámetro que quieren estimar. Pero asumimos que en un (100-Q)% de las veces da un intervalo que no contiene el valor del parámetro poblacional, y no sabemos cuándo sí y cuándo no. De manera que solo podemos tener una cierta confianza, fruto del optimismo, de que esta fórmula acierta con nuestra muestra. Ejemplo 13.1 En un experimento se midió el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. En el Ejemplo 13.4 calcularemos con los datos obtenidos en este experimento un IC-95% para el porcentaje de aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Obtendremos el intervalo [40.53, 41.87]. Esto significará que tenemos un 95% de seguridad en que el aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza está entre el 40.53% y el 41.87%, porque habremos calculado este intervalo con una fórmula que el 95% de las veces que la aplicamos a muestras aleatorias de tamaño 40 da un intervalo que contiene la media poblacional que queremos estimar. Nosotros somos optimistas y “confiamos” estar dentro de este 95% de aciertos. A menudo esto lo escribiremos diciendo que: Hay un 95% de probabilidad de que el intervalo [40.53, 41.87] contenga el valor real del aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Pero hay que entender lo que dice esta frase: Por definición, un 95% de los intervalos de confianza del 95% para el aumento medio de alcohol etc. contienen el valor real de este aumento medio. [40.53, 41.87] es un intervalo de confianza del 95% para el aumento medio de alcohol etc., obtenido a partir de una muestra aleatoria. Entonces, [40.53, 41.87] tiene una probabilidad del 95% de contener el valor real del aumento medio de alcohol etc. en el mismo sentido que si un 95% de las personas tienen una determinada característica, y cojo una persona al azar, esta persona tiene un 95% de probabilidad de tener esa característica. A menudo calcularéis un intervalo de confianza del Q% para un cierto parámetro \\(\\theta\\) de una población, os dará \\([a,b]\\), y con el poco rigor con el que a veces os expresáis, os será igual decir “el valor real de \\(\\theta\\) tiene una probabilidad del Q% de pertenecer a \\([a,b]\\)” que “\\([a,b]\\) tiene una probabilidad del Q% de contener el valor real de \\(\\theta\\)” Pero estas dos frases no dicen exactamente lo mismo, y de hecho la primera es falsa. Fijaos en que, en la primera frase hablamos de la probabilidad de que a \\(\\theta\\) le pase algo, y en la segunda de que a \\([a,b]\\) le pase algo. La primera frase dice que \\(\\theta\\) varía y un Q% de sus valores pertenecen a \\([a,b]\\). Esto es falso. “El valor real de \\(\\theta\\)” es un número que no varía. Para nuestra población vale algo concreto, desconocido pero concreto, que pertenecerá o no al intervalo \\([a,b]\\). La segunda frase en cambio se puede entender de la manera siguiente. El intervalo \\([a,b]\\) forma parte de todo el conjunto de IC-Q% para \\(\\theta\\) calculados a partir de todas las muestras aleatorias simples de nuestra población. La probabilidad de que uno de estos intervalos contenga el valor real de \\(\\theta\\) es del Q%. Por lo tanto, podemos decir que nuestro intervalo \\([a,b]\\) tiene una probabilidad del Q% de contener el valor real de \\(\\theta\\). Esta interpretación es correcta. Figura 13.2: Un intervalo de confianza es como el juego de las anillas: el palo (el parámetro) es fijo, y intentas acertar con la anilla (el intervalo). No confundáis: Intervalo de referencia del Q% para una variable aleatoria: Intervalo que contiene el valor de la variable aleatoria en un individuo con probabilidad Q%. Intervalo de confianza del Q% para un parámetro: Intervalo que contiene el valor poblacional del parámetro de la variable aleatoria “con probabilidad” Q%, en el sentido de que lo hemos calculado con una fórmula que da un intervalo que contiene dicho parámetro el Q% de las veces que la aplicamos a una muestra aleatoria. Intervalo de referencia del Q% para un estimador: Intervalo que contiene el valor del estimador sobre una muestra aleatoria con probabilidad Q%. Por ejemplo: Si decimos que un intervalo de referencia del 95% para la concentración de una proteína en suero en individuos sanos en g/dl es [11,16], esto significa que un 95% de los individuos sanos tienen una concentración de esta proteína en suero entre 11 y 16 g/dl es decir, que si escogemos al azar un individuo sano, la probabilidad de que su concentración de esta proteína en suero esté entre 11 y 16 g/dl es del 95%. Si decimos que un intervalo de confianza del 95% para la concentración media de una proteína en suero en individuos sanos tamaño en g/dl es [11,16], esto significa que este intervalo tiene un 95% de probabilidad de contener la concentración media de esta proteína en suero en individuos sanos tamaño en g/dl, en el sentido de que lo hemos obtenido aplicando a una muestra aleatoria de concentraciones de esta proteína en suero en individuos sanos una fórmula que da un intervalo que contiene la media poblacional un 95% de las veces que la aplicamos a muestras aleatorias del mismo tamaño que la nuestra. Si decimos que el 95% de las muestras de 100 concentraciones de una determinada proteína en suero en individuos sanos tienen la media muestral entre 11 y 16 g/dl, esto es un intervalo de referencia del 95% para la media muestral de muestras de tamaño 100, no un intervalo de confianza para la concentración media poblacional ni un intervalo de referencia para el valor de la concentración en un individuo. Que un IC-Q% para un parámetro \\(\\theta\\) sea \\([a,b]\\) sirve: Para estimar \\(\\theta\\) con este margen de confianza: Estamos muy seguros de que el valor poblacional de \\(\\theta\\) está entre \\(a\\) y \\(b\\) (porque la fórmula usada acierta a menudo). Para descartar, con este margen de confianza, que \\(\\theta\\) valga cualquier valor concreto fuera de \\([a,b]\\): Como estamos muy seguros de que el valor real de \\(\\theta\\) está entre \\(a\\) y \\(b\\), también estamos muy seguros de que es diferente de cualquier valor que sea menor que \\(a\\) o mayor que \\(b\\). Por ejemplo: si un IC-95% para la prevalencia \\(p\\) de una determinada enfermedad en una población va de 0.025 a 0.047: Estamos muy (“un 95%”) seguros de que \\(p\\) está entre 0.025 y 0.047 (porque la probabilidad de que un IC-95% para \\(p\\) contenga el valor real de \\(p\\) es del 95%). Estamos muy (“un 95%”) seguros de que \\(p\\) no vale 0.05 (porque 0.05 no pertenece al intervalo al que estamos muy seguros de que pertenece el valor real de \\(p\\)). Pero no estamos muy seguros de que \\(p\\) sea 0.03, por mucho que \\(0.03\\in [0.025,0.047]\\): estamos muy seguros de que \\(p\\) está entre 0.025 y 0.047, pero solo eso. Ejemplo 13.2 Supongamos que estimamos el RR de una cierta enfermedad relativo a una determinada exposición y nos da 2, con un IC-95% de 1.2 a 4.5. Entonces, estamos muy seguros de que el RR “poblacional” no es 1 (porque 1 no pertenece a [1.2,3.5]), y en realidad podemos estar muy seguros de que este RR es mayor que 1 (porque todos los valores del intervalo [1.2,3.5] son &gt;1). Por lo tanto, concluimos (con un 95% de confianza) que la probabilidad de la enfermedad entre los expuestos es mayor que entre los no expuestos. Ahora bien, no tenemos un 95% de confianza en ni estamos muy seguros de que el RR poblacional sea 2. Solo estamos muy seguros de que está entre 1.2 y 4.5. En cambio, si al estimar dicho RR nos da 2 pero con un IC-95% de 0.7 a 5.5, entonces no podemos concluir nada sobre el RR poblacional: con este nivel de confianza, podría ser menor que 1, mayor que 1 o incluso exactamente 1, en cuyo caso la enfermedad sería independiente de la exposición. Hay dos tipos de métodos básicos de cálculo de intervalos de confianza a partir de una muestra aleatoria: Paramétricos: Usando alguna fórmula basada en la distribución muestral del estimador. Se basan en teoremas y solo tiene sentido usarlos si la variable aleatoria y la muestra aleatoria satisfacen (aproximadamente) las hipótesis de los teoremas. No paramétricos. Los otros. El más popular, y nuestro favorito, es el bootstrap: De nuestra muestra, tomamos al azar muchas (miles) muestras aleatorias con reposición del mismo tamaño que nuestra muestra. Calculamos el estimador para cada una de estas muestras. Usamos el vector de resultados para estimar un intervalo de confianza. Por ejemplo, tomamos como IC-95% el intervalo entre los cuantiles 0.025 y 0.975 de este vector. El bootstrap se puede usar siempre y funciona bien si la muestra es aleatoria, pero se basa en un proceso aleatorio y por lo tanto cada ejecución sobre una misma muestra puede dar un intervalo diferente. El bootstrap es una herramienta muy poderosa para calcular intervalos de confianza y, en general, para estimar la distribución muestral de un estadístico. Tanto, que en la práctica ya empieza a sustituir los métodos paramétricos. Pero no hace milagros: si la muestra es pequeña o muy poco representativa de la población, un intervalo de confianza calculado con el bootstrap sirve de tan poco como uno calculado con un método paramétrico. Figura 13.3: En inglés, la bootstrap es la trabilla de la bota, y el método del bootstrap refiere a la expresión inglesa “elevarse tirando de las trabillas”. 13.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal Una de las fórmulas más conocidas para intervalos de confianza es la siguiente: Si \\(X\\) es normal de media \\(\\mu\\) y tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y desviación típica muestral \\(\\widetilde{S}_X\\), un IC-95% para \\(\\mu\\) es \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] donde \\(t_{n-1,0.975}\\) denota el 0.975-cuantil de la distribución t de Student \\(t_{n-1}\\). Este intervalo a veces lo escribiremos \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] para recalcar que estamos estimando \\(\\mu\\) por medio de \\(\\overline{X}\\) más o menos un cierto error. A algunos de vosotros os habrán explicado en Bachillerato, o encontraréis en libros que consultéis, una fórmula para el IC-95% para \\(\\mu\\) similar a esta, pero cambiando la \\(\\widetilde{S}_X\\) por la desviación típica de \\(X\\), \\(\\sigma\\), y el \\(t_{n-1,0.975}\\) por \\(z_{0.975}\\), el 0.975-cuantil de la normal estándar. Esta otra fórmula solo se puede usar si se conoce la desviación típica poblacional \\(\\sigma\\), lo que, en la práctica, nunca pasará. Por lo tanto, por favor, olvidadla. ¿Cómo podemos estar seguros de que en un 95% de las aplicaciones de esta fórmula a una muestra aleatoria simple el intervalo que obtengamos contendrá el valor real de la media? Vamos a explicar de dónde sale esta fórmula, puesto que es un paradigma de cómo se obtienen la mayoría de las fórmulas paramétricas para intervalos de confianza. Quien se la quiera tomar como dogma de fe, que salte directamente al Ejemplo 13.3. Supongamos pues que normal de media \\(\\mu\\) y que tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y desviación típica muestral \\(\\widetilde{S}_X\\). En esta situación, sabemos que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Si podemos encontrar \\(A,B\\in \\mathbb{R}\\) tales que \\[ P(A\\leqslant T\\leqslant B)=0.95, \\] entonces: \\[ \\begin{array}{rl} 0.95\\!\\!\\!\\! &amp; =P\\Bigg(A\\leqslant \\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leqslant B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\overline{X}-\\mu \\leqslant B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant -\\mu \\leqslant -\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu \\leqslant \\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Como \\(P(A\\leqslant T\\leqslant B)=0.95\\) significa que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) el valor de \\(T\\) está entre \\(A\\) y \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu \\leqslant \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significará que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) la \\(\\mu\\) cae dentro del intervalo \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Por lo tanto, ¡esto será un IC-95% para \\(\\mu\\)! Nos falta encontrar los \\(A,B\\) tales que \\(P(A\\leqslant T\\leqslant B)=0.95\\). Para encontrarlos, usaremos cuantiles de la distribución de \\(T\\). Recordemos que, por definición de cuantil, \\[ P(T\\leqslant t_{n-1,0.975})=0.975 \\] y por la simetría de la \\(t\\) de Student, \\[ P(T\\leqslant -t_{n-1,0.975})=P(T\\geqslant t_{n-1,0.975})=0.025 \\] Por tanto: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leqslant T\\leqslant t_{n-1,0.975})\\\\ \\quad =P(T\\leqslant t_{n-1,0.975})-P(T\\leqslant -t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Así pues, podemos tomar \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] y obtenemos el IC-95% para \\(\\mu\\) anunciado: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Ejemplo 13.3 El ítem “Testing hypothesis” del módulo Demonstration de JAMOVI permite, entre otras cosas, realizar experimentos con la fórmula anterior para estudiar su frecuencia de “aciertos”, o sea, cuántas veces el intervalo que produce al aplicarla a una muestra contiene la \\(\\mu\\). Aquí vamos a llevar a cabo explícitamente un experimento en el mismo sentido. En el bloque de código de R siguiente, que podéis ejecutar en el editor de R de JAMOVI: Generamos al azar una Población de 107 “individuos” que siguen una ley normal estándar y calculamos la media mu de esta población. Definimos una función IC que calcula el IC-95% para la media \\(\\mu\\) con la fórmula anterior. Tomamos, al azar, 200 muestras aleatorias simples de tamaño 50 de nuestra población y les aplicamos esta función. Obtenemos una matriz M de 200 columnas formadas por los dos extremos de los intervalos. Dibujamos los intervalos de confianza en un gráfico como segmentos horizontales, en gris los que contienen el valor “poblacional” de mu y en rojo los que no lo contienen. La recta vertical marca el valor de mu. Población=rnorm(10^7) mu=mean(Población) mu ## [1] 0.0002423589 N=200 #Número de muestras n=50 #Tamaño de las muestras IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(N,IC(sample(Población,n,replace=TRUE))) plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valores&quot;,ylab=&quot;Repeticiones&quot;, main=&quot;200 IC-95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:N,FUN=seg.int) abline(v=mu,lwd=2) Si contáis los intervalos rojos, veréis que hemos fallado 11 veces y por lo tanto hemos acertado 189 veces, es decir, en un 94.5% de los intervalos. Es aproximadamente lo que esperábamos. Si lo probáis en casa, ejecutando el código de R que hemos dado, obtendréis otros resultados, a veces mejores, a veces peores. Es lo que tiene la aleatoriedad. Podéis cambiar el valor de N (número de muestras) o n(el tamaño de las muestras) para ver qué pasa si tomáis más muestras o muestras más grandes. (Si queréis obtener exactamente nuestro gráfico, justo antes de Población=rnorm(10^7) ejecutad set.seed(1200).) Queremos remarcar que, en nuestra simulación, de los 200 IC-95% que hemos calculado, 11 no han contenido el valor real de \\(\\mu\\). Un intervalo de confianza no siempre acierta. De media, un IC-Q% NO contiene el valor real del parámetro en un (100-Q)% de las ocasiones. Por ejemplo, de media, un 5% de las veces que calculemos un IC-95%, el parámetro poblacional no pertenecerá al intervalo obtenido. Por lo tanto, si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, el número de veces en que el intervalo resultante no contendrá el parámetro poblacional seguirá una distribución binomial \\(B(n,0.05)\\). El gráfico siguiente representa el valor de \\(P(X\\geqslant 1)\\) para una variable aleatoria \\(X\\) de tipo \\(B(n,0.05)\\), para \\(n=0,...,100\\), y por lo tanto la probabilidad de que si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, al menos uno de ellos no contenga el parámetro poblacional deseado. Esto es un problema grave en artículos científicos donde se calculen intervalos de confianza para muchos parámetros. De media, uno de cada veinte IC-95% que se calculan no contiene el valor real del parámetro que se pretende estimar. Y no se puede hacer nada al respecto, forma parte de la definición. Si queréis bajar este porcentaje de errores, hay que aumentar el nivel de confianza y los intervalos serán más anchos y por lo tanto menos útiles. Ejemplo 13.4 Volvamos al experimento en el que se midió el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. La media y la desviación típica muestral de estos porcentajes de incremento fueron \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1. \\] Para calcular un IC-95% para el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza, \\(\\mu\\) para abreviar, supondremos que la variable aleatoria de interés (de la que queremos estimar la media) \\(X\\), que es “Tomamos una persona, bebe 4 cañas de cerveza y medimos el porcentaje de aumento de alcohol en sangre tras beberlas”, es normal y que la muestra que hemos tomado de esta variable es aleatoria simple. Entonces, como \\(t_{n-1,0.975}=2.0227\\), un IC-95% para \\(\\mu\\) es \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Por lo tanto, estimamos con un 95% de confianza que el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza está entre el 40.5% y el 41.9%, o que es del 41.2% más menos 0.7 puntos porcentuales. Para calcular el intervalo anterior hemos supuesto que la variable poblacional “Porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza” sigue una distribución normal. ¿Y si no fuera normal? En este caso, como el tamaño de la muestra \\(n=40\\) es lo bastante grande, el Teorema 13.2 de la próxima sección nos dice que el intervalo obtenido sigue siendo (aproximadamente) un intervalo de confianza del 95% para \\(\\mu\\). Si \\(n\\) fuera pequeño y \\(X\\) muy diferente de una normal, no se puede usar esta fórmula y habría que buscarse la vida (por ejemplo, usar el método bootstrap). También hemos supuesto que era una muestra aleatoria simple. ¿Y si no lo es? Si es aleatoria sin reposición, como la población sobre la que tenemos definida nuestra variable aleatoria, las personas que pueden tomar 4 cañas de cerveza, es muy grande, a efectos prácticos la podemos considerar simple. Pero seguro que no es aleatoria, sino oportunista. En este caso, no se eligieron 40 personas por sorteo de la lista de toda la población mundial, ni siquiera de la de Mallorca, sino que se reclutaron voluntarios. Entonces, no podemos hacer nada para salvar la fórmula, y su validez depende de si la muestra de personas usada puede pasar por aleatoria o no. 13.3 Intervalo de confianza para la media basado en la t de Student A partir de ahora, para evitar ambigüedades, en las fórmulas expresaremos el nivel de confianza de los intervalos en tanto por uno, no en tanto por ciento; es decir, como una proporción en vez de como un porcentaje. Por lo tanto, hablaremos de intervalos de confianza de nivel de confianza \\(q\\) (IC-\\(q\\)), con \\(q\\) entre 0 y 1, en vez de intervalos de confianza del Q% con Q=100q. Con estas notaciones, por ejemplo, los intervalos de confianza del 95% serán intervalos de confianza de nivel de confianza 0.95, IC-0.95. El mismo argumento de la sección anterior, cambiando 0.95 por \\(q\\), da: Teorema 13.1 Si \\(X\\) es normal de media \\(\\mu\\) y tomamos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y desviación típica muestral \\(\\widetilde{S}_X\\), un IC-\\(q\\) para \\(\\mu\\) es \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La fórmula de la sección anterior es un caso particular de esta, porque en los IC-0.95, \\(q=0.95\\) y por lo tanto \\((1+q)/2=1.95/2=0.975\\). Más en general: Teorema 13.2 Si \\(X\\) es una variable aleatoria cualquiera de media poblacional \\(\\mu\\) y tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande (digamos, de 40 o más elementos), entonces, un IC-\\(q\\) para \\(\\mu\\) es aproximadamente \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La aproximación del teorema anterior es mejor cuanto mayor sea \\(n\\) o cuanto más próxima a una normal sea la variable poblacional \\(X\\). En resumen: Podemos usar la fórmula para el IC-\\(q\\) para la media poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] si la variable poblacional es normal o si la muestra aleatoria simple es grande. Observad que la estructura del IC-\\(q\\) para \\(\\mu\\) dado por esta fórmula es estimador \\(\\pm\\) (\\(\\frac{1+q}{2}\\)-cuantil de la distr. muestral)\\(\\times\\)(error típico de la muestra) Esta estructura es muy típica (pero no universal: no creáis que todos los intervalos de confianza paramétricos tienen esta forma) y cumple que: El intervalo de confianza está centrado en la estimación puntual. La “probabilidad de equivocarnos” se reparte por igual a los dos lados del intervalo: de media, en una fracción \\((1-q)/2\\) de las veces que se aplica la fórmula, el valor real del parámetro cae a la izquierda del extremo inferior y en otra fracción \\((1-q)/2\\) de estas ocasiones cae a la derecha del extremo superior. Para una misma muestra y una misma fórmula (paramétrica) para calcular el intervalo de confianza, si el nivel de confianza crece, el intervalo se ensancha. Esto es general, para todos los intervalos de confianza paramétricos. El motivo intuitivo es que, para estar más seguros de que un intervalo contiene un valor, el intervalo tiene que ser más ancho. En un intervalo de confianza con la estructura descrita hace un momento, el motivo matemático es que a mayor \\(q\\), mayor \\((1+q)/2\\)-cuantil de la distribución muestral. Por ejemplo, en el Ejemplo 13.4, teníamos \\(n=40\\), \\(\\overline{x}=41.2\\) y \\(\\widetilde{s}=2.1\\): El IC-95% tiene \\(q=0.95\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), y daba \\[ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] El IC-99% tiene \\(q=0.99\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), y da \\[ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] más ancho Pero si cambiamos de muestra (o de fórmula, si hay más de una) para calcular el intervalo de confianza, puede pasar cualquier cosa. El intervalo de confianza para una media usando la fórmula basada en la t de Student se puede calcular con JAMOVI marcando las casillas Diferencia de medias e Intervalo de confianza (y eligiendo el nivel de confianza) en T-tests/Prueba T en una muestra. Ejemplo 13.5 Queremos calcular un intervalo de confianza del 95% para la temperatura media de las personas. Para ello, vamos a usar unos datos recogidos por P.A. Mackowiak, S. S. Wasserman y M.M. Levine en un estudio de 1992, en el que tomaron la temperatura a una muestra transversal de 230 personas (114 hombres y 116 mujeres). Tenemos guardadas estas temperaturas en la tabla Temperaturas.txt que podéis descargar de https://raw.githubusercontent.com/AprendeR-UIB/INREMDN/master/Dades/Temperaturas.txt. Tras descargarla, la importamos abriéndola con Importar especial. Seleccionamos T-tests/Prueba T en una muestra, elegimos la variable Temperatura como “variable dependiente” y marcamos Diferencia de medias e Intervalo de confianza (hemos marcado también Descriptivas para calcular algunos estadísticos de la muestra). Obtenemos la pantalla siguiente: Por ahora nos fijamos solo en las tres últimas columnas de la tabla superior: el valor “Diferencia de medias” es la media de la muestra (su “diferencia” con 0, que es el Valor de prueba en la columna de la izquierda) y los extremos inferior y superior del intervalo de confianza para la media poblacional del nivel de confianza que hayamos escogdo. La media muestral ha dado 36.8o y el intervalo de confianza del 95% va de 36.8o a 36.9o. Podéis comprobar que coincide (salvo errores de redondeo) con lo que da la fórmula que hemos explicado: al marcar la casilla Descriptivas hemos obtenido el tamaño de la muestra N, la media y la desviación típica (DE, desviación estándar) y podéis calcular que \\(z_{229,0.975}=1.97\\), y tenéis todos los datos necesarios para usar la fórmula. 13.4 Intervalos de confianza para proporciones Supongamos que tenemos una variable Bernoulli \\(X\\) con probabilidad poblacional de éxito \\(p_X\\) desconocida. Queremos calcular un intervalo de confianza para \\(p_X\\). Para hacerlo, tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\), con número de éxitos \\(S\\) y por tanto proporción muestral de éxitos \\(\\widehat{p}_{X}=S/n\\). Explicaremos los tres métodos más populares para calcular este intervalo de confianza: El método exacto de Clopper-Pearson, que se puede aplicar siempre pero suele dar intervalos de confianza más anchos de lo necesario (o dicho de otra manera, de “más confianza” de la que pedíamos). El método aproximado de Wilson, que se puede usar cuando la muestra es grande, digamos que de tamaño 40 o más. Su fórmula se basa en que, por el Teorema Central del Límite, la proporción muestral de muestras aleatorias simples grandes sigue una distribución aproximadamente normal. El método aproximado de Laplace, que es una simplificación del método de Wilson, pero solo se puede usar cuando la muestra es bastante más grande, digamos que de tamaño 100 o más, y la proporción muestral \\(\\widehat{p}_{X}\\) no es muy próxima ni a 0 ni a 1. Es el método más clásico y conocido. Los tres métodos solo valen para muestras aleatorias simples, o al menos que puedan pasar por aleatorias simples. Método “exacto” de Clopper-Pearson Este método se basa en que el número de éxitos \\(S\\) en muestras aleatorias simples de tamaño \\(n\\) de \\(X\\) tiene una distribución conocida: es binomial \\(B(n,p_X)\\). Razonando de manera similar a cómo obteníamos el intervalo para \\(\\mu\\) basado en la t de Student se llega a una fórmula de un intervalo de confianza para \\(p_X\\) que os vamos a ahorrar, ya que nunca se aplica “a mano”. Este método tiene la ventaja de que se puede usar siempre, independientemente del tamaño de la muestra, y es “exacto” porque se basa en la distribución exacta de \\(S\\). Pero tiene algunos inconvenientes: Como los números de éxitos en muestras de tamaño fijo avanzan a saltos (0, 1, 2, 3,…), suele dar intervalos de confianza más anchos de lo necesario. Los intervalos que produce no son de la forma “probabilidad muestral \\(\\pm\\) algo”. Se necesita un ordenador para calcularlo, no basta una calculadora. Con JAMOVI, se calcula en Frecuencias/2 Resultados. Prueba binomial. Ejemplo 13.6 En una muestra de 600 personas de una población, ha habido 8 con una determinada enfermedad X. Queremos calcular un intervalo de confianza del 95% para la prevalencia de esta enfermedad. Para ello, entramos en una variable las frecuencias de éxitos (enfermos) y fracasos (sanos), 8 y 592, respectivamente. Luego, en Frecuencias/2 Resultados. Prueba binomial seleccionamos esta variable y marcamos las casillas Los valores son frecuencias e Intervalos de confianza especificando el nivel de confianza deseado: De esta manera obtenemos los intervalos de confianza de Clopper-Pearson para las proporciones poblacionales tanto de éxitos como de fracasos. En nuestro ejemplo, el de los éxitos es el que queremos: estimamos con un 95% de confianza que la prevalencia de la enfermedad está entre el 0.58% y el 2.61%. Si en vez de tener las frecuencias de enfermos y sanos dispusiéramos de una variable con esta información para cada sujeto de la muestra, seleccionaríamos esta variable y no marcaríamos la casilla Los valores son frecuencias. Método aproximado de Wilson Supongamos ahora que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande, pongamos \\(n\\geqslant 40\\), y proporción muestral de éxitos \\(\\widehat{p}_{X}\\). En estas condiciones, por el Teorema Central del Límite, sabemos que la distribución de \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}} \\] es aproximadamente la de una \\(N(0,1)\\). Por lo tanto \\[ P\\Big(-z_{(1+q)/2}\\leqslant \\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leqslant z_{(1+q)/2}\\Big)\\approx q \\] Despejando \\(p_X\\) como en el cálculo del IC-95% para la \\(\\mu\\) usando la t de Student, obtenemos el resultado siguiente (que no hay que saber, tranquilos): Teorema 13.3 Si \\(n\\) es grande, un IC-\\(q\\) para \\(p_X\\) es aproximadamente: \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}}\\pm z_{(1+q)/{2}}\\cdot \\frac{\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Fijaos en que: Este método no se puede usar con muestras de cualquier tamaño, han de ser lo bastante grandes como para poder invocar el Teorema Central del Límite. El centro del intervalo no es \\(\\widehat{p}_X\\). Se basa en la aproximación a la normal dada por el Teorema Central del Límite, y por lo tanto el intervalo resultante es un intervalo de confianza “aproximado”, no exacto como el de Clopper-Pearson. Esto no es un gran problema, porque total, la muestra usada seguramente tampoco será aleatoria simple. Fórmula de Laplace Supongamos finalmente que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) todavía más grande y que el valor de \\(\\widehat{p}_{X}\\) no es muy próximo ni a 0 ni a 1. Para fijar unas condiciones suficientes, supongamos que: \\(n\\geqslant 100\\). Tanto el número de éxitos, \\(S\\), como el número de fracasos, \\(n-S\\), en la muestra son \\(\\geqslant 10\\). En este caso, en la fórmula del intervalo de Wilson los términos \\(z_{(1+q)/{2}}^2/n\\) son despreciablemente pequeños comparados con los otros. Si los igualamos a 0, obtenemos la fórmula siguiente: Teorema 13.4 En las condiciones explicadas, un IC-\\(q\\) para \\(p_X\\) es aproximadamente \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Esta fórmula es la más popular, y forma parte de la “cultura general” de un científico. De hecho, tiene más de 200 años y precede en más de 100 años a los otros dos métodos. Además, tiene la forma familiar “estimador \\(\\pm\\) cuantil\\(\\times\\)error típico”. Os tenéis que saber la fórmula de Laplace, no hace falta saber las fórmulas de los otros dos métodos. Pero sí cuándo se pueden usar y cuándo no y sus ventajas e inconvenientes. JAMOVI por ahora no incorpora el cálculo de los intervalos de Wilson y de Laplace, pero los podéis calcular en la ventana de su editor de R con las funciones binom.wilson y binom.approx del paquete epitools, respectivamente (y ya que estamos, el intervalo de Clopper-Pearson se obtiene con la función binom.exact). La sintaxis de estas funciones es siempre la misma: binom.lo-que-sea(x,n,conf.level) donde x y n representan, respectivamente, el número de éxitos y el tamaño de la muestra, y conf.level es nuestra \\(q\\), el nivel de confianza en tanto por uno. El valor por defecto de conf.level es 0.95, por lo que no hace falta especificarlo si queréis calcular un IC-95%. El intervalo que se obtiene tiene como extremo inferior el valor lower y extremo superior el valor upper. Así, siguiendo con el Ejemplo 13.6, para calcular los intervalos de confianza de Wilson y de Laplace del 95% para la prevalencia de la enfermedad ejecutaríamos en R/Rj Editor (tras elegir en la ruedecita de opciones de la esquina superior derecha System R): Así que, en resumen, los IC-95% que hemos obtenido son: Clopper-Pearson: [0.0058,0.0261] Wilson: [0.0068,0.0261] Laplace: [0.0042,0.0225] ¿Con cuál nos quedamos? Cuando podemos calcular más de un intervalo de confianza para \\(p_X\\), ¿cuál calculamos? De entrada hay que advertir que si podemos calcular más de un intervalo, seguramente los que podamos calcular darán resultados muy parecidos. Además, recordad que las tres fórmulas solo nos dan “un nivel de confianza \\(q\\)” si se aplican a muestras aleatorias simples, y nuestras muestras casi siempre serán oportunistas, en cuyo caso, si nos ponemos tiquismiquis, no podemos aplicar ninguna. Ni hacer nada de estadística inferencial. Solo un consejo: Si podéis usar la fórmula de Laplace, usadla. Todo el mundo lo conoce, forma parte de la cultura general del científico, y da un intervalo centrado en la proporción muestral. Ejemplo 13.7 En una muestra de 20 pacientes operados de cáncer de próstata con una nueva técnica, ninguno desarrolló complicaciones importantes en las 24 horas siguientes a la operación. ¿Cuál sería un IC-95% para la proporción de pacientes operados con esta técnica nueva que desarrollan complicaciones importantes en las 24 horas siguientes a la operación? Para calcularlo solo podemos usar el método de Clopper-Pearson, y este es uno de los pocos casos en que este intervalo tiene una expresión analítica sencilla. Si en una muestra aleatoria simple de tamaño \\(n\\) de una variable \\(Be(p_X)\\) obtenemos 0 éxitos, el IC-\\(q\\) de Clopper-Pearson para \\(p_X\\) es \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] En nuestro caso, \\(n=20\\), da el intervalo [0,0.1684]. Por lo tanto, estimamos con un 95% de confianza que menos del 16.84% de los pacientes operados con esta técnica nueva desarrollan complicaciones importantes en las 24 horas siguientes a la operación. Con JAMOVI, tras entrar 0 y 20 en la variable A: Cuando se tiene que calcular “a mano” un intervalo de confianza del 95% para una probabilidad \\(p_X\\) a partir de una muestra aleatoria simple donde no ha habido ningún éxito, a menudo se usa la regla siguiente: Regla del 3: Cuando en una muestra aleatoria simple de tamaño \\(n\\) de una variable aleatoria de Bernoulli de parámetro \\(p_X\\) no encontramos ningún éxito, un IC-95% para \\(p_X\\) va, aproximadamente, de 0 a \\(3/n\\). Con esta regla, en nuestro ejemplo con \\(n=20\\) obtendríamos el intervalo [0,3/20]=[0,0.15], no muy lejos del [0,0.1684] que hemos obtenido. Para ver cómo la regla del 3 aproxima el intervalo de Clopper-Pearson, el gráfico siguiente muestra los valores \\(3/n\\) y el extremo superior del IC-95% de Clopper-Pearson a partir de una muestra de tamaño \\(n\\) con 0 éxitos: Si la muestra hubiera sido mayor, pongamos de 50 pacientes y de nuevo 0 complicaciones graves, también podríamos usar el método de Wilson. Calculémoslo con R: binom.wilson(0,50) ## x n proportion lower upper conf.level ## 1 0 50 0 0 0.0713476 0.95 Da el intervalo [0,0.0713]. El método de Clopper-Pearson da en este caso binom.exact(0,50) ## x n proportion lower upper conf.level ## 1 0 50 0 0 0.07112174 0.95 y la regla del 3 da [0,0.06]. El gráfico siguiente muestra los valores \\(3/n\\) y los extremos superiores de los IC-95% de Clopper-Pearson y de Wilson a partir de una muestra de tamaño \\(n\\) (\\(n\\geqslant 40\\) para los intervalos de confianza de Wilson) con 0 éxitos: Los extremos superiores de los intervalos de Clopper-Pearson y Wilson se superponen en este último gráfico. Aunque la muestra de pacientes hubiera sido enorme, yo qué sé, de 30000 pacientes, con 0 casos de complicaciones graves no se puede usar la fórmula de Laplace. De hecho, si la aplicáis con 0 éxitos obtenéis el interval [0,0]. Comprobadlo. Ejemplo 13.8 En un ensayo de un tratamiento de quimioterapia, en una muestra de 100 pacientes tratados, 25 desarrollaron cáncer testicular secundario. ¿Cuál es un IC-95% para la proporción de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular? En este caso podemos usar los tres métodos. Clopper-Pearson, porque se puede usar siempre. Wilson, porque \\(n=100\\geqslant 40\\). Laplace, porque \\(n\\geqslant 100\\), \\(S=25\\geqslant 10\\) y \\(n-S=75\\geqslant 10\\). Vamos a aplicar a mano la fórmula de Laplace, que es la única que es sensato calcular a mano (y es la que os recomendamos usar si podéis). Tenemos que \\(\\widehat{p}_{X}=25/100=0.25\\) y \\(z_{0.975}=1.96\\). Da: \\[ 0.25\\pm 1.96\\sqrt{\\frac{0.25\\cdot 0.75}{100}}=0.25\\pm 0.085\\Rightarrow [0.165, 0.335] \\] Concluimos, con un nivel de confianza del 95%, que entre aproximadamente un 16.5% y un 33.5% de los pacientes tratados con esta quimioterapia desarrollan cáncer testicular. En este caso podríamos decir que estimamos, con un nivel de confianza del 95%, que el porcentaje de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular es del 25% más o menos 8.5 puntos porcentuales. Por si os interesan: El intervalo de Clopper-Pearson da binom.exact(25,100) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1687797 0.3465525 0.95 El intervalo de Wilson da binom.wilson(25,100) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1754521 0.3430446 0.95 Ya que estamos, calculamos el intervalo de Laplace con R: binom.approx(25,100) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1651311 0.3348689 0.95 Da lo mismo que a mano. Como podéis ver, los tres dan muy parecidos, con diferencias en los extremos de un punto porcentual. Cálculo del tamaño de la muestra para fijar el error Llamaremos margen de error (o error, precisión…) de un intervalo de confianza de Laplace a la mitad de su amplitud. En el caso del intervalo de Laplace, este margen de error es lo que sumamos y restamos a la proporción muestral para obtenerlo: \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Fijaos en que el intervalo de confianza de Laplace es \\(\\widehat{p}_X\\pm M\\) y por lo tanto, si contiene el valor real de \\(p_X\\), el error \\(|\\widehat{p}_X-p_X|\\) que cometemos cuando decimos que el valor de \\(p_X\\) es \\(\\widehat{p}_X\\) es como máximo este “margen de error” \\(M\\). Id con cuidado si llamáis precisión a la mitad de la amplitud del intervalo de confianza. ¿Qué será entonces un intervalo “más preciso”? ¿Uno con mayor precisión, es decir, más ancho? ¿O todo lo contrario? Nosotros lo evitaremos. Una pregunta que hay que hacerse al diseñar un estudio es ¿de qué tamaño he de tomar la muestra para garantizar que el margen de error en la estimación sea como máximo un valor dado \\(M_{max}\\)? En el caso del intervalo de Laplace para una proporción, podemos dar un tamaño \\(n\\) que garantice un error máximo dado \\(M_{max}\\) valga lo que valga \\(\\widehat{p}_{X}\\in [0,1]\\). Fijaos en que la función \\(y=p(1-p)\\), con \\(p\\in [0,1]\\), es una parábola cóncava con vértice en su punto \\(p=0.5\\). Por lo tanto, \\(y=p(1-p)\\) toma su valor máximo en \\(p=0.5\\). Así, pues, valga lo que valga \\(\\widehat{p}_{X}\\), siempre pasa que \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leqslant 0.5(1-0.5)=0.5^2 \\] y por lo tanto \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leqslant z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] Así pues, si tomamos \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leqslant M_{max} \\] entonces seguro que \\(M\\leqslant M_{max}\\), independientemente del valor de \\(\\widehat{p}_{X}\\). Por consiguiente, lo que haremos será calcular la \\(n\\) para obtener un margen de error como máximo \\(M_{max}\\) en el caso más desfavorable: cuando el intervalo de confianza es lo más ancho posible, es decir, suponiendo que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geqslant \\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Longrightarrow n\\geqslant \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}} \\right)^2 \\] En resumen: Teorema 13.5 Si \\[ n\\geqslant \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] el margen de error del intervalo de Laplace calculado con una muestra de tamaño \\(n\\) será como máximo \\(M_{max}\\). Ejemplo 13.9 ¿Cuál es el menor tamaño de una muestra que garantiza un margen de error de como máximo 5 puntos porcentuales al estimar una proporción \\(p_X\\) usando un intervalo de confianza de Laplace del 95%? Por el teorema anterior, para garantizar un margen de error máximo \\(M_{max}= 0.05\\) al calcular un IC-95% para una proporción \\(p_X\\) usando la fórmula de Laplace, tenemos que usar una muestra de tamaño \\(n\\) tal que \\[ n\\geqslant \\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{2\\cdot 0.05}\\Bigg)^2=384.16 \\] El menor tamaño que satisface esta condición es \\(n=385\\). La respuesta correcta no es 384, por mucho que 384.16 se redondee a 384. Fijaos en que 384 no es más grande que 384.16. Observad tres cosas: El valor de \\(n\\) solo depende del margen de error deseado y del nivel de confianza, no de la naturaleza del estudio ni de la población. Para garantizar un margen de error de como máximo 5 puntos porcentuales, es suficiente tomar una muestra aleatoria simple de 385 sujetos, tanto si queremos estimar la prevalencia de la diabetes en la India (1400 millones de habitantes) como la proporción de personas tatuadas en Mallorca (menos de 1 millón de habitantes). Tal y como hemos encontrado la \\(n\\), estamos seguros de que si tomamos una muestra como mínimo de este tamaño, el margen de error del intervalo de confianza de Laplace será como máximo \\(M_{max}\\), sea cual sea la muestra. ¡Es de las pocas veces que podemos estar seguros de algo en estadística! El teorema anterior es para el intervalo de Laplace, pero la \\(n\\) seguramente os saldrá muy grande y en este caso el intervalo de Laplace aproxima muy bien los otros dos intervalos si la proporción muestral luego no os sale muy extrema. “Poblaciones finitas” En esta sección hasta ahora hemos usado muestras aleatorias simples. Ya sabemos que si tomamos muestras aleatorias sin reposición y la población es mucho más grande que el tamaño \\(n\\) de las muestras, las fórmulas que hemos dado siguen funcionando (aproximadamente) bien. Pero, ¿qué pasa si tomamos una muestra aleatoria sin reposición y la población no es mucho más grande que la muestra? Cierto es que hay métodos tipo el de Clopper-Pearson que usan que el número de éxitos en muestras aleatorias sin reposición sigue una distribución hipergeométrica, pero son aun más complicados que el de Clopper-Pearson. Lo que se hace cuando se puede es usar la fórmula de Laplace teniendo en cuenta el factor de población finita: Si \\(X\\) una variable aleatoria de Bernoulli \\(Be(p_X)\\) definida sobre una población de tamaño \\(N\\) y tomamos una muestra aleatoria sin reposición de \\(X\\), con \\(n\\geqslant 100\\) y números de éxitos y fracasos \\(\\geqslant 10\\), un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) es, aproximadamente, \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En las condiciones del punto anterior, para obtener un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) con un margen de error \\(M_{max}\\) en el caso más desfavorable (\\(\\widehat{p}_X=0.5\\)) habrá que tomar una muestra de tamaño \\[ n\\geqslant \\frac{Nz_{(q+1)/2}^2}{4(N-1)M_{max}^2+z_{(q+1)/2}^2} \\] Ejemplo 13.10 En una muestra aleatoria sin reposición de 727 estudiantes de la UIB (\\(N=11797\\)), 557 afirmaron haber cometido plagio en algún trabajo durante sus estudios. ¿Cuál sería un intervalo de confianza del 95% para la proporción \\(p_X\\) de estudiantes de la UIB que han cometido plagio en algún trabajo? Una muestra de 727 estudiantes diferentes es muy grande respecto del total de estudiantes de la UIB, por lo que conviene usar la fórmula de Laplace con el factor de población finita: \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] donde \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) y \\(N=11797\\): da \\[ 0.766\\pm 1.96\\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}11797-727}{11797-1}}\\Rightarrow [0.736, 0.796] \\] Estimamos con un nivel de confianza del 95% que entre un 73.6% y un 79.6% de los estudiantes de la UIB han cometido plagio en algún trabajo. Figura 13.4: https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf 13.5 (Bonus track) Otros intervalos de confianza Como os podéis imaginar, hay fórmulas paramétricas para calcular intervalos de confianza (y a veces más de una) para todos los parámetros de interés: varianza, desviación típica, RR, RA, odds ratios, etc. No vamos a dar las fórmulas de todos ellos; en la vida real, los intervalos de confianza se calculan con algún paquete estadístico. Pero al menos vamos a dar dos fórmulas muy comunes y conocidas. 13.5.1 Un intervalo de confianza para la diferencia de proporciones Sean \\(X_1\\) y \\(X_2\\) dos variables Bernoulli de probabilidades poblacionales de éxito \\(p_1\\) y \\(p_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de estas probabilidades, \\(p_1-p_2\\). Para ello, tomamos dos muestras independientes, una de cada variable: Una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de proporción muestral \\(\\widehat{p}_1\\). Una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de proporción muestral \\(\\widehat{p}_2\\). Si las dos muestras son grandes, pongamos cada una de 50 o más sujetos, y las proporciones muestrales no son muy cercanas a 0 o a 1 (para fijar ideas, que en cada muestra haya como mínimo 5 éxitos y 5 fracasos), un IC-\\(q\\) para la diferencia \\(p_1-p_2\\) es, aproximadamente, \\[ \\widehat{p}_1-\\widehat{p}_2 \\pm z_{(q+1)/2}\\cdot \\sqrt{\\frac{n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2}{n_1 +n_2}\\cdot \\frac{n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)}{n_1 +n_2}\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)} \\] Notad que \\(n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) es el número total de éxitos y \\(n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)\\) el número total de fracasos en las dos muestras. Ejemplo 13.11 En un estudio francés sobre la efectividad de la hidroxicloroquina en el tratamiento de la COVID-19 leve o moderada en personas de edad avanzada, participaron 247 pacientes de este grupo de riesgo. Se dividieron al azar en dos grupos de 124 y 123 sujetos. Los del primer grupo fueron tratados con hidroxicloroquina y los del segundo grupo, con un placebo. Se anotó en cada grupo cuántos fallecieron o necesitaron intubación en los 14 días siguientes al inicio del tratamiento (lo resumiremos en “desenlace negativo”). En el grupo tratado con hidroxicloroquina hubo 9 desenlaces negativos y en el grupo del placebo, 8. Llamemos \\(p_1\\) a la probabilidad de que un paciente de edad avanzada con COVID-19 leve o moderada tratado con placebo tenga un desenlace negativo, y \\(p_2\\) a la correspondiente probabilidad para los tratados con hidroxicloroquina. Queremos calcular un IC-95% para la RAR de desenlace negativo con hidroxicloroquina comparado con placebo, es decir, para la diferencia \\(p_1-p_2\\). Las variables de interés son: \\(X_1\\): Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con placebo y miramos si tiene un desenlace negativo; es Bernoulli \\(Be(p_1)\\). \\(X_2\\): Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con hidroxicloroquina y miramos si tiene un desenlace negativo; es Bernoulli \\(Be(p_2)\\). Se tomó una muestra de \\(X_1\\) de tamaño \\(n_1=123\\) y hubo 8 éxitos, de manera que su proporción muestral de éxitos fue \\(\\widehat{p}_1=8/123=0.06504\\), y una muestra de \\(X_2\\) de tamaño \\(n_2=124\\), donde hubo 9 éxitos y por lo tanto su proporción muestral de éxitos fue \\(\\widehat{p}_2=9/124=0.07258\\). El número total de éxitos (es decir, de desenlaces negativos) fue \\(8+9=17\\) y el de fracasos \\(247-17=230\\). Las dos muestras son independientes, ya que los sujetos se asignaron al azar a uno u otro grupo. Suponiendo que las muestras puedan pasar por aleatorias, estamos en condiciones de aplicar la fórmula anterior. Obtenemos \\[ \\begin{array}{l} \\displaystyle 0.06504-0.07258 \\pm 1.96\\cdot \\sqrt{\\frac{17}{247}\\cdot \\frac{230}{247}\\cdot \\Big(\\frac{1}{123}+\\frac{1}{124} \\Big)}\\\\ \\qquad\\qquad =-0.00754\\pm 0.06314\\Rightarrow [-0.0707, 0.0556] \\end{array} \\] Así pues, estimamos con un 95% de confianza que la RAR de desenlace negativo con hidroxicloroquina entre estos pacientes está entre -0.0707 y 0.0556. Es decir, estimamos con una confianza del 95% que el efecto de administrar hidroxicloroquina está entre el aumento en 7.1 puntos porcentuales del riesgo de desenlace negativo y su disminución en 5.6 puntos porcentuales. En particular, no podemos ni afirmar ni descartar que su uso mejore el pronóstico del paciente. Con JAMOVI, podemos calcular este intervalo de confianza en Frecuencias/Muestras independientes: Prueba de asociación de \\(\\chi^2\\) a partir de una tabla de datos que contenga la muestra. En este caso concreto, hemos guardado los datos en la tabla EstudioHCQ.csv que podéis descargar de https://raw.githubusercontent.com/AprendeR-UIB/INREMDN/master/Dades/EstudioHCQ.csv. Contiene las variables Tratamiento que indica el tratamiento (HCQ es la abreviatura de hidroxicloroquina) y DN que indica si hubo desenlace negativo o no. Para calcular el intervalo de confianza anterior, importamos la tabla y cambiamos el orden de los niveles de DN para que 1 vaya antes que 0. A continuación, seleccionamos en Frecuencias/Muestras independientes: Prueba de asociación de \\(\\chi^2\\) las casillas Diferencia de proporciones e Intervalo de confianza, así como Comparar columnas si, como hemos hecho nosotros, hemos definido el Tratamiento como la variable de las columnas: Obtenemos el mismo intervalo de confianza que antes. 13.5.2 Intervalos de confianza para diferencias de medias Sean \\(X_1\\) y \\(X_2\\) dos variables de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de medias \\(\\mu_1-\\mu_2\\). Para ello, tomamos: Una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de media muestral \\(\\overline{X}_1\\). Una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de media muestral \\(\\overline{X}_2\\). Si \\(X_1\\) y \\(X_2\\) son aproximadamente normales o si las muestras usadas son grandes (de nuevo, digamos, ambas de tamaño como mínimo 40), entonces podemos usar un método paramétrico basado en una distribución t de Student, que da un intervalo centrado en la diferencia de medias muestrales, de la forma \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\times\\text{error típico} \\] Pero el número de grados de libertad \\(\\nu\\) a usar en el cuantil y la fórmula del error típico van a depender de dos factores. Por un lado, de que las muestras sean independientes (hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras obtenidas de manera independiente la una de la otra) o apareadas (hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra o hay algún apareamiento explícito entre los sujetos de las dos muestras; en particular, si las muestras son apareadas ha de pasar que \\(n_1=n_2\\)). Y si las muestras son independientes, la fórmula a usar depende de si las varianzas de \\(X_1\\) y \\(X_2\\) son iguales o diferentes. (¿Y cómo podemos saber si son iguales o diferentes? Ya os podéis imaginar que, con un 100% de seguridad, no podremos; pero sí que podemos determinar si son iguales o no con un cierto margen de confianza, es decir, aceptando una pequeña probabilidad de equivocarnos. No os perdáis las próximas lecciones.) Os damos las fórmulas. No hace falta saberlas, pero sí recordar que la fórmula concreta a usar depende de estas condiciones. Supongamos, pues, que \\(X_1\\) y \\(X_2\\) son aproximadamente normales o que \\(n_1,n_2\\geqslant 40\\). Entonces: Si las muestras son apareadas y \\(n_1=n_2=n\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{n-1,(q+1)/2}\\cdot \\frac{\\widetilde{S}_D}{\\sqrt{n}} \\] donde \\(\\widetilde{S}_D\\) es la desviación típica muestral de las diferencias \\(X_1-X_2\\) sobre las parejas de la muestra. Esta fórmula es simplemente la traducción de la fórmula basada en la t de Student del IC-\\(q\\), aplicada a estimar la media \\(\\mu_1-\\mu_2\\) de la variable \\(D=X_1-X_2\\) a partir de una muestra de valores de esta diferencia. Si las muestras son independientes y \\(\\sigma_{X_1}^2=\\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{n_1+n_2-2,(q+1)/2} \\sqrt{\\Big(\\frac{1}{n_1}+\\frac{1}{n_2}\\Big)\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2} {n_1+n_2-2}} \\] donde \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente. Si las muestras son independientes y \\(\\sigma_{X_1}^2\\neq \\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\cdot\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}} \\] donde, de nuevo, \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente, y ahora el número de grados de libertad que tenemos que usar al calcular el cuantil es \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2}{\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} \\] Ejemplo 13.12 Queremos calcular un intervalo de confianza del 95% para la diferencia en la temperatura media de las mujeres y los hombres. Para ello, vamos a usar la tabla de datos que ya usamos en el Ejemplo 13.5. Demos algunos nombres. Las variables aleatorias de interés son: \\(X_F\\): “Tomamos una mujer y le tomamos la temperatura, en grados C”,de media \\(\\mu_F\\) y desviación típica \\(\\sigma_F\\). \\(X_M\\): “Tomamos un hombre y le tomamos la temperatura, en grados C”, de media \\(\\mu_M\\) y desviación típica \\(\\sigma_M\\). Vamos a calcular un IC-95% para \\(\\mu_F-\\mu_M\\). Como ambas muestras son grandes, vamos a usar una fórmula basada en la t de Student. Calculamos con JAMOVI los estadísticos necesarios: Tenemos pues los datos siguientes: Para la muestra de \\(X_F\\), su tamaño es \\(n_F=116\\), su media muestral es \\(\\overline{X}_F=36.9\\) y su varianza muestral es \\(\\widetilde{S}_F^2=0.191\\). Para la muestra de \\(X_M\\), su tamaño es \\(n_M=114\\), su media muestral es \\(\\overline{X}_M=36.75\\) y su varianza muestral es \\(\\widetilde{S}_M^2=0.228\\). Para calcular el IC-95%, necesitamos saber si \\(\\sigma_M^2=\\sigma_F^2\\) o \\(\\sigma_M^2\\neq \\sigma_F^2\\). Vamos a suponer que \\(\\sigma_M^2=\\sigma_F^2\\), es decir, que las temperaturas de las mujeres son “igual de variadas” que las de los hombres, básicamente porque no vemos ningún motivo para que no sea así (bueno, y porque en una próxima lección veremos cómo decidir, con una cierta probabilidad de equivocarnos, si dos varianzas poblacionales son iguales o diferentes, y en concreto concluiremos que, en este caso, podemos aceptar que \\(\\sigma_M^2=\\sigma_F^2\\): mirad el spoiler al final de esta sección). Así que hemos de usar la fórmula para muestras independientes y varianzas iguales: \\[ \\overline{X}_F-\\overline{X}_M\\pm t_{n_F+n_M-2,0.975} \\sqrt{\\Big(\\frac{1}{n_F}+\\frac{1}{n_M}\\Big)\\cdot \\frac{(n_F-1)\\widetilde{S}_F^2+(n_M-1)\\widetilde{S}_M^2} {n_F+n_M-2}} \\] donde \\(t_{n_F+n_M-2,0.975}=t_{228,0.975}=1.97\\). Da \\[ \\begin{array}{l} \\displaystyle 36.9-36.7\\pm 1.97 \\sqrt{\\Big(\\frac{1}{116}+\\frac{1}{114}\\Big)\\cdot \\frac{115\\cdot 0.191+113\\cdot 0.228} {228}}\\\\ \\qquad \\displaystyle = 0.2\\pm 1.97\\cdot 0.06\\Longrightarrow [ 0.037, 0.273] \\end{array} \\] Estimamos con un 95% de confianza que la temperatura media de las mujeres es entre una y dos décimas de grado C más alta que la de los hombres. Con JAMOVI, podemos calcular estos intervalos de confianza a partir de una tabla de datos en T-Tests/Prueba T para muestras independientes (si las muestras son independientes) o T-Tests/Prueba T para muestras apareadas (si las muestras son apareadas). En el primer caso, a parte de Diferencia de medias e Intervalo de confianza, hay que marcar t de Student si suponemos que las varianzas poblacionales son iguales y t de Welch si suponemos que las varianzas poblacionales son diferentes. Por ejemplo, para calcular el intervalo de confianza anterior suponiendo que las varianzas poblacionales de las temperaturas de hombres y mujeres son iguales: (no da exactamente igual a nuestro intervalo por errores de redondeo) y suponiendo que las varianzas poblacionales de las temperaturas de hombres y mujeres son diferentes: No hay apenas diferencia entre los dos intervalos: [0.0363,0.274] contra [0.0362,0.274]. Un pequeño spoiler para introducir el próximo tema. Para decidir, con un cierto nivel de seguridad, si las dos varianzas poblacionales son iguales o diferentes basta marcar en la ventana T-Tests/Prueba T para muestras independientes la casilla Prueba de homogeneidad: en este contexto, homogeneidad significa “igualdad de varianzas poblacionales”. Hay que mirar entonces el resultado p de la tabla “Prueba de Levene para homogeneidad de varianzas” (con el módulo moretests instalado, esta tabla tiene más filas). Esta p es lo que llamaremos el p-valor en el próximo tema. Avanzando acontecimientos, es la probabilidad de obtener varianzas muestrales tan diferentes como las de nuestras muestras si las varianzas poblacionales fueran iguales. Un p-valor pequeño nos permite dudar de que las varianzas poblacionales sean diferentes (porque si fueran iguales sería mucha casualidad obtener varianzas muestrales tan diferentes como las nuestras), mientras que un p-valor grande no aporta evidencia de que sean diferentes y nos hace concluir que son iguales. Como regla general, p-valores por encima de 0.1 se consideran grandes. Así que en este caso, con un p-valor 0.266, podemos aceptar que las varianzas poblacionales de las temperaturas de hombres y mujeres son iguales. 13.6 Test (1) En un estudio transversal sobre una muestra de 500 sujetos representativos de una comunidad, se ha observado una prevalencia de una determinada enfermedad del 20% (IC 95%: 16.5%-23.5%). ¿Cuál de las afirmaciones siguientes es correcta? Si tomamos otra muestra de 500 sujetos de la misma comunidad, hay un 95% de probabilidad de que el intervalo 16.5%-23.5% contenga el porcentaje de sujetos de la muestra que tienen esta enfermedad. Un 95% de los individuos de la comunidad tienen entre el 16.5% y el 23.5% de probabilidad de tener esta enfermedad. La fórmula con la que hemos obtenido el intervalo 16.5%-23.5% produce intervalos que contienen la proporción poblacional de enfermos en un 95% de las ocasiones. La fórmula con la que hemos obtenido el intervalo 16.5%-23.5% produce intervalos que contienen la proporción de enfermos en la muestra en un 95% de las ocasiones. Todas las otras respuestas son falsas. (2) Tomamos una muestra aleatoria simple de tamaño 50 de una variable aleatoria. Calculamos un intervalo de confianza del 90% para la media de la variable aleatoria a partir de esta muestra, da [11.8,12.8]. ¿Qué significa esto? Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor real de la variable. Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor de la media de la muestra usada para calcularlo. Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor de la media muestral de cualquier muestra. Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor real de la media de la variable aleatoria. Ninguna de las respuestas anteriores es correcta. (3) En un estudio transversal sobre una muestra de sujetos representativos de una comunidad, se ha observado una prevalencia de la hipertensión arterial (HTA) del 20% (intervalo de confianza del 95%: 15%-25%). ¿Qué conclusión es la correcta? Se tiene un 95% de seguridad de que entre un 15% y un 25% de los sujetos de la muestra son hipertensos. Se tiene un 95% de seguridad de que entre un 15% y un 25% de los sujetos de la comunidad son hipertensos. Se tiene un 95% de seguridad de que la prevalencia de la HTA en la comunidad es del 20%. La prevalencia real de HTA en la comunidad se sitúa entre el 15% y el 25%. Ninguna de las respuestas anteriores es correcta. (4) Un intervalo de confianza del 99% para la concentración de un determinado metabolito en sangre es [10,12]. De acuerdo con esto, esperamos encontrar fuera de este intervalo: Un 1% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de las concentraciones medias de las muestras grandes (con \\(n\\geqslant 40\\)) Un 99% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de todas las concentraciones en la población Un 99% de todas las concentraciones en la población Ninguna de las anteriores respuestas es correcta (5) En un artículo publican un intervalo de confianza del 95% para una media \\(\\mu\\) calculado con la fórmula basada en la t de Student sobre una muestra de tamaño 100: es [11.8,12.8]. ¿Qué ha valido, aproximadamente, la desviación típica muestral de la muestra? 12.3 2.5 3 6.5 No lo podemos saber a partir de los datos dados (6) En una muestra de 88 estudiantes, se encontró que un 8% consumían bebidas energéticas (IC 95%: 2% a 14%, método de Laplace). ¿Cuál o cuáles de las afirmaciones siguientes son ciertas? Otra muestra del mismo tamaño siempre mostraría una tasa de estudiantes consumidores de bebidas energéticas entre el 2% y el 14%. El 95% del estudiantes tiene una probabilidad de entre el 2% y el 14% de consumir bebidas energéticas. Estamos muy seguros de que entre el 2% y el 14% de los estudiantes consumen bebidas energéticas. Si la muestra hubiera sido de 880 estudiantes y también hubiera tenido un 8% de consumidores de bebidas energéticas, el intervalo de confianza del 95% hubiera sido más estrecho. Sería imposible obtener este IC-95% si la tasa de consumo de bebidas energéticas entre los estudiantes fuera del 20%. (7) Tomamos una muestra aleatoria de 200 residentes de Santa Margalida (con una población de unos 12000 habitantes) para calcular un intervalo de confianza para la proporción de los margalidans que presentan una determinada condición. ¿Cuál o cuáles de las afirmaciones siguientes son verdaderas? Si la muestra es simple, no hay que tener en cuenta el factor de población finita. Aunque la muestra sea simple, hay que tener en cuenta el factor de población finita. Si la muestra no es simple, hay que tener en cuenta el factor de población finita. Una muestra aleatoria sin reposición de tamaño 200 de una población de tamaño 12000 siempre podemos entender que es simple, a efectos de calcular intervalos de confianza de proporciones. Todas las otras respuestas son falsas. (8) Estamos calculando intervalos de confianza para la probabilidad de éxito de una variable de Bernoulli a partir de muestras aleatorias simples del mismo tamaño usando la fórmula de Laplace. Sobre una muestra hemos obtenido una proporción muestral de éxitos \\(\\widehat{p}_X=0.5\\) y sobre otra muestra una proporción muestral de éxitos \\(\\widehat{p}_X=0.7\\). ¿Cuál de los dos intervalos de confianza es más ancho? El calculado con la muestra con \\(\\widehat{p}_X=0.5\\) El calculado con la muestra con \\(\\widehat{p}_X=0.7\\) Como las dos muestras son del mismo tamaño, los dos intervalos tienen la misma amplitud Como las dos muestras son diferentes, no lo podemos saber Ninguna de las respuestas anteriores es correcta (9) Para calcular un intervalo de confianza del 95% para el valor medio \\(\\mu\\) de una población, hemos tomado una muestra aleatoria simple de tamaño 100. Si, con la misma muestra, calculáramos un intervalo de confianza del 99% para \\(\\mu\\), ¿cómo sería este intervalo? Más ancho que el anterior Más estrecho que el anterior Como la muestra es la misma, el intervalo será el mismo Puede pasar cualquier cosa Ninguna de las otras respuestas es correcta (10) Para calcular un intervalo de confianza del 95% para el valor medio de una población, habíamos decidido tomar una muestra aleatoria simple de tamaño 200, pero resulta demasiado costoso, y hemos decidido reducir el tamaño a 100. ¿Tiene esta decisión algún efecto sobre el tamaño del intervalo de confianza? Con 100 el intervalo de confianza seguro que será más ancho que con 200 Con 100 el intervalo de confianza seguro será más estrecho que con 200 Como que el nivel de confianza es el mismo, los intervalos de confianza seguro que tendrán el mismo tamaño Con 100 esperamos que el intervalo de confianza sea más ancho que con 200 Con 100 esperamos que el intervalo de confianza sea más estrecho que con 200 Como que el nivel de confianza es el mismo, esperamos que los intervalos de confianza tengan el mismo tamaño Ninguna de las otras afirmaciones es correcta (11) Con el fin de disminuir el margen de error en la estimación de la media de una variable aleatoria por medio de la media aritmética de una muestra, lo mejor que podemos hacer es (marca una única respuesta): Disminuir la varianza de la variable aleatoria poblacional. Aumentar el nivel de confianza. Disminuir el nivel de confianza. Aumentar el tamaño de la muestra. Reducir el tamaño de la muestra. Eliminar los valores dudosos de la muestra. (12) Un investigador quiere determinar la proporción de estudiantes de secundaria de una determinada comunidad que consumen bebidas energéticas mediante una encuesta a una muestra de estudiantes. Para calcular el tamaño muestral que necesita para su estudio ya dispone de los datos siguientes: tamaño de la población objetivo; porcentaje esperado de estudiantes que no contestarán la encuesta; la precisión con la que desea dar la estimación de la proporción (5 puntos porcentuales); el nivel de confianza (95%). Quiere calcular esta tamaño muestral en el caso más desfavorable. ¿Qué otros datos le faltan? (marcad todas las respuestas correctas): Saber el error estándar de la proporción muestral de estudiantes consumidores de bebidas energéticas. Estimar la desviación típica de la proporción de consumidores de bebidas energéticas. Conocer la proporción de consumidores de bebidas energéticas en el total de la población de la zona de interés. Estimar la proporción de estudiantes consumidores de bebidas energéticas con una pequeña prueba piloto. Como quiere calcular el intervalo de confianza en el caso más desfavorable, ya no le hace falta ningún otro dato. (13) En España hay aproximadamente 43,000 estudiantes universitarios de Medicina. Imaginad que se pasó una encuesta a una muestra aleatoria simple de 200 de ellos y que 198 respondieron que la materia que menos les había gustado había sido la Estadística. Si quisiera calcular un intervalo de confianza para la proporción de estudiantes de Medicina para los que la materia menos favorita es la Estadística a partir de estos datos, ¿qué métodos podría usar? Solo el de Clopper-Pearson Solo el de Clopper-Pearson y el de Wilson El de Clopper-Pearson, el de Wilson y el de Laplace Solo el método de Laplace con el factor de población finita Ninguna de las otras respuestas es correcta (14) Los EE. UU. tienen aproximadamente 330 millones de habitantes. Imaginad que queremos estimar con un 95% de confianza la proporción de ellos que tienen algún tatuaje. ¿Cuántos estadounidenses elegidos al azar tendríamos que entrevistar como mínimo para garantizar un margen de error inferior a 0.05 (5 puntos porcentuales)? Escoge de entre los números siguientes el que creas que más se acerca. Unos 50 Unos 500 Unos 5000 Unos 50,000 Unos 500,000 (15) España tiene un poco más de una décima parte de los habitantes de EEUU. Imaginad que ahora queremos estimar con un 95% de confianza la proporción de españoles que tienen algún tatuaje. El número mínimo de españoles que tendríamos que entrevistar al azar para garantizar un margen de error inferior a 0.05 (marca la continuación correcta): Es menor que el que tendríamos que usar en los EEUU (para estimar la proporción de estadounidenses tatuados con un 95% de confianza y un margen de error inferior a 0.05, se sobreentiende) Es mayor que el que tendríamos que usar en los EEUU Es exactamente el mismo que el que tendríamos que usar en los EEUU Nos faltan datos para establecer su relación con el que tendríamos que usar en los EEUU (16) Para calcular un IC de nivel de confianza \\(q\\) para la media poblacional \\(\\mu\\) de un cierto parámetro con la fórmula basada en la t de Student, hemos tomado una muestra aleatoria simple de 100 individuos con \\(\\overline{x}=2\\) y \\(\\widetilde{s}_X^2=0.8\\). Si ahora usamos otra muestra aleatoria simple de 100 individuos y obtenemos \\(\\overline{x}=3\\) y \\(\\widetilde{s}_X^2=0.6\\), ¿cómo será el IC-\\(q\\) que obtengamos? Igual de ancho que el anterior. Más estrecho que el anterior. Más ancho que el anterior. No podemos saber si el nuevo IC será más ancho, más estrecho o igual de ancho que el anterior. (17) Un artículo de una revista científica informa de que el intervalo de confianza del 95% del nivel medio de colesterol en sangre en los adultos atendidos en un Centro de Salud es 192-208 mg/dl. Se aceptó que la variable tenía una distribución normal y el número de pacientes estudiados fue de 100. ¿Cuáles de las siguientes afirmaciones son verdaderas? Es muy probable que el nivel medio poblacional esté comprendido entre 192 y 208 mg/dl. Si se repitiera el estudio muchas veces, en un 95% de ellas se obtendría una media muestral comprendida entre 192 y 208 mg/dl. El 95% de los adultos de la población tiene un nivel de colesterol comprendido entre 192 y 208 mg/dl. La media muestral encontrada en el estudio es de 200. La desviación típica muestral encontrada en el estudio ha sido aproximadamente 40 o 41. Ninguna de las anteriores respuestas es correcta. (18) Un intervalo de confianza del 95% para la media estimado a partir de una muestra (marca todas las afirmaciones correctas): Es un intervalo en el cual, a largo plazo, caen el 95% de las observaciones. Es una manera de expresar la precisión de la estimación de la media. Es un intervalo que se ha calculado con una fórmula para que incluya la media muestral en el 95% de las ocasiones que la apliquemos a muestras. Es un intervalo que se ha calculado con una fórmula para que incluya la media de la población en el 95% de las ocasiones que la apliquemos a muestras. Es una manera de expresar la variabilidad de un conjunto de observaciones. "],["contrastes-de-hipótesis.html", "Lección 14 Contrastes de hipótesis 14.1 Hipótesis nula y alternativa 14.2 Un ejemplo 14.3 El p-valor 14.4 Tipo de errores 14.5 Ejemplo: El test t 14.6 La potencia de un contraste 14.7 Intervalo de confianza de un contraste 14.8 Ajuste de p-valores 14.9 Resultados estadísticamente significativos versus resultados clínicamente significativos 14.10 Test", " Lección 14 Contrastes de hipótesis En muchas situaciones, queremos tomar una decisión sobre si podemos aceptar o rechazar una hipótesis relativa al valor de un parámetro en una o varias poblaciones, y para tomar esta decisión, nos basamos en los datos de una muestra. Por ejemplo: Queremos saber si una moneda está trucada a favor de cara. Para decidirlo, la lanzamos varias veces y contamos cuántas caras salen. Queremos decidir si un tratamiento nuevo A es más efectivo que el tratamiento anterior B en la curación de una enfermedad X. Para decidirlo, llevamos a cabo un ensayo clínico, tratando con A un grupo de enfermos y con B otro grupo de enfermos, y comparamos la tasa de curación de los tratamientos sobre estos dos grupos. El método estadístico que se usa para aceptar o rechazar una hipótesis a partir de los datos de una muestra recibe el nombre de contraste de hipótesis. 14.1 Hipótesis nula y alternativa En un contraste de hipótesis, se comparan siempre dos hipótesis alternativas: la hipótesis nula \\(H_{0}\\) y la hipótesis alternativa \\(H_{1}\\). Se suele plantear formalmente \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{hipótesis nula}\\\\ H_{1}:\\text{hipótesis alternativa} \\end{array} \\right. \\] En los contrastes de hipótesis de este curso: La hipótesis nula \\(H_{0}\\) es “no hay diferencia”, “no pasa nada”, “no hay nada extraño” o el equivalente en el contexto del contraste: La moneda es equilibrada (50% de probabilidad de cara). Los tratamientos A y B son igual de efectivos en la curación de la enfermedad X. La hipótesis alternativa \\(H_{1}\\) plantea la diferencia de la que buscamos evidencia: La moneda está trucada a favor de cara (más del 50% de probabilidad de cara). A es más efectivo que B en la curación de la enfermedad X. Estamos dispuestos a aceptar \\(H_0\\) por defecto: que no hay diferencia, que no pasa nada. Por defecto, estamos dispuestos a aceptar que la moneda es equilibrada (la mayoría lo son, ¿no?). Por defecto, estamos dispuestos a aceptar que los dos tratamientos son igual de efectivos (si tomáis dos sustancias cualesquiera y las administráis a enfermos de X, lo más normal es que ninguna de los dos tenga efecto alguno, y por lo tanto que las dos sean igual de (in)efectivas). Si obtenemos evidencia suficiente de que \\(H_0\\) es falsa, rechazaremos \\(H_0\\) en favor de \\(H_1\\) y concluiremos que \\(H_1\\) es verdadera. ¿Qué quiere decir “obtener evidencia suficiente de que \\(H_0\\) es falsa”? Pues que las pruebas obtenidas hacen que \\(H_0\\) sea inverosímil (difícil de creer) por comparación con \\(H_1\\): Tendremos evidencia de que la moneda está trucada a favor de cara si en nuestra serie de lanzamientos la proporción de caras es tan grande que se nos hace muy difícil creer que la moneda sea equilibrada. Tendremos evidencia de que A es más efectivo que B en la curación de X si en nuestro ensayo la tasa de curación de la enfermedad X con el tratamiento A es tan superior a la de B que se nos hace muy difícil creer que los dos tratamientos tengan la misma efectividad. Si no obtenemos evidencia suficiente de que \\(H_0\\) es falsa, es decir, si nuestros datos son razonablemente compatibles con \\(H_0\\), no podremos rechazarla. Entonces, aceptaremos la hipótesis nula. Aceptaremos que la moneda no está trucada a favor de cara si en nuestra serie de lanzamientos la proporción de caras no es lo bastante grande como para hacernos dudar de que sea equilibrada Aceptaremos que A es igual de efectivo que B en la curación de X si en nuestro ensayo la tasa de curación de la enfermedad X con el tratamiento A no es lo bastante superior a la de B como para hacernos dudar de que los dos tratamientos sean igual de efectivos. Rechazamos la hipótesis nula en favor de la alternativa cuando sería mucha casualidad obtener los resultados obtenidos si la hipótesis nula fuera cierta en vez de la alternativa. Si rechazamos \\(H_0\\) en favor de \\(H_1\\), en general no será porque hayamos demostrado que \\(H_0\\) sea imposible, ni siquiera que sea improbable: tan solo resultará difícil de creer a la vista de los resultados de nuestro experimento. Por ejemplo, si en una secuencia de 30 lanzamientos de una moneda obtenemos todas las veces cara, seguramente lo consideraremos evidencia de que la moneda está trucada, pero no demuestra que la moneda esté trucada. Sí, cuesta creer que no esté trucada, pero no es imposible: la moneda podría ser equilibrada y por puro azar nosotros haber tenido esta racha de caras. Y tampoco podemos decir que sea improbable que sea equilibrada, puesto que no sabemos calcular \\[ P(\\text{La moneda es equilibrada}\\,|\\,\\text{30 caras en 30 lanzamientos}). \\] Lo que sabemos calcular es \\[ P(\\text{30 caras en 30 lanzamientos}\\,|\\,\\text{La moneda es equilibrada}) \\] que vale \\(0.5^{30}=9.3\\cdot 10^{-10}\\) (y por lo tanto, de media, aproximadamente en una de cada mil millones de veces que se efectúan 30 lanzamientos seguidos de una moneda equilibrada, se obtienen 30 caras: no es imposible). Si aceptamos la hipótesis nula es porque no encontramos motivos para dudar de ella, pero no habremos encontrado evidencia de que sea verdadera ni habremos demostrado que sea probable (y posible en principio lo es siempre). Por ejemplo, si en una secuencia de 4 lanzamientos de una moneda obtenemos 2 caras, tendremos que aceptar que la moneda es equilibrada. Pero podría ser que estuviera ligeramente sesgada hacia cara y no haberse notado en una secuencia tan corta de lanzamientos. Así que no hemos encontrado evidencia de que sea equilibrada, simplemente no lo podemos descartar (como tampoco podemos descartar que la probabilidad de cara sea, por ejemplo, 0.50001). Ejemplo 14.1 En un juicio (en el que el acusado es inocente si no se demuestra lo contrario) se busca evidencia suficiente de que el acusado es culpable. Por lo tanto, esta es la hipótesis alternativa. Por otro lado, que “no pase nada” significa que el acusado es inocente: casi todo el mundo es inocente del cargo concreto que se juzga en ese momento. Esta será la hipótesis nula. Por lo tanto, el contraste es: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El acusado es inocente}\\\\ H_{1}:\\text{El acusado es culpable} \\end{array} \\right. \\] En el juicio se aportan pruebas, y: Si el jurado las encuentra lo bastante incriminatorias, “más allá de toda duda razonable”, declara culpable el acusado (rechaza \\(H_0\\) en favor de \\(H_1\\)). Si el jurado no las encuentra lo bastante incriminatorias, lo considera no culpable (no rechaza \\(H_{0}\\)). Observad que considerar no culpable no es lo mismo que demostrar que es inocente: simplemente, se considera que el acusado no es culpable porque no se ha encontrado evidencia suficiente de que sea culpable. Ejemplo 14.2 Un examen es un contraste de hipótesis. En este caso, “no pasa nada” significa que el estudiante es como si no hubiera ido al curso, no ha aprendido nada, y por lo tanto esta es la hipótesis nula. Con el examen buscamos evidencia de que el estudiante ha aprendido la materia, por lo tanto esta será la hipótesis alternativa. Así pues, el contraste es: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El estudiante no sabe la materia}\\\\ H_{1}:\\text{El estudiante sabe la materia} \\end{array} \\right. \\] Tomamos una muestra de los conocimientos del estudiante (el estudiante hace el examen), y: Si hay suficiente evidencia en favor de \\(H_1\\) (si el examen le sale lo bastante bien), rechazamos \\(H_0\\): decidimos que el estudiante sabe la materia, aprueba la asignatura. Si no hay evidencia suficiente en favor de \\(H_1\\) (si el examen no le sale lo bastante bien), nos quedamos con \\(H_0\\): concluimos que el estudiante no ha aprendido la materia, suspende la asignatura. Ejemplo 14.3 Una prueba diagnóstica de una enfermedad es un contraste de hipótesis. En este caso, “no pasa nada” significa que la persona no tiene la enfermedad, y por lo tanto esta es la hipótesis nula. Con la prueba diagnóstica buscamos evidencia de que tiene la enfermedad, por lo tanto esta será la hipótesis alternativa. Es decir, el contraste es \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{La persona no tiene la enfermedad}\\\\ H_{1}:\\text{La persona sí tiene la enfermedad} \\end{array} \\right. \\] Ejemplo 14.4 Si leemos la noticia siguiente en el diario, puede que nos preguntemos si es verdad que las mujeres practican menos deporte que los hombres. Esta pregunta la podemos plantear de muchas maneras: ¿Toda mujer hace cada día menos horas de deporte que cualquier hombre? Si tomo una mujer y un hombre al azar, ¿es más probable que ella practique menos deporte que él? ¿La mayoría de las mujeres hacen cada día menos horas de deporte que la mayoría de los hombres? ¿La proporción de practicantes de deporte entre las mujeres es menor que entre los hombres? ¿La media semanal de veces que las mujeres practican deporte es menor que la de los hombres? ¿La media semanal de horas que las mujeres practican deporte es menor que la de los hombres? … Cada una de estas preguntas se traduciría en un contraste de hipótesis diferente. Puesto que aquí estamos tratando contrastes sobre parámetros poblacionales (medias, proporciones, etc.), podríamos plantear alguno de los tres últimos contrastes. Vamos a centrarnos en la última cuestión, sobre medias semanales de horas de deporte. En este contraste, las variables poblacionales de interés son: \\(X_m\\): “Tomo una mujer y calculo su número medio de horas semanales de deporte”, con media \\(\\mu_m\\): la media semanal de horas de deporte de las mujeres (la media de las medias de horas semanales de deporte de todas las mujeres es la media de horas semanales de deporte de las mujeres). \\(X_h\\): “Tomo un hombre y calculo su número medio de horas semanales de deporte”, con media \\(\\mu_h\\): la media semanal de horas de deporte de los hombres. El contraste que queremos realizar es Hipótesis nula: no hay diferencia entre las medias semanales de horas de deporte de hombres y mujeres. Hipótesis alternativa: la media semanal de horas de deporte de las mujeres es menor que la de los hombres. Es decir \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&lt;\\mu_h \\end{array} \\right. \\] El procedimiento para llevar a cabo este contraste sería: Tomaríamos muestras aleatorias de mujeres y de hombres y les preguntaríamos sus hábitos de práctica de deporte. Calcularíamos la media muestral \\(\\overline{X}_m\\) de horas semanales de deporte de las mujeres de la muestra. Calcularíamos la media muestral \\(\\overline{X}_h\\) de horas semanales de deporte de los hombres de la muestra. Si \\(\\overline{X}_m\\) fuera mucho menor que \\(\\overline{X}_h\\), lo tomaríamos como evidencia de que \\(\\mu_m&lt;\\mu_h\\). Si \\(\\overline{X}_m\\) no fuera mucho menor que \\(\\overline{X}_h\\), no podríamos rechazar que \\(\\mu_m=\\mu_h\\). ¿Qué significa “\\(\\overline{X}_m\\) mucho menor que \\(\\overline{X}_h\\)”? Una opción, que podríamos importar del tema anterior, seria calcular un intervalo de confianza del 95% para \\(\\mu_m-\\mu_h\\) a partir de la muestra. Entonces: Si este intervalo de confianza estuviera totalmente a la izquierda del 0, con un 95% de confianza podríamos concluir que \\(\\mu_m&lt;\\mu_h\\) (porque tendríamos un 95% de seguridad de que el valor real de la diferencia \\(\\mu_m-\\mu_h\\) pertenece a un intervalo de números estrictamente negativos). En caso contrario (si contuviera el 0 o si estuviera totalmente a la derecha del 0), con un 95% de confianza no podríamos concluir que \\(\\mu_m&lt;\\mu_h\\). Aquí querremos afinar un poco más que lo del “nivel de confianza”, por lo que el procedimiento será algo más complicado. Básicamente, la idea es que vamos a usar diferentes fórmulas para calcular los intervalos de confianza según la forma de la hipótesis alternativa, ya lo veremos. Antes de cerrar esta sección, queremos destacar algunas advertencias. Las hipótesis de los contrastes son sobre parámetros de las poblaciones, NO sobre estadísticos de las muestras. En el ejemplo anterior, las hipótesis del contraste comparaban las medias poblacionales de horas semanales de deporte de las mujeres y los hombres, no las medias de horas semanales de deporte de las mujeres y los hombres de la muestra. Para comparar las medias muestrales no nos hace falta un contraste de hipótesis: las calculamos y punto. En cambio, como no podemos calcular las medias semanales de horas de deporte de todas las mujeres y de todos los hombres, nos vemos obligados a hacer un contraste de hipótesis. La falta de evidencia en favor de \\(H_1\\) no es evidencia en favor de \\(H_0\\). Si no podemos asegurar que las mujeres practiquen menos deporte que los hombres (porque no hayamos encontrado evidencia a favor de esta hipótesis), esto no significará que hayamos encontrado evidencia de que los hombres y las mujeres practiquen la misma cantidad de deporte o de que las mujeres practiquen más deporte. Lo que significará es que la evidencia en favor de \\(H_1\\) no ha sido lo bastante contundente como para poder concluir que esta es la hipótesis verdadera y por lo tanto aceptamos que no hay diferencia en la media semanal de horas de deporte de ambos sexos. De hecho, (casi) nunca podremos encontrar evidencia de la hipótesis nula. Si por ejemplo en nuestro estudio hubiéramos encontrado que \\(\\overline{X}_m=\\overline{X}_h\\), esto sería compatible con la hipótesis nula \\(\\mu_m=\\mu_h\\), y por eso no la podríamos rechazar. Pero no aportaría evidencia de que \\(\\mu_m=\\mu_h\\), puesto que seguramente también sería compatible, por ejemplo, con \\(\\mu_m=\\mu_h+0.0007\\) (las mujeres hacen, de media, un minuto más de deporte a la semana que los hombres) y por lo tanto, si “ser compatible” fuera lo mismo que “aportar evidencia”, nuestros datos aportarían evidencia de que dos hipótesis que se contradicen son verdaderas. La pregunta (el contraste) se plantea a priori a partir de hipótesis o suposiciones previas, antes de obtener los datos. No vale cambiar de contraste a la vista de los datos obtenidos. Tenemos que plantear la pregunta antes de recoger la muestra. Si estamos interesados en el contraste \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&lt;\\mu_h \\end{array} \\right. \\] y obtenemos que \\(\\overline{X}_m\\) es mucho mayor que \\(\\overline{X}_h\\) en nuestra muestra, concluimos que no tenemos evidencia de que \\(\\mu_m&lt;\\mu_h\\) y punto. Sería hacer trampas decir: “No hemos encontrado evidencia de que las mujeres practiquen menos deporte que los hombres, pero si con estos mismos datos realizamos el contraste \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&gt;\\mu_h \\end{array} \\right. \\] sí que obtenemos evidencia de que ellas practican más deporte que ellos.” De esto se dice ir a pescar evidencias o también torturar los datos: obtener unos datos y buscar de qué dan evidencia. Es mala praxis científica. Cualquier conjunto de datos, si lo torturamos lo suficiente, acaba dando evidencia de algo. Escoged la hipótesis alternativa en función de lo que buscáis evidencia. No confundáis \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m&lt;\\mu_h \\end{array} \\right. \\] con \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_m=\\mu_h\\\\ H_{1}:\\mu_m \\neq \\mu_h \\end{array} \\right. \\] que traduce la pregunta “Los hombres y las mujeres, ¿practican deporte un número diferente de horas a la semana, de media?” Reglas para elegir \\(H_0\\) y \\(H_1\\) en este curso: \\(H_0\\) siempre se tiene que definir mediante una igualdad. \\(H_1\\) es la hipótesis de la que buscamos evidencia, y se tiene que definir mediante algo “estricto”: Hipótesis unilateral (one-sided; también de una cola, one-tailed): definida con &lt; o con &gt;. Hipótesis bilateral (two-sided; también de dos colas, two-tailed): definida con \\(\\mathbf{\\neq}\\). Los contrastes toman el nombre del tipo de hipótesis alternativa: contraste unilateral, contraste de dos colas, etc. 14.2 Un ejemplo Tenemos una moneda, y creemos que está trucada en favor de cara. Queremos contrastarlo. Aquí la variable aleatoria \\(X\\) que nos interesa es “lanzamos la moneda y miramos si sale cara”, que es de Bernoulli con probabilidad de éxito (es decir, probabilidad de sacar cara con nuestra moneda) \\(p_{\\mathit{Cara}}\\). La hipótesis nula será que la moneda no está trucada (no le pasa nada a nuestra moneda), y la alternativa que la moneda está trucada en favor de cara. En términos de \\(p_{\\mathit{Cara}}\\), el contraste es \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Ejemplo 14.5 Supongamos que lanzamos la moneda 3 veces y obtenemos 3 caras. ¿Es evidencia suficiente de que está trucada a favor de cara? Llamemos \\(S_3\\) a la variable aleatoria “Número de caras en 3 lanzamientos de esta moneda.” Si la moneda no está trucada, \\(S_3\\) es binomial \\(B(3,0.5)\\), y por lo tanto \\[ P(S_3=3)=0.5^{3}=0.125. \\] El resultado obtenido no es muy improbable con una moneda equilibrada: pasa, de media, en 1 de cada 8 secuencias de 3 lanzamientos. Por lo tanto, no vamos a considerarlo evidencia suficiente de que la moneda esté trucada. Aceptamos que la moneda es equilibrada. A este tipo de procedimiento, usar la distribución binomial del número de éxitos en una muestra aleatoria simple de una variable aleatoria de Bernoulli para contrastar un valor de su probabilidad poblacional de éxito, lo llamaremos un test binomial. Ejemplo 14.6 Supongamos que ahora lanzamos la moneda 10 veces y obtenemos 10 caras. ¿Es evidencia suficiente de que está trucada a favor de cara? Llamemos \\(S_{10}\\) a la variable aleatoria “Número de caras en 10 lanzamientos.” Si la moneda no está trucada, \\(S_{10}\\) es \\(B(10,0.5)\\) y por lo tanto \\[ P(S_{10}=10)=0.5^{10}=0.001 \\] El resultado obtenido es bastante improbable si la moneda no está trucada: si la moneda fuera equilibrada, de media solo en 1 de cada 1000 secuencias de 10 lanzamientos obtendríamos 10 caras. Es decir: El resultado de nuestro experimento sería muy raro si la moneda fuera equilibrada, lo que nos hace dudar de que sea equilibrada. Lo consideramos evidencia de que está trucada. Observad el razonamiento que hemos efectuado. Tenemos una hipótesis nula y una alternativa, realizamos un experimento y obtenemos un resultado que es muy improbable si la hipótesis nula es verdadera. Una de dos: O la hipótesis nula es falsa. O la hipótesis nula es verdadera y ha pasado algo muy raro. ¿Qué es lo más sensato concluir? Teniendo en cuenta que las cosas muy raras no suelen pasar, lo más sensato es concluir que la hipótesis nula es falsa. El procedimiento que hemos seguido en los dos ejemplos anteriores ha sido el siguiente: Hemos planteado el contraste: \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Hemos recogido una muestra aleatoria simple de valores: la secuencia de lanzamientos. Hemos elegido un estadístico de contraste con distribución de probabilidades conocida cuando \\(H_0\\) es verdadera: en nuestro caso, el número de caras. Hemos calculado el valor de este estadístico sobre nuestra muestra. Hemos calculado la probabilidad de que el estadístico tome el valor observado si \\(H_0\\) es verdadera. Si esta probabilidad es muy pequeña, lo tomamos como evidencia de que \\(H_1\\) es verdadera. Si no es lo bastante pequeña, no consideramos que hayamos obtenido evidencia de que \\(H_0\\) sea falsa y \\(H_1\\) verdadera. Bien, esto es lo que hemos hecho, pero no es del todo correcto. En los puntos (5) y (6) decimos que: “Calculamos la probabilidad de que el estadístico tome el valor observado si \\(H_0\\) es verdadera y si es muy pequeña, lo consideramos evidencia de que \\(H_1\\) es verdadera.” ¿Seguro que queremos hacer esto? Supongamos que, en el contraste anterior, lanzamos la moneda 10 veces y obtenemos 10 cruces. ¿Es evidencia suficiente de que está trucada en favor de cara? Obviamente no lo puede ser, pero la probabilidad es la misma que antes: \\[ P(S_{10}=0)=0.5^{10}=0.001 \\] En muchos casos, la probabilidad de obtener exactamente lo que hemos obtenido puede ser muy pequeña, independientemente de lo que hayamos obtenido. Por ejemplo, supongamos que lanzamos la moneda 10000 veces y obtenemos 5000 caras. Si la moneda es equilibrada, el número de caras seguirá una distribución binomial \\(B(10000,0.5)\\) y la probabilidad de obtener 5000 caras será \\[ \\binom{10000}{5000}0.5^{10000}=0.008 \\] muy pequeña, pero está claro que si la mitad de lanzamientos dan cara, no se puede considerar evidencia de que la moneda esté trucada. O, más exagerado aún, si el estadístico de contraste es una variable continua, la probabilidad de que tome un valor concreto, el que sea, es 0 por definición. Más pequeño imposible, pero no siempre rechazaremos la hipótesis nula. Figura 14.1: “Null hypothesis” (https://xkcd.com/892/ (CC-BI-NC 2.5)) Así que: En realidad, en (5) se calcula la probabilidad de que, si \\(H_0\\) es verdadera, el estadístico tome un valor tan extremo o más, en el sentido de \\(H_1\\), que el obtenido. A esta probabilidad la llamamos el p-valor. En nuestro ejemplo de la moneda, como la hipótesis nula es \\(p_{\\mathit{Cara}}= 0.5\\) y la hipótesis alternativa es \\(p_{\\mathit{Cara}}&gt; 0.5\\), el p-valor es la probabilidad de que, si \\(p_{\\mathit{Cara}}= 0.5\\), el número de caras sea mayor o igual que el obtenido en nuestra muestra. En los dos ejemplos anteriores concretos, donde obteníamos 3 caras en 3 lanzamientos y 10 caras en 10 lanzamientos, era lo mismo pedir que el número de caras fuera igual al obtenido y pedir que el número de caras fuera mayor o igual que el obtenido, porque en los dos experimentos hemos obtenido el número máximo posible de caras; por ejemplo, sacar 3 o más caras en 3 lanzamientos es exactamente lo mismo que sacar 3 caras en 3 lanzamientos. Pero en general esto no será así. Ejemplo 14.7 Volvamos a nuestro contraste \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Supongamos que lanzamos la moneda 10 veces y obtenemos 7 caras. ¿Es evidencia suficiente de que está trucada a favor de cara? Seguimos llamando \\(S_{10}\\) a la variable aleatoria “Número de caras en 10 lanzamientos”. Si la moneda no está trucada, \\(S_{10}\\) es \\(B(10,0.5)\\). Como la hipótesis alternativa es \\(p_{\\mathit{Cara}}&gt; 0.5\\), “obtener un número de caras tan extremo o más que el que hemos obtenido en el sentido de la hipótesis alternativa” es sacar tantas caras como las que hemos obtenido o más, es decir sacar 7 o más caras. Por lo tanto \\[ \\text{p-valor}=P(S_{10}\\geqslant 7)=0.172 \\] Un número de caras igual o superior al obtenido no es muy improbable si la moneda no está trucada: pasaría en 1 de cada 6 secuencias de 10 lanzamientos. Por lo tanto, como es bastante compatible con el equilibrio de la moneda, no lo podemos considerar evidencia de que esté trucada a favor de cara. Ejemplo 14.8 Tenemos una moneda, y ahora creemos que está trucada a favor de cruz. Queremos contrastarlo. Planteado en términos de \\(p_{\\mathit{Cara}}\\), el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}: p_{\\mathit{Cara}}&lt; 0.5 \\end{array} \\right. \\] Imaginad que lanzamos la moneda 10 veces y obtenemos 1 cara. ¿Es suficiente evidencia de que \\(p_{\\mathit{Cara}}&lt; 0.5\\)? Seguimos llamando \\(S_{10}\\) a la variable aleatoria “Número de caras en 10 lanzamientos de esta moneda.” Si la moneda no está trucada, \\(S_{10}\\) es \\(B(10,0.5)\\). Ahora, como \\(H_{1}\\) es \\(p_{\\mathit{Cara}}&lt; 0.5\\), “obtener un número de caras tan extremo o más que el que hemos obtenido, en el sentido de la hipótesis alternativa” es sacar tantas caras como las que hemos obtenido o menos, es decir sacar como máximo 1 cara. Por lo tanto \\[ \\text{p-valor}=P(S_{10}\\leqslant 1)=0.01 \\] Un resultado tan o más extremo como el obtenido es muy improbable si \\(p_{\\mathit{Cara}}= 0.5\\): de media, solo ocurre en 1 de cada 100 secuencias de 10 lanzamientos. Lo podemos considerar evidencia de que la moneda sí que está trucada en favor de cruz. 14.3 El p-valor El p-valor de un contraste es la probabilidad de que, si la hipótesis nula es verdadera, el estadístico de contraste tome en una muestra aleatoria simple del mismo tamaño que la nuestra un valor tan o más extremo, en el sentido de la hipótesis alternativa, que el obtenido con la muestra usada para realizar el contraste. Lo repetimos, poniendo énfasis en los componentes fundamentales de la definición. El p-valor es: La probabilidad de que, si la hipótesis nula es verdadera, el estadístico de contraste tome en una muestra aleatoria simple del mismo tamaño que la nuestra un valor tan o más extremo, en el sentido de la hipótesis alternativa, que el obtenido con nuestra muestra. Ejemplo 14.9 Supongamos que en el contraste de las medias semanales de horas de deporte de hombres y mujeres del Ejemplo 14.4 usamos como estadístico de contraste la diferencia entre las medias muestrales \\(\\overline{X}_m-\\overline{X}_h\\) (no será así: ¡solo es un ejemplo!), que hemos tomado muestras de 50 mujeres y de 50 hombres, y que la diferencia de medias muestrales ha sido -1.2. Entonces, el p-valor del contraste es La probabilidad de que, si la hipótesis nula es verdadera, si \\(\\mu_m=\\mu_h\\), es decir, si los hombres y las mujeres practican de media el mismo número de horas de deporte a la semana, el estadístico de contraste tome en una muestra aleatoria simple del mismo tamaño que la nuestra el valor de \\(\\overline{X}_m-\\overline{X}_h\\), es decir, de la diferencia entre las medias muestrales de horas semanales de deporte en las mujeres y en los hombres, en una muestra aleatoria formada por 50 mujeres y 50 hombres, sea un valor tan o más extremo, en el sentido de la hipótesis alternativa, menor o igual (porque la hipótesis alternativa es \\(\\mu_m&lt;\\mu_h\\), es decir \\(\\mu_m-\\mu_h&lt;0\\)) que el obtenido con nuestra muestra. que el de nuestra muestra, -1.2. En resumen, el p-valor seria en este caso La probabilidad de que, si \\(\\mu_m=\\mu_h\\), el valor de \\(\\overline{X}_m-\\overline{X}_h\\) en una muestra aleatoria de 50 mujeres y 50 hombres sea menor o igual que -1.2. Si esta probabilidad es muy pequeña, la muestra obtenida es poco consistente con la hipótesis nula y por lo tanto concluiremos que la hipótesis alternativa es verdadera. Si, en cambio, esta probabilidad no es muy pequeña, la muestra obtenida es consistente con la hipótesis nula y por lo tanto no podremos rechazar que \\(H_0\\) sea verdadera. El p-valor NO es: La probabilidad de que \\(H_0\\) sea verdadera condicionada a nuestro resultado. La probabilidad de que \\(H_1\\) sea falsa condicionada a nuestro resultado. Es al revés: El p-valor es la probabilidad de nuestro resultado (o uno más extremo) condicionada a que \\(H_0\\) sea verdadera. Por lo tanto, el p-valor es una evidencia indirecta inversa de \\(H_1\\): Cuanto menor sea el p-valor, más raro sería lo que hemos obtenido si \\(H_0\\) fuera verdadera y \\(H_1\\) falsa, y por lo tanto más evidencia aporta de que \\(H_0\\) no puede ser verdadera y de que la verdadera es \\(H_1\\). Por ejemplo, si el p-valor de un contraste es 0.03: Significa que, si \\(H_0\\) fuera verdadera, el estadístico de contraste valdría en 3 de cada 100 muestras algo al menos tan extremo, en el sentido de \\(H_1\\), como lo que hemos obtenido. ¿Lo encontráis poco? Lo tomáis como evidencia de que \\(H_0\\) es falsa y \\(H_1\\) verdadera. ¿No lo encontráis poco? No tenéis evidencia para rechazar que \\(H_0\\) sea verdadera. Pero no significa que: La probabilidad de que \\(H_0\\) sea verdadera es 0.03. \\(H_0\\) es verdadera un 3% de las veces. En un contraste de hipótesis no obtenemos ninguna información directa sobre la probabilidad de \\(H_0\\) o de \\(H_1\\). Ejemplo 14.10 Tenemos una moneda y nos preguntamos si está trucada; a favor de cara o a favor de cruz, nos da igual, solo si está trucada o es equilibrada. Planteado en términos de la probabilidad de sacar cara \\(p_{\\mathit{Cara}}\\), el contraste que queremos realizar ahora es \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}\\neq 0.5 \\end{array} \\right. \\] Supongamos que la lanzamos 10 veces y obtenemos 9 caras. ¿Es evidencia suficiente de que está trucada? Como en la sección anterior, sea \\(S_{10}\\) la variable “Número de caras en 10 lanzamientos”. Si \\(p_{\\mathit{Cara}}= 0.5\\), \\(S_{10}\\) es \\(B(10,0.5)\\). Si la hipótesis nula fuera verdadera, esperaríamos sacar 5 caras y 5 cruces. Como la hipótesis alternativa es \\(H_{1}:p_{\\mathit{Cara}}\\neq 0.5\\), ahora “obtener un resultado tan o más extremo, en el sentido de la hipótesis alternativa, que el obtenido” es sacar un resultado que se aleje tanto, o más, de 5 caras y 5 cruces como el que hemos obtenido. Es decir, sacar al menos 9 caras o al menos 9 cruces, o lo que es el mismo, sacar o bien 9 o más caras, o bien 1 o menos caras. Por lo tanto, el p-valor es \\[ \\begin{array}{l} P(S_{10}\\geqslant 9\\text{ o }S_{10}\\leqslant 1) =P(S_{10}\\geqslant 9) + P(S_{10}\\leqslant 1)\\\\ \\qquad = 0.0107+0.0107=0.0214 \\end{array} \\] Por lo tanto, si la moneda no estuviera trucada, un resultado tan alejado de “mitad caras, mitad cruces” como el nuestro se obtendría en alrededor de 1 de cada 50 secuencias de 10 lanzamientos. ¿Es evidencia suficiente de que esté trucada? La respuesta corta es que seguramente sí. La respuesta larga es que depende de cuánto estemos dispuestos a arriesgarnos a rechazar la hipótesis nula cuando es verdadera. 14.4 Tipo de errores La comparación entre la realidad y la conclusión de un contraste da lugar a cuatro situaciones posibles, resumidas en la tabla siguiente: Si \\(H_0\\) es la hipótesis verdadera en la realidad y nosotros decidimos que \\(H_1\\) es verdadera: La conclusión del contraste es errónea. Lo llamaremos un error de tipo I, error \\(\\alpha\\) o falso positivo. Denotaremos por \\(\\alpha\\) la probabilidad de cometer un error de tipo I, es decir, de rechazar \\(H_0\\) si es verdadera, y la llamaremos el nivel de significación: \\[ \\alpha=P(\\text{Rechazar } H_0\\,|\\, H_0\\text{ verdadera}). \\] Si \\(H_1\\) es la hipótesis verdadera en la realidad y nosotros aceptamos \\(H_0\\): La conclusión del contraste es errónea. Lo llamaremos un error de tipo II, error \\(\\beta\\) o falso negativo. Denotaremos por \\(\\beta\\) la probabilidad de cometer un error de tipo II, es decir, de aceptar \\(H_0\\) si \\(H_1\\) es verdadera: \\[ \\beta=P(\\text{Aceptar } H_0\\,|\\, H_1\\text{ verdadera}). \\] Si \\(H_1\\) es la hipótesis verdadera en la realidad y nosotros decidimos rechazar \\(H_0\\) en favor de \\(H_1\\): La conclusión del contraste es correcta. Lo llamaremos un verdadero positivo. La probabilidad de acertar con un verdadero positivo es \\(1-\\beta\\) y la llamaremos la potencia: \\[ 1-\\beta=P(\\text{Rechazar } H_0\\,|\\, H_1\\text{ verdadera}). \\] Si \\(H_0\\) es la hipótesis verdadera en la realidad y nosotros la aceptamos: La conclusión del contraste es correcta. Lo llamaremos un verdadero negativo. La probabilidad de acertar con un verdadero negativo es \\(1-\\alpha\\) y la llamaremos el nivel de confianza: \\[ 1-\\alpha=P(\\text{Aceptar } H_0\\,|\\, H_0\\text{ verdadera}). \\] En el contexto de un contraste de hipótesis, Un resultado positivo es rechazar la hipótesis nula y decidir que la alternativa es la verdadera (hemos encontrado algo). Un resultado negativo es aceptar la hipótesis nula (no hemos encontrado nada y nos quedamos con la hipótesis nula). Repetimos: El nivel de significación de un contraste es la probabilidad de que, si la hipótesis nula es verdadera, nosotros nos equivoquemos y la rechacemos en favor de la alternativa: \\[ \\alpha=P(\\text{Rechazar } H_0\\,|\\, H_0\\text{ verdadera}). \\] La potencia de un contraste es la probabilidad de que, si la hipótesis alternativa es verdadera, nosotros lo detectemos y rechacemos la hipótesis nula en favor de la alternativa: \\[ 1-\\beta=P(\\text{Rechazar } H_0\\,|\\, H_1\\text{ verdadera}). \\] Ejemplo 14.11 En un test de embarazo, el contraste que se realiza es: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{No estás embarazada}\\\\ H_{1}:\\text{Estás embarazada} \\end{array} \\right. \\] Ejemplo 14.12 En un juicio, donde se tiene que declarar un acusado inocente o culpable, el contraste era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El acusado es inocente}\\\\ H_{1}:\\text{El acusado es culpable} \\end{array} \\right. \\] Se pueden cometer dos errores: Error de tipo I: Declarar culpable a un inocente. Error de tipo II: Declarar inocente a un culpable. Es peor el error de tipo I, conviene minimizar la probabilidad de cometerlo. Por eso solo se declara a alguien culpable cuando las pruebas “lo demuestran más allá de toda duda razonable”. Ejemplo 14.13 En un examen, el contraste era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{El estudiante no sabe la materia}\\\\ H_{1}:\\text{El estudiante sabe la materia} \\end{array} \\right. \\] Los errores que pueden darse son: Que apruebe un estudiante que no sabe la materia Que suspenda un estudiante que sí sabe la materia ¿Cuál es el de tipo I y cuál el de tipo II? ¿Cuál creéis que es peor? Recordad la interpretación de una prueba diagnóstica como un contraste de hipótesis (Ejemplo 14.3). Interpretad su especificidad y sensibilidad en términos de \\(\\alpha\\) y \\(\\beta\\). Normalmente, se considera peor cometer un error de tipo I que cometer un error de tipo II. Por lo tanto, el objetivo primario en un contraste es encontrar una regla de decisión que tenga poca probabilidad \\(\\alpha\\) de error de tipo I. Pero también querríamos minimizar la probabilidad \\(\\beta\\) de error de tipo II. El problema es que cuando hacemos que \\(\\alpha\\) disminuya, \\(\\beta\\) suele aumentar, porque al hacer más difícil rechazar la hipótesis nula, aumenta el riesgo de no rechazarla aunque sea falsa. ¿Qué se suele hacer? Se da una regla de decisión para el nivel de significación \\(\\alpha\\) deseado. Después, se toma el tamaño \\(n\\) adecuado de la muestra para que la potencia sea la deseada. Es costumbre (pero solo eso, una costumbre, no un dogma de fe) tomar \\(\\alpha=0.05\\), una probabilidad de 1 entre 20: algo menos que la probabilidad de sacar 4 caras seguidas con una moneda equilibrada. Figura 14.2: No adoraréis falsos dioses. Tomando este \\(\\alpha=0.05\\), aceptamos una probabilidad de equivocarnos rechazando \\(H_0\\) en favor de \\(H_1\\) de 0.05. Es decir, asumimos que, de media, nos vamos a equivocar en 1 de cada 20 veces en que la hipótesis nula sea verdadera. 14.5 Ejemplo: El test t La concentración media de calcio en plasma en hombres sanos de 22 a 44 años es de 2.5 mmol/l. Nos preguntamos si los hombres jóvenes con diabetes tienen una concentración de calcio en plasma mayor que estos 2.5 mmol/l. Traducimos esta cuestión en un contraste de hipótesis sobre la concentración media de calcio en plasma en los hombres jóvenes con diabetes, a la que llamaremos \\(\\mu\\): La hipótesis nula será que no hay diferencia entre \\(\\mu\\) y la concentración media de calcio en plasma en los hombres jóvenes sanos, es decir, que \\(\\mu=2.5\\) La hipótesis alternativa es de lo que buscamos evidencia: que \\(\\mu&gt;2.5\\). Por lo tanto, el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt;2.5 \\end{array} \\right. \\] Llamemos \\(X\\) a la variable aleatoria “Tomamos un hombre diabético de 22 a 44 años y le medimos la concentración de calcio en plasma en mmol/l”, cuya media hemos llamado \\(\\mu\\). Vamos a suponer en esta sección que esta variable \\(X\\) sigue una ley normal. En una muestra de 40 diabéticos de esta franja de edad, se obtuvo una concentración media de calcio en plasma de \\(\\overline{x}=3.2\\) mmol/l con una desviación típica muestral \\(\\widetilde{s}=1.5\\). Vamos a suponer que podemos considerar esta muestra de diabéticos jóvenes como aleatoria simple. Nos encontramos ante un caso particular de la situación siguiente. Tenemos una variable aleatoria poblacional \\(X\\) normal de media \\(\\mu\\) y planteamos el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt;\\mu_0 \\end{array} \\right. \\] para un valor concreto \\(\\mu_0\\). Queremos tomar una decisión a partir de una muestra aleatoria simple. La idea es que rechazaremos \\(H_0\\) en favor de \\(H_1\\) si la media muestral es mucho mayor que \\(\\mu_0\\): tanto, que sería muy improbable que fuera así de grande si la media poblacional fuera exactamente \\(\\mu_0\\). El problema es que no sabemos calcular \\(P(\\overline{X}-\\mu_0)\\) si solo sabemos que \\(X\\) es normal de media \\(\\mu_0\\), porque no sabemos la distribución de \\(\\overline{X}\\) (sabemos que será normal de media \\(\\mu_0\\), pero desconocemos su desviación típica). Por lo tanto tenemos que usar otro estadístico de contraste, \\(\\overline{X}\\) no funcionará. Llegados a este punto, nos acordamos de que si \\(H_0\\) es verdadera, es decir, si la media de \\(X\\) es \\(\\mu_0\\), entonces \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] tiene distribución \\(t_{n-1}\\). Y podemos traducir que “\\(\\overline{X}\\) sea mucho mayor que \\(\\mu_0\\)” en que “\\(T\\) sea mucho mayor que 0”. Entonces, la idea que guiará el procedimiento para tomar una decisión en este contraste será la siguiente: Rechazaremos \\(H_0\\) en favor de \\(H_1\\) si este estadístico de contraste \\(T\\) toma un valor “muy grande” sobre la muestra. La definición precisa de “muy grande” dependerá del valor de \\(\\alpha\\) que queramos tomar, es decir, de la probabilidad de cometer un error de tipo I que estemos dispuestos a asumir: cuanto menor queramos que sea \\(\\alpha\\), mayor tendrá que ser la evidencia a favor de \\(\\mu&gt;\\mu_0\\), es decir, mayor tendrá que ser \\(T\\). Aquí vamos a tomar el valor usual \\(\\alpha=0.05\\). Sea \\(T_0\\) el valor que toma el estadístico de contraste \\(T\\) en nuestra muestra. Rechazaremos \\(H_{0}\\) si \\(T_0\\) es mayor que un cierto umbral \\(L_0\\), que determinamos a partir de \\(\\alpha\\): \\[ \\begin{array}{l} \\alpha = P(\\text{Rechazar } H_{0}\\,|\\, H_{0} \\text{ cierta})=P(T&gt; L_0)\\\\ \\qquad\\quad \\Longrightarrow 1-\\alpha= P(T\\leqslant L_0)\\Longrightarrow L_0= t_{n-1,1-\\alpha} \\end{array} \\] Por lo tanto, para que el nivel de significación del contraste sea \\(\\alpha\\), Rechazaremos \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) Llamaremos a esta regla una regla de rechazo para este tipo de contraste. Volvamos a nuestro ejemplo de los jóvenes diabéticos \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt; 2.5 \\end{array} \\right. \\] Si \\(\\alpha=0.05\\) y \\(n=40\\), el umbral a partir del cual rechazamos \\(H_0\\) es \\(t_{n-1,1-\\alpha}=t_{39,0.95}=1.685\\). En nuestra muestra tenemos que \\(\\overline{x}=3.2\\), \\(\\widetilde{s}=1.5\\) y \\(n=40\\), por lo tanto el estadístico de contraste vale \\[ T_0=\\frac{3.2-2.5}{1.5/\\sqrt{40}}=2.95 \\] Como 2.95&gt;1.685, concluimos con un nivel de significación del 5% que el nivel medio de calcio en sangre en los jóvenes diabéticos es mayor que en los jóvenes sanos. Vamos a ver cómo entra en juego el p-valor. Recordad que rechazamos \\(H_0\\) cuando \\(T_0&gt;t_{n-1,1-\\alpha}\\): \\[ \\begin{array}{l} \\text{Rechazamos $H_0$} \\Longleftrightarrow T_0&gt; t_{n-1,1-\\alpha}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; P(T\\geqslant t_{n-1,1-\\alpha})\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; 1-P(T\\leqslant t_{n-1,1-\\alpha})=1-(1-\\alpha)=\\alpha\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt;\\alpha \\end{array} \\] I ahora notad que \\(P(T\\geqslant T_0)\\) es la probabilidad de que, si \\(H_0\\) es verdadera, el estadístico de contraste \\(T\\) tome un valor tan o más extremo, en el sentido de \\(H_1: \\mu&gt;2.5\\), que el obtenido en nuestra muestra, \\(T_0\\): ¡es el p-valor del contraste! Por lo tanto, tenemos otra regla de rechazo, equivalente a la anterior: Rechazaremos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) En nuestro ejemplo, ya hemos calculado \\(T_0=2.95\\). Entonces, \\[ \\text{p-valor} =P(T\\geqslant 2.95)=P(t_{39}\\geqslant 2.95)=0.003 \\] Como el p-valor es menor que 0.05: Concluimos con un nivel de significación del 5% que el nivel medio de calcio en plasma de los jóvenes diabéticos es mayor que el de los jóvenes sanos. Esto se suele expresar diciendo que Hemos obtenido evidencia estadísticamente significativa de que el nivel medio de calcio en plasma de los jóvenes diabéticos es mayor que el de los jóvenes sanos. A este tipo de procedimiento para comparar la \\(\\mu\\) de una variable con un valor dado \\(\\mu_0\\), usando que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] sigue una distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\), se le llama un test t. En la próxima lección explicaremos cuándo se puede usar. Fijaos en que nuestra conclusión ha sido que “concluimos con un nivel de significación del 5% que el nivel medio de calcio en sangre de los jóvenes diabéticos es mayor que el de los jóvenes sanos.” Por lo tanto, aceptamos una probabilidad del 5% de cometer un falso positivo. Si en realidad el nivel medio de calcio en sangre de los jóvenes diabéticos fuera el mismo que el de los sanos, la probabilidad que tendríamos de equivocarnos y concluir que el nivel medio de calcio en sangre de los jóvenes diabéticos es mayor que el de los sanos es del 5%. Que tengamos un 5% de probabilidad de equivocarnos significa que, si la hipótesis nula es verdadera, un 5% de las muestras aleatorias de 40 diabéticos sanos dan un valor de \\(T\\) que nos hace rechazar la hipótesis nula. Ejemplo 14.14 Vamos a estudiar esta tasa de aciertos por medio de una simulación. Primero supondremos que el nivel medio real es 2.5, y simularemos la probabilidad de error de tipo I. Como estamos realizando el contraste con nivel de significación 0.05, esperamos alrededor de un 5% de errores de tipo I. Para fijar ideas, modelaremos la población de jóvenes diabéticos por medio de una variable aleatoria normal \\(N(2.5,0.5)\\). La \\(\\sigma=0.5\\) nos la hemos inventado. Damos el código R de la simulación, por si la queréis repetir en casa. Cada simulación dará resultados diferentes, pero en general serán muy parecidos a los nuestros. mu0=2.5 sigma0=0.5 El umbral \\(L_0\\) para \\(n=40\\) y \\(\\alpha=0.05\\) es \\(t_{39,0.975}\\): L0=qt(0.95,39) L0 ## [1] 1.684875 La función estadístico siguiente toma una muestra aleatoria de tamaño \\(n\\) de una variable \\(N(\\mu, \\sigma)\\) y calcula el estadístico de contraste \\(T\\): estadístico=function(n,mu,sigma){ muestra=rnorm(n,mu,sigma) (mean(muestra)-mu0)/(sd(muestra)/sqrt(n)) } Ahora, repetimos 200 veces el proceso de tomar una muestra aleatoria de tamaño 40 de nuestra población y calcular la \\(T\\) correspondiente. Llamamos Tes al vector de estos valores de \\(T\\): Tes=replicate(200,estadístico(40,mu0,sigma0)) Tes ## [1] -0.204556115 0.551277014 0.317804933 -1.916424317 0.228799593 ## [6] -0.636252541 0.546424036 -0.411971051 -0.424224911 1.184281984 ## [11] -1.372747727 0.319514212 -0.485567240 0.724620331 -1.114121167 ## [16] 1.002994827 -0.892700484 -2.394044325 -1.024911510 -1.273715103 ## [21] -0.676221781 0.012311445 1.558797931 -0.189208386 1.137960594 ## [26] -0.362377491 -1.342997649 0.100980325 0.532357160 -0.370579439 ## [31] 0.577851111 -0.047777832 0.684704147 -1.208505741 -1.329676807 ## [36] -0.284045263 -0.284095079 -0.291495898 -0.878941168 1.051862629 ## [41] 1.579509611 1.251686082 2.045852094 -2.360865854 -0.103192516 ## [46] 0.390701261 1.880219725 -0.018662794 -3.024762654 0.123696814 ## [51] 0.761344572 -0.090605574 -2.687031800 0.801886366 -0.536807420 ## [56] -0.028474151 0.196027879 0.682146866 1.411321489 -0.188707738 ## [61] 1.546524165 -0.347908999 -0.026022121 0.209821139 0.805317582 ## [66] 1.314081240 -0.839884569 0.396920453 0.660980262 -0.906549698 ## [71] -0.359463173 -0.147452173 -0.064257189 -2.155846414 -0.139568976 ## [76] -0.376455346 2.092808159 -0.709729535 -1.463534383 -1.809695988 ## [81] 0.742383769 -0.622674376 0.983232702 0.788220841 -0.154184656 ## [86] -1.161571197 -0.004649001 -0.438892198 -0.423543531 -0.264518977 ## [91] 0.767939038 -0.182387180 0.080963916 0.320526506 0.280413272 ## [96] 0.513633868 -1.638150471 -0.296678393 -0.543844147 0.392508189 ## [101] -1.998219688 -1.462626783 -1.047438984 -1.051544062 0.875209713 ## [106] -2.259121522 -0.001964387 -0.373639492 0.666057937 0.789694009 ## [111] -0.702070906 3.201760850 0.722601940 0.197681171 -0.628662655 ## [116] 2.445684957 -1.564835664 -0.421947252 -0.115222019 -0.670212416 ## [121] 1.074994408 -1.144731548 0.014513287 -0.045690803 1.767038039 ## [126] -0.490172630 -0.515288612 -0.723240119 0.114766130 2.233403900 ## [131] 1.044936465 -0.924690832 1.853218655 -1.907551408 0.126266762 ## [136] -0.688907166 1.117818143 1.821936572 0.329612552 0.071381075 ## [141] -0.021639874 0.676769124 0.520849057 -2.006704343 -0.914341584 ## [146] 0.585164132 0.655106533 0.119263816 0.262166125 0.803028099 ## [151] -0.980923973 0.771922952 1.409751739 -0.831274271 0.946192097 ## [156] -0.069357657 -2.266986664 1.339021435 -0.749638232 0.908952239 ## [161] 0.413367570 2.009701264 0.455159446 -1.104914158 -0.643085983 ## [166] -0.429874411 -0.196858070 -1.429470266 -2.181882962 1.466635278 ## [171] 0.742815143 1.213190128 1.085521457 -1.497524599 -0.672070568 ## [176] 0.262390233 0.852553576 0.390132290 1.692839873 -1.970368198 ## [181] -1.173300556 -0.076807106 0.969328371 -0.284565211 -2.289453979 ## [186] 0.535255778 -2.899705754 0.156836454 1.670103115 0.568690995 ## [191] -2.543506854 -0.577244792 -1.696047276 0.991672787 -0.582753120 ## [196] -2.219149723 0.109210103 0.279098618 -0.847558940 -1.390283286 Finalmente, calculamos la proporción de veces que la \\(T\\) ha dado un valor mayor que el umbral \\(L_0\\), es decir, la proporción de veces que rechazamos la hipótesis nula \\(\\mu=2.5\\) y que por lo tanto cometemos un error de tipo I. p.error.Tipo.I=length(which((Tes&gt;L0)==TRUE))/200 p.error.Tipo.I ## [1] 0.055 Hemos cometido un 5.5% de errores de tipo I, muy cercano al 5% “poblacional” (en el conjunto de todas las muestras aleatorias que pudiéramos tomar). Ahora vamos a suponer que el nivel medio real es estrictamente mayor que 2.5, y vamos a simular los errores de tipo II, para ver con qué frecuencia los cometemos. Para empezar, generamos al azar un vector de 100 \\(\\mu\\)’s entre 2.6 y 3, de manera que todos los valores tengan la misma probabilidad de salir. mus=runif(100,2.6,3) Para cada \\(\\mu_i\\) de este vector, tomaremos como “población de diabéticos” una variable \\(N(\\mu_i,0.5)\\). A continuación, para cada una de estas poblaciones, repetiremos 200 veces el proceso de tomar una muestra aleatoria simple de tamaño 40 de esta población y calcular la \\(T\\) correspondiente. Después, para cada población, miraremos la proporción de veces que la \\(T\\) ha dado menor o igual que el umbral \\(L_0\\), es decir, la proporción de veces que aceptaríamos la hipótesis nula \\(\\mu=2.5\\) y que por lo tanto cometeríamos un error de tipo II. Organizamos todas estas proporciones en un vector que llamamos p.error.Tipo.II. p.error.Tipo.II=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístico(40,mus[j],sigma0)) p.error.Tipo.II[j]=length(which((Tes&lt;=L0)==TRUE))/200 } p.error.Tipo.II ## [1] 0.015 0.275 0.055 0.005 0.495 0.040 0.000 0.005 0.420 0.090 0.000 0.085 ## [13] 0.245 0.000 0.195 0.000 0.080 0.000 0.525 0.000 0.000 0.410 0.140 0.000 ## [25] 0.000 0.330 0.050 0.000 0.010 0.610 0.460 0.575 0.000 0.000 0.005 0.000 ## [37] 0.110 0.000 0.000 0.000 0.000 0.000 0.015 0.115 0.020 0.000 0.000 0.000 ## [49] 0.040 0.015 0.000 0.005 0.000 0.000 0.045 0.190 0.000 0.005 0.560 0.085 ## [61] 0.000 0.000 0.595 0.015 0.005 0.000 0.000 0.000 0.500 0.000 0.085 0.195 ## [73] 0.370 0.645 0.015 0.000 0.245 0.130 0.140 0.590 0.315 0.325 0.000 0.105 ## [85] 0.000 0.085 0.000 0.460 0.000 0.000 0.005 0.175 0.065 0.390 0.000 0.000 ## [97] 0.010 0.000 0.000 0.000 En algunos casos no hemos cometido ningún error de tipo II, y en otros, en más de la mitad de las veces. La proporción media de errores de tipo II ha sido: mean(p.error.Tipo.II) ## [1] 0.1179 Si tomamos muestras más grandes, la probabilidad de error de tipo II disminuye. Comprobémoslo repitiendo este segundo experimento con muestras de tamaño 400. p.error.Tipo.II.400=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístico(400,mus[j],sigma0)) p.error.Tipo.II.400[j]=length(which((Tes&lt;=L0)==TRUE))/200 } mean(p.error.Tipo.II.400) ## [1] 2e-04 Por si no os habéis encontrado nunca con la notación que ha usado R para dar este resultado, es la llamada notación científica y se usa para expresar números muy grandes o muy pequeños. La e significa “multiplica el número que me precede por 10 elevado al número que me sigue”. Así, 2e-04 significa \\(2\\times 10^{-4}\\), o sea, 0.0002. Multiplicando por 10 el tamaño de las muestras, hemos bajado de una tasa de errores de tipo II del 11.79% al 0.02%. Recordad que la potencia de un contraste es la probabilidad de no cometer un error de tipo II. Hemos visto que tomando muestras más grandes, la proporción de errores de tipo II ha disminuido. Esto es general: Si fijamos el nivel de significación, cuanto mayores son las muestras, mayor es la potencia del contraste. Volvemos a la situación general en la que tenemos una variable aleatoria \\(X\\) normal \\(N(\\mu,\\sigma)\\) y queremos comparar \\(\\mu\\) con cierto valor \\(\\mu_0\\) y supongamos que ahora buscamos evidencia de que \\(\\mu&lt;\\mu_0\\), de manera que el contraste es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] En este caso, el p-valor es \\(P(T\\leqslant T_0)\\) y, razonando exactamente igual que antes, obtenemos las dos reglas de rechazo equivalentes siguientes: Rechazaremos \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) Rechazaremos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) ¿Y qué pasa si ahora buscamos evidencia de que \\(\\mu\\) es diferente de \\(\\mu_0\\)? Es decir, si nos planteamos el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\ \\neq \\mu_0 \\end{array} \\right. \\] En este caso, rechazaremos \\(H_{0}\\) cuando \\(\\overline{X}\\) es muy diferente de \\(\\mu_0\\) y esto lo traducimos en que rechazaremos \\(H_{0}\\) cuando el valor absoluto de \\(T_0\\), \\(|T_0|\\), sea mayor que un cierto umbral \\(L_0\\), que determinamos a partir de \\(\\alpha\\) como antes: \\[ \\begin{array}{l} \\alpha = P(\\text{Rechazar } H_{0}| H_{0} \\text{ verdadera})=P(|T|&gt; L_0)\\\\ \\hphantom{\\alpha} = P(T&lt; -L_0\\text{ o } T&gt;L_0)= P(T&lt; -L_0)+P(T&gt;L_0)\\\\ \\hphantom{\\alpha} =2P(T&gt;L_0) \\text{ (por la simetría de $t_{n-1}$)}\\\\ \\Longrightarrow \\alpha/2=P(T&gt;L_0)= 1-P(T\\leqslant L_0) \\\\ \\Longrightarrow P(T\\leqslant L_0)=1-\\alpha/2\\Longrightarrow L_0= t_{n-1,1-\\alpha/2} \\end{array} \\] Por lo tanto, en un contraste bilateral con nivel de significación \\(\\alpha\\), tenemos la regla de rechazo siguiente: Rechazaremos \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) En este caso, el p-valor será la probabilidad de que \\(T\\) tome un valor tan o más extremo que \\(T_0\\) en el sentido de la hipótesis alternativa, es decir, más lejos de 0 que \\(T_0\\): mayor que \\(|T_0|\\) o menor que \\(-|T_0|\\): \\[ \\text{p-valor} =P(T\\leqslant -|T_0|)+P(T\\geqslant |T_0|)=2 P(T\\geqslant |T_0|). \\] Fijaos en que usamos que, por la simetría de las variables t de Student, \\(P(T\\leqslant -|T_0|)=P(T\\geqslant |T_0|)\\). Por lo tanto, \\[ \\begin{array}{l} \\text{Rechazamos $H_0$} \\Longleftrightarrow |T_0|&gt;t_{n-1,1-\\alpha/2}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant |T_0|)&lt;{\\alpha}/{2}\\\\ \\qquad\\Longleftrightarrow 2 P(T\\geqslant |T_0|)&lt;\\alpha\\\\ \\qquad \\Longleftrightarrow \\text{p-valor} &lt; \\alpha \\end{array} \\] Así pues, en un contraste bilateral con nivel de significación \\(\\alpha\\) también tenemos la regla de rechazo: Rechazaremos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) En resumen, en un contraste de una media \\(\\mu\\) usando un test t sobre una muestra de tamaño \\(n\\) y nivel de significación \\(\\alpha\\): Si \\(H_1:\\mu&gt; \\mu_0\\): Rechazamos \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) El p-valor es \\(P(T\\geqslant T_0)\\) Rechazamos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) Si \\(H_1:\\mu&lt; \\mu_0\\): Rechazamos \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) El p-valor es \\(P(T\\leqslant T_0)\\) Rechazamos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) Si \\(H_1:\\mu\\neq \\mu_0\\): Rechazamos \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) El p-valor es \\(2P(T\\geqslant |T_0|)\\) Rechazamos \\(H_0\\) si el p-valor es menor que \\(\\alpha\\) Siempre, en todos los contrastes y no solo en los tests t, se rechaza la hipótesis nula en favor de la alternativa si el p-valor es menor que el nivel de significación. Ejemplo 14.15 Sea \\(X\\) una variable poblacional normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Tomamos una muestra aleatoria simple de \\(n=25\\) observaciones y obtenemos \\(\\overline{x}=20.7\\) y \\(\\widetilde{s}=1.8\\). ¿Qué decidimos? El estadístico de contraste que usaremos es \\[ T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}} \\] con \\(\\mu_0=20\\) y \\(n=25\\). Su valor en nuestra muestra es \\[ T_0=\\dfrac{20.7-20}{{1.8}/{\\sqrt{25}}}=1.944 \\] El p-valor es \\[ P(T\\geqslant 1.944)=P(t_{24}\\geqslant 1.944)=0.032 \\] Decisión: Como el p-valor es menor que 0.05, rechazamos \\(H_0\\) y concluimos (con \\(\\alpha=0.05\\)) que \\(\\mu&gt;20\\). Es decir, hemos obtenido evidencia estadísticamente significativa de que \\(\\mu&gt;20\\). Ejemplo 14.16 Sea \\(X\\) una variable poblacional normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] con un nivel de significación de 0.01. Con la misma muestra aleatoria simple del ejemplo anterior, ¿qué decidimos? El p-valor es el mismo que antes, 0.032, porque el contraste y la muestra son los mismos. Como este p-valor es mayor que 0.01, no podemos rechazar \\(H_0\\) con \\(\\alpha=0.01\\) y tenemos que aceptar que \\(\\mu=20\\). Con este nivel de significación, no hemos obtenido evidencia de que \\(\\mu&gt;20\\). Fijaos en que para reducir la probabilidad de equivocarnos rechazando \\(H_0\\) si es verdadera, facilitamos aceptarla “por si acaso”. Ejemplo 14.17 Sea \\(X\\) una variable poblacional normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&lt; 20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Con la misma muestra aleatoria simple de los ejemplos anteriores (\\(n=25\\), \\(\\overline{x}=20.7\\), \\(\\widetilde{s}=1.8\\)), ¿qué decidimos? El estadístico de contraste y su valor \\(T_0\\) son el mismos que antes. p-valor \\[ P(T\\leqslant 1.944)=P(t_{24}\\leqslant 1.944)=0.968 \\] Decisión: Como el p-valor es mayor que 0.05, no podemos rechazar \\(H_0\\) y tenemos que aceptar que \\(\\mu=20\\). Es decir, no hemos obtenido evidencia estadísticamente significativa de que \\(\\mu&lt;20\\). Vamos a ver, ¿cómo queríais que hubiéramos encontrado evidencia de que \\(\\mu&lt;20\\) si nos ha salido una media muestral 20.7, mayor que 20? No hacía falta hacer ningún cálculo (y exponernos a equivocarnos), bastaba razonar un poco. Ejemplo 14.18 Sea \\(X\\) una variable poblacional normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Con la misma muestra aleatoria simple de los ejemplos anteriores, ¿qué decidimos? Recordemos que \\(n=25\\), \\(\\overline{x}=20.7\\) y \\(\\widetilde{s}=1.8\\). El estadístico de contraste valía \\(T_0=1.944\\). Ahora el p-valor es \\[ 2\\cdot P(T\\geqslant 1.944)=2\\cdot P(t_{24}\\geqslant 1.944)=0.064 \\] Como el p-valor es mayor que \\(\\alpha\\), no podemos rechazar \\(H_0\\): no podemos afirmar con \\(\\alpha=0.05\\) que \\(\\mu\\neq 20\\). Es decir, no hemos obtenido evidencia estadísticamente significativa de que \\(\\mu\\neq 20\\). ¿Cómo puede ser que, con la misma muestra y mismo nivel de significación, podamos concluir que \\(\\mu&gt; 20\\) pero no podamos concluir que \\(\\mu \\neq 20\\)? ¿Acaso \\(\\mu&gt; 20\\) no implica que \\(\\mu \\neq 20\\)? Veamos, si hubiéramos demostrado que seguro que \\(\\mu&gt; 20\\), está claro que esto implicaría que \\(\\mu \\neq 20\\). Pero habíamos llegado a la conclusión de que \\(\\mu&gt; 20\\) asumiendo una cierta probabilidad de cometer un error de tipo I, y ahora nos preguntamos si podemos decidir que \\(\\mu \\neq 20\\) asumiendo el mismo riesgo de equivocarnos. En esta situación las reglas de la lógica aristotélica ya no funcionan. Fijaos en que, en realidad, lo que pasa es que encontraríamos evidencia de que \\(\\mu \\neq 20\\) si \\(T\\) fuera muy grande o muy pequeño. Por lo tanto, en el contraste bilateral tenemos dos fuentes de error de tipo I: que por puro azar \\(T\\) nos salga muy grande o que nos salga muy pequeño. En cambio, solo encontraremos evidencia de que \\(\\mu&gt; 20\\) si \\(T\\) es muy grande, y por consiguiente en el contraste unilateral tenemos una sola fuente de error de tipo I. Entonces, para garantizar la misma probabilidad de error de tipo I, tenemos que ser mucho más exigentes en el contraste bilateral, donde nos podemos equivocar de dos maneras diferentes, que en el unilateral. Por eso es más fácil rechazar la hipótesis nula en un contraste unilateral que en uno bilateral. Ejemplo 14.19 Sea \\(X\\) una variable poblacional normal. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu \\neq 20 \\end{array} \\right. \\] con un nivel de significación de 0.05. Tomamos una muestra aleatoria simple de \\(n=25\\) observaciones y obtenemos \\(\\overline{x}=19\\) y \\(\\widetilde{s}=1.8\\). ¿Qué decidimos? El estadístico de contraste \\[ T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}} \\] ahora vale \\[ T_0=\\dfrac{19-20}{{1.8}/{\\sqrt{25}}}=-2.778 \\] El p-valor es \\[ 2P(T\\geqslant -2.778)=P(t_{24}\\geqslant -2.778)=1.99 \\] Decisión: como el p-valor es mayor que \\(\\alpha\\), no podemos rechazar \\(H_0\\). El p-valor es una probabilidad. ¿Cómo queréis que dé 1.99? ¡NO! El p-valor no es \\(2\\cdot P(T\\geqslant T_0)\\), sino \\(2\\cdot P(T\\geqslant |T_0|)\\). Por lo tanto, el p-valor es \\[ 2\\cdot P(T\\geqslant 2.778)=2\\cdot P(t_{24}\\geqslant 2.778)=0.01 \\] y como este p-valor es menor que \\(\\alpha\\), podemos rechazar \\(H_0\\) y concluir, con nivel de significación 0.05, que \\(\\mu\\neq 20\\). Es decir, hemos obtenido evidencia estadísticamente significativa de que \\(\\mu\\neq 20\\). 14.6 La potencia de un contraste Recordad que la potencia \\(1-\\beta\\) es la probabilidad de rechazar \\(H_0\\) cuando \\(H_1\\) es verdadera. Por ejemplo, en el ejemplo del calcio en diabéticos de la Sección 14.5, la regla de rechazo era \\[ T=\\frac{\\overline{X}-2.5}{\\widetilde{S}_X/\\sqrt{n}}&gt;1.685, \\] por lo tanto la potencia era \\[ 1-\\beta=P(\\text{Rechazar } H_0\\,|\\, H_1\\text{ verdadera})=P(T&gt;1.685\\,|\\, \\mu&gt;2.5). \\] Esta probabilidad es imposible de calcular, pero hay programas que la saben estimar para los tests más usuales. Por ejemplo, el paquete pwr de R, el módulo jpower de JAMOVI o la aplicación G*Power que podéis descargar del url https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower. Esta estimación de la potencia se basa en la idea siguiente. Para cada tipo de contraste se tiene una relación numérica entre: La potencia El tamaño de la muestra \\(n\\): la potencia crece con \\(n\\) El nivel de significación \\(\\alpha\\): la potencia decrece con \\(\\alpha\\) El tamaño del efecto, un valor que cuantifica la diferencia entre el parámetro muestral y el valor contrastado. La potencia crece con el valor absoluto del tamaño del efecto. Esta relación permite calcular cualquiera de los cuatro valores a partir de los otros tres. Así, sabiendo \\(n\\), \\(\\alpha\\) y el tamaño del efecto, podemos calcular la potencia del contraste efectuado. La aplicación más importante de estos cálculos es la determinación del tamaño de la muestra necesario para la potencia deseada. Al planear un experimento para realizar un contraste, hay que: Fijar el nivel de significación deseado Fijar la potencia deseada Estimar el tamaño del efecto esperado (a partir de nuestra teoría, de nuestra experiencia, de los resultados de otros estudios…). y usar un programa adecuado que calcule el tamaño de la muestra necesario para lograr la potencia deseada a partir de estos valores. Desconfiad de los trabajos donde esto no se haga. Podría ser que la potencia fuera muy baja y hubiera un sesgo de infrapotencia (underpower): se necesitaba un efecto muy grande para poder rechazar la hipótesis nula y publicar el artículo. Por ejemplo, imaginad que en un estudio para determinar si la tasa de efectividad de un cierto tratamiento de una enfermedad es mayor del 90% se prueba sobre una muestra de solo 10 enfermos. Entonces, para obtener un p-valor inferior al 0.05 sería necesario que los 10 enfermos se curaran. Por lo tanto, lo más seguro es que los resultados de este estudio solo vieran la luz en un revista científica si la tasa observada de curación en la muestra fuera del 100%. Animado por esta tasa de curación perfecta, uno prueba el tratamiento y comprueba en sus pacientes que su eficacia queda lejos del 100%. 14.7 Intervalo de confianza de un contraste Repasemos los conceptos introducidos hasta ahora, y pongamos nombre a otros: Nivel de significación, \\(\\alpha\\): probabilidad de rechazar \\(H_0\\) si esta es verdadera (probabilidad de error de tipo I, de falso positivo). Nivel de confianza, \\(1-\\alpha\\): probabilidad de aceptar \\(H_0\\) si esta es verdadera (probabilidad de verdadero negativo). Potencia, \\(1-\\beta\\): probabilidad de rechazar \\(H_0\\) si \\(H_1\\) es verdadera (probabilidad de verdadero positivo). Estadístico de contraste: el valor que calculamos sobre una muestra aleatoria simple para efectuar el contraste Región crítica o de rechazo: el rango de valores del estadístico de contraste para los que rechazamos \\(H_{0}\\) con un nivel de significación \\(\\alpha\\) dado. Región de aceptación: el complementario de la región de rechazo, es decir, el rango de valores del estadístico de contraste para los que aceptamos \\(H_{0}\\) con un nivel de significación \\(\\alpha\\) dado. p-valor: la probabilidad de que, si \\(H_0\\) es verdadera, el estadístico de contraste tome sobre una muestra aleatoria simple del mismo tamaño que la nuestra un valor tan o más extremo (en el sentido de \\(H_1\\)) que el obtenido sobre nuestra muestra. Rechazamos \\(H_{0}\\) con un nivel de significación \\(\\alpha\\) si el p-valor es menor que \\(\\alpha\\). Ejemplo 14.20 Si realizamos un test t para efectuar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] rechazamos \\(H_0\\) con nivel de significación \\(\\alpha\\) (o con nivel de confianza \\(1-\\alpha\\)) cuando \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&gt;t_{n-1,1-\\alpha} \\] Por lo tanto: Estadístico de contraste: este \\(T\\) Región crítica para el nivel de significación \\(\\alpha\\): el intervalo \\((t_{n-1,1-\\alpha},\\infty)\\) Región de aceptación para el nivel de significación \\(\\alpha\\): el intervalo \\((-\\infty,t_{n-1,1-\\alpha}]\\) p-valor: \\(P(T\\geqslant T_0)\\), donde \\(T_0\\) denota el valor de \\(T\\) en nuestra muestra Si en cambio el contraste que queremos efectuar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] rechazamos \\(H_0\\) con nivel de significación \\(\\alpha\\) (o con nivel de confianza \\(1-\\alpha\\)) cuando \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&lt;t_{n-1,\\alpha} \\] Por lo tanto: Estadístico de contraste: el mismo \\(T\\) que antes Región crítica para el nivel de significación \\(\\alpha\\): el intervalo \\((-\\infty,t_{n-1,\\alpha})\\) Región de aceptación para el nivel de significación \\(\\alpha\\): el intervalo \\([t_{n-1,\\alpha},\\infty)\\) p-valor: \\(P(T\\leqslant T_0)\\) Finalmente, si el contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] rechazamos \\(H_0\\) con nivel de significación \\(\\alpha\\) (o con nivel de confianza \\(1-\\alpha\\)) cuando \\[ |T|=\\left|\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\right|&gt;t_{n-1,1-\\alpha/2} \\] Por lo tanto: Estadístico de contraste: el mismo \\(T\\) que antes Región crítica para el nivel de significación \\(\\alpha\\): la unión de intervalos \\((-\\infty,-t_{n-1,1-\\alpha/2})\\cup (t_{n-1,1-\\alpha/2},\\infty)\\) Región de aceptación para el nivel de significación \\(\\alpha\\): el intervalo \\([-t_{n-1,1-\\alpha/2},t_{n-1,1-\\alpha/2}]\\) p-valor: \\(2P(T\\geqslant |T_0|)\\) El intervalo de confianza de nivel de confianza \\(1-\\alpha\\) de un contraste es un intervalo que tiene una probabilidad \\(1-\\alpha\\) de contener el parámetro poblacional que contrastamos, en el sentido de los intervalos de confianza del tema anterior: se calcula con una fórmula que en un \\((1-\\alpha)\\cdot 100\\%\\) de las veces que se aplica a una muestra aleatoria simple, produce un intervalo que contiene el parámetro poblacional. El intervalo de confianza de un contraste se obtiene imponiendo que el estadístico de contraste pertenezca a la región de aceptación para el nivel de significación \\(\\alpha\\) y despejando el parámetro poblacional. Cuando \\(H_1\\) es bilateral, el intervalo de confianza del contraste coincide con el intervalo de confianza dado en el tema anterior. Pero cuando \\(H_1\\) es unilateral, el intervalo de confianza del contraste es infinito en el lado definido por la hipótesis alternativa. Por ejemplo, consideremos el caso de un test t para efectuar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] Aceptamos \\(H_0\\) con nivel de significación \\(\\alpha\\) cuando \\[ \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha} \\] Despejando \\(\\mu_0\\), obtenemos \\[ \\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu_0 \\] Por lo tanto, el intervalo de confianza de nivel de confianza \\(1-\\alpha\\) para este contraste es \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\infty\\Bigg) \\] Si la \\(\\mu_0\\) que contrastamos pertenece a este intervalo, no podemos concluir que la \\(\\mu\\) poblacional sea mayor que \\(\\mu_0\\), y por lo tanto no podemos rechazar que \\(\\mu=\\mu_0\\). Los valores de \\(\\mu_0\\) en este intervalo son tan grandes que con nuestra muestra no hemos obtenido evidencia de que la \\(\\mu\\) real sea mayor que ellos. En el ejemplo de los diabéticos de la Sección 14.5, da el intervalo \\[ \\Bigg[3.2- 1.73\\cdot \\dfrac{1.5}{\\sqrt{20}},\\infty\\Bigg)=[2.62,\\infty) \\] Concluimos que, con un nivel de confianza del 95%, la concentración media de calcio en sangre en los jóvenes diabéticos es como mínimo 2.62, y que por lo tanto, con este nivel de confianza, no puede ser 2.5, aunque por poco. Si efectuamos un contraste bilateral con un test t \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] aceptamos \\(H_0\\) con nivel de significación \\(\\alpha\\) cuando \\[ -t_{n-1,1-\\alpha/2}\\leqslant \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha/2} \\] Despejando \\(\\mu_0\\), obtenemos: \\[ \\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu_0 \\leqslant \\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}} \\] Por lo tanto, el intervalo de confianza de nivel de confianza \\(1-\\alpha\\) para este contraste es \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] ¿Os suena? Llamando \\(q\\) a \\(1-\\alpha\\), de manera que \\[ 1-\\frac{\\alpha}{2}=1-\\frac{1-q}{2}=\\frac{1+q}{2}, \\] da \\[ \\Bigg[\\overline{X}- t_{n-1,(1+q)/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\overline{X}+ t_{n-1,(1+q)/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Es el intervalo de confianza para \\(\\mu\\) basado en la t de Student que vimos en el tema anterior. En resumen, dado un contraste de hipótesis, podemos decidir si rechazamos \\(H_0\\) en favor de \\(H_1\\) con nivel de significación \\(\\alpha\\) usando: La región crítica: Si el estadístico de contraste cae dentro de la región crítica para el nivel de significación \\(\\alpha\\), rechazamos \\(H_0\\). El p-valor: Si el p-valor es menor que el nivel de significación \\(\\alpha\\), rechazamos \\(H_0\\). El intervalo de confianza: Si el valor que contrastamos del parámetro poblacional no pertenece al intervalo de confianza de nivel de confianza \\(1-\\alpha\\), rechazamos \\(H_0\\). Los tres métodos son equivalentes. En la práctica no se usa la región crítica: su papel se reduce a ser un paso intermedio en la obtención de las otras dos reglas de rechazo. Por otro lado, el uso del p-valor es muy discutido porque da lugar a falsas interpretaciones (la probabilidad de que la hipótesis nula sea verdadera; un valor a comparar con el umbral absoluto 0.05 sin tener nada más en consideración; …), pero bien entendido (como una medida de la consistencia de lo observado con la hipótesis nula) es útil. Lo más adecuado es dar el p-valor y el intervalo de confianza: El p-valor, porque aun es lo que todo el mundo espera y para que el lector lo pueda comparar con el nivel de significación que considere oportuno. El intervalo de confianza, porque muestra el margen con el cual hemos aceptado o rechazado la hipótesis nula con nuestro nivel de significación. Si no establecemos un nivel de significación \\(\\alpha\\), lo habitual es: Aceptar \\(H_0\\) si el p-valor es mayor que 0.1: se dice que el p-valor no es estadísticamente significativo Rechazar \\(H_0\\) si el p-valor es menor que 0.05: se dice que el p-valor es estadísticamente significativo Si el p-valor está entre 0.05 y 0.1 y no se ha fijado nivel de significación, lo mejor que podéis hacer es no concluir nada y decir que es necesario repetir el estudio con una muestra mayor. Cuando el p-valor es menor que 0.05, se suelen distinguir tres franjas: Significativo si está entre 0.01 y 0.05 Fuertemente significativo si está entre 0.001 y 0.01 Muy significativo si es menor que 0.001 Normalmente estas franjas se indican con un código de asteriscos: Un asterisco, *, para los p-valores entre 0.01 y 0.05 Dos asteriscos, **, para los p-valores entre 0.001 y 0.01 Tres asteriscos, ***, para los p-valores por debajo de 0.001 Aunque hay otras propuestas: Figura 14.3: “P-values” (https://xkcd.com/1478/ (CC-BI-NC 2.5)) Dado que rechazamos \\(H_0\\) si, y solo si, el p-valor es menor que \\(\\alpha\\), el p-valor de un contraste es el nivel de significación más pequeño para el cual rechazaríamos la hipótesis nula. Es decir: El p-valor obtenido en un contraste es la probabilidad mínima de equivocarnos que asumimos al rechazar la hipótesis nula si esta es verdadera. Por lo tanto, por favor, acostumbraos a dar el p-valor, y no la franja de significación donde cae. 14.8 Ajuste de p-valores Si efectuamos \\(M\\) contrastes independientes usando una regla de decisión que garantice un nivel de significación \\(\\alpha\\) dado, y en todos ellos la \\(H_0\\) es verdadera, el número de contrastes donde nos equivocaremos y rechazaremos \\(H_0\\) tiene distribución binomial \\(B(M,\\alpha)\\). En particular, esperamos cometer \\(\\alpha M\\) errores de tipo I, y la probabilidad de cometer alguno es \\(1-(1-\\alpha)^M\\). Este valor es mayor que \\(\\alpha\\). Por ejemplo, si realizamos 3 contrastes con nivel de significación \\(\\alpha =0.05\\) y en los tres la hipótesis nula es vertadera, la probabilidad de que cometamos algún Error de Tipo I es \\(1-(1-0.05)^{3} \\approx 0.14\\). Si efectuamos muchos contrastes, aumenta la probabilidad de “encontrar algo” aunque no haya nada que encontrar, y acabar diciendo que las gominolas verdes curan el acné. Figura 14.4: “Significant” (https://xkcd.com/882/ (CC-BI-NC 2.5)) Si queremos mantener un nivel de significación global \\(\\alpha\\), es decir, que la probabilidad de cometer algún error de tipo I sea \\(\\alpha\\), hay que reducir el nivel de significación de cada uno de ellos, o equivalentemente aumentar (ajustar) el p-valor de cada contraste y comparar el valor ajustado con el \\(\\alpha\\) fijado. Se han propuesto muchos métodos para ajustar los p-valores de grupos de contrastes. El más sencillo, y el más popular, es el de Bonferroni. Su idea es que, usando la aproximación \\(1-(1-x)^M \\approx M\\cdot x\\), para efectuar \\(M\\) contrastes con un nivel de significación global \\(\\alpha\\): tenemos que realizar cada contraste con nivel de significación \\(\\alpha/M\\) (y así el nivel de significación global será \\(\\approx\\) \\(M\\cdot \\alpha/M=\\alpha\\)) o equivalentemente: tenemos que multiplicar el p-valor de cada contraste por \\(M\\) antes de compararlo con el nivel de significación \\(\\alpha\\). Ambos métodos son equivalentes, porque \\[ p&lt; \\alpha/M\\Longleftrightarrow M\\cdot p&lt;\\alpha \\] Por ejemplo, si realizamos 3 contrastes, para obtener un nivel de significación global \\(\\alpha =0.05\\) el método de Bonferroni nos dice que tenemos que multiplicar cada p-valor por 3 y comparar los p-valores ajustados resultantes con 0.05. Recordad que un p-valor es una probabilidad, por lo tanto no puede pasar de 1. Si al ajustar algún p-valor pasa de 1, se da 1 como resultado del ajuste. 14.9 Resultados estadísticamente significativos versus resultados clínicamente significativos Que en un contraste obtengamos un valor estadísticamente significativo quiere decir que es muy improbable que el valor del estadístico se obtenga por pura casualidad si la hipótesis nula es verdadera, y que es más verosímil que en la realidad sea la hipótesis alternativa la verdadera. Pero que un resultado sea estadísticamente significativo puede deberse a una diferencia muy pequeña en una muestra muy grande. Y esta diferencia tan pequeña puede que no sea clínicamente relevante. Figura 14.5: Estadísticamente significativo no significa clínicamente relevante. Por ejemplo, imaginad que queremos estudiar si una vacuna para una determinada enfermedad es efectiva. Tomamos dos grupos de personas, vacunamos las de un grupo, dejamos sin vacunar las del otro, esperamos un tiempo prudencial, y contamos cuántos han enfermado en cada grupo. Fijemos el nivel de significación usual \\(\\alpha=0.05\\) y supongamos que obtenemos un p-valor por debajo de 0.05. ¡Gran júbilo! Hemos obtenido evidencia estadísticamente significativa de que nuestra vacuna funciona. Una diferencia entre las proporciones de enfermos en el grupo de control y el grupo de vacunados como la que hemos encontrado sería muy improbable si la vacuna no fuera efectiva. Pero a este p-valor pequeño podemos llegar de muchas maneras. Por ejemplo: Puede que hayamos tomado 100 sujetos en cada grupo y que hayan enfermado 20 controles, un 20%, y 10 vacunados, un 10% (el p-valor del test aproximado de dos proporciones que explicaremos en el próximo tema es, con estos valores, 0.024). En este caso podríamos considerar el resultado no solo estadísticamente significativo, sino clínicamente relevante: en nuestro experimento, la vacuna ha reducido a la mitad el riesgo de contraer la enfermedad, 10 puntos porcentuales en términos absolutos. Podríamos haber tomado 100000 sujetos en cada grupo y que hayan enfermado 20000 controles, un 20%, y 19600 vacunados, un 19.6% (el p-valor del test aproximado que hemos mencionado antes es, con estos valores, 0.0126). En este caso el resultado sigue siendo estadísticamente significativo, incluso más que antes, porque el p-valor es más pequeño, pero la relevancia clínica ya no está tan clara: estimamos que la vacuna reduce en un 2% el riesgo de contraer la enfermedad, en términos absolutos 4 décimas de punto porcentual. En el segundo caso, con una muestra tan grande, la potencia era muy grande y como consecuencia cualquier pequeña diferencia se convertía en estadísticamente significativa, aunque fuera eso, pequeña. En este curso nos preocupamos sobre todo del significado estadístico del resultado de un estudio, que medimos con el p-valor. Más adelante en vuestra vida profesional, el significado clínico lo tendréis que decidir vosotros a partir de vuestra experiencia. Y tened en cuenta que un resultado publicado puede ser estadísticamente significativo y no significar nada. Por ejemplo, el paquete statcheck de R permite revisar de manera automática todos los cálculos de un artículo escrito en un formato concreto usado en revistas de psicología y comprobar los p-valores. Los autores del paquete analizaron 30,000 artículos y concluyeron que: “Hemos encontrado que la mitad de los artículos contienen al menos un p-valor erróneo. Y uno de cada ocho artículos contiene un p-valor erróneo que además afecta la conclusión estadística.” Por lo tanto, Cualquier artículo puede dar un p-valor pequeño que esté equivocado No os fiéis de los resultados. Si las conclusiones os interesan, revisad los cálculos. Además, tened presente que: Cualquier estudio mal diseñado o mal realizado puede dar un p-valor pequeño… que no signifique absolutamente nada. Si las conclusiones de un artículo os interesan, revisad si el estudio ha sido bien diseñado, ejecutado y analizado. Cualquier estudio perfectamente diseñado y realizado puede dar por puro azar un p-valor pequeño… que implique un falso positivo. Contra esto último no podemos hacer nada, salvo ser escépticos. Ejemplo 14.21 En un artículo publicado en 2010 se obtuvo evidencia de que una persona que fuera Aries, Tauro, Géminis, Leo, Escorpio o Capricornio tenía una mayor probabilidad de supervivencia a 5 años vista tras un alotransplante de células madre para tratar una leucemia mieloide crónica que una persona de fuera de los otros signos del zodíaco (58% de tasa de supervivencia frente a un 48%, p-valor 0.007). ¿Nos lo tenemos a creer? Spoiler: El subtítulo del artículo es An artificial association. 14.10 Test (1) Cuando escribimos formalmente un contraste de hipótesis, ¿qué es \\(H_1\\)? Es la primera hipótesis que hacemos y que después ya modificaremos en función de los datos obtenidos Es la hipótesis nula Es la hipótesis alternativa Es la variable haleatoria poblacional de interés Ninguna de las otras respuestas es la correcta (2) Un test de COVID-19 no es nada más que un contraste de hipótesis: tomas una muestra del individuo y decides si tiene COVID-19 o no. ¿Qué contraste es? H0: El individuo tiene COVID-19; H1: El individuo no tiene COVID-19 H0: El individuo no tiene COVID-19; H1: El individuo tiene COVID-19 H0: El individuo no tiene COVID-19; H1: El individuo podría tener COVID-19 H0: No sé si el individuo tiene COVID-19; H1: El individuo tiene COVID-19 (3) Un científico publica un artículo donde afirma que las personas que toman un determinado medicamento tienen una mayor probabilidad de formación de cálculos renales. Más tarde se descubre que en realidad esta asociación no existe. ¿Qué tipo de error cometió el científico y por qué? Tipo I, porque afirmó que la hipótesis nula es cierta cuando en realidad es falsa. Tipo I, porque afirmó que la hipótesis nula es falsa cuando en realidad es cierta. Tipo II, porque afirmó que la hipótesis nula es cierta cuando en realidad es falsa. Tipo II, porque afirmó que la hipótesis nula es falsa cuando en realidad es cierta. (4) En un examen considerado como un contraste (marca todas las respuestas correctas): Que el estudiante apruebe sin saber la materia es un error de tipo I Que el estudiante apruebe sin saber la materia es un error de tipo II Que el estudiante apruebe sin saber la materia es simultáneamente un error de tipo I y de tipo II El nivel de significación es la probabilidad de que el estudiante apruebe sin saber la materia El nivel de significación es la probabilidad de que el estudiante suspenda si no sabe la materia (5) ¿Qué significa que en un contraste de hipótesis tomemos un nivel de significación del 1%? Marca la respuesta correcta: Que un 1% de las veces que la hipótesis nula sea falsa la rechazaremos en favor de la alternativa. Que un 1% de las veces que la hipótesis nula sea falsa la aceptaremos. Que un 1% de las veces que la hipótesis nula sea verdadera la rechazaremos en favor de la alternativa. Que un 1% de las veces que la hipótesis nula sea verdadera la aceptaremos. Que un 1% de las veces rechazaremos la hipótesis nula. Que un 1% de las veces aceptaremos la hipótesis nula. Todas las otras respuestas son incorrectas. (6) Al analizar los resultados de un ensayo clínico, se concluye que las tasas de curación de los dos tratamientos estudiados son diferentes, con un p-valor de 0.034. Esto significa (marca todas las respuestas correctas): Que hay un 3.4% de probabilidad de que, si se repite el estudio, no se encuentren diferencias significativas. Que hay un 3.4% de probabilidad de que la tasa de curación de los tratamientos estudiados sean iguales. Que hay un 3.4% de diferencia, o más, en las tasas de curación de los tratamientos estudiados. Que ha habido un 3.4% de diferencia, o más, en las tasas de curación de los tratamientos en nuestras muestras. Que hay un 3.4% de probabilidad de que la diferencia obtenida entre las tasas de curación, o una aún mayor, se obtenga por pura casualidad. Todas las otras respuestas son incorrectas. (7) En un pequeño ensayo aleatorio simple ciego de un nuevo tratamiento en pacientes con infarto de miocardio agudo, la mortalidad en el grupo tratado fue la mitad que en el grupo control, pero la diferencia no resultó estadísticamente significativa. Podemos concluir que (marca todas las respuestas correctas): Como la diferencia no es estadísticamente significativa, el tratamiento es inútil. Podría ser que el contraste tuviera poca potencia, y por eso la diferencia detectada no ha sido estadísticamente significativa. La reducción observada de la mortalidad es tan grande que deberíamos introducir el tratamiento inmediatamente, aunque dicha reducción no sea estadísticamente significativa. Esto se debe a que el ensayo fue simple ciego, y no doble ciego. Es conveniente llevar a cabo un nuevo ensayo sobre una muestra de pacientes de mayor tamaño. Todas las otras respuestas son incorrectas. (8) En un estudio donde se contrastó si los individuos con hipertensión arterial tienen un mayor riesgo de sufrir un infarto de miocardio que los individuos normotensos, se obtuvo un p-valor de 0.02. ¿Qué quiere decir esto? (Marca una sola respuesta.) La probabilidad de que los hipertensos tengan más riesgo de sufrir un infarto de miocardio que los normotensos es 0.02 La probabilidad de que los hipertensos tengan más riesgo de sufrir un infarto de miocardio que los normotensos es 0.98 Un hipertenso tiene una probabilidad de sufrir un infarto de miocardio un 2% mayor que un normotenso. En las muestras que hemos usado en el estudio, la proporción de hipertensos que han sufrido un infarto de miocardio es un 2% mayor que la de normotensos que han sufrido un infarto de miocardio Ninguna de las otras respuestas es correcta. (9) En un estudio sobre lactancia materna e inteligencia, a 300 niños que fueron muy pequeños al nacer se les dio la leche materna de su madre o leche infantil, a elección de la madre. A la edad de 8 años, se midió el CI (cociente intelectual) de estos niños. El CI medio en el grupo de leche infantil fue 92.8, en comparación con un CI medio de 103.0 en el grupo de leche materna. La diferencia fue estadísticamente significativa, con un p-valor inferior a 0.001. Marca todas las afirmaciones correctas: Hay evidencia estadísticamente significativa de que la alimentación mediante leche infantil de los bebés muy pequeños reduce su CI a los 8 años. Hay evidencia estadísticamente significativa de que elegir alimentar un bebé muy pequeño con leche materna aumenta el CI del niño a los 8 años. Hay evidencia estadísticamente significativa de que el tipo de leche no tiene ningún efecto en el CI subsecuente. La probabilidad de que el tipo de leche no afecte al CI subsiguiente es inferior al 0.1%. Si la elección del tipo de leche influyera en el CI, la probabilidad de que la diferencia observada del CI medio en el grupo de leche materna menos el del grupo de leche infantil fuera la de este estudio, o menor, es menor que 0.001. Todas las otras respuestas son incorrectas. (10) En un contraste de hipótesis, si la hipótesis alternativa es verdadera pero se acepta la hipótesis nula (marca todas las conclusiones correctas, hay al menos una): Se comete un error de tipo I. Se comete un error de tipo II. La potencia disminuye. El p-valor es mayor que el nivel de significación. El p-valor es menor que el nivel de significación. (11) Siempre que en un contraste de hipótesis NO se rechaza la hipótesis nula, ¿cuál o cuáles de las siguientes afirmaciones son correctas? Se ha demostrado que la hipótesis nula es verdadera. Se ha demostrado que la hipótesis alternativa es falsa. Se ha encontrado evidencia de que la hipótesis nula es verdadera Se ha encontrado evidencia de que la hipótesis alternativa es falsa Ninguna de las otras afirmaciones es verdadera. (12) Si en un contraste de hipótesis tomamos un nivel de significación del 10% y una potencia del 60% y obtenemos un p-valor de 0.28, ¿cuál de las afirmaciones siguientes es verdadera? Aceptamos la hipótesis nula porque 0.28&gt;0.1. Aceptamos la hipótesis nula porque 0.28&lt;0.6. Rechazamos la hipótesis nula porque 0.28&gt;0.1. Rechazamos la hipótesis nula porque 0.28&lt;0.6. Con los datos dados, no tenemos criterio para aceptar o rechazar la hipótesis nula. (13) En un estudio se trató con un suplemento dietético más dieta a 39 insuficientes renales y solamente con dieta a 40, de manera que los pacientes conocían qué tratamiento recibieron. Se compararon 20 variables entre ambos grupos y en una comparación se encontró una diferencia a favor del suplemento estadísticamente significativa con un nivel de significación del 5% (p-valor 0.000021). ¿Cómo interpretas estos resultados? Marca una sola respuesta. El estudio no permite concluir nada, ya que si realizamos 20 contrastes con un nivel de significación del 5%, esperamos que alguno dé un resultado estadísticamente significativo aunque no haya diferencia entre los tratamientos El p-valor tan pequeño descarta la posibilidad de un falso positivo en el caso en que se ha encontrado una diferencia estadísticamente significativa El hecho de haber encontrado una diferencia estadísticamente significativa en una comparación puede deberse a un error de tipo II Con unas muestras de pacientes tan pequeñas, la potencia de los contrastes seguramente es muy baja, lo que explica que hayamos obtenido algún resultado estadísticamente significativo Como en un 5% (el nivel de significación) de los contrastes se obtuvo un resultado favorable a favor del suplemento dietético, concluimos que su introducción es eficaz (14) En un contraste que hemos llevado a cabo con nivel de significación 0.05 hemos obtenido un p-valor de 1.8. ¿Cuál ha de ser nuestra decisión? Aceptar la hipótesis nula, porque el p-valor es mayor que el nivel de significación. Rechazar la hipótesis nula, porque el p-valor es tan raro que hace inverosímil que la hipótesis nula sea verdadera. Revisar los cálculos, a ver dónde nos hemos equivocado. Ninguna de las otras respuestas es correcta. (15) En un contraste con \\(\\alpha=0.05\\) rechazamos la hipótesis nula. ¿Qué pasaría si, con la misma muestra, tomáramos \\(\\alpha=0.1\\)? Seguro que también rechazaríamos la hipótesis nula Seguro que no rechazaríamos la hipótesis nula Puede pasar cualquier cosa (16) En un contraste con \\(\\alpha=0.05\\) no rechazamos la hipótesis nula. ¿Qué pasaría si, con la misma muestra, tomáramos \\(\\alpha=0.1\\)? Seguro que tampoco rechazaríamos la hipótesis nula Seguro que sí que rechazaríamos la hipótesis nula Puede pasar cualquier cosa (17) En un contraste de una media usando un test t, el aumento del tamaño de la muestra (marca todas las respuestas correctas): Mejora la aproximación del estadístico de contraste a una distribución normal. Esperamos que disminuya la probabilidad de error de tipo I. Esperamos que disminuya la probabilidad de error de tipo II. Esperamos que disminuya la potencia del contraste. Hace menos probable que la hipótesis nula sea verdadera. Todas las otras respuestas son incorrectas. (18) En un contraste de hipótesis en el que la hipótesis nula es verdadera (marca una sola respuesta): Solo podemos cometer un error de tipo I. Solo podemos cometer un error de tipo II. Podemos cometer tanto un error de tipo I como un error de tipo II, pero no los dos. Podemos cometer tanto un error de tipo I como un error de tipo II, y podemos cometerlos los dos simultáneamente. Como la hipótesis nula es verdadera, no podemos cometer ni un error de tipo I ni un error de tipo II. Todas las otras respuestas son falsas. (19) ¿Qué es la región de aceptación de un contraste sobre un parámetro poblacional? El conjunto de los valores del parámetro poblacional para los que tenemos que aceptar la hipótesis nula El conjunto de los valores del parámetro poblacional para los que tenemos que aceptar la hipótesis alternativa El conjunto de los valores del estadístico de contraste para los que tenemos que aceptar la hipótesis nula El conjunto de los valores del estadístico de contraste para los que tenemos que aceptar la hipótesis alternativa El conjunto de las estimaciones aceptables del parámetro poblacional a partir de la muestra (20) Si efectuamos un mismo contraste con el mismo nivel de significación dos veces con dos muestras diferentes del mismo tamaño (marca las continuaciones correctas): La región de aceptación del contraste será las dos veces la misma La región de aceptación del contraste puede dar diferente con cada muestra El intervalo de confianza del contraste será las dos veces el mismo El intervalo de confianza del contraste puede dar diferente con cada muestra (21) En un contraste de hipótesis hemos rechazado la hipótesis nula en favor de la alternativa con nivel de significación del 10%. El contraste ha tenido una potencia del 60%. ¿Cuál o cuáles de las afirmaciones siguientes son correctas en esta situación? La probabilidad que la hipótesis nula sea verdadera es 0.1 La probabilidad que la hipótesis nula sea verdadera es 0.4 La probabilidad que la hipótesis alternativa sea verdadera es 0.1 La probabilidad que la hipótesis alternativa sea verdadera es 0.4 Ninguna de las otras respuestas es correcta. (22) Hemos efectuado el mismo contraste con dos muestras: con la primera hemos obtenido un p-valor de 0.1 y con la segunda un p-valor de 0.01. ¿Cuál o cuáles de las afirmaciones siguientes son correctas? Es más probable que sea verdadera la hipótesis nula del contraste con la primera muestra que la hipótesis nula del contraste con la segunda muestra Es más probable que sea verdadera la hipótesis nula del contraste con la segunda muestra que la hipótesis nula del contraste con la primera muestra No hay manera de saber si la hipótesis nula del contraste con la primera muestra es más probable o menos probable que la hipótesis nula del contraste con la segunda muestra Ninguna de las otras respuestas es correcta (23) Hemos efectuado un test t de una media, con hipótesis alternativa \\(\\mu\\neq 2\\). ¿Es posible que hayamos obtenido (con la misma muestra) un intervalo de confianza del contraste del 95% [2.1,3.2] y un p-valor 0.13? Sí No (24) Hemos efectuado un test t de una media, con hipótesis alternativa \\(\\mu\\neq 2\\). ¿Es posible que hayamos obtenido (con la misma muestra) un intervalo de confianza del contraste del 95% [1.8,3.2] y un p-valor 0.13? Sí No (25) Hemos efectuado un test t de una media, con hipótesis alternativa \\(\\mu&lt;2\\). ¿Es posible que hayamos obtenido (con la misma muestra) un intervalo de confianza del contraste del 95% [1.8,3.2] y un p-valor 0.13? Sí No (26) Hemos efectuado dos veces, con dos muestras diferentes, un mismo test t de una media, con hipótesis alternativa \\(\\mu\\neq 2\\). ¿Es posible que con una muestra hayamos obtenido un intervalo de confianza del contraste del 95% [2.1,3.2] y con la otra muestra un p-valor 0.13? Sí No "],["qué-test-usar.html", "Lección 15 ¿Qué test usar? 15.1 Contrastes para medias 15.2 Contrastes para varianzas 15.3 Contrastes para proporciones 15.4 Contrastes para distribuciones 15.5 Contrastes de correlación 15.6 Test", " Lección 15 ¿Qué test usar? En esta lección estudiamos los contrastes de hipótesis más frecuentes sobre medias, varianzas, proporciones, etc. El objetivo principal es explicar qué tests resuelven cada tipo de contraste. Para la mayoría de estos tests no vamos a explicar las fórmulas de los estadísticos de contraste o intervalos de confianza, solo cuándo se pueden usar, cómo efectuarlos con JAMOVI y cómo interpretar los resultados. 15.1 Contrastes para medias 15.1.1 Contrastes para una media Sea \\(X\\) una variable aleatoria de media \\(\\mu\\). Queremos realizar un contraste sobre \\(\\mu\\), de la forma \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq\\mu_0\\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] Para ello, medimos \\(X\\) sobre una muestra aleatoria simple de tamaño \\(n\\). 15.1.1.1 Test t Supongamos que estamos en una de las dos situaciones siguientes: \\(X\\) es normal; o \\(X\\) no es necesariamente normal pero el tamaño \\(n\\) de la muestra que tomamos es grande (digamos, para fijar ideas, que \\(n\\geqslant 40\\)). En cualquiera de estas dos situaciones, podemos usar el test t que hemos explicado en la lección anterior para realizar el contraste. JAMOVI lo ofrece en la sección Pruebas T/Prueba T en una muestra de su instalación básica. Ejemplo 15.1 La temperatura media del cuerpo humano, ¿es el valor comúnmente aceptado de 37o C? Para empezar, tenemos que traducir esta pregunta a un contraste de hipótesis: Variable aleatoria poblacional: \\(X\\): temperatura del cuerpo humano en oC, de media \\(\\mu\\). Contraste: Nos preguntamos si \\(\\mu=37^{\\mathrm{o}}\\) o no, por lo que el contraste es bilateral: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=37\\\\ H_{1}:\\mu\\neq 37 \\end{array}\\right. \\] Para efectuar el contraste, necesitamos una muestra de temperaturas. Vamos a usar las recogidas por P. A. Mackowiak, S. S. Wasserman y M. M. Levine que ya usamos en el Ejemplo 13.5, y que tenemos guardadas en la variable Temperatura de la tabla de datos Temperaturas.txt. Con JAMOVI, importamos el fichero Temperaturas.txt en una tabla de datos (con Importar especial). Dando una ojeada a la tabla de datos (con el menú Datos), o usando la casilla N de Exploración/Descriptivas, vemos que la muestra es de tamaño 230, más que suficiente para poder usar un test t. Entonces, abrimos Pruebas T/Prueba T en una muestra; seleccionamos como variable dependiente la Temperatura; entramos 37 en la casilla Valor de la prueba; y marcamos las casillas que se muestran en la figura que sigue. Obtenemos la tabla de la derecha de la figura (observad que JAMOVI llama \\(H_a\\) a nuestra hipótesis alternativa \\(H_1\\)): El intervalo de confianza del 95% para la \\(\\mu\\) se obtiene sumando el valor que se contrasta (en nuestro caso 37) al “intervalo de confianza al 95%” obtenido, por lo tanto es [36.765, 36.886]. Sobre el p-valor, sólo nos dice que es menor que 0.001, no nos da su valor exacto. En resumen, hemos encontrado evidencia estadísticamente significativa de que la temperatura media del cuerpo humano no es de 37o C, y estimamos con un 95% de confianza que está entre 36.8o C y 36.9o C, o sea, entre una y dos décimas por debajo de 37o C. Si esto es clínicamente importante o no para definir “fiebre” ya no es un problema de estadística. En este caso, si queremos saber qué vale el p-valor (que es lo que en el tema anterior os recomendábamos publicar), tendremos que usar la función t.test de R . Esta función t.test se aplica a un argumento formado por: el vector que contiene la muestra; el parámetro mu igualado al valor que contrastamos; el paràmetro alternative que indica el tipo de contraste, igualándolo a \"two.sided\" (para contrastes bilaterales, es decir, con \\(\\neq\\)), \"less\" (\\(&lt;\\)) o \"greater\" (\\(&gt;\\)); no os olvidéis de las comillas en los valores de este parámetro; el parámetro conf.level que indica el nivel de confianza \\(1-\\alpha\\), en nuestro caso 0.95, que corresponde a \\(\\alpha=0.05\\) (como este es el valor por defecto de este parámetro, no es necesario especificarlo). JAMOVI ha importado el fichero Temperaturas.txt en una tabla de datos que ha llamado data. El código siguiente, ejecutado en la ventana de R/Rj Editor, define un vector llamado Temps con la variable Temperatura de data y efectua el test t deseado: El resultado contiene: El p-valor (p-value) del contraste: 3·10-8 El intervalo de confianza del 95% (95 percent confidence interval): va de 36.77o C a 36.89o C La media muestral (mean of x): 36.83 15.1.1.2 Test no paramétrico Si no podemos suponer que la variable aleatoria de interés sea normal y la muestra no es lo bastante grande, no podemos usar un test t. Entonces, hay que usar algún test no paramétrico que no requiera de la normalidad de la variable poblacional. El más popular es el Test de Wilcoxon, aunque conviene tener presente que, en el fondo, este test compara medianas y no medias. Con JAMOVI, hay que marcar la casilla Rangos de Wilcoxon en vez de t de Student en Pruebas T/Prueba T en una muestra: Con R se usa la función wilcox.test, con la misma sintaxis que t.test salvo que, si eso, hay que indicar con conf.int=TRUE que queremos el intervalo de confianza para la temperatura media (en realidad, este intervalo, y el que da JAMOVI, es para la pseudomediana: la mediana de las medias aritméticas de pares independientes de temperaturas, que coincide con la media si la distribución es simétrica), ya que por defecto no lo da: 15.1.2 Inciso: tests de normalidad Muchos tests, como por ejemplo los tests t cuando las muestras son pequeñas, requieren que las variables poblacionales sea normales para que las conclusiones sean válidas. Para poder decidir si podemos aceptar o no que la variable poblacional es normal, se usa un contraste de normalidad, con hipótesis nula \\[ H_0: \\text{Esta muestra proviene de una variable aleatoria normal} \\] e hipótesis alternativa \\[ H_1: \\text{No es verdad que esta muestra provenga de una variable aleatoria normal} \\] Hay muchos tests que se pueden usar para efectuar este contraste. Por ejemplo, tras instalar el módulo moretests (que añade funcionalidades a los módulos básicos), cuando marcamos la casilla Prueba de normalidad al realizar algún test t, JAMOVI realiza tres pruebas de normalidad: la de Shapiro-Wilk, la de Kolmogorov-Smirnov y la de Anderson-Darling: Os recomendamos que, en caso de disparidad de conclusiones según los p-valores (como pasa en nuestro ejemplo, donde el p-valor del test de Kolgomorov-Smirnov es mayor que 0.1 y los otros dos son 0.003) os quedéis con la conclusión del test de Shapiro-Wilk, que es el más fiable (el test de Kolmogorov-Smirnov es el más conocido, pero no es bueno detectando diferencias con la normal en las colas; el test de Anderson-Darling resuelve este problema, pero en muestras muy grandes tiende a dar muchos falsos positivos). El test de Shapiro-Wilk también está disponible en Exploración/Descriptivas. Con R se efectua con la función shapiro.test aplicado a la muestra. Así pues, como vemos, hemos obtenido evidencia estadísticamente significativa de que la muestra de temperaturas no proviene de una variable normal. Por suerte, esto no afecta a la validez de la conclusión del test t, porque la muestra era muy grande. La conclusión de un test de normalidad se puede ilustrar con algún gráfico que muestre si la muestra se ajusta o no a lo que sería de esperar si proviniera de una variable poblacional normal. Por ejemplo, un histograma de la muestra superponiendo la densidad de la normal de media y desviación típicas estimadas con la muestra. Otro de los gráficos más usados en este contexto son los q-q-plots. Un q-q-plot de una muestra y una distribución teórica concreta (por ejemplo, una normal \\(N(\\mu,\\sigma)\\)) es el gráfico de los llamados q-q-puntos: los puntos de la forma \\[ (q\\text{-cuantil de la distribución téorica},\\ q\\text{-cuantil de la muestra}), \\] para varios valores de \\(q\\). Si la muestra proviene de la distribución teórica, es de esperar que el q-cuantil de la muestra sea muy parecido al q-cuantil de la distribución y por lo tanto que estos q-q-puntos estén cerca de la diagonal principal \\(y=x\\). JAMOVI dibuja un q-q-plot marcando la casilla Gráfica Q-Q en cualquier prueba t o en Exploración/Descriptivas. La función qqPlot del paquete car de R produce unos q-q-plots más adecuados que incluyen una “región de confianza del 95%” con el significado usual de nivel de confianza (para el 95% de las muestras de la distribución, los q-q-plot caen dentro de esta región; por lo tanto, si nuestro q-q-plot sale fuera de esta región, tenemos evidencia de que la muestra no proviene de la distribución teórica). La sintaxis para usarla es la que sigue (cambiad Temps por la muestra de la que queráis dibujar el q-q-plot) library(car) qqPlot(Temps, distribution=&quot;norm&quot;, mean=mean(Temps), sd=sd(Temps), ylab=&quot;Cuantiles de la muestra&quot;, xlab=&quot;Cuantiles de normal&quot;, pch=20, id=FALSE) La existencia de muchos q-q-puntos fuera de la franja de confianza nos vuelve a aportar evidencia de que la muestra de temperaturas no se ajusta a una distribución normal. 15.1.3 Contrastes para dos medias Sean ahora \\(X_1\\) y \\(X_2\\) dos variables aleatorias de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Queremos compararlas, mediante un contraste de la forma \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] Para ello, medimos \\(X_1\\) sobre una muestra aleatoria simple de tamaño \\(n_1\\), y \\(X_2\\) sobre una muestra aleatoria simple de tamaño \\(n_2\\). 15.1.3.1 Tests t Supongamos que estamos en una de las dos situaciones siguientes: \\(X_1,X_2\\) son ambas normales; o \\(X_1,X_2\\) no son necesariamente ambas normales pero los tamaños \\(n_1,n_2\\) de las muestras son ambos grandes (digamos, para fijar ideas, que \\(n_1,n_2\\geqslant 40\\)). Si se cumple alguna de estas dos condiciones, podemos usar un test t, basado en un estadístico de contraste \\(T\\) adecuado con distribución t de Student. Los estadísticos de contraste concretos y los grados de libertad de su distribución t de Student son los que dimos al hablar de intervalos de confianza para la diferencia de dos medias en el tema anterior, y dependen de las mismas condiciones que comentábamos allí: De si las dos muestras son: independientes: hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras aleatorias simples obtenidas de manera independiente la una de la otra; o apareadas (o pareadas, emparejadas…): hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra aleatoria simple o hay un apareamiento natural entre los sujetos de las dos muestras. En el caso apareado, podemos entender que tenemos una sola muestra, formada por los sujetos que medimos dos veces o por las parejas de sujetos. Entonces, podemos considerar la diferencia \\(D=X_1-X_2\\), que tendrá media poblacional \\(\\mu_D=\\mu_1-\\mu_2\\), y traducir el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] en el contraste de una sola media \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_D=0\\\\ H_{1}:\\mu_D \\neq 0\\text{ o }\\mu_D &gt;0\\text{ o }\\mu_D&lt;0 \\end{array} \\right. \\] Es decir, cuando las muestras son apareadas, consideramos nuestro contraste de dos medias como un contraste de una sola media, usando como muestra las diferencias \\(X_1-X_2\\) sobre nuestras parejas de sujetos. Cuando las muestras son independientes, el estadístico y sus grados de libertad también dependen de si las variables poblacionales \\(X_1\\) y \\(X_2\\) tienen la misma varianza o no, que en principio se ha de decidir con otro contraste. Todos estos tests t están implementados en la función t.test de R y en el módulo Pruebas T de JAMOVI. Ejemplo 15.2 La temperatura media de las hombres, ¿es menor que la de las mujeres? Traducimos esta pregunta en un contraste de hipótesis: Variables aleatorias poblacionales: \\(X_m\\): temperatura de un hombre en oC, de media \\(\\mu_m\\) \\(X_f\\): temperatura de una mujer en oC, de media \\(\\mu_f\\) Contraste: Nos preguntamos si \\(\\mu_m\\) es menor que \\(\\mu_f\\) \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_m=\\mu_f\\\\ H_{1}:\\mu_m&lt; \\mu_f \\end{array}\\right. \\] Necesitamos una muestra de temperaturas de hombres y de mujeres. La tabla de datos Temperaturas.txt que hemos usado en el ejemplo anterior contiene una variable Sexo con el sexo de los sujetos: M para hombres y F para mujeres. La muestra fue transversal, así que las muestras de hombres y mujeres son independientes (las que salieron en la muestra global). Con JAMOVI, tras importar el fichero Temperaturas.txt en una tabla de datos, calculamos los tamaños de ambas muestras con la casilla N de Exploración/Descriptivas, seleccionando como variable dependiente la Temperatura y como variable de agrupación el Sexo. Aprovechamos para calcular los estadísticos básicos de cada muestra y dibujar sus boxplot: Vemos que las temperaturas de las mujeres (F), y en particular su media y su mediana, son ligeramente mayores que las de los hombres (M). Como las muestras de mujeres y hombres son lo bastante grandes (116 y 114 sujetos, respectivamente), podemos usar un test t para realizar el contraste. Para ello, usamos Pruebas T/Prueba T para muestras independientes y seleccionamos de nuevo como variable dependiente la Temperatura y como variable de agrupación el Sexo. Como en la variable Sexo las mujeres son F y los hombres M y JAMOVI los va a tomar ordenados alfabéticamente, la hipótesis alternativa tiene que ser Grupo 1 &gt; Grupo 2, es decir, con las notaciones que usamos, \\(\\mu_f&gt;\\mu_m\\). En esta ventana, la casilla t de Student corresponde al test suponiendo varianzas poblacionales iguales y la casilla t de Welch al test suponiendo varianzas poblacionales diferentes. Vamos a efectuar los dos tests de golpe, y cruzaremos los dedos para que den la misma conclusión: En ambos casos el p-valor es (redondeado) 0.005, muy pequeño. Así, pues, hemos obtenido evidencia estadísticamente significativa de que los hombres tienen una temperatura corporal media inferior a la de las mujeres. Además, ambos intervalos de confianza del 95% para \\(\\mu_f-\\mu_m\\) van de alrededor de 0.056 a \\(\\infty\\) (Inf), por lo que tenemos un 95% de confianza de que la temperatura corporal media es al menos unas 5.6 centésimas de grado mayor en las mujeres que en los hombres. La diferencia de las medias muestrales \\(\\overline{X}_f-\\overline{X}_m\\) ha sido 0.155o C, es decir, la media muestral de temperaturas de mujeres ha sido 0.16o C mayor que en los hombres. ¿Qué pasaría si los tests suponiendo varianzas iguales y diferentes hubieran dado resultados diferentes? En este caso tendríamos que decidir qué conclusion tenemos que creer, decidiendo si podemos aceptar o rechazar que las varianzas poblacionales sean iguales o no. Podéis contrastar la igualdad de varianzas en esta misma ventana marcando la casilla Test de homogeneidad, que efectua el contraste con hipótesis nula que las dos varianzas poblacionales son iguales e hipótesis alternativa que son diferentes. Con el módulo moretests instalado, da el resultado de dos tests: el de Levene y el test F (Variance ratio). Ya volveremos sobre ellos en la próxima sección. En todo caso, como su p-valor es grande, aquí aceptaríamos que las dos varianzas poblacionales son iguales. Si preferís usar la función t.test, hay que entrar como argumentos: Los vectores que contienen la muestra de \\(X_1\\) y la muestra de \\(X_2\\). El tipo de contraste, que se especifica con el parámetro alternative como en el caso de una sola media. El tipo de muestras, que se especifica igualando el parámetro paired a FALSE si son independientes o a TRUE si son apareadas. En caso de muestras independientes, si las varianzas poblacionales son iguales o diferentes igualando el parámetro var.equal a TRUE o a FALSE, respectivamente. El nivel de confianza, que se especifica con el parámetro conf.level como en el caso de una sola media y no hace falta si es 0.95. El código siguiente define vectores TempsH y TempsM con las temperaturas de los hombres y las mujeres de esta tabla, y efectua los tests t suponiendo que las varianzas son iguales y que son diferentes, respectivamente 15.1.3.2 Tests no paramétricos Si no podemos suponer que las variables aleatorias de interés sean normales y si alguna muestra es pequeña, hay que usar algún test no paramétrico. Los más populares son: el test de Wilcoxon para muestras apareadas (que, recordad, se traduce en un contraste sobre la media de las diferencias, y en los contrastes de una media ya recomendábamos el test de Wilcoxon). el test de Mann-Whitney para muestras independientes. En JAMOVI se marcan las casillas rangos de Wilcoxon o U de Mann-Whitney, según corresponda. Usad tests paramétricos siempre que podáis, pero solo cuando podáis. Los mejores tests no paramétricos suelen tener potencia inferior a los mejores tests paramétricos. Pero usar, por ejemplo, un test t cuando no toca, porque alguna variable no sea normal y alguna muestra sea pequeña, puede llevar a conclusiones equivocadas. Con R, ambos tests se calculan con la función wilcox.test, con una sintaxis idéntica a la de t.test para dos muestras excepto que no dispone del parámetro var.equal (ya que ahora no nos interesa lo más mínimo saber si las variables tienen varianzas iguales o diferentes en el caso de contrastes de dos medias con muestras independientes) y hay que usar el parámetro conf.int=TRUE si se quiere un intervalo de confianza (para la diferencia de las pseudomedianas de \\(X_1\\) y \\(X_2\\)). En el caso de dos muestras, para comprobar si ambas muestras se ajustan a variables normales con JAMOVI, no podemos hacerlo desde el módulo Pruebas T sino desde Exploración/Descriptivas. En nuestro ejemplo (véase la figura que sigue), tenemos que separar la variable Temperatura según el Sexo. Marcando la casilla Shapiro-Wilk, obtenemos los p-valores del test de Shapiro-Wilk tanto para F como para M. Ambos son menores que 0.05, así que tenemos evidencia estadísticamente significativa de que ni las temperaturas de hombres ni las de mujeres siguen distribuciones normales. Veamos otro ejemplo. Ejemplo 15.3 Desayunar salvado de avena (oat bran) en lugar de copos de maíz (corn flakes), ¿ayuda a reducir el nivel de colesterol? Planteémoslo como un contraste de hipótesis. Las variables aleatorias poblacionales de interés son: \\(X_{ob}\\): nivel de colesterol al consumir salvado de avena, de media \\(\\mu_{ob}\\) \\(X_{cf}\\): nivel de colesterol al consumir copos de maíz, de media \\(\\mu_{cf}\\) El contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{ob}=\\mu_{cf}\\\\ H_{1}:\\mu_{ob}&lt; \\mu_{cf} \\end{array}\\right. \\] Para hacerlo, vamos a usar los datos obtenidos por J. Anderson et al en su estudio “Oat-bran cereal lowers serum total and LDL cholesterol in hypercholesterolemic men” (The American Journal of Clinical Nutrition 52 (1990), pp. 495-499). Se trata de un ensayo clínico cruzado sobre 14 individuos. A cada uno de ellos se le asignó uno de los dos desayunos de manera aleatoria y lo tomaron durante 15 días. Al final de este periodo, se les midió el nivel de colesterol en sangre. Pasado un mes de descanso, cada participante desayunó durante 15 días el otro producto, y al final se les volvió a medir el nivel de colesterol en sangre. Tenemos los niveles de colesterol que obtuvieron en la tabla de datos oatbran.txt, donde están medidos en milimoles por litro (mmol/l), así que esta será la unidad que tomamos en las variables poblacionales. Con JAMOVI, importamos el fichero oatbran.txt en una tabla de datos. Como las muestras son pequeñas (de tamaño 14), si queremos aplicar un test t necesitamos poder aceptar que provienen de variables normales. Vamos a Exploración/Descriptivas, escogemos ambas variables, CORNFLK y OATBRAN, y marcamos el test de Shapiro-Wilk (y, ya que estamos, las gráficas Q-Q): Ambos p-valores son muy grandes, así que vamos a aceptar que ambas muestras provienen de variables normales y usaremos un test t de dos medias. En este caso, como las muestras son apareadas (hemos medido las dos variables aleatorias sobre los mismos individuos), hay que elegir Pruebas T/Prueba t para muestras apareadas. Cuidado con la hipótesis alternativa: como JAMOVI toma como primera variable CORNFLK y segunda variable OATBRAN y nuestra hipótesis alternativa es que los oat bran reducen el nivel de colesterol respecto de los corn flakes, hemos de marcar “Medida 1 &gt; Medida 2”. Obtenemos un p-valor de 0.003. Por lo tanto, hemos encontrado evidencia estadísticamente significativa de que desayunar salvado reduce el nivel medio de colesterol respecto de desayunar copos de maíz. El intervalo de confianza del 95% para \\(\\mu_{cf}-\\mu_{ob}\\) va de 0.163 a \\(\\infty\\). Por lo tanto, tenemos un 95% de confianza en que desayunar salvado reduce en al menos 0.163 mmol/l el nivel medio de colesterol respecto de desayunar copos de maíz. ¿Y si no quisiéramos, o no pudiéramos, suponer que las muestras provienen de distribuciones normales? Entonces usaríamos un test de Wilcoxon: El p-valor da 0.006, por lo que la conclusión es la misma. Típica pregunta de MIR (esta, de 2017): El grosor del pliegue subcutáneo de grasa a nivel del tríceps se utiliza a veces para evaluar la cantidad de grasa corporal. Esta variable no se distribuye normalmente en las poblaciones. Queremos comparar el valor medio de esta variable en dos poblaciones que suponemos presentan distinta condición nutricional. La prueba estadística más adecuada para contrastar la hipótesis es: La prueba de Mann-Whitney. La prueba t de Student. El cálculo del coeficiente de correlación de Pearson. La prueba F de Snedecor. 15.1.4 Contrastes para más de dos medias Sean ahora \\(X_1,X_2,\\ldots, X_k\\) \\(k\\) variables aleatorias de medias \\(\\mu_1,\\mu_2,\\ldots,\\mu_k\\) y desviaciones típicas \\(\\sigma_1,\\sigma_2,\\ldots,\\sigma_k\\), respectivamente. Normalmente, se tratará de una misma variable aleatoria definida sobre \\(k\\) poblaciones diferentes. Nos preguntamos si es verdad o no que estas \\(k\\) variables tienen la misma media. Es decir, planteamos el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2=\\cdots=\\mu_k\\\\ H_{1}:\\text{No es verdad que } \\mu_1=\\mu_2=\\cdots=\\mu_k \\end{array} \\right. \\] Para ello, medimos cada \\(X_i\\) sobre una muestra aleatoria simple de tamaño \\(n_i\\). Observad que \\(H_1\\) en el contraste anterior es equivalente a \\[ \\text{Existen $i,j$ tales que } \\mu_i \\neq \\mu_j \\] no a \\[ \\mu_i \\neq \\mu_j \\text{ para todos los pares $i,j$ con $i\\neq j$} \\] Ejemplo 15.4 En un estudio (publicado en Personality and Social Psychology Bulletin 21 (1995), pp. 207-214) se quiso determinar si la benevolencia con la se juzga a una persona depende de cómo sonríe. Para ello se seleccionaron 136 personas, que se dividieron al azar en 4 grupos de 34. A las personas de cada grupo se les pasó un dosier donde se acusaba a un hombre de una falta grave (en un contexto universitario) y, tras estudiarlo, se les pusieron cinco preguntas sobre la culpabilidad del acusado y el castigo que se merecía. A partir de las respuestas de cada sujeto, se calculó un “índice de benevolencia” de cómo había juzgado al acusado. Los dosieres eran idénticos, excepto la foto del acusado: mismo hombre, pero diferente tipo de sonrisa: Tenemos los índices obtenidos en el fichero smiles.txt. Veamos sus estadísticos básicos y un diagrama de cajas. Vemos que la sonrisa neutra ha generado una menor benevolencia y la falsa, mayor. Queremos determinar si las diferencias son lo bastante grandes para aportar evidencia que la benevolencia depende de la sonrisa. En este caso tenemos una variable aleatoria, el índice de benevolencia con el que se juzga al acusado, definida sobre cuatro subpoblaciones definidas por el tipo de sonrisa en la foto. Llamemos \\(\\mu_s\\), \\(\\mu_f\\), \\(\\mu_c\\) y \\(\\mu_n\\) a sus medias: los índices de benevolencia medios con los que se juzga el dosier cuando la sonrisa es sincera, falsa, compungida o neutra, respectivamente. Entonces, queremos realizar el contraste \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_s=\\mu_{f}=\\mu_{c}=\\mu_{n} \\\\ H_1 : \\mbox{Hay algún par de sonrisas }i,j\\mbox{ tales que } \\mu_i \\neq \\mu_j \\end{array} \\right. \\] Un posible modo de resolver este contraste sería realizar los seis contrastes de pares de medias \\(\\mu_i=\\mu_j\\) contra \\(\\mu_i\\neq \\mu_j\\), pero esto aumenta la probabilidad de error si no ajustamos los p-valores. Y tenemos que comparar todas las medias dos a dos, porque podría pasar, por ejemplo, que no pudiéramos rechazar que \\(\\mu_n= \\mu_s\\) ni que \\(\\mu_s= \\mu_f\\), pero sí que pudiéramos rechazar que \\(\\mu_n= \\mu_f\\). Lo que queremos es un test que nos diga en un solo paso si todas las medias son iguales o si por el contrario hay alguna diferencia. La técnica más usual es el Análisis de la Varianza (ANOVA, del inglés ANalysis Of VAriance). Esta técnica se puede aplicar bajo diferentes diseños experimentales: por ejemplo, según cuántos factores usemos para separar la población en subpoblaciones (uno o varios) o según cómo escojamos las muestras (independientes o apareadas). La idea básica del ANOVA es que tenemos evidencia de que no todas las medias poblacionales son iguales si la variabilidad de las medias poblacionales es muy grande en relacion a la variabilidad total de los datos obtenidos: de ahí la VAriancia en el nombre. Esta variabilidad relativa se mide mediante un estadístico de contraste adecuado que, si todas la medias poblacionales son iguales y se satisfacen las condiciones adecuadas, tiene una distribución conocida (llamada F de Fisher-Snedecor: es la distribución de un cociente de dos variables \\(\\chi^2\\) independientes, y sus parámetros son los grados de libertad de estas dos distribuciones \\(\\chi^2\\)). Por lo tanto podemos usar esta distribución para calcular un p-valor que nos dé lo improbablemente grande que es la variabilidad de las medias muestrales si las medias poblacionales fueran todas iguales. 15.1.4.1 Diseño ANOVA de un factor En un estudio de diseño ANOVA de un factor o de una vía (One way ANOVA): Usamos un solo factor para clasificar la población en subpoblaciones. Tomamos una muestra aleatoria simple de la variable aleatoria sobre cada subpoblación, independientes unas de otras. El Ejemplo 15.4 es de tipo ANOVA de un factor: se clasifican los índices de benevolencia según un solo factor, el tipo de sonrisa en la foto, y se ha tomado una muestra de índices de benevolencia para cada tipo de sonrisa. Estas muestras son independientes porque se asignaron las fotos al azar a los participantes. ANOVA de un factor Supongamos que tenemos que realizar una comparación de medias en un estudio de diseño ANOVA de un factor. Si se cumple que: Cada una de las \\(k\\) variables aleatorias de las que hemos tomado muestras sigue una ley normal Homocedasticidad u homogeneidad: Todas estas variables tienen la misma varianza entonces podemos usar un test ANOVA. JAMOVI ofrece el ANOVA de un factor en ANOVA/ANOVA de Un Factor. Ejemplo 15.5 Sigamos con el Ejemplo 15.4. Ya hemos cargado la tabla. Efectuamos los tests de Shapiro-Wilks (separando la variable benevolencia según el factor sonrisa) y obtenemos los 4 p-valores por encima de 0.05, así que vamos a aceptar que para los cuatro tipos de sonrisas los índices de benevolencia se ajustan a distribuciones normales. Abriendo entonces ANOVA/ANOVA de Un Factor, separamos de nuevo la variable dependiente benevolencia según el factor sonrisa, marcamos la Prueba de homogeneidad para saber si podemos aceptar o no que las varianzas poblacionales son todas iguales, y como el p-valor de ambos tests es grande, marcamos la casilla Asumir iguales (Fisher), que efectua el test ANOVA. El p-valor es 0.018, por lo que obtenemos evidencia estadística de que al menos un par de medias son diferentes. Un ANOVA de un factor aplicado a solo dos medias es equivalente a un test t para dos medias suponiendo varianzas iguales. También podéis usar ANOVA/ANOVA para efectuar un ANOVA de un factor, mucho más rico en opciones (pero para el nivel de este curso casi todas innecesarias). Alternativas El test ANOVA de Fisher es bastante robusto a una ligera desviación de la normalidad de las muestras, pero deja estrepitosamente de ser válido si las varianzas poblacionales no son iguales. Si las variables poblacionales son normales, pero no podemos aceptar que tengan todas la misma varianza, lo recomendado es usar una variante llamada ANOVA de Welch, y que en JAMOVI se ejecuta marcando No asumir iguales (Welch) en lugar de Asumir iguales (Fisher). Otra posibilidad es usar el test no paramétrico de Kruskal-Wallis, que extiende a más de dos medias el test de Mann-Whitney. JAMOVI lo ofrece en ANOVA/No paramétrico/ANOVA de Un Factor: Kruskall-Wallis. Tests post hoc Si hemos rechazado la hipótesis nula \\(H_0:\\mu_1=\\cdots =\\mu_k\\), nos puede interesar estimar qué parejas de niveles tienen medias diferentes. La manera más popular es realizar los \\(\\binom{k}{2}\\) contrastes \\[ \\left\\{ \\begin{array}{ll} H_0 &amp;: \\mu_i=\\mu_j \\\\ H_1 &amp;: \\mu_i \\neq \\mu_j \\end{array} \\right. \\] usando un test t adecuado (si las muestras se ajustan a normalidad o son lo bastante grandes) o un test de Mann-Whitney (si no se puede usar un test t para todos los pares de medias). En caso de homogeneidad de varianzas, el test t no es exactamene el que hemos explicado para pares de medias y varianzas iguales porque usa todas las muestras, y no solo las dos involucradas, para estimar el error típico. Pero hay que ir con cuidado con el nivel de significación global. Como vimos en el tema anterior, si efectuamos muchos contrastes de pares de medias, la probabilidad de cometer un error de tipo I en alguno aumenta, por lo que hay que reducir el nivel de significación con el que los efectuamos o, equivalentemente, ajustar los p-valores. En ANOVA/ANOVA de Un Factor JAMOVI efectua un ajuste por defecto que es más que suficiente para nuestros propósitos. Si queréis usar otros ajustes, por ejemplo el de Bonferroni que mencionábamos en el tema anterior (multiplicar los p-valores por el número de tests), los encontraréis en ANOVA/ANOVA/Pruebas Post Hoc. Normalmente no habrá grandes diferencias en las conclusiones de los tests según el método de ajuste usado. Ejemplo 15.6 Seguimos con nuestro ejemplo sobre la benevolencia que suscitan los diferentes tipos de sonrisa. Con un ANOVA de un factor hemos obtenido evidencia significativa de que hay pares de sonrisas que inducen índices de benevolencia medios diferentes. Vamos a investigar cuáles. Antes de nada, un gráfico: en ANOVA/ANOVA de Un Factor pedimos que añada “Gráficas Descriptivas”: Nos da los intervalos de confianza del 95% para las cuatro medias. Observad que todos los pares de intervalos de confianza se solapan salvo dos: el de la sonrisa falsa y el de la sonrisa neutra. Este gráfico nos aporta evidencia de que estas dos medias no son iguales (cada una pertenece a su intervalo de confianza con una confianza del 95%, y estos dos intervalos son disjuntos) y nos indica que los otros pares de medias pueden ser iguales (sus intervalos de confianza no son disjuntos). Esto es solo una indicación gráfica del resultado que tenemos que esperar, pero no nos da el resultado del test con la confianza que deseamos: las conclusiones se basan en que todos los IC 95% aciertan, y la probabilidad de que eso ocurra es menor que 0.95. Vamos ya a realizar las comparaciones posteriores por parejas. Usamos para ello la ventana ANOVA/ANOVA de Un Factor/Pruebas Post-Hoc. Como hemos aceptado que las variables poblacionales son todas iguales, marcamos Tukey (varianzas iguales): En la tabla obtenemos la diferencia de medias “fila menos columna” y el p-valor del test para cada par formado por las medias para el tipo de sonrisa de la fila y el de la columna. Los p-valores están ajustados por el método de Tukey, que no vamos a explicar. Lo importante es que, como ya están ajustados, hay que compararlos directamente con el nivel de significación elegido. Tomando \\(\\alpha=0.05\\), solo obtenemos evidencia de diferencia de medias para el par sonrisa falsa-sonrisa neutra. Para el resto de pares de medias no podemos rechazar que sean iguales. Era lo que esperábamos. Si quisiéramos usar por ejemplo el ajuste de Bonferroni, tendríamos que efectuar el ANOVA con ANOVA/ANOVA: Hemos marcado también la columna de p-valores sin ajustar (“p”) y la del ajuste de Tukey para que veáis que el ajuste de Bonferroni consiste en tomar el mínimo de 1 y el resultado de multiplicar el p-valor por 6 (el número total de contrastes de pares de medias) y podáis comparar los valores ajustados de Bonferroni con los de Tukey. La conclusión con los dos tipos de ajuste es la misma. 15.1.4.2 Diseño ANOVA de bloques Así como el diseño de ANOVA de una vía generaliza a más de dos medias el contraste de igualdad de dos medias con muestras independientes, el ANOVA de bloques generaliza a más de dos medias el contraste de igualdad de dos medias con muestras apareadas. Ejemplo 15.7 Para comparar los efectos de dos analgésicos y un placebo en el tratamiento de la cefalea se reclutaron 10 enfermos de cefalea y a cada uno se le aplicaron los tres tratamientos en diferentes episodios de cefalea. El orden de los tratamientos en cada sujeto fue aleatorio. El efecto de los tratamientos se cuantificó mediante el tiempo (en minutos) que tardó en desaparecer la cefalea con el tratamiento. Los resultados fueron los siguientes: \\[ \\begin{array}{c|ccc} \\text{Sujeto} &amp; \\text{Placebo} &amp; \\text{Analgésico A}&amp;\\text{Analgésico B}\\\\\\hline 1 &amp; 35 &amp; 20 &amp; 22\\\\ 2 &amp; 40 &amp; 35 &amp; 42\\\\ 3 &amp; 60 &amp; 50 &amp; 30\\\\ 4 &amp; 50 &amp; 40 &amp; 35\\\\ 5 &amp; 50 &amp; 30 &amp; 22 \\\\ 6 &amp; 52 &amp; 30 &amp; 25\\\\ 7 &amp; 37 &amp; 22 &amp; 18\\\\ 8 &amp; 45 &amp; 30 &amp; 28\\\\ 9 &amp; 40 &amp; 45 &amp; 35\\\\ 10 &amp; 47 &amp; 40 &amp; 37 \\end{array} \\] Si llamamos \\(\\mu_P\\): Tiempo medio tomando el placebo \\(\\mu_A\\): Tiempo medio tomando el analgésico A \\(\\mu_B\\): Tiempo medio tomando el analgésico B queremos realizar el contraste: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_P =\\mu_A =\\mu_B \\\\ H_1 : \\mu_P\\neq \\mu_A\\mbox{ o }\\mu_P\\neq \\mu_B\\mbox{ o }\\mu_A\\neq \\mu_B \\end{array} \\right. \\] Aunque se ha usado un factor para clasificar la población (el tipo de tratamiento), no se trata de un diseño de ANOVA de una vía, porque las muestras de cada nivel no son independientes, sino apareadas. Se trata de un diseño de ANOVA de bloques. En un experimento con diseño de ANOVA de bloques: Tenemos \\(k\\) tratamientos que queremos comparar. Escogemos \\(b\\) bloques: conjuntos de \\(k\\) sujetos apareados (por ejemplo, cada bloque formado por \\(k\\) copias del mismo sujeto). Dentro de cada bloque, asignamos aleatoriamente a cada sujeto un tratamiento, de manera que cada tratamiento se use exactamente una vez dentro de cada bloque. Por ejemplo, si cada bloque corresponde a un único sujeto, le asignamos los tratamientos en diferentes momentos de tiempo en un orden aleatorio, como hemos hecho en nuestro ejemplo. El contraste que se quiere realizar es \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1} =\\mu_{2} =\\cdots =\\mu_{k} \\\\ H_1 : \\mbox{Hay $i,j$ tales que } \\mu_{i} \\neq \\mu_{j} \\end{array} \\right. \\] donde cada \\(\\mu_{i}\\) es la media del tratamiento \\(i\\)-ésimo La filosofía del contraste ANOVA es similar al de un factor: se considera que se tiene evidencia de que no todas las medias poblacionales son iguales si la variabilidad de las medias poblacionales es muy grande en relacion a la variabilidad total de los datos obtenidos, pero ahora tras descontar la contribución a esta última de la variabilidad de las medias de los bloques. Para que las conclusiones de un ANOVA de bloques tengan sentido, ha de pasar que Las \\(k\\cdot b\\) observaciones sean muestras aleatorias (de tamaño 1) e independientes de las \\(k\\cdot b\\) poblaciones definidas por las medidas que se tomarían para cada combinación de sujeto y tratamiento Estas \\(k\\cdot b\\) poblaciones sean normales y todas tengan la misma varianza No haya interacción entre los bloques y los tratamientos: Que para cada par de tratamientos \\(i,j\\), la diferencia entre las medias (poblacionales) de las mediciones del tratamiento \\(i\\) y el tratamiento \\(j\\) en todos los bloques sea la misma. Ninguna de estas condiciones se puede contrastar directamente, por lo tanto el experimentador ha de decidir si se cumplen o no según su experiencia. Si no se cree que se cumpla (b), puede ser conveniente efectuar un test no paramétrico. Si se cree que puede haber interacción entre los bloques y los tratamientos, es más recomendable usar un ANOVA de 2 factores (véase la siguiente sección). Podemos efectuar un ANOVA de bloques con JAMOVI en la pestaña ANOVA/ANOVA de Medidas Repetidas. Para ello, tenemos que tener la tabla con los resultados de las mediciones en una tabla de datos con filas los bloques y columnas los tratamientos. Para el ejemplo anterior, la tenemos en el fichero Analgesicos.csv. Tras importarla, comprobad (o especificad) que las variables de los tratamientos son numéricas. A continuación, en la ventana “Factores de Medidas Repetidas” de ANOVA/ANOVA de Medidas Repetidas tenemos que indicar cuántos tratamientos usamos. Como en nuestro ejemplo usamos tres tratamientos, hemos de añadir un “Nivel 3” a los dos que se especifican por defecto. Es una buena idea poner nombres tanto al factor que usamos para clasificar los tratamientos como a sus niveles (clicando encima y reescribiendo). A continuación, arrastramos las variables de cada tratamiento a su nivel correspondiende en la ventana “Celdas de Medidas Repetidas”: El p-valor &lt;0.001 nos indica que hay evidencia estadística de diferencia en las eficacias medias de al menos dos tratamientos. Los contrastes post hoc por parejas se efectuan más abajo en la misma pestaña, seleccionando el factor. Se puede también elegir el método de corrección de p-valores. Obtenemos evidencia significativa de diferencia entre ambos tratamientos y el placebo, pero no de diferencia entre los dos tratamientos. El test no paramétrico que generaliza al diseño ANOVA de bloques el test de Wilcoxon es el test de Friedman que se encuentra en la pestaña ANOVA/No Paramétrico/ANOVA de Medidas Repetidas (Friedman). En él solo hay que seleccionar las variables que contienen las mediciones de tratamientos. También se pueden efectuar los tests post hoc por parejas (y no os burléis del “no paramédico” por “no paramétrico” de la versión actual en español, ya lo arreglarán). 15.1.4.3 Diseño ANOVA multifactorial En un experimento de diseño de ANOVA factorial se usan las combinaciones de niveles de dos o más factores para definir las subpoblaciones para las que comparamos las medias de una variable aleatoria. El caso más sencillo, que es el único que trataremos aquí es el diseño de ANOVA de dos vías o de dos factores: Usamos las combinaciones de niveles de dos factores para definir las subpoblaciones Para cada pareja de niveles, uno de cada factor, tomamos una muestra aleatoria simple de la subpoblación definida por la combinación de ambos niveles. Estas muestras han de ser independientes las unas de las otras y todas del mismo tamaño \\(n\\geqslant 2\\). Ejemplo 15.8 Para contrastar si el nivel de colesterol depende del sexo o la complexión de las personas, se midió el nivel de colesterol (en mg/dL) de 30 personas de cada combinación de sexo (male o female) y complexión (small, medium o large). Tenemos los datos guardados en el tabla de datos colesterol.csv, con variables chol (el nivel de colesterol), sex (el sexo) y frame (la complexión). En un estudio como el de este ejemplo, en realidad nos podemos plantear cuatro preguntas: ¿Hay diferencia en el nivel medio de colesterol según el sexo, teniendo en cuenta la posible influencia de la complexión en el nivel del colesterol? ¿Hay diferencia en el nivel medio de colesterol según la complexión, teniendo en cuenta la posible influencia del sexo en el nivel del colesterol? ¿Hay diferencia en el nivel medio de colesterol según la combinación sexo-complexión? ¿Hay interacción en el nivel medio de colesterol entre el sexo y la complexión (en el sentido de que el efecto de los niveles de un factor se magnifiquen en los del otro factor: por ejemplo, que la diferencia en el nivel medio de colesterol entre hombres y mujeres dependa de su complexión)? Formalmente, usamos dos factores \\(A\\) y \\(B\\) para clasificar la población sobre la que medimos una variable \\(X\\). El factor \\(A\\) tiene \\(k\\) niveles: \\(a_1,\\ldots,a_k\\). El factor \\(B\\) tiene \\(l\\) niveles: \\(b_1,\\ldots,b_l\\). Tomamos para cada par \\((a_i,b_j)\\) una muestra aleatoria simple de tamaño \\(n\\), independientes las unas de las otras. Por lo tanto, el número total de observaciones es \\(n\\cdot k\\cdot l\\). Llamemos: \\(\\mu_{i\\bullet}\\): media poblacional de \\(X\\) para los sujetos del nivel \\(a_i\\) de \\(A\\) \\(\\mu_{\\bullet j}\\): media poblacional de \\(X\\) para los sujetos del nivel \\(b_j\\) de \\(B\\) \\(\\mu_{ij}\\): media poblacional de \\(X\\) para los sujetos que son simultáneamente del nivel \\(a_i\\) de \\(A\\) y del nivel \\(b_j\\) de \\(B\\) Planteamos los cuatro contrastes siguientes: Contraste de medias del factor \\(A\\): Contrastamos si hay diferencias entre los niveles del factor \\(A\\): \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1\\bullet}=\\mu_{2\\bullet}=\\cdots =\\mu_{k\\bullet} \\\\ H_1 : \\mbox{Hay $i,i&#39;$ tales que $\\mu_{i\\bullet}\\neq \\mu_{i&#39;\\bullet}$} \\end{array} \\right. \\] Contraste de medias del factor \\(B\\): Contrastamos si hay diferencias entre los niveles del factor \\(B\\): \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{\\bullet 1}=\\mu_{\\bullet 2}=\\cdots =\\mu_{\\bullet l} \\\\ H_1 : \\mbox{Hay $j,j&#39;&#39;$ tales que $\\mu_{\\bullet j}\\neq \\mu_{\\bullet j&#39;}$} \\end{array} \\right. \\] Contraste de medias de la combinación \\(A\\)-\\(B\\): Contrastamos si hay diferencias entre las parejas (nivel de \\(A\\), nivel de \\(B\\)): \\[ \\left\\{ \\begin{array}{l} H_0 : \\mbox{Para todos $i,j,i&#39;,j&#39;$, $\\mu_{ij}=\\mu_{i&#39;j&#39;}$} \\\\ H_1 : \\mbox{Hay $i,j,i&#39;,j&#39;$ tales que $\\mu_{ij}\\neq \\mu_{i&#39;j&#39;}$} \\end{array} \\right. \\] Contraste de interacción: Contrastamos si hay interacción entre los niveles de \\(A\\) y \\(B\\) \\[ \\left\\{ \\begin{array}{l} H_0 : \\mbox{No hay interacción entre ningún par de niveles} \\\\ H_1 : \\mbox{Hay interacción entre algún par de niveles} \\end{array} \\right. \\] Para que las conclusiones del ANOVA de dos vías tengan sentido, es necesario que: Las observaciones para cada combinación de niveles constituyan muestras aleatorias simples independientes, cada una de tamaño \\(n\\), de las \\(k\\cdot l\\) subpoblaciones definidas por las combinaciones de un nivel de \\(A\\) y un nivel de \\(B\\). La restricción de \\(X\\) a cada una de estas \\(k\\cdot l\\) poblaciones sea normal y todas tengan la misma varianza. En JAMOVI, los ANOVA factoriales, y en particular el de dos vías, se pueden efectuar en la pestaña ANOVA/ANOVA, seleccionando la variable que contiene los valores como “Variable dependiente” y las variables correspondientes a los factores como “Factores Fijos”, y marcando la casilla “Modelo Global”: En esta tabla: La fila “frame” corresponde al contraste de medias del factor frame: como el p-valor es 0.066, con nivel de significación 0.05 no tenemos evidencia estadística de que el nivel medio de colesterol varíe con la complexión La fila “sex” corresponde al contraste de medias del factor sex: como el p-valor es 0.332, no tenemos evidencia estadística de que el nivel medio de colesterol varíe con el sexo La fila “Modelo Global” corresponde al contraste de medias de la combinación sex-frame: como el p-valor es 0.26, no tenemos evidencia estadística de que el nivel medio de colesterol varíe con la combinación de sexo y complexión La fila “frame*sex” corresponde al contraste de interacción: como el p-valor es 0.958, no tenemos evidencia estadística de que haya interacción entre el sexo y la complexión en el nivel medio de colesterol: es decir, no tenemos evidencia de que las diferencias entre los niveles medios de hombres y mujeres de las tres complexiones no sean iguales. Si hubiéramos encontrado evidencia de diferencias entre medias para algún factor, podríamos efectuar los contrastes post-hoc por parejas en la sección “Pruebas post-hoc”. 15.2 Contrastes para varianzas 15.2.1 Contrastes bilaterales para dos varianzas Sean \\(X_1\\) y \\(X_2\\) dos variables aleatorias de desviaciones típicas \\(\\sigma_1\\) y \\(\\sigma_2\\). Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1=\\sigma_2\\\\ H_{1}:\\sigma_1\\neq \\sigma_2 \\end{array} \\right. \\] o, equivalentemente, \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2=\\sigma_2^2\\\\ H_{1}:\\sigma_1^2\\neq \\sigma_2^2 \\end{array} \\right. \\] Si \\(X_1\\) y \\(X_2\\) son las dos normales, podemos usar el test F. Este test usa como estadístico de contraste el cociente de varianzas muestrales, \\(\\widetilde{S}^2_{X_1}/\\widetilde{S}^2_{X_2}\\), que, si \\(\\sigma_1=\\sigma_2\\), tiene distribución F de Fisher-Snedecor, de ahí el nombre del test. Con JAMOVI, se realiza marcando la casilla Test de homogeneidad al llevar a cabo un test t de dos muestras independientes con el módulo moretests instalado: es el resultado de la fila “Variance ratio”. Con R se realiza con la función var.test aplicada a las dos muestras y además os da un intervalo de confianza para el cociente \\(\\sigma_1^2/\\sigma_2^2\\). La ventaja de var.test es que también permite efectuar contrastes unilaterales, especificando el parámetro alternative. El test F no és válido a poco que las variables \\(X_1\\) o \\(X_2\\) difieran de normales, incluso aunque las muestras sean grandes. Si no podemos aceptar que \\(X_1\\) y \\(X_2\\) sean normales, es necesario usar un test no paramétrico. JAMOVI usa el test de Levene, que lleva a cabo marcando la mencionada casilla Test de homogeneidad. Ya hemos visto un ejemplo de contraste bilateral de varianzas en el Ejemplo 15.2. 15.2.2 Contrastes de homogeneidad para más de dos varianzas Sean ahora \\(X_1,X_2,\\ldots,X_k\\) \\(k\\) variables aleatorias, de desviaciones típicas \\(\\sigma_1,\\sigma_2,\\ldots,\\sigma_k\\) respectivamente.. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1=\\sigma_2=\\cdots=\\sigma_k\\\\ H_{1}: \\text{Hay algún par }i,j\\text{ tal que }\\sigma_i\\neq \\sigma_j \\end{array} \\right. \\] o, equivalentemente, \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2=\\sigma_2^2=\\cdots=\\sigma_k^2\\\\ H_{1}: \\text{Hay algún par }i,j\\text{ tal que }\\sigma_i^2\\neq \\sigma_j^2 \\end{array} \\right. \\] Si todas las variables son normales, lo mejor es usar el test de Bartlett, pero si alguna muestra no se ajusta a una variable normal, conviene usar algún test no paramétrico. JAMOVI ofrece el test de Levene, que también sirve para dos medias, ya está bien. Como hemos visto en la sección anterior, ambos tests se pueden efectuar marcando la casilla Prueba de homogeneidad al hacer un ANOVA de un factor con ANOVA/ANOVA de Un Factor y el módulo moretests instalado. 15.3 Contrastes para proporciones 15.3.1 Contrastes para una proporción Sea \\(X\\) una variable aleatoria Bernoulli de parámetro \\(p\\). Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:p=p_0\\\\ H_{1}:p\\neq p_0\\text{ o }p&gt; p_0\\text{ o }p&lt; p_0 \\end{array} \\right. \\] Tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\). 15.3.1.1 Test binomial Como vimos en el tema anterior, siempre podemos usar el test binomial, que usa que si \\(p=p_0\\), el número de éxitos en una m.a.s. de tamaño \\(n\\) tiene distribución \\(B(n,p_0)\\). Para llevarlo a cabo con JAMOVI, podemos usar Frecuencias/Prueba binomial. Ejemplo 15.9 La muestra de personas recogidas en la tabla de datos de temperaturas usada hasta ahora fue transversal, sin números prefijados de hombres y mujeres. Su composición en sexos, ¿aporta evidencia estadística de que la proporción de mujeres en la población es estrictamente mayor que la de hombres? Sea \\(p\\) la proporción de mujeres en la población. Podemos traducir la pregunta planteada en el contraste \\[ \\left\\{ \\begin{array}{l} H_0:p=0.5\\\\ H_1:p&gt;0.5 \\end{array} \\right. \\] La ventana del test binomial para este contraste con JAMOVI es: JAMOVI ha realizado el test binomial para las mujeres (F) y para los hombres (M): el que nos interesa es el primero. Con un p-valor 0.474 y un intervalo de confianza para \\(p\\) de 0.448 a 1, no podemos rechazar que \\(p\\) sea 0.5. Si no disponemos de la tabla de datos sino solo de las frecuencias, tenemos que entrarlas como una variable en una tabla de datos: y al cargar la variable en la ventana Frecuencias/Prueba binomial, marcar la casilla Los valores son frecuencias: 15.3.1.2 Test aproximado Si el tamaño \\(n\\) de la muestra es grande (digamos \\(\\geqslant 40\\)), podemos usar el test aproximado basado en que, si \\(H_0: p=p_0\\) es verdadera y \\(n\\) es grande, por el Teorema Central del Límite \\[ \\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{\\widehat{p}_X(1-\\widehat{p}_X)}{n}}}\\approx N(0,1) \\] Este test es mucho más popular que el binomial, porque se puede efectuar “a mano” con una simple calculadora. Curiosamente, JAMOVI no lo implementa tal cual (solo un test equivalente y solo para el contraste bilateral, en Frecuencias/Prueba de proporciones (N resultados); volveremos sobre él al hablar de contrastes para dos, o más, proporciones), pero podéis usar la función prop.test de R , aplicada a: el número de éxitos; el tamaño total de la muestra; el parámetro p igualado al valor a contrastar \\(p_0\\); el parámetro alternative igualado al tipo de contraste; y el parámetro conf.level igualado al nivel de confianza (si es 0.95, no hace falta especificarlo). En esta función R usa por defecto una corrección de continuidad que se suele usar al aproximar variables aleatorias discretas por medio de variables continuas y que suele mejorar los resultados del test. Podéis cancelar esta corrección de continuidad con el parámetro correct=FALSE pero os recomendamos que la mantengáis. 15.3.2 Contrastes para dos proporciones Sean \\(X_1\\) y \\(X_2\\) dos variables aleatorias Bernoulli de probabilidades poblacionales de éxito \\(p_1\\) y \\(p_2\\), respectivamente. Queremos realizar un contraste \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] Para ello, tomamos una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\) y una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\). Como en la comparación de dos medias, estas muestras pueden ser independientes o apareadas. 15.3.2.1 Tests para dos proporciones con muestras independientes Test \\(\\chi^2\\) Cuando las dos muestras son grandes, digamos las dos de tamaño \\(\\geqslant 40\\), podemos usar el llamado test \\(\\chi^2\\). Usa el estadístico de contraste que ya explicamos al hablar de intervalos de confianza para la diferencia de dos proporciones. Si \\(p_1=p_2\\) y las muestras son lo bastante grandes, este estadístico de contraste sigue una ley aproximadamente normal estándar (por si os lía el nombre del test, recordad que el cuadrado de una normal estándar tiene distribución \\(\\chi_1^2\\) y esto es lo que realmente usa el test). En JAMOVI lo encontramos en Frecuencias/Muestras independientes: Prueba de asociación de \\(\\chi^2\\). Os recomendamos usar la versión “con corrección de continuidad”, que aplica la corrección de continuidad que comentábamos al hablar de prop.test. Ejemplo 15.10 ¿Hay asociación positiva entre bronquitis en la infancia y tos crónica en la adolescencia, en el sentido de que el riesgo de tos crónica es mayor entre los adolescentes que siendo niños tuvieron bronquitis? Para responder esta cuestión, en un estudio transversal se tomaron 1319 niños de 14 años, se miró si en ese momento tenían tos crónica o no y si a los 5 años habían tenido bronquitis o no. El resultado fue la tabla siguiente: \\[ \\begin{array}{c} \\qquad\\qquad\\qquad\\qquad\\textbf{Bronquitis}\\\\ \\qquad\\qquad\\qquad\\qquad\\textbf{a los 5 años}\\\\ \\begin{array}{ll|cc} &amp; &amp; \\quad\\text{Sí}\\quad &amp;\\quad \\text{No}\\quad \\\\ \\hline \\textbf{Tos a los} &amp; \\text{Sí} &amp; 26 &amp; 44 \\\\ \\textbf{14 años} &amp; \\text{No} &amp; 247 &amp; 1002 \\end{array} \\end{array} \\] Tenemos los datos de los niños guardados en el fichero bronquitis.txt. Las variables aleatorias de interés son: \\(X_1\\): Que un niño que tuvo bronquitis a los 5 años, tenga tos crónica a los 14, de probabilidad poblacional de éxito \\(p_1\\) \\(X_2\\): Que un niño que no tuvo bronquitis a los 5 años, tenga tos crónica a los 14, de probabilidad poblacional de éxito \\(p_2\\) El contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1&gt;p_2 \\end{array}\\right. \\] Como las dos muestras son grandes, podemos usar el test \\(\\chi^2\\). Para hacerlo con JAMOVI, importamos el fichero bronquitis.txt en una tabla de datos. A continuación, en Datos/Configuración, en la lista de “Niveles” ponemos el 1 encima del 0 (seleccionándolo y subíendolo con la flecha). Finalmente, vamos a Frecuencias/Muestras independientes, elegimos bronquitis como variable columna y tos como variable fila y marcamos que queremos comparar por “columnas” (la dimensión de las dos variables cuyas probabilidades de éxito queremos comparar). Observad que en este fichero los Síes son 1 y los Noes 0, y en la tabla de frecuencias la primera columna ahora es 1 y la segunda 0, por lo que la hipótesis alternativa ha de ser “Grupo 1 &gt; Grupo 2”. Mirad en la figura el resto de casillas marcadas. El p-valor es menor que 0.001, por lo que obtenemos evidencia estadísticamente significativa de que la probabilidad de tos crónica en la adolescencia es mayor entre los que sufrieron bronquitis infantil. El Riesgo Absoluto Atribuible estimado es de 0.174, con un IC 95% entre 0.077 y 1, y el Riesgo Relativo estimado es de 1.88, con un IC 95% entre 1.36 y 2.60; es decir, con un 95% de confianza estimamos que: El riesgo de tos crónica en la adolescencia es al menos 7.7 puntos porcentuales mayor entre los adolescentes que tuvieron bronquitis infantil que entre los que no El riesgo de tos crónica en la adolescencia es entre un 36% y un 160% mayor entre los adolescentes que tuvieron bronquitis infantil que entre los que no En los tests \\(\\chi^2\\) unilaterales para dos proporciones, el intervalo de confianza para el RR que calcula JAMOVI es el del test bilateral. Bueno, menos es nada. Si no hubiéramos dispuesto del fichero con los datos brutos y solo tuviéramos la tabla de frecuencias, las entraríamos en una tabla de datos como la que sigue: y procederíamos como antes, solo que ahora declararíamos la variable con las frecuencias como “Frecuencias”: Test exacto de Fisher En un contraste de dos proporciones a partir de muestras independientes siempre podemos usar el test exacto de Fisher. Se basa en la idea de que si la hipótesis nula es verdadera (es decir, si \\(p_1=p_2\\)) entonces sería como si las dos muestras se hubieran obtenido de la misma población. No entraremos en detalle. Lo importante, y lo que lo hace impopular en algunos ámbitos, es que en realidad no compara las proporciones poblacionales de éxito \\(p_1\\) y \\(p_2\\), sino sus odds y el intervalo de confianza que da es para el cociente de estas odds: es decir, para la odds ratio. En particular, si el estudio es de casos y controles con una muestra estratificada que no permita estimar riesgos, el test exacto de Fisher es el único test válido, ya que entonces no tiene sentido comparar las probabilidades del desenlace codicionadas a la exposición y la no exposición. Con JAMOVI se efectua marcando Test exacto de Fisher y Razón de Odds en Datos/Configuración, y el resto de casillas (y preparación) como para el test \\(\\chi^2\\). Por ejemplo, para efectuarlo en la situación del Ejemplo 15.10 a partir del fichero de datos marcaríamos: El p-valor es de nuevo menor que 0.001, por lo que obtenemos evidencia estadísticamente significativa de que las odds, y por lo tanto el riesgo, de tos crónica en la adolescencia aumentan en los adolescentes que tuvieron bronquitis infantil. La OR estimada de tos crónica relativa a la bronquitis infantil es de 2.4, con un IC 95% entre 1.45 y 3.97. Por lo tanto estimamos con un 95% de confianza que las odds de tos crónica en la adolescencia son entre un 45% y un 297% mayores entre los que tuvieron bronquitis infantil. De nuevo, este IC es el del test bilateral, aunque hayamos efectuado un test unilateral. Si queréis, o necesitáis, efectuar estos dos tests con R , por ejemplo para calcular el p-valor exacto o, en el caso unilateral, el intervalo de confianza correcto: El test \\(\\chi^2\\) también se hace con la función prop.test, ahora aplicada al vector con los números de éxitos y el vector con el tamaño de las muestras El test exacto de Fisher se hace con la función fisher.test aplicada a la matriz con la tabla de contingencia. Observad la sintaxis para nuestro ejemplo en ambos casos en la figura siguiente: El p-valor del test \\(\\chi^2\\) es 0.0004. El p-valor del test exacto de Fisher es 0.0008 y el IC 95% del contraste unilateral para la odds ratio va de 1.509 a \\(\\infty\\), por lo que estimamos que las odds de tos crónica en la adolescencia si se ha tenido bronquitis en la infancia son al menos un 50.9% mayores que si no se ha tenido. 15.3.2.2 Tests para dos proporciones con muestras apareadas Supongamos ahora que tomamos las muestras apareadas, ambas de tamaño \\(n\\). Para simplificar el lenguaje, supondremos que las dos muestras se obtienen midiendo las variables \\(X_1\\) y \\(X_2\\) sobre los sujetos de una misma muestra aleatoria simple. Test de McNemar Si el contraste es bilateral y el número de casos discordantes (aquellos que son éxito para una variable y fracaso para la otra) es lo bastante grande (digamos que \\(\\geqslant 25\\)), el test recomendado es el test de McNemar. Si la tabla de contingencia es \\[ \\begin{array}{c} \\hphantom{Variable No}\\quad\\textbf{Variable $X_1$}\\\\ \\begin{array}{ll|cc} &amp; &amp; \\quad \\text{Sí}\\quad &amp; \\quad\\text{No}\\quad \\\\ \\hline \\textbf{Variable} &amp; \\text{Sí} &amp; a &amp; b \\\\ \\textbf{$X_2$} &amp; \\text{No} &amp; c &amp; d \\end{array} \\end{array} \\] (y por lo tanto el número de casos discordantes, que ha de ser \\(\\geqslant 25\\), es \\(b+c\\)), este test usa que el estadístico \\[ \\frac{(b-c)^2}{b+c} \\] tiene una distribución aproximadamente \\(\\chi^2_1\\) si la hipótesis nula es cierta. En JAMOVI lo encontramos en Frecuencias/Muestras apareadas: Prueba de McNemar. Ejemplo 15.11 Si en el tratamiento del cáncer de mama, a la quimioterapia perioperatoria y la mastectomía le añadimos quimioterapia postoperatoria durante 6 meses, ¿hay diferencia en la tasa de supervivencia a 5 años vista? Para resolver esta cuestión, en un ensayo clínico se trató un grupo de 1244 pacientes, apareadas según diferentes características. En cada pareja de pacientes se repartieron los dos tratamientos al azar: quimioterapia perioperatoria y mastectomía, o quimioterapia perioperatoria, mastectomía y quimioterapia postoperatoria durante 6 meses. Se anotó la supervivencia a los 5 años de las pacientes. Los datos obtenidos fueron: \\[ \\begin{array}{c} \\hphantom{postoperatoria No sobrevive}\\qquad\\textbf{No quimio postperatoria}\\\\ \\begin{array}{ll|cc} &amp; &amp; \\quad\\text{Sobrevive}\\quad &amp; \\quad\\text{No sobrevive}\\quad \\\\ \\hline \\textbf{Sí quimio} &amp; \\text{Sobrevive} &amp; 510 &amp; 17 \\\\ \\textbf{postoperatoria} &amp; \\text{No sobrevive} &amp; 5 &amp; 90 \\end{array} \\end{array} \\] En este caso, las variables aleatorias de interés son: \\(X_1\\): Que una paciente con cáncer de mama tratada con mastectomía y quimioterapia perioperatoria sobreviva 5 años, de probabilidad de éxito \\(p_1\\) \\(X_2\\): Que una paciente con cáncer de mama tratada con mastectomía, quimioterapia perioperatoria y quimioterapia postoperatoria sobreviva 5 años, de probabilidad de éxito \\(p_2\\) El contraste que nos interesa es si hay diferencia entre \\(p_1\\) y \\(p_2\\), no tenemos una hipótesis alternativa preconcebida sobre si un tratamiento es superior al otro: \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2 \\end{array}\\right. \\] El contraste es bilateral, tenemos dos muestras apareadas y 22 casos discordantes (parejas de pacientes en las que una murió antes de los 5 años y la otra sobrevivió). En principio este número es algo justo para poder usar un test de McNemar, pero a falta de alternativa será el que emplearemos. Entramos las frecuencias en una tabla de datos: A continuación, en la lista de “Niveles” de Datos/Configuración ponemos en cada variable el nivel correspondiente al Éxito (en nuestro caso, Sobrevive) encima del fracaso. Finalmente, vamos a Frecuencias/Muestras apareadas, entramos las variables, y marcamos Test \\(\\chi^2\\) con corrección de continuidad (recomendable sobre el Test \\(\\chi^2\\) a secas). Obtenemos un p-valor 0.019. Por lo tanto, con un nivel de significación del 5% concluimos que la probabilidad de supervivencia a 5 años bajo los dos tratamientos es diferente. Y entonces, como la supervivencia a 5 años ha sido más frecuente entre las que sí recibieron quimioterapia postoperatoria, concluímos que incluirla aumenta significativamente la probabilidad de supervivencia a 5 años. Test binomial Si no podéis usar el test de McNemar, siempre podéis usar un test binomial para efectuar un contraste de dos proporciones con dos muestras apareadas. La idea es que si \\(p_1=p_2\\), las probabilidades poblacionales de los pares (Sí,No) y (No,Sí) entre los pares discordantes son la misma, ambas 0.5, mientras que si, por ejemplo, \\(p_1&gt; p_2\\), la probabilidad poblacional del par (Sí,No) entre los pares discordantes es mayor que la del par (No,Sí), y por lo tanto mayor que 0.5. Entonces: tomamos la muestra solo de los casos discordantes, y comparamos la probabilidad de (Sí,No) con 0.5 exactamente en el mismo sentido con el que comparábamos \\(p_1\\) y \\(p_2\\). Fijaos que en este contraste solo nos interesará el p-valor, porque el intervalo de confianza va a ser para la proporción de los pares (Si,No) en la población de casos discordantes. Imaginemos por ejemplo que ahora sí que nos preguntamos si añadir, en el tratamiento del cáncer de mama, quimioterapia postoperatoria durante 6 meses a la quimioterapia perioperatoria y la mastectomía aumenta la tasa de supervivencia a 5 años. Con las notaciones del ejemplo anterior, el contraste es ahora \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1&gt; p_2 \\end{array}\\right. \\] Como es un contraste unilateral, no podemos usar un test de McNemar, así que vamos a usar el test binomial. Entramos las frecuencias de los dos tipos de casos discordantes de nuestra muestra y efectuamos el test binomial correspondiente en Frecuencias/Prueba binomial Obtenemos un p-valor 0.008. Por lo tanto, con un nivel de significación del 5% concluimos que la probabilidad de supervivencia a 5 años con quimioterapia postoperatoria es mayor que sin quimioterapia postoperatoria. 15.3.3 Contrastes para más de dos proporciones El contraste de igualdad o no de más dos o más proporciones es un caso particular de contraste de igualdad de dos o más distribuciones que estudiaremos en la Sección 15.4.2 15.4 Contrastes para distribuciones 15.4.1 Contrastes de bondad de ajuste de una muestra a una distribución A menudo queremos contrastar si una muestra proviene o no de una distribución concreta. Por ejemplo: Lanzamos un dado cúbico varias veces, apuntamos los resultados, y de estos resultados queremos deducir si el dado está equilibrado o no: es decir, si al lanzarlo todas sus caras tienen la misma probabilidad de salir, 1/6, o no. Anotamos los casos diarios de ingresos por una enfermedad concreta en un hospital, y deseamos saber si se ajustan a una distribución de Poisson. Hemos usado unas muestras pequeñas en un test t para comparar dos medias; para que nos podamos fiar del resultado del contraste, estas muestras tendrían que provenir de distribuciones aproximadamente normales. En todos estos casos, nos interesa un contraste cuya hipótesis nula es que la muestra sigue una cierta distribución: técnicamente, se dice que la muestra se ajusta a esa distribución. La hipótesis alternativa es que la muestra no sigue dicha distribución, es decir, que no se ajusta a la misma. Genéricamente, a este tipo de contrastes se les llama de bondad de ajuste. \\[ \\left\\{ \\begin{array}{l} H_0: \\text{ la muestra se ajusta a una determinada distribución}\\\\ H_1: \\text{ la muestra NO se ajusta a esa distribución} \\end{array} \\right. \\] Como siempre, si obtenemos evidencia que nos permita rechazar la hipótesis nula, concluiremos que la muestra no se ajusta a esa distribución. Esta evidencia se obtiene comparando nuestra muestra con la “esperada” para la distribución que contrastamos: si son muy diferentes, lo tomamos como evidencia de que nuestra muestra no sigue dicha distribución, porque sería muy “rara” si la siguiera. Si nuestra muestra no es lo bastante diferente de la esperada como para hacernos dudar de que siga dicha distribución, no obtenemos evidencia que nos permita rechazar la hipótesis nula y aceptamos que la muestra se ajusta a la distribución dada. 15.4.1.1 Test \\(\\chi^2\\) de bondad de ajuste para distribuciones discretas El test más popular para contrastar si una muestra de una variable aleatoria cualitativa, ordinal o cuantitativa discreta se ajusta a una distribución dada es el test \\(\\chi^2\\) de Pearson. Este test compara las frecuencias de los posibles valores de la variable en la muestra observada con las esperadas en una muestra de la distribución contrastada del mismo tamaño mediante un estadístico que cuantifica esta diferencia y que, si se cumplen unas determinadas condiciones, tiene una distribución de probabilidad conocida (¡Sorpresa! Será una \\(\\chi^2\\)). Si el estadístico toma un valor improbablemente grande, es señal de que las frecuencias observadas son muy diferentes de las frecuencias esperadas y nos hace dudar de que la hipótesis nula sea verdadera. Veamos un ejemplo que igual os es útil. Ejemplo 15.12 La tabla que sigue muestra las frecuencias de aparición de las últimas cifras del Gordo de Navidad entre 1812 y 2023. En total, 213 sorteos contando la repetición de un sorteo durante la Guerra Civil. \\[ \\begin{array}{l|cccccccccc} \\hline \\text{cifra} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 \\\\ \\hline \\text{frecuencia} &amp; 23 &amp; 8 &amp; 13 &amp; 21 &amp; 26 &amp; 31 &amp; 27 &amp; 23 &amp; 25 &amp; 16 \\\\ \\hline \\end{array} \\] Si estas últimas cifras tuvieran todas la misma probabilidad de salir, esta probabilidad sería 1/10. Entonces, esperaríamos de media unas 213/10=21.3 ocurrencias de cada cifra. El diagrama de barras inferior muestra que hay algunas desviaciones notables respecto de esta media, marcada con la línea roja discontinua. Las diferencias que observamos respecto de los valores esperados, ¿son los bastante grandes como para hacernos dudar de que todas las cifras salgan con la misma probabilidad, sin ningún tipo de sesgo? O, por el contrario, ¿son razonables dentro de lo que se puede achacar al azar? Este ejemplo ilustra la situación general siguiente: Tenemos una muestra aleatoria simple de n observaciones que queremos contrastar si se ajusta o no a una distribución totalmente determinada. El contraste que queremos realizar es \\[ \\left\\{\\begin{array}{l} H_{0}: \\mbox{ La muestra se ajusta a esta distribución}\\\\ H_{1}: \\mbox{ La población no se ajusta a esta distribución} \\end{array} \\right. \\] En el ejemplo anterior, queremos contrastar si las últimas cifras del Gordo se ajustan a una distribución uniforme: si todas tienen la misma probabilidad. Agrupamos todos los elementos del dominio de la distribución teórica que contrastamos en un número finito k de clases que denotaremos por \\(C_1,\\ldots,C_k\\). Cada clase puede corresponder a un solo elemento del dominio o a más de uno, pero todo elemento del dominio ha de pertenecer a una, y solo una, clase. Queremos recalcar que el número de clases ha de ser finito. En nuestro ejemplo, hemos tomado 10 clases, una para cada elemento del dominio: la clase formada solo por el 0, la clase formada solo por el 1, etc. El hecho de que la distribución que queremos contrastar esté totalmente determinada nos ha de permitir calcular la probabilidad de cada clase. Para cada clase \\(C_i\\), sean \\(obs_i\\): la frecuencia absoluta observada de esta clase en la muestra. En nuestro ejemplo, son las frecuencias de cada última cifra que hemos dado en la tabla. \\(p_i\\): la probabilidad teórica de esta clase para la distribución de probabilidades que estamos contrastando. En nuestro ejemplo, cada \\(p_i\\) vale 1/10. \\(esp_i\\): la frecuencia absoluta esperada de esta clase si se hubiera obtenido con la distribución que estamos contrastando: \\(esp_i=p_i\\cdot n\\). En nuestro ejemplo, cada \\(esp_i\\) vale 21.3. Se calcula entonces el estadístico de contraste \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Fijaos en que \\(\\chi^2\\) mide, de una manera concreta, la diferencia entre las \\(obs_i\\) y las \\(esp_i\\). Lo que necesitamos ahora es saber a partir de qué valor esta \\(\\chi^2\\) es tan grande que sería muy improbable si la muestra proviniera de la distribución contrastada, lo que nos permitiría concluir que es inverosímil que provenga de dicha distribución. Teorema 15.1 Si \\(n\\) es grande (digamos que \\(n\\geqslant 30\\)) Las \\(k\\) clases elegidas forman una partición del dominio: \\(p_1+\\cdots+p_k=1\\) Las clases cumplen la regla de Cochran: \\(esp_i\\geqslant 5\\) para todo \\(i=1,\\ldots,k\\) entonces el estadístico \\(\\chi^2\\) tiene distribución aproximadamente \\(\\chi_{k-1}^2\\) (\\(\\chi^2\\) con número de grados de libertad el número de clases menos 1). Por lo tanto, si llamamos \\(\\chi^2_0\\) a lo que ha valido el estadístico de contraste \\(\\chi^2\\) en nuestra muestra, el p-valor del contraste, que nos permite decidir si aceptamos o rechazamos la hipótesis nula de que la muestra proviene de la distribución contrastada, es \\[ P(\\chi_{k-1}^2\\geqslant \\chi^2_0). \\] Siguiendo con nuestro ejemplo del Gordo de Navidad, si calculamos el valor de \\(\\chi^2_0\\), da \\[ \\frac{(23-21.3)^2}{21.3}+\\frac{(8-21.3)^2}{21.3}+\\frac{(13-21.3)^2}{21.3}+\\cdots+\\frac{(16-21.3)^2}{21.3}=20.756 \\] Como \\(k=10\\), el p-valor será \\(P(\\chi_9^2\\geqslant 20.756)=0.014\\). Naturalmente, puede ser un error de tipo I. Pero por si acaso, no juguéis a números que terminen en 1 o 2… En JAMOVI, este test \\(\\chi^2\\) se encuentra disponible en la pestaña Recuento/N Resultados (\\(\\chi^2\\) de bondad de ajuste). Se puede aplicar directamente a una muestra o a las frecuencias observadas. Ejemplo 15.13 Seguimos con el ejemplo de las terminaciones de los Gordos de Navidad. Tenemos estas terminaciones en la variable ultimacifra de la tabla de datos loteria.csv. Si, tras cargar la tabla de datos, en Recuento/N Resultados (\\(\\chi^2\\) de bondad de ajuste) elegimos esta variable, por defecto realiza el contraste de bondad de ajuste a la distribución uniforme, en la que todos los resultados presentes en dicha variable tienen la misma probabilidad y que es el que queremos efectuar en este ejemplo. Hemos marcado además la casilla de “Frecuencias esperadas” para que nos dé las frecuencias esperadas de cada clase y así comprobar que se satisface la regla de Cochran: Obtenemos al final el valor del estadístico \\(\\chi^2\\), el número gl de grados de libertad que ha usado para calcular el p-valor, y el valor p de este último. Supongamos ahora que no disponemos de los datos originales, sino solo de las frecuencias observadas de las clases. Entonces, primero tenemos que definir una variable con las diferentes clases (en nuestro ejemplo las cifras de 0 a 9) y una variable con sus frecuencias observadas. A continuación, en Recuento/N Resultados (\\(\\chi^2\\) de bondad de ajuste) elegimos como “Variable” la que especifica las clases y como “Frecuencias (opcional)” la columna con las frecuencias: El resultado es el mismo que antes. En ambos casos, si en vez de contrastar si todas las últimas cifras aparecen con la misma probabilidad quisiéramos contrastar alguna otra hipótesis sobre los valores de estas probabilidades, las especificaríamos en la columna “Razón” de la tabla de “Proporciones esperadas”. Ejemplo 15.14 La distribución por edades de la población española es la siguiente: \\[ \\begin{array}{c|ccccccccc} \\text{edad} &amp; 0\\!-\\!9 &amp; 10\\!-\\!19 &amp; 20\\!-\\!29 &amp; 30\\!-\\!39 &amp; 40\\!-\\!49 &amp; 50\\!-\\!59 &amp; 60\\!-\\!69 &amp; 70\\!-\\!79 &amp; 80\\text{ o más}\\\\\\hline \\text{%} &amp; 9.3 &amp; 10&amp; 10&amp;13.2&amp; 17&amp; 14.9&amp; 11&amp; 8.4&amp; 6.2 \\end{array} \\] En una muestra de 65 españoles diagnosticados de COVID-19 durante la primera ola pandémica, se obtuvieron las frecuencias de edades siguientes: \\[ \\begin{array}{c|ccccccccc} \\text{edad} &amp; 0\\!-\\!9 &amp; 10\\!-\\!19 &amp; 20\\!-\\!29 &amp; 30\\!-\\!39 &amp; 40\\!-\\!49 &amp; 50\\!-\\!59 &amp; 60\\!-\\!69 &amp; 70\\!-\\!79 &amp; 80\\text{ o más}\\\\\\hline \\text{frecuencia} &amp; 1 &amp; 1&amp; 5&amp;8&amp; 11&amp; 10&amp; 11&amp; 11&amp; 7 \\end{array} \\] Nos preguntamos si esta muestra aporta evidencia de que la distribución por edades de los españoles con COVID-19 durante la primera ola es diferente a la de la población española en general y por lo tanto de que la COVID-19 afectó de manera diferente unas franjas de edad que otras. Es un ejemplo típico de contraste de bondad de ajuste. La hipótesis nula del contraste es que nuestra muestra de edades se ajusta a la distribución de las edades de la población española, y la hipótesis alternativa es que esto no es verdad. Tomamos como clases las 9 franjas de edad dadas. Sus probabilidades teóricas \\(p_i\\) son las definidas por la población española, y sus frecuencias esperadas \\(esp_i\\) serán las probabilidades teóricas multiplicadas por el tamaño de la muestra, 65. \\[ \\begin{array}{c|ccccccccc} C_i &amp; 0\\!-\\!9 &amp; 10\\!-\\!19 &amp; 20\\!-\\!29 &amp; 30\\!-\\!39 &amp; 40\\!-\\!49 &amp; 50\\!-\\!59 &amp; 60\\!-\\!69 &amp; 70\\!-\\!79 &amp; 80\\text{ o más}\\\\\\hline obs_i &amp; 1 &amp; 1&amp; 5&amp;8&amp; 11&amp; 10&amp; 11&amp; 11&amp; 7\\\\ p_i &amp; 0.093 &amp; 0.100&amp; 0.100&amp; 0.132&amp; 0.170&amp; 0.149&amp; 0.110&amp; 0.084&amp; 0.062\\\\ esp_i &amp; 6.045 &amp; 6.500 &amp; 6.500 &amp; 8.580 &amp; 11.050 &amp; 9.685 &amp; 7.150 &amp; 5.460 &amp; 4.030 \\end{array} \\] El estadístico de contraste vale \\[ \\chi^2_0=\\frac{(1-6.045)^2}{6.045}+\\frac{(1-6.5)^2}{6.5}+\\cdots+\\frac{(7-4.03)^2}{4.03}=19.14 \\] y el p-valor vale \\(P(\\chi_8^2\\geqslant 19.14)=0.014\\). En JAMOVI se hace como antes, solo que ahora en la columna “Razón” de la tabla de “Proporciones esperadas” entramos las probabilidades teóricas. Con un p-valor de 0.014, tenemos evidencia estadística de que la distribución por edades de los españoles con COVID-19 durante la primera ola fue diferente de la de la población española en general. ¿Seguro? ¿Y la regla de Cochran? En este ejemplo no podemos usar tal cual el test \\(\\chi^2\\), porque no se cumplen las condiciones teóricas que nos garantizan que sus conclusiones sean significativas: tenemos una clase con frecuencia esperada &lt;5. Por lo tanto, lo que hemos hecho no es correcto y no nos podemos fiar de la conclusión. ¿Qué podemos hacer en este caso? Una opción es unir clases: si unimos las dos últimas clases en una única clase “70 o más” su frecuencia esperada será la suma de las frecuencias esperadas de las clases agrupadas, 9.49, y habremos solventado el problema. La nueva tabla será: \\[ \\begin{array}{c|cccccccc} C_i &amp; 0\\!-\\!9 &amp; 10\\!-\\!19 &amp; 20\\!-\\!29 &amp; 30\\!-\\!39 &amp; 40\\!-\\!49 &amp; 50\\!-\\!59 &amp; 60\\!-\\!69 &amp; 70\\text{ o más}\\\\\\hline obs_i &amp; 1 &amp; 1&amp; 5&amp;8&amp; 11&amp; 10&amp; 11&amp; 18\\\\ p_i &amp; 0.093 &amp; 0.100&amp; 0.100&amp; 0.132&amp; 0.170&amp; 0.149&amp; 0.110&amp; 0.146\\\\ esp_i &amp; 6.045 &amp; 6.500 &amp; 6.500 &amp; 8.580 &amp; 11.050 &amp; 9.685 &amp; 7.150 &amp; 9.49 \\end{array} \\] El estadístico de contraste vale \\[ \\chi^2_0=\\frac{(1-6.045)^2}{6.045}+\\frac{(1-6.5)^2}{6.5}+\\cdots+\\frac{(18-9.49)^2}{9.49}=18.964 \\] y el p-valor vale \\(P(\\chi_7^2\\geqslant 18.964)=0.0083\\). Otra opción, si queréis mantener como clases las definidas al principio, es usar la versión MonteCarlo del test \\(\\chi^2\\), basada en simulaciones. Este test consiste en: Se genera un conjunto muy grande de muestras aleatorias simples (nosotros tomaremos 5000) con la distribución contrastada, todas del mismo tamaño que nuestra muestra. Se calcula el estadístico de contraste \\(\\chi^2\\) para cada muestra. Se estima el p-valor como la fracción de muestras que han dado un valor de \\(\\chi^2\\) mayor que el de nuestra muestra. JAMOVI no tiene implementado por ahora este test MonteCarlo, y es una pena porque es el que os recomendamos usar. Se puede efectuar con las funciones adecuadas en su ventana del editor de R : Definimos un vector Obs con las frecuencias observadas: Obs=c(1, 1, 5, 8, 11, 10, 11, 11, 7) Definimos un vector Probs con las probabilidades teóricas Probs=c(0.093, 0.100, 0.100, 0.132, 0.170, 0.149, 0.110, 0.084, 0.062) Ejecutamos la función siguiente (donde el valor de B es el número de simulaciones que queremos) chisq.test(Obs, p=Probs, simulate.p.value=TRUE, B=5000) Obtenemos el p-valor (p-value) 0.01. Esto significa que solo un 1% de las muestras de 65 personas cuyas edades siguen la distribución española en general, han dado un valor de \\(\\chi^2\\) mayor que el de nuestra muestra original. Esto nos tiene que hacer concluir que nuestra muestra sería muy rara si se hubiera obtenido con la distribución de franjas de edad española en general. Así que, ahora sí de manera fiable, hemos obtenido evidencia estadística de que la distribución por edades de los españoles con COVID-19 durante la primera ola fue diferente a la de la población española en general. El test de MonteCarlo se basa en simulaciones aleatorias, por lo que ejecuciones diferentes con los mismos datos pueden dar p-valores diferentes. Pero si el número de simulaciones es lo bastante grande, es muy robusto y las conclusiones no difieren. Veamos ahora un ejemplo detallado de la aplicación de un test \\(\\chi^2\\) a un contraste de bondad de ajuste a una familia de distribuciones, no a una distribución completamente determinada. Ejemplo 15.15 Si la concepción fuera un acontecimiento aleatorio en mujeres en edad fértil, los números de hijos de mujeres en edad fértil seguirían una distribución de Poisson. La tabla siguiente da los números de hijos de 125 mujeres entre 20 y 45 años (elegidas al azar entre las pacientes del servicio de ginecología de un hospital concreto). \\[ \\begin{array}{l|ccccccc} \\hline \\text{hijos} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; \\geqslant 6 \\\\ \\hline \\text{frecuencia} &amp; 59 &amp; 44 &amp; 14 &amp; 3 &amp; 4 &amp;1 &amp; 0\\\\ \\hline \\end{array} \\] Queremos contrastar si podemos aceptar que estos números de hijos provienen de una distribución de Poisson. Es decir, queremos realizar el contraste \\[ \\left\\{\\begin{array}{l} H_{0}: \\mbox{La muestra se ajusta a una distribución de Poisson}\\\\ H_{1}: \\mbox{La muestra no se ajusta a una distribución de Poisson} \\end{array} \\right. \\] Fijaos antes de empezar en que no estamos en la situación general para poder efectuar un test \\(\\chi^2\\): “una distribución de Poisson” no es una distribución completamente determinada, para la que podamos calcular probabilidades. Necesitamos saber su \\(\\lambda\\) para poder calcular probabilidades. Como \\(\\lambda\\) es la esperanza de la variable aleatoria, la podemos estimar con la media muestral de nuestra muestra: \\[ \\lambda= \\frac{59\\cdot 0+ 44\\cdot 1+ 14\\cdot 2+ 3\\cdot 3+ 4\\cdot 4+1\\cdot 5}{125}=0.816 \\] Pero ¡ATENCIÓN! Cuando hay que estimar algún parámetro de la distribución con la muestra, se tiene que tener en cuenta la regla siguiente: Si para determinar completamente la distribución hemos tenido que estimar algún parámetro (\\(\\mu\\), \\(\\sigma\\), \\(\\lambda\\), …) con nuestra muestra, para calcular el p-valor se ha de restar a los grados de libertad el número de parámetros estimados. Es decir, si se han estimado \\(m\\) parámetros, el p-valor es \\[ P(\\chi_{k-1-m}^2\\geqslant \\chi^2_0). \\] Tendremos que recordarlo al final, en el momento de calcular el p-valor. Por ahora seguimos con el proceso. Hay que partir el dominio de la distribución teórica en un número finito de clases. El dominio de una variable de Poisson en todo el conjunto de los números naturales, por lo que no podremos usar como clases sus elementos uno a uno. Lo que haremos por ahora será tomar las clases que nos dan en la tabla de frecuencias. Es decir, tomamos como clases \\(C_1=\\{0\\}\\), \\(C_2=\\{1\\}\\), \\(C_3=\\{2\\}\\), \\(C_4=\\{3\\}\\), \\(C_5=\\{4\\}\\), \\(C_6=\\{5\\}\\) y \\(C_7=\\{6,7,8,\\ldots\\}\\). \\[ \\begin{array}{l|ccccccc} \\hline C_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; \\geqslant 6 \\\\ \\hline obs_i &amp; 59 &amp; 44 &amp; 14 &amp; 3 &amp; 4 &amp;1 &amp; 0 \\\\ \\hline \\end{array} \\] Las clases han de cubrir todo el dominio de la distribución teórica que contrastamos, no solo los valores de la muestra. Si el dominio es todo \\(\\mathbb{N}\\), las clases tienen que cubrir todo \\(\\mathbb{N}\\). Calculamos (Ejercicio) la probabilidad \\(p_i\\) de cada clase para una variable \\(X\\) con distribución de Poisson con \\(\\lambda=0.816\\) y su frecuencia esperada \\(esp_i=p_i\\cdot 125\\): \\[ \\begin{array}{l|cccccc} \\hline C_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; \\geqslant 6 \\\\ \\hline obs_i &amp; 59 &amp; 44 &amp; 14 &amp; 3 &amp; 4 &amp;1 &amp; 0 \\\\\\hline p_i &amp; 0.442 &amp; 0.361 &amp; 0.147 &amp; 0.040 &amp; 0.008 &amp; 0.001 &amp; 0.001\\\\ \\hline esp_i&amp; 55.250 &amp; 45.125 &amp; 18.375 &amp; 5.000 &amp; 1.000 &amp;0.125 &amp; 0.125\\\\ \\hline \\end{array} \\] Nuestra muestra es de tamaño mayor que 30 y las clases cubren todo el dominio de la variable teórica con la que comparamos nuestra muestra. Pero hay clases con frecuencia esperada menor que 5, por lo que tal cual no podemos usar el test \\(\\chi^2\\). Cuando hemos tenido que estimar parámetros, como en este ejemplo, no es adecuado usar la versión MonteCarlo del test \\(\\chi^2\\), porque la conclusión sería sobre si la muestra se ajusta o no a la distribución de Poisson concreta usada en las simulaciones, no sobre si se ajusta o no a una distribución de Poisson. Lo adecuado entonces es agrupar el mínimo número de clases consecutivas para conseguir que todas las frecuencias esperadas sean \\(\\geqslant 5\\). En nuestro caso, agruparemos las clases \\(C_4=\\{3\\}\\), \\(C_5=\\{4\\}\\), \\(C_6=\\{5\\}\\) y \\(C_7=\\{6,7,8,\\ldots\\}\\) en una sola. \\[ \\begin{array}{l|cccc} \\hline C_i &amp; 0 &amp; 1 &amp; 2 &amp; \\geqslant 3 \\\\ \\hline obs_i &amp; 59 &amp; 44 &amp; 14 &amp; 8 &amp; \\\\\\hline p_i &amp; 0.442 &amp; 0.361 &amp; 0.147 &amp; 0.05\\\\ \\hline esp_i&amp; 55.250 &amp; 45.125 &amp; 18.375 &amp; 6.250 \\\\ \\hline \\end{array} \\] Ya estamos en las condiciones de efectuar el test \\(\\chi^2\\): entramos en JAMOVI una variable con los valores 0, 1, 2, 3 (este último representará toda la clase \\(\\geqslant 3\\)), una variable con sus frecuencias observadas 59, 44, 14, 8, y en “Proporciones esperadas” de Recuento/N Resultados (\\(\\chi^2\\) de bondad de ajuste) entramos las probabilidades teóricas: El p-valor 0.612 indica que podemos aceptar que los números de hijos se ajustan a una distribución de Poisson. ¡No! Para calcular el p-valor, hay que restar el número de parámetros estimados al número de grados de libertad. Como R no sabe que hemos estimado la \\(\\lambda\\) con nuestra muestra, ha usado 3 grados de libertad (gl en la tabla inferior), pero en realidad el p-valor ha de ser \\(P(\\chi^2_2\\geqslant 1.81)\\). Tenemos que calcularlo nosotros al final. El p-valor correcto es 0.405. Por lo tanto, ahora sí, podemos aceptar que nuestra muestra de números de hijos sigue una distribución de Poisson. 15.4.1.2 Contrastes de normalidad Que una o varias muestras provengan de una distribución normal es una hipótesis en muchos teoremas. Por ejemplo, para efectuar un test t con muestras pequeñas, es necesario que las poblacionales sean normales, o lo que es lo mismo, que las muestras provengan de variables normales. En realidad, lo que miramos en estos casos es si cada muestra se ajusta a una variable normal. Si lo podemos rechazar, entonces podemos rechazar que provenga de una variable con distribución normal. Si no lo podemos rechazar, entonces no podemos rechazar que provenga de una variable con distribución normal y aceptamos que lo cumple. Hay muchos tests de normalidad diferentes. Ya hemos explicado cómo efectuar algunos en un Inciso en la sección de contrastes de una media, así que no lo repetiremos aquí, aunque convendría que, ahora que tenéis una nueva luz sobre contrastes de bondad de ajuste, revisitarais ese Inciso. 15.4.2 Contrastes de igualdad de dos o más distribuciones Supongamos que tenemos \\(m\\) variables aleatorias \\(X_1,\\ldots,X_m\\), todas ellas con el mismo dominio finito \\(\\{x_1,\\ldots,x_k\\}\\). Usualmente, se tratará de la restricción de una variable aleatoria \\(X\\) a diferentes subpoblaciones de la población en la que está definida. Queremos contrastar si es verdad o no que todas estas variables aleatorias tienen la misma distribución de probabilidad. Es decir, si se cumple que \\[ P(X_i=x_l)=P(X_j=x_l)\\text{ para todos $i,j=1,\\ldots,m$ y $l=1,\\ldots,k$} \\] o si, por el contrario, al menos dos variables \\(X_{i_0}\\) y \\(X_{j_0}\\) tienen diferentes probabilidades de tomar algún mismo valor. Por lo tanto, el contraste que nos interesa es \\[ \\left\\{\\begin{array}{l} H_0:\\text{ $X_1,\\ldots,X_m$ tienen todas la misma distribución de probabilidad}\\\\ H_1:\\text{ No es verdad que $X_1,\\ldots,X_m$ tengan todas la misma distribución de probabilidad} \\end{array}\\right. \\] Un caso particular de este contraste es el de igualdad de varias proporciones: si \\(X_1,\\ldots,X_m\\) son de Bernoulli, contrastar si tienen o no la misma distribución es exactamente lo mismo que contrastar si tienen o no la misma probabilidad de éxito. Otro caso particular son los contrastes de independencia en los que tenemos dos variables aleatorias con dominio finito, llamémoslas \\(A\\) con dominio \\(\\{a_1,\\ldots,a_m\\}\\) y \\(B\\) con dominio \\(\\{b_1,\\ldots,b_k\\}\\), y nos preguntamos si son independientes o no: es decir, si es verdad que para todos \\(i,j=1,\\ldots,m\\) y \\(l=1,\\ldots,k\\) \\[ P(B=b_l|A=a_i)=P(B=b_l|A=a_j) \\] Si llamamos \\(B_i\\) a la variable \\(B\\) restringida a los sujetos de la población en los que \\(A\\) vale \\(a_i\\), tenemos que la independencia de \\(A\\) y \\(B\\) es equivalente a que las variables \\(B_1,\\ldots,B_m\\) tengan todas la misma distribución. Volvamos a la situación inicial: \\(m\\) variables aleatorias \\(X_1,\\ldots,X_m\\) con dominio \\(\\{x_1,\\ldots,x_k\\}\\). Para contrastar la igualdad de sus distribuciones, tomamos una muestra aleatoria simple de cada una de ellas, independientes las unas de las otras. Estas muestras se pueden tomar de manera estratificada, escogiendo una muestra de tamaño prefijado de cada una, o de manera transversal, si se trataba de la misma variable definida sobre diferentes subpoblaciones y hemos elegido una muestra transversal de la población global. Sea como sea, obtendremos una tabla de frecuencias como la siguiente: \\[ \\begin{array}{c|cccc} &amp; X_1 &amp; X_2 &amp; \\ldots &amp; X_m\\\\ \\hline x_1 &amp; n_{1,1} &amp; n_{1,2} &amp; \\ldots &amp; n_{1,m}\\\\ x_2 &amp; n_{2,1} &amp; n_{2,2} &amp; \\ldots &amp; n_{2,m}\\\\ \\vdots &amp; \\vdots &amp;\\vdots &amp;\\ddots &amp; \\vdots \\\\ x_k &amp; n_{k,1} &amp; n_{k,2} &amp; \\ldots &amp; n_{k,m}\\\\ \\end{array} \\] Ejemplo 15.16 Queremos contrastar si el tipo de parto de una gestante que haya tenido COVID-19 durante el embarazo depende de la sintomatología de la enfermedad. Para ello, hemos tomado una muestra de 1000 gestantes españolas que dieron positivo en COVID-19 durante su embarazo y hemos anotado el nivel de gravedad de la infección (clasificado en asintomático, leve o grave) y el tipo de parto que tuvieron (eutócico, instrumental, cesárea programada o cesárea urgente). Hemos obtenido la tabla de frecuencias siguiente: \\[ \\begin{array}{c} \\qquad\\qquad\\qquad\\qquad\\qquad\\qquad \\textbf{Síntomas}\\\\[-2ex] \\begin{array}{lr|ccc|c} &amp; &amp; \\text{Asintomática} &amp; \\text{Leve} &amp; \\text{Grave} &amp; \\text{Total}\\\\ \\hline &amp; \\text{Eutócico} &amp; 305 &amp; 234 &amp; 95 &amp; 634\\\\ \\textbf{Tipo de} &amp; \\text{Instrumental} &amp; 48 &amp; 46 &amp; 13 &amp; 107\\\\ \\textbf{parto} &amp; \\text{Cesárea programada} &amp; 28 &amp; 43 &amp; 30 &amp; 101\\\\ &amp; \\text{Cesárea urgente} &amp; 72 &amp; 58 &amp; 28 &amp; 158\\\\ \\hline &amp; \\text{Total} &amp; 453 &amp; 381 &amp; 166 &amp; 1000 \\end{array} \\end{array} \\] En este ejemplo, queremos contrastar si las variables aleatorias \\(X_a\\): Tomamos una gestante que tuvo COVID-19 asintomático durante el embarazo y anotamos su tipo de parto \\(X_l\\) y \\(X_g\\): Lo mismo, para COVID-19 leve y grave, respectivamente tienen la misma distribución de probabilidad: \\[ \\left\\{ \\begin{array}{l} H_0: \\text{ $X_a$, $X_l$ y $X_g$ tienen la misma distribución de probabilidad}\\\\ H_0: \\text{ No es verdad que $X_a$, $X_l$ y $X_g$ tengan la misma distribución de probabilidad} \\end{array} \\right. \\] En este ejemplo, la muestra aleatoria de cada variable proviene de una muestra transversal de gestantes con COVID-19, asignando cada gestante a su grupo sintomático y anotando su tipo de parto. Volvamos a la situación general. Para cada \\(i=1,\\ldots,m\\), sea \\(n_{\\bullet,i}\\) la suma de la columna \\(i\\)-ésima de la tabla de frecuencias, es decir, el tamaño de la muestra de la variable \\(X_i\\), y para cada \\(l=1,\\ldots,k\\) sea \\(n_{l,\\bullet}\\) la suma de la fila \\(l\\)-ésima de la tabla de frecuencias, es decir, el número total de apariciones de \\(x_l\\) en la muestra global. Finalmente, sea \\(n\\) el tamaño de la muestra total. \\[ \\begin{array}{c|cccc|c} &amp; X_1 &amp; X_2 &amp; \\ldots &amp; X_m &amp; \\text{Total}\\\\ \\hline x_1 &amp; n_{1,1} &amp; n_{1,2} &amp; \\ldots &amp; n_{1,m} &amp; n_{1,\\bullet}\\\\ x_2 &amp; n_{2,1} &amp; n_{2,2} &amp; \\ldots &amp; n_{2,m}&amp; n_{2,\\bullet}\\\\ \\vdots &amp; \\vdots &amp;\\vdots &amp;\\ddots &amp; \\vdots &amp; \\vdots \\\\ x_k &amp; n_{k,1} &amp; n_{k,2} &amp; \\ldots &amp; n_{k,m} &amp; n_{k,\\bullet}\\\\\\hline \\text{Total} &amp; n_{\\bullet,1} &amp; n_{\\bullet,2} &amp;\\ldots &amp; n_{\\bullet,m} &amp; n \\end{array} \\] Resulta que el contraste de igualdad de varias distribuciones se puede interpretar como un contraste de bondad de ajuste. La manera más sencilla de entenderlo es suponer que, como en nuestro ejemplo, las variables \\(X_1,\\ldots,X_m\\) que comparamos son la restricción de una cierta variable aleatoria \\(X\\) a diferentes poblaciones que forman una partición de la población donde \\(X\\) está definida. Es el caso de nuestro ejemplo, donde esta variable \\(X\\) es la que toma una embarazada con COVID-19 y anota su tipo de parto, y las variables \\(X_a,X_l,X_g\\) se obtienen partiendo el conjunto de embarazadas en tres grupos sintomáticos y restringiendo la \\(X\\) a cada uno de ellos. En este caso, que las variables \\(X_1,\\ldots,X_m\\) tengan todas exactamente la misma distribución de probabilidad es equivalente a que todas tengan la misma distribución de probabilidad que \\(X\\). En efecto, para cada \\(l=1,\\ldots,k\\), si \\[ P(X_1=x_l)=P(X_2=x_l)=\\cdots=P(X_m=x_l) \\] entonces \\[ P(X=x_l)=P(X_1=x_l)=P(X_2=x_l)=\\cdots=P(X_m=x_l) \\] Si la hipótesis nula es cierta, podemos estimar \\(P(X=x_l)\\) a partir de la muestra global como \\(n_{l,\\bullet}/n\\). Por lo tanto, si la hipótesis nula fuera cierta, para cada \\(i=1,\\ldots,m\\), la frecuencia esperada del valor \\(x_l\\) en la muestra de \\(X_i\\) sería \\[ P(X_i=x_l)\\cdot n_{\\bullet,i}=P(X=x_l)\\cdot n_{\\bullet,i}=\\frac{n_{l,\\bullet}\\cdot n_{\\bullet,i}}{n} \\] Y resulta que podemos comparar las frecuencias que hemos observado, \\(n_{i,l}\\), con estas frecuencias esperadas si la hipótesis nula fuera cierta usando un estadístico \\(\\chi^2\\) como el de los contrastes de bondad de ajuste: Teorema 15.2 Con las notaciones anteriores, si \\(n\\) es grande (digamos que \\(n\\geqslant 30\\)) Regla de Cochran: cada frecuencia esperada \\((n_{l,\\bullet}\\cdot n_{\\bullet,i})/n\\) es \\(\\geqslant 5\\) entonces \\[ \\chi^2=\\sum_{i=1}^m\\sum\\limits_{l=1}^k \\frac{ \\left( n_{ij}- \\frac{n_{l,\\bullet}\\cdot n_{\\bullet,i}}{n}\\right)^2 } {\\frac{n_{l,\\bullet}\\cdot n_{\\bullet,i}}{n}} \\] tiene distribución aproximadamente \\(\\chi_{(m-1)(k-1))}^2\\). Mirad el número de grados de libertad: número de filas menos 1 por número de columnas menos 1. Volvemos a nuestro ejemplo. Las probabilidades estimadas de la variable \\(X\\) definida por el tipo de parto son: \\[ \\begin{array}{r|cc} \\textbf{Tipo} &amp; \\textbf{Prob. estimada}\\\\ \\hline \\text{Eutócico} &amp; 634/1000=0.634\\\\ \\text{Instrumental} &amp; 107/1000=0.107\\\\ \\text{Cesárea programada} &amp; 101/1000=0.101\\\\ \\text{Cesárea urgente} &amp; 158/1000=0.158 \\end{array} \\] y la tabla de frecuencias esperadas será \\[ \\begin{array}{c} \\begin{array}{r|ccc} &amp; \\text{Asintomática} &amp; \\text{Leve} &amp; \\text{Grave} \\\\ \\hline \\text{Eutócico} &amp; \\frac{453\\cdot 634}{1000} &amp; \\frac{381\\cdot 634}{1000} &amp; \\frac{166\\cdot 634}{1000} \\\\ \\text{Instrumental} &amp; \\frac{453\\cdot 107}{1000} &amp; \\frac{381\\cdot 107}{1000} &amp; \\frac{166\\cdot 107}{1000} \\\\ \\text{Cesárea programada} &amp; \\frac{453\\cdot 101}{1000} &amp; \\frac{381\\cdot 101}{1000} &amp; \\frac{166\\cdot 101}{1000}\\\\ \\text{Cesárea urgente} &amp; \\frac{453\\cdot 158}{1000} &amp; \\frac{381\\cdot 158}{1000} &amp; \\frac{166\\cdot 158}{1000} \\end{array}\\\\ \\downarrow\\\\ \\begin{array}{r|ccc} &amp; \\text{Asintomática} &amp; \\text{Leve} &amp; \\text{Grave} \\\\ \\hline \\text{Eutócico} &amp; 287.202 &amp; 241.554 &amp; 105.244 \\\\ \\text{Instrumental} &amp; 48.471 &amp; 40.767 &amp; 17.762 \\\\ \\text{Cesárea programada} &amp; 45.753 &amp; 38.481 &amp; 16.766\\\\ \\text{Cesárea urgente} &amp; 71.574 &amp; 60.198 &amp; 26.228 \\end{array} \\end{array} \\] El valor del estadístico de contraste es \\[ \\begin{array}{rl} \\chi^2_0 &amp;\\displaystyle =\\frac{(305-287.202)^2}{287.202}+\\frac{(234-241.554)^2}{241.554}+\\frac{(95-105.224)^2}{105.224}+\\frac{(48-48.471)^2}{48.471}+\\cdots\\\\ &amp; =22.357 \\end{array} \\] El número de grados de libertad de la \\(\\chi^2\\) con la que tenemos que calcular el p-valor es \\((4-1)\\cdot (3-1)=6\\). Por lo tanto el p-valor es \\(P(\\chi^2_6\\geqslant 22.357)=0.001\\). Hemos obtenido evidencia estadística de que las distribuciones de tipos de parto en los tres grupos sintomáticos de COVID-19 en embarazadas no son la misma. Esto se suele abreviar diciendo que hemos encontrado evidencia estadística de asociación entre el tipo de parto y el grupo sintomático de la embarazada. En JAMOVI este test está implementado en la pestaña Frecuencias/Muestras independientes (Prueba de asociación de \\(\\chi^2\\)). Se puede aplicar a una tabla de datos con los datos originales o a unas variables en las que hayamos entrado las frecuencias observadas. Vamos a hacerlo de esta última manera. En primer lugar, definimos tres variables: Tipo, con los tipos de parto, Síntomas, con el grupo sintomático, y Frecuencias, con las frecuencias observadas. Las dos primeras variables tienen que estar definidas de manera que formen cada par (Tipo,Grupo sintomático) y la tercera tiene que valer la frecuencia observada de dicho par. A continuación, en Frecuencias/Muestras independientes (Prueba de asociación de \\(\\chi^2\\)) seleccionamos como “Filas” y “Columnas” las variables Tipo y Síntomas y como “Frecuencias” la variable Frecuencias. Si además marcamos en Celdas la casilla de “Frecuencias esperadas” obtendremos las frecuencias esperadas y en particular podremos comprobar si se cumple la regla de Cochran y por lo tanto tiene sentido usar el test \\(\\chi^2\\). Tal y como se calculan las frecuencias esperadas, vemos que la más pequeña va a ser la correspondiente a la fila de suma mínima y la columna de suma mínima, e igual al producto de estas dos sumas dividido por el tamaño total de la muestra. Si esta frecuencia esperada mínima es \\(\\geqslant 5\\), el resto también lo serán y se cumplirá la regla de Cochran. En nuestro ejemplo, la fila de suma mínima es la de las cesáreas programadas y la columna de suma mínima es la de las infectadas graves: la frecuencia esperada mínima es 166·101/1000=16.766, mayor que 5. Veamos otro ejemplo, en este caso de comparación de proporciones. Ejemplo 15.17 Para estudiar si hay asociación en los niños entre el hábito tabáquico y la tos nocturna, se tomó una muestra de 2847 niños de 12 años y se obtuvo la siguiente información: \\[ \\begin{array}{c} \\qquad\\qquad\\qquad\\qquad\\textbf{Hábito tabáquico}\\\\ \\begin{array}{lc|ccc|c} &amp; &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\textbf{Tos} &amp;\\text{Sí} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\textbf{nocturna} &amp;\\text{No}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline &amp;\\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847\\\\ \\end{array} \\end{array} \\] Llamemos \\(p_n\\), \\(p_o\\) y \\(p_r\\) a las probabilidades de que tenga tos nocturna un niño no fumador, un niño fumador ocasional y un niño fumador regular, respectivamente. Queremos realizar el contraste \\[ \\left\\{\\begin{array}{ll} H_0:\\ p_n=p_o=p_r\\\\ H_1:\\text{ No es cierto que $p_n=p_o=p_r$} \\end{array} \\right. \\] Si llamamos \\(X_n\\) a la variable aleatoria de Bernoulli que toma un niño no fumador y da 1 si tiene tos nocturna y 0 si no, y \\(X_o,X_r\\) a las variables aleatorias similares para niños fumadores ocasionales y regulares, respectivamente, el contraste planteado es equivalente a \\[ \\left\\{\\begin{array}{ll} H_0:\\text{ $X_n,X_o,X_r$ tienen la misma distribución de probabilidad}\\\\ H_1:\\text{ No es cierto que $X_n,X_o,X_r$ tengan la misma distribución de probabilidad} \\end{array} \\right. \\] La muestra es muy grande, pero para poder usar un test \\(\\chi^2\\) tenemos que confirmar que la frecuencia esperada mínima es \\(\\geqslant 5\\). La frecuencia esperada mínima será el producte de la suma mínima de una fila por la suma mínima de una columna, dividido por el tamaño de la muestra: 172·741/2847=44.767. Por lo tanto todas las frecuencias esperadas serán mayores que esta, y en particular mayores que 5. Entramos la tabla de frecuencias observadas en JAMOVI: y efectuamos el test: Como el p-valor es menor que 0.001, hemos obtenido evidencia estadística de asociación entre la tos nocturna y el hápito tabáquico en niños. De nuevo, si el tamaño de la muestra no es lo bastante grande o si no se cumple la regla de Cochran, se puede usar la versión MonteCarlo. Por ejemplo, imaginad que la muestra de niños del ejemplo anterior hubiera sido 10 veces más pequeña, de tamaño 285, y las frecuencias hubieran sido las originales divididas por 10: \\[ \\begin{array}{c} \\qquad\\qquad\\qquad\\qquad\\textbf{Hábito tabáquico}\\\\[-1ex] \\begin{array}{lc|ccc|c} &amp; &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\textbf{Tos} &amp;\\text{Sí} &amp; 27 &amp; 39 &amp; 8 &amp; 74\\\\ \\textbf{nocturna} &amp;\\text{No}&amp; 104 &amp; 98 &amp; 9 &amp; 211\\\\\\hline &amp;\\text{Total} &amp;131 &amp; 137 &amp; 17 &amp; 285\\\\ \\end{array} \\end{array} \\] Si las probabilidades de tos nocturna en los tres grupos de hábito tabáquico fueran las mismas, la menor frecuencia esperada sería 17·74/285=4.41, y no se podría usar el test \\(\\chi^2\\) tal cual. Para usar el test MonteCarlo: Definimos una matriz con la tabla de frecuencias (la función rbind define una matriz con filas las que le entramos) Obs=rbind(c(27, 39, 8), c(104, 98, 9)) Ejecutamos la función siguiente: chisq.test(Obs, simulate.p.value=TRUE, B=5000) Como el p-valor es 0.04, volvemos a obtener evidencia estadística de asociación entre la tos nocturna y el hábito tabáquico en niños. 15.5 Contrastes de correlación Imaginad que queremos estudiar si el consumo de frutos secos se asocia a una disminución del nivel de colesterol. Una posibilidad es plantear la pregunta ¿Consumir habitualmente frutos secos reduce el nivel medio de colesterol?. Para responder esta pregunta, tomaríamos una muestra de individuos y de cada uno de ellos anotaríamos su nivel de colesterol y si come frutos secos habitualmente o no. Entonces, con estos datos, podríamos efectuar un contraste de dos medias con muestras independientes. Pero también podríamos plantear la pregunta ¿Cuanto más frutos secos se comen, menos colesterol se tiene?. Tomaríamos una muestra grande de individuos y de cada uno de ellos anotaríamos su nivel de colesterol y la cantidad de frutos secos que come en una semana. ¿Y ahora qué? Recordad de la lección de Estadística Descriptiva de datos continuos que dados los valores de dos variables medidas sobre una misma muestra de sujetos, podíamos cuantificar la tendencia a crecer, o decrecer, conjuntamente de estos dos conjuntos de valores mediante su correlación, bien de Pearson o de Spearman. Resulta que la correlación de Pearson de los valores de dos variables medidas sobre una misma muestra de sujetos estima la correlación poblacional de estas variables, y que el signo de esta correlación sirve para determinar si, a nivel poblacional, las dos variables tienden a crecer o a decrecer conjuntamente (y su valor absoluto mide la tendencia a hacerlo de manera lineal). En particular, podremos usar la correlación dos muestras apareadas para contrastar si las variables poblacionales tienen tendencia a crecer o decrecer conjuntamente o si, por el contrario, el comportamiento de una no tienen nada que ver con el de la otra. Hay que introducir algunos conceptos para poder fijar exactamente de qué estamos hablando. Sean \\(X,Y\\) dos variables aleatorias, de medias \\(\\mu_X,\\mu_Y\\) y desviaciones típicas \\(\\sigma_X,\\sigma_Y\\), definidas sobre una misma población. La covarianza y la correlación de Pearson (poblacionales) de \\(X\\) e \\(Y\\) se definen como las de las muestras, pero ahora para toda la población. En concreto, la covarianza de \\(X\\) y \\(Y\\) es \\[ \\sigma_{X,Y}=E((X-\\mu_X)\\cdot ( Y-\\mu_Y)) = E(X\\cdot Y) -\\mu_X\\cdot \\mu_Y \\] Si \\(X,Y\\) son discretas, \\[ \\sigma_{X,Y}=\\sum_{x,y} x\\cdot y\\cdot P(X=x,Y=y) -\\Big(\\sum_{x} x\\cdot P(X=x)\\Big)\\Big(\\sum_{y} y\\cdot P(Y=y)\\Big) \\] Ejemplo 15.18 Sea \\(X\\) la variable que cuenta el número de caras al lanzar 2 veces una moneda equilibrada e \\(Y\\) la variable de Bernoulli que vale 1 si al lanzar 2 veces una moneda equilibrada dan el mismo resultado, y 0 si no. \\[ \\begin{array}{c|c|c} \\text{Resultado} &amp; X &amp; Y\\\\ \\hline \\text{Cara-Cara} &amp; 2 &amp; 1\\\\ \\text{Cara-Cruz} &amp; 1&amp; 0\\\\ \\text{Cruz-Cara} &amp; 1&amp; 0\\\\ \\text{Cruz-Cruz} &amp; 0&amp; 1 \\end{array} \\] Calculemos las probabilidades involucradas en el cálculo de \\(\\sigma_{X,Y}\\): \\(P(X=0)=0.25\\), \\(P(X=1)=0.5\\), \\(P(X=2)=0.25\\) \\(P(Y=0)=0.5\\), \\(P(Y=1)=0.5\\) \\(P(X=2,Y=1)=0.25\\), \\(P(X=1,Y=0)=0.5\\), \\(P(X=0,Y=1)=0.25\\), \\(P(X=2,Y=0)=P(X=1,Y=1)=P(X=0,Y=0)=0\\) Entonces \\(\\mu_X=\\sum_{x} x\\cdot P(X=x)=0\\cdot 0.25+1\\cdot 0.5+2\\cdot 0.25=1\\) \\(\\mu_Y=\\sum_{y} y\\cdot P(Y=y)=0\\cdot 0.5+1\\cdot 0.5=0.5\\) \\(E(X\\cdot Y)=\\sum_{x,y} x\\cdot y\\cdot P(X=x,Y=y)=2\\cdot 1\\cdot 0.25+1\\cdot 0\\cdot 0.5+0\\cdot 1\\cdot 0.25=0.5\\) y finalmente \\[ \\sigma_{X,Y}=E(X\\cdot Y) -\\mu_X\\cdot \\mu_Y=0.5-1\\cdot 0.5=0 \\] La covarianza de \\(X\\) y \\(Y\\) tiene las mismas propiedades para toda la población que la covarianza de dos muestras. \\(\\sigma_{X,Y}\\) mide la tendencia al crecimiento conjunto de \\(X,Y\\) \\(\\sigma_{X,Y}&gt;0\\) significa que Cuando \\(X\\) es más grande en un individuo 1 que en un individuo 2, \\(Y\\) tiende a ser más grande en el individuo 1 que en el individuo 2 Cuando \\(X\\) es más pequeño en un individuo 1 que en un individuo 2, \\(Y\\) tiende a ser más pequeño en el individuo 1 que en el individuo 2 \\(\\sigma_{X,Y}&lt;0\\) significa que Cuando \\(X\\) es más grande en un individuo 1 que en un individuo 2, \\(Y\\) tiende a ser máspequeño en el individuo 1 que en el individuo 2 Cuando \\(X\\) es más pequeño en un individuo 1 que en un individuo 2, \\(Y\\) tiende a ser más grande en el individuo 1 que en el individuo 2 \\(\\sigma_{X,Y}=0\\) significa que no hay ninguna tendencia en este sentido Las unidades son las de \\(X\\) por las de \\(Y\\) La covarianza es simétrica: \\(\\sigma_{X,Y}=\\sigma_{Y,X}\\) La covarianza de una variable consigo misma es su varianza: \\(\\sigma_{X,X}=\\sigma^2_X\\) Si \\(X\\) e \\(Y\\) son independientes, \\(\\sigma_{X,Y}=0\\) Pero \\(\\sigma_{X,Y}=0\\) no implica que \\(X\\) e \\(Y\\) sean independientes. Por ejemplo, las variables \\(X,Y\\) del ejemplo anterior tienen \\(\\sigma_{X,Y}=0\\) pero no son independientes porque \\[ P(X=1,Y=1)=0,\\ P(X=1)\\cdot P(Y=1)=0.5\\cdot 0.5=0.25 \\] \\(\\sigma_{X,Y}\\) mide la “tendencia al crecimiento conjunto” de \\(X,Y\\), y el signo es fácil de interpretar, pero el valor absoluto no La correlación (de Pearson) de \\(X,Y\\) es \\[ \\rho_{X,Y}=\\frac{\\sigma_{X,Y}}{\\sigma_{X}\\cdot \\sigma_{Y}} \\] De nuevo, sus propiedades son las de la correlación de Pearson de muestras, pero ahora para toda la población: \\(\\rho_{X,Y}\\) no tiene unidades \\(\\rho_{X,Y}=\\rho_{Y,X}\\) \\(\\rho_{X,X}=1\\) El signo de \\(\\rho_{X,Y}\\) es el mismo que el de \\(\\sigma_{X,Y}\\) \\(\\rho_{X,Y}=0 \\Longleftrightarrow \\sigma_{X,Y}=0\\) Por lo tanto Si \\(X\\) y \\(Y\\) son independientes, \\(\\rho_{X,Y}=0\\) Pero \\(\\rho_{X,Y}=0\\) no implica que \\(X\\) y \\(Y\\) sean independientes Se dice que dos variables \\(X,Y\\) son incorreladas cuando \\(\\rho_{X,Y}=0\\) \\(-1\\leqslant \\rho_{X,Y}\\leqslant 1\\) \\(\\rho_{X,Y}=\\pm 1\\) si, y solo si, \\(Y=a X+b\\). La pendiente \\(a\\) de esta recta tiene el mismo signo que \\(\\rho_{X,Y}\\). Cuanto más se acerca \\(|\\rho_{X,Y}|\\) a 1, más se acerca \\(Y\\) a ser función lineal de \\(X\\) Si \\(\\rho_{X,Y}&gt;0\\), la dependencia lineal es creciente Si \\(\\rho_{X,Y}&lt;0\\), la dependencia lineal es decreciente La correlación de Pearson mide la tendencia de dos variables a variar conjuntamente de manera lineal. No mide que el aumento de una variable implique o sea la causa del crecimiento o decrecimiento de la otra. Un ejemplo, que además es importante tener siempre en cuenta: Teorema 15.3 Si \\(X_1,X_2\\) son dos copias independientes de una misma variable aleatoria \\(X\\), \\[ \\rho_{X_1,X_2-X_1}=-\\frac{1}{\\sqrt{2}}\\approx -0.71 \\] Por lo tanto, \\(X_2-X_1\\) decrece “bastante” linealmente en \\(X_1\\). Por ejemplo, suponed que un día hacéis un test (su nota es \\(X_1\\)) y que al día siguiente hacéis otro test de dificultad similar y sin haber estudiado más (su nota es \\(X_2\\)). Si sacáis una nota baja en \\(X_1\\), lo más probable es que \\(X_2-X_1\\) sea grande (positivo) y por lo tanto \\(X_2\\) sea más alta Si sacáis una nota alta en \\(X_1\\), lo más probable es que \\(X_2-X_1\\) sea pequeño (negativo) y por lo tanto \\(X_2\\) sea más baja Ejemplo 15.19 Sea \\(X\\) el resultado de lanzar un dado de 4 caras, y sean \\(X_1,X_2\\) dos copias independientes de \\(X\\), es decir, los resultados de lanzar dos veces consecutivas el dado. Los resultados posibles son los siguientes: \\[ \\begin{array}{c|cccc} X_1\\backslash X_2&amp; 1 &amp; 2 &amp; 3 &amp; 4\\\\\\hline 1 &amp; X_1=1 &amp; X_1=1 &amp; X_1=1 &amp; X_1=1\\\\ &amp; X_2\\!-\\!X_1=0&amp; X_2\\!-\\!X_1=1&amp; X_2\\!-\\!X_1=2&amp; X_2\\!-\\!X_1=3\\\\\\hline 2 &amp; X_1=2&amp; X_1=2&amp; X_1=2&amp; X_1=2\\\\ &amp; X_2\\!-\\!X_1=\\!-\\!1&amp; X_2\\!-\\!X_1=0&amp; X_2\\!-\\!X_1=1&amp; X_2\\!-\\!X_1=2\\\\\\hline 3 &amp; X_1=3&amp; X_1=3&amp; X_1=3&amp; X_1=3\\\\ &amp; X_2\\!-\\!X_1=\\!-\\!2&amp; X_2\\!-\\!X_1=\\!-\\!1&amp; X_2\\!-\\!X_1=0&amp; X_2\\!-\\!X_1=1\\\\\\hline 4&amp; X_1=4&amp; X_1=4&amp; X_1=4&amp; X_1=4\\\\ &amp; X_2\\!-\\!X_1=\\!-\\!3&amp; X_2\\!-\\!X_1=\\!-\\!2&amp; X_2\\!-\\!X_1=\\!-\\!1&amp; X_2\\!-\\!X_1=0\\\\\\hline \\end{array} \\] El gráfico de los pares \\((X_1,X_2-X_1)\\) muestra que \\(X_2-X_1\\) tiene una tendencia clara a decrecer a medida que \\(X_1\\) aumenta: Por si alguien necesita la demostración del teorema anterior, aquí va. Es pura manipulación algebraica recordando que la covarianza de dos variables independientes es 0. Por definición, \\[ \\rho_{X_1,X_2-X_1}=\\dfrac{\\sigma_{X_1,X_2-X_1}}{\\sigma_{X_1}\\sigma_{X_2-X_1}} \\] donde \\[ \\begin{array}{l} \\sigma_{X_2-X_1}=\\sqrt{\\sigma^2_{X_2-X_1}}\\\\[2ex] \\quad =\\sqrt{\\sigma^2_{X_2}+\\sigma^2_{X_1}}\\ \\text{(porque son independientes)}\\\\[2ex] \\quad =\\sqrt{\\sigma^2_{X}+\\sigma^2_{X}}\\ \\text{(porque $X_1,X_2$ son copias de $X$)}\\\\[2ex] \\quad =\\sqrt{2\\sigma^2_{X}}=\\sigma_{X}\\sqrt{2} \\end{array} \\] y \\[ \\begin{array}{l} \\sigma_{X_1,X_2-X_1}=E(X_1(X_2-X_1))-E(X_1)E(X_2-X_1)\\\\[1ex] \\quad =E(X_1X_2-X_1^2)-E(X_1)(E(X_2)-E(X_1))\\\\[1ex] \\quad =E(X_1X_2)-E(X_1^2)-E(X_1)E(X_2)+E(X_1)E(X_1)\\\\[1ex] \\quad =E(X_1)E(X_2)-E(X_1^2)-E(X_1)E(X_2)+E(X_1)E(X_1)\\\\[1ex] \\quad \\text{(porque son independientes)}\\\\[1ex] \\quad =-E(X_1^2)+E(X_1)E(X_1)=-\\sigma^2_{X_1}=-\\sigma^2_{X} \\end{array} \\] de donde \\[ \\rho_{X_1,X_2-X_1}=\\dfrac{\\sigma_{X_1,X_2-X_1}}{\\sigma_{X_1}\\sigma_{X_2-X_1}}=\\dfrac{-\\sigma^2_{X}}{\\sigma_{X}\\cdot \\sigma_{X}\\sqrt{2}} =-\\frac{1}{\\sqrt{2}} \\] Un contraste de correlación de dos variables aleatorias \\(X,Y\\) es un contraste de la forma \\[ \\left\\{ \\begin{array}{ll} H_0: &amp; \\rho_{X,Y}=0\\\\ H_1: &amp; \\rho_{X,Y}&gt; 0\\text{ o }\\rho_{X,Y}&lt; 0\\text{ o }\\rho_{X,Y}\\neq 0 \\end{array} \\right. \\] Si rechazamos \\(H_0\\), en particular rechazamos que \\(X\\) e \\(Y\\) sean independientes. No vamos explicar las fórmulas para efectuar este contraste, ni las condiciones necesarias para que el contraste sea válido. En JAMOVI, disponéis de este test en la sección Regresión/Matriz de Correlaciones. Ejemplo 15.20 La tabla de datos Temperaturas.txt que ya hemos usado en otras ocasiones contiene no solo las temperaturas de 231 personas, sino también sus números de pulsaciones por minuto. Nos preguntamos si hay asociación entre la temperatura y el número de pulsaciones por minuto de una persona, o si por el contrario son independientes. Aquí traducimos esta pregunta en términos de correlación, cambiando “independientes” por “incorreladas”. Por lo tanto, el contraste que nos interesa es \\[ \\left\\{ \\begin{array}{ll} H_0: &amp; \\rho_{\\text{Pulsaciones}, \\text{Temperatura}}=0\\\\ H_1: &amp; \\rho_{\\text{Pulsaciones}, \\text{Temperatura}}\\neq 0 \\end{array} \\right. \\] Si, tras cargar la tabla de datos, dibujamos el diagrama de dispersión de los pares pulsaciones-temperatura, vemos que hay una tendencia a que ambas variables crezcan conjuntamente. ¿Es esta tendencia suficiente para aportar evidencia de que estas variables tienen correlación no nula? Vamos a Regresión/Matriz de Correlaciones, seleccionamos ambas variables y marcamos las casillas “Pearson” (para trabajar con al correlación de Pearson), “Hipótesis Correlacionada” (para indicar que la hipótesis alternativa es que las variables son correlacionadas, es decir, que su correlación es no nula), “Mostrar significación” (para que nos dé el p-valor) e “Intervalos de Confianza” (para que también lo dé): Obtenemos un p-valor menor que 0.001 y un intervalo de confianza del 95% para \\(\\rho_{\\text{Pulsaciones}, \\text{Temperatura}}\\) que va de 0.201 a 0.433. Tenemos por lo tanto evidencia de que \\(\\rho_{\\text{Pulsaciones}, \\text{Temperatura}}\\neq 0\\), y en particular de que el número de pulsaciones y la temperatura no son variables independientes. 15.6 Test (1) En un estudio clínico, a una serie de pacientes se les trata con un nuevo fármaco para determinar si, en un cierto período de tiempo después de la administración de dicho fármaco, el nivel de bilirrubina ha disminuido. Se acepta que la distribución de la bilirrubina es normal. ¿Cuál es la prueba estadística de elección? Un test t para muestras apareadas Un test t para muestras independientes Un test F de comparación de varianzas Un test de Wilcoxon Un test exacto de Fisher (2) La prueba para comparar dos medias usando muestras apareadas basada en la t de Student (marca todas las respuestas correctas): Es adecuada cuando las muestras son pequeñas También se puede usar para muestras independientes Solo se puede usar si las poblaciones tienen distribuciones normales En el fondo es un test t de una media Ninguna de las otras respuestas es correcta (3) ¿Cuál de las siguientes condiciones permite usar, por si sola, un test t para comparar dos medias? El número de observaciones tiene que ser el mismo en los dos grupos Las varianzas muestrales tienen que ser aproximadamente las mismas en los dos grupos Las medias tienen que ser aproximadamente iguales en los dos grupos Las observaciones tienen que provenir de distribuciones aproximadamente normales Las muestras tienen que ser pequeñas (4) En un ensayo clínico comparando dos grupos de pacientes, una de las medidas que se estudió fue un cierto tiempo de reacción que es muy asimétrico a la derecha. Para contrastar la diferencia entre las medias de este tiempo de reacción en los dos grupos de pacientes, los enfoques correctos posibles incluyen (marca todas las respuestas correctas): Un test t si los dos grupos tenían más de 100 sujetos cada uno Como se trata de un contraste de medias con muestras independientes, podemos usar un test t aunque los grupos sean pequeños Como las medidas de este tiempo de reacción siguen una ley normal, podemos usar un test t aunque los grupos sean pequeños Un test de Wilcoxon Un test de Mann-Whitney (5) En un test t de comparación de medias usando dos muestras independientes, el hecho de que las distribuciones poblacionales se desvíen mucho de una normal puede afectar seriamente la validez del contraste (marca todas las continuaciones correctas): Si los tamaños de las muestras son iguales Si los tamaños de las muestras son diferentes Si el tamaño de una de las muestras es pequeño, aunque la suma de ambos tamaños sea muy grande Independientemente de los tamaños de las muestras, si las distribuciones poblacionales son muy asimétricas Si las varianzas poblacionales son diferentes (6) Se pretende comparar la frecuencia de complicaciones de dos preparados distintos de un mismo fármaco. Se observó un 5% de complicaciones con un preparado y un 3% con el otro, siendo esta diferencia estadísticamente significativa (p=0.005). La interpretación correcta de este resultado es (marca la respuesta correcta): Si ambos preparados tuvieran la misma frecuencia de complicaciones, la probabilidad de encontrar una diferencia igual o mayor a la observada es 0.005. La probabilidad de que ambos preparados tengan la misma frecuencia de complicaciones es de 0.005. Es seguro que los dos preparados tienen distinta frecuencia de complicaciones. Es seguro que los dos preparados no tienen la misma frecuencia de complicaciones. La probabilidad de que ambos preparados tengan la misma frecuencia de complicaciones es de 0.995. (7) En un estudio que compara la eficacia de dos fármacos por medio de un test t no se observa una diferencia estadísticamente significativa entre ellos. Si en realidad la eficacia de estos tratamientos fuera diferente, todos los siguientes factores podrían explicar por qué se ha obtenido un resultado “falso negativo”, EXCEPTO uno. ¿Cuál? Las variables no tienen distribución normal. Las muestras no son lo bastante grandes. No se ha tenido en cuenta si las muestras son independientes o apareadas. Si las muestras eran independientes, no se ha tenido en cuenta si las variancias muestrales eran iguales o diferentes. Falta de potencia del contraste. (8) Para que la prueba estándar \\(\\chi^2\\) aplicada a una tabla de contingencia para comparar las distribuciones de dos variables con el mismo dominio sea válida, es necesario que (marca todas las respuestas correctas): Todas las frecuencias esperadas sean mayores que 5 Las dos variables sean continuas Las dos variables tengan distribución aproximadamente normal Todas las frecuencias observadas sean mayores que 5 La muestra global tenga como mínimo 100 sujetos (9) En una prueba estándar \\(\\chi^2\\) aplicada a una tabla de contingencia para comparar las distribuciones de tres variables que pueden tomar los mismos 5 valores cada una (marca todas las continuaciones correctas): Las variables han de ser cuantitativas Las frecuencias observadas se comparan con las frecuencias esperadas El estadístico de contraste tiene 15 grados de libertad Para que sea válida, todos los valores observados han de ser mayores que uno El estadístico de contraste tiene 14 grados de libertad \\[ \\begin{array}{c} \\qquad\\qquad\\qquad\\textbf{Según los hijos}\\\\ \\begin{array}{l|cc|c} \\textbf{Según los padres} &amp; \\text{Tos} &amp; \\text{No tos} &amp; \\text{Total}\\\\ \\hline \\text{Tos} &amp;100 &amp; 300 &amp; 400\\\\ \\text{No tos} &amp; 400 &amp; 4200 &amp; 4600\\\\ \\hline \\text{Total} &amp; 500 &amp; 4500 &amp; 5000 \\end{array} \\end{array} \\] (10) La tabla anterior recoge los casos de tos a primera hora de la mañana en un grupo de escolares, según los hijos y según los padres. En esta tabla (marca todas las continaciones correctas) Si los informes de tos matutina por parte de padres y de hijos fueran independientes, esperaríamos que las cuatro entradas de la tabla central fueran iguales Si hubiera asociación entre los informes de tos matutina por parte de padres y de hijos, esperaríamos que las cuatro entradas de la tabla central fueran iguales Si hubiera asociación entre los informes de tos matutina por parte de padres y de hijos, esperaríamos que no hubiera casos discordantes Si los informes de tos matutina por parte de padres y de hijos fueran independientes, esperaríamos unos 40 casos en los que padres e hijos informaran ambos de tos matutina Si el p-valor del test adecuado para contrastar la asociación entre el informe de tos matutina por los hijos y por los padres aplicado a esta tabla fuera prácticamente 0 (que lo es), deduciríamos que hay evidencia estadísticamente significativa de que los informes de tos matutina por parte de padres y de hijos son independientes (11) En la tabla anterior (marca todas las respuestas correctas): La asociación, o no, entre el informe de tos matutina por los hijos y por los padres se puede contrastar con un test \\(\\chi^2\\) La asociación, o no, entre el informe de tos matutina por los hijos y por los padres se puede contrastar con el test de McNemar La asociación, o no, entre el informe de tos matutina por los hijos y por los padres se puede contrastar con el test exacto de Fisher La igualdad, o no, de la prevalencia de la tos matutina según los hijos y según los padres se puede contrastar con un test \\(\\chi^2\\) La igualdad, o no, de la prevalencia de la tos matutina según los hijos y según los padres se puede contrastar con el test de McNemar La igualdad, o no, de la prevalencia de la tos matutina según los hijos y según los padres se puede contrastar con el test exacto de Fisher (12) ¿En cuáles de estos contrastes se puede usar un test de McNemar? (marca todas las respuestas correctas): Comparar la proporción de fumadores de cigarrillos entre casos de cáncer y controles sanos apareados por edad y sexo Contrastar la asociación entre el tabaquismo y los síntomas de enfermedades respiratorias en un grupo de asmáticos Contrastar si la prevalencia de los síntomas de enfermedades respiratorias en fumadores aumenta con el número medio de cigarrillos diarios fumados Contrastar si cambia la media del flujo espiratorio máximo en un grupo de asmáticos de invierno a verano Comparar la proporción de fumadores de cigarrillos entre un grupo de casos de cáncer y una muestra aleatoria de la población general (13) En un ensayo clínico se comparan tres tratamientos (placebo, tratamiento establecido y un tratamiento nuevo). La variable respuesta es el nivel de glucosa en sangre. Aceptando que esta variable tiene una distribución normal, la prueba correcta para comparar la respuesta es: Un test t Un test de Wilcoxon Un Análisis de la Varianza Un test de Kruskal-Wallis Un test ji-cuadrado (14) En un ensayo clínico se comparan tres tratamientos (placebo, tratamiento establecido y un tratamiento nuevo). La variable respuesta es continua, pero muy asimétrica a la derecha. El test correcto para comparar la respuesta es: Un test t Un test de Wilcoxon Un Análisis de la Varianza Un test de Kruskal-Wallis Un test ji-cuadrado (15) Un investigador está interesado en determinar si existe una asociación entre las cifras de tensión arterial diastólica (medida en mm de Hg) y los niveles de colesterol (medidos en mgr/ml). Para ello, ha realizado estas mediciones a 230 voluntarios. ¿Qué prueba estadística es la más apropiada para examinar esta asociación? Un test t Un Análisis de la Varianza Un test ji-cuadrado Un test de correlación de Pearson Un test exacto de Fisher (16) Un ensayo clínico evalúa tres pautas terapéuticas en pacientes hipertensos. Para comparar las cifras de presión arterial sistólica observadas en los tres grupos a los 6 meses de tratamiento, ¿qué prueba estadística es la más adecuada? Un Análisis de la Varianza Un test t para muestras independientes Un test de correlación de Pearson Un test ji-cuadrado Un coeficiente de correlación de Spearman (17) Un ensayo clínico evalúa dos pautas terapéuticas en pacientes hipertensos. Para comparar los porcentajes de pacientes en los que el tratamiento ha tenido efecto en cada grupo a los 6 meses de tratamiento, ¿qué prueba estadística es la más adecuada? Un test t para muestras independientes Un test de Wilcoxon Un Análisis de la Varianza Un test de McNemar Un test ji-cuadrado (18) Se ha realizado un ensayo clínico encaminado a valorar el descenso de la presión portal obtenido después de la administración aguda de tres alternativas de tratamiento en pacientes cirróticos con varices esofágicas. La variable de respuesta es el gradiente de presión venosa hepática que es continua y de distribución normal. ¿Cuál de las siguientes pruebas estadísticas es la correcta para comparar la respuesta?: Un test t para muestras independientes Un test de Wilcoxon Un Análisis de la Varianza Una test exacto de Fisher Una prueba de Mann-Whitney (19) ¿Para qué sirve un q-q-plot? Para estimar la q de una muestra Para visualizar si una muestra sigue una distribución dada Para visualizar si los puntos de una muestra tienden a estar sobre una recta Para visualizar si dos muestras son aparejadas o independientes (20) Hemos efectuado un test bilateral de Fisher de dos proporciones. ¿Es posible que hayamos obtenido un IC 95% [0.5,3.8] y un p-valor 0.15? Sí No (21) ¿Cuál, o cuáles, de las afirmaciones siguientes son verdaderas sobre un test \\(\\chi^2\\) de bondad de ajuste? Si todas las frecuencias observadas son más grandes o iguales que 5, seguro que podemos aplicarlo Si todas las frecuencias esperadas son más grandes o iguales que 5, seguro que podemos aplicarlo Si todas las frecuencias observadas son más grandes o iguales que 5, y empleamos 10 clases, seguro que podemos aplicarlo Si todas las frecuencias esperadas son más grandes o iguales que 5, y empleamos 10 clases, seguro que podemos aplicarlo Ninguna de las otras afirmaciones es verdadera (22) En un contraste de bondad de ajuste para decidir si una muestra se ajusta a una variable normal o no, obtenemos un p-valor más grande que el nivel de significación. ¿Cuál, o cuáles, de las afirmaciones siguientes son correctas? Concluimos que la variable no sigue una distribución normal Aceptamos que la variable sigue una distribución normal. Hemos obtenido evidencia estadísticamente significativa que la variable es normal. No hemos obtenido evidencia estadísticamente significativa que la variable sea normal. No hemos obtenido evidencia estadísticamente significativa que la variable no sea normal. Podría tratarse de un error de tipo I Podría tratarse de un error de tipo II Todas las otras afirmaciones son falsas. (23) Para que el test ji cuadrado para contrastar la igualdad de la distribución de una variable discreta a varias subpoblaciones sea válido, es necesario que (marca todas las continuaciones correctas): Todas las frecuencias esperadas sean más grandes o iguales que 5 Todas las frecuencias observadas sean más grandes o iguales que 5 El tamaño total de la muestra sea como mínimo 30 El tamaño total de la muestra sea como mínimo 100 La variable poblacional sea normal o todas las muestras sean de tamaño como mínimo 40 Todas las otras respuestas son incorrectas (24) ¿Para qué sirve un ANOVA? Para contrastar si los valores medios de una variable cuantitativa sobre varias poblaciones son todos diferentes o no Para contrastar si los valores medios de una variable cuantitativa sobre varias poblaciones son todos iguales o no Para contrastar si entre los valores medios de una variable cuantitativa sobre varias poblaciones hay exactamente dos que sean diferentes o no. Para contrastar si las medias muestrales de una variable cuantitativa sobre varias muestras extraídas de diferentes subpoblaciones son todas iguales o no Para contrastar si las medias muestrales de una variable cuantitativa sobre varias muestras extraídas de diferentes subpoblaciones son todas diferentes o no Para contrastar si las varianzas de una variable cuantitativa sobre varias poblaciones son todas diferentes o no Para contrastar si las varianzas de una variable continua sobre varias poblaciones son todas iguales o no (25) ¿Cuál es la hipótesis alternativa en el contraste que efectuamos con un ANOVA? Que todas las medias muestrales son diferentes. Que todas las medias poblacionales son diferentes. Que hay alguna pareja de medias muestrales que son diferentes Que hay alguna pareja de medias poblacionales que son diferentes Que hay exactamente una pareja de medias muestrales que son diferentes Que hay exactamente una pareja de medias poblacionales que son diferentes Ninguna de las anteriores (26) ¿Qué sería un error de tipo II en una ANOVA? Concluir que todas las medias muestrales son iguales cuando en realidad son todas diferentes Concluir que hay una pareja de medias muestrales que son iguales cuando en realidad son todas diferentes Concluir que todas las medias muestrales son iguales cuando en realidad hay alguna pareja que son diferentes Concluir que todas las medias poblacionales son iguales cuando en realidad son todas diferentes Concluir que hay una pareja de medias poblacionales que son iguales cuando en realidad son todas diferentes Concluir que todas las medias poblacionales son iguales cuando en realidad hay alguna pareja que son diferentes "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
