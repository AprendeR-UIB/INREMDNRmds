[
["index.html", "Bioestadística (Medicina UIB) Presentación", " Bioestadística (Medicina UIB) 2020-11-22 Presentación Esto es una edición en línea de los apuntes de Introducción a la Investigación en Salud y Bioestadística del grado de Medicina de la UIB. Este trabajo se publica bajo licencia Atribución-No Comercial-SinDerivados 4.0 Estos apuntes están en construcción. En la lista siguiente iremos anunciando las actualizaciones: 2020-11-19: Publicadas las lecciones 10 a 12. 2020-11-07: Corregidos errores varios en la lección 5. 2020-11-03: Corregido error en las “consideraciones” al principio de la sección 5.2. 2020-11-01: Publicadas las lecciones 6 a 9. 2020-10-24: Publicada la lección 5. 2020-10-21: Corregido el error en la Figura 2.14 (la clasificación de los estudios de cohorte y de casos y controles estaba intercambiada). 2020-10-05: Publicada la lección 4. 2020-09-30: Cambios cosméticos en la lección 2: añadidos algunos dibujos, reescrito algunas frases, añadido un ejemplo (2.10) sobre la importancia de la elección de controles. 2020-09-27: Publicadas las lecciones 1, 2 y 3. El libro está escrito en R Markdown, usando RStudio como editor de textos y el paquete bookdown para convertir los ficheros markdown en un libro. Significado de algunas cajas: Material muy importante. ¡Cuidado! Ejercicio. Detalles matemáticos que os pueden interesar, pero que podéis obviar sin ningún problema. Comentario que queremos enfatizar. Comentario que queremos que recordéis Cuestión en la que queremos que caigáis en la cuenta. Acabamos de matar un gatito "],
["intervalos-de-confianza.html", "Lección 1 Intervalos de confianza 1.1 Definiciones básicas 1.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal 1.3 Intervalo de confianza para la media basado en la t de Student 1.4 Intervalos de confianza para proporciones 1.5 Intervalos de confianza para diferencias de medias 1.6 Un intervalo de confianza para la diferencia de proporciones 1.7 Test", " Lección 1 Intervalos de confianza Los estimadores de la lección anterior nos permiten estimar el valor de una característica de una población, pero no nos indican el error que cometemos con esta estimación. En la práctica, lo que se suele hacer es complementar una estimación puntual con un intervalo que indique la precisión de la estimación. Esta precisión va a depender: De la variabilidad del estimador: cuánta menos variabilidad tenga, más precisa será la estimación. Normalmente, la variabilidad del estimador crece con la desviación típica de la variable poblacional y decrece con el tamaño de las muestras. Del nivel de confianza, o de seguridad, deseado para la estimación: cómo de seguros queremos estar de que la estimación es correcta. 1.1 Definiciones básicas Un intervalo de confianza del Q% (para abreviar, un IC-Q%) de un parámetro poblacional es un intervalo obtenido aplicando a una muestra aleatoria simple de tamaño \\(n\\) una fórmula que satisface la propiedad siguiente: El intervalo obtenido contiene el valor del parámetro poblacional el Q% de las veces que aplicamos la fórmula a muestras aleatorias simples de tamaño \\(n\\) tomadas al azar. Tener una confianza del Q% significa pues que usamos una fórmula que acierta el Q% de las veces; o, para ser precisos, el Q% de las veces que la aplicamos bien. Pero asumimos que en un (100-Q)% de las veces que la aplicamos da un intervalo que no contiene el valor del parámetro poblacional, y no sabemos cuándo sí y cuándo no. De manera que solo podemos tener una cierta confianza, fruto del optimismo, de que con nuestra muestra acierta, pero no podemos estar seguros del todo. Ejemplo 1.1 En un experimento hemos medido el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. En el Ejemplo 1.3 calcularemos con los datos obtenidos en este experimento un IC-95% para el porcentaje de aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Obtendremos el intervalo [40.53, 41.87]. Esto significa que estamos un 95% seguros de que el aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza está entre el 40.53% y el 41.87%, porque este intervalo lo habremos calculado con una fórmula que el 95% de las veces que la aplicamos a muestras aleatorias de 40 personas da un intervalo que contiene la media poblacional que queremos estimar. Nosotros somos optimistas y “confiamos” estar dentro de este 95% de aciertos. No confundáis: Intervalo de referencia del Q% para una variable aleatoria: Intervalo que contiene el valor de la variable aleatoria en un individuo con probabilidad Q%. Intervalo de confianza del Q% para un parámetro: Intervalo que contiene el valor poblacional del parámetro de la variable aleatoria “con probabilidad” Q%, en el sentido de que lo hemos calculado con una fórmula que da un intervalo que contiene el parámetro el Q% de las veces que la aplicamos a una muestra aleatoria. Intervalo de referencia del Q% para un estimador: Intervalo que contiene el valor del estimador sobre una muestra aleatoria con probabilidad Q%. Por ejemplo: Si decimos que un intervalo de referencia del 95% para la concentración de una proteína en suero en individuos sanos medida en g/dl es [11,16], esto significa que un 95% de los individuos sanos tienen una concentración de esta proteína en suero entre 11 y 16 g/dl o, equivalentemente, que si escogemos al azar un individuo sano,la probabilidad de que su concentración de esta proteína en suero esté entre 11 y 16 g/dl es del 95%. Si decimos que un intervalo de confianza del 95% para la concentración media de una proteína en suero en individuos sanos medida en g/dl es [11,16], esto significa que hemos tomado una muestra aleatoria de concentraciones de esta proteína en suero en individuos sanos y a partir de esta muestra hemos estimado que, con un 95% de seguridad, la concentración media de esta proteína en suero en el total de la población de individuos sanos está entre 11 y 16 g/dl; y que tenemos este 95% de seguridad porque hemos calculado este intervalo con una fórmula que da un intervalo que contiene la media poblacional un 95% de las veces que la aplicamos a muestras aleatorias del misma tamaño que la nuestra. Si decimos que el 95% de las muestras de 100 concentraciones de una determinada proteína en suero en individuos sanos tienen la media muestral entre 11 y 16 g/dl, esto es un intervalo de referencia del 95% para la media muestral de muestras de tamaño 100, no un intervalo de confianza para la concentración media poblacional ni un intervalo de referencia para el valor de la concentración en un individuo. Que un IC-Q% para un parámetro \\(\\theta\\) sea \\([a,b]\\) sirve: Para estimar \\(\\theta\\) con este margen de confianza: Estamos bastante seguros de que el valor poblacional de \\(\\theta\\) está entre \\(a\\) y \\(b\\) (porque la fórmula usada acierta a menudo). Para descartar, con este margen de confianza, que \\(\\theta\\) valga cualquier valor concreto fuera de \\([a,b]\\): Estamos bastante seguros de que el valor real de \\(\\theta\\) no está ni por debajo de \\(a\\) ni por encima de \\(b\\) y por tanto de que es diferente de todos los valores menores que \\(a\\) o mayores que \\(b\\). Por ejemplo: si un IC-95% para la prevalencia \\(p\\) de una determinada enfermedad en una población va de 0.025 a 0.047: Estamos muy (“un 95%”) seguros de que \\(p\\in [0.025,0.047]\\) (porque la fórmula usada para calcular este intervalo acierta en un 95% de las veces). Estamos muy (“un 95%”) seguros de que \\(p\\neq 0.05\\) (porque 0.05 no pertenece al intervalo que estamos muy seguros que contiene el valor real de \\(p\\)). Pero no estamos muy seguros de que \\(p=0.03\\), por mucho que \\(0.03\\in [0.025,0.047]\\): estamos muy seguros de que \\(p\\) está entre 0.025 y 0.047, pero no tenemos ninguna seguridad de que valga un valor concreto entre estos límites, solo de que está entre estos límites. Hay dos tipos de métodos básicos de cálculo de intervalos de confianza a partir de una muestra aleatoria: Paramétricos: Usando alguna fórmula basada en la distribución muestral del estimador. Se basan en teoremas y solo tiene sentido usarlos si la variable aleatoria y la muestra aleatoria satisfacen (aproximadamente) las hipótesis de los teoremas. No paramétricos. Los otros. El más popular, y nuestro favorito, es el bootstrap: De nuestra muestra, tomamos al azar muchas (miles) muestras aleatorias simples (permitiendo repeticiones) del misma tamaño que nuestra muestra. Calculamos el estimador para cada una de estas muestras. Usamos el vector de resultados para estimar un intervalo de confianza. Por ejemplo, tomamos como IC-95% el intervalo entre los cuantiles 0.025 y 0.975 de este vector. El bootstrap se puede usar siempre y funciona bien si la muestra es aleatoria, pero se basa en un proceso aleatorio y por lo tanto cada ejecución sobre una misma muestra puede dar un intervalo diferente (y un 95% de ellos contendrán el valor que queremos estimar). El bootstrap es una herramienta muy poderosa para calcular intervalos de confianza y, en general, para estimar la distribución muestral de un estadístico. Tanto, que en la práctica ya empieza a sustituir los métodos paramétricos. Pero no hace milagros: si la muestra es pequeña o muy poco representativa de la población, un intervalo de confianza calculado con el bootstrap sirve de tan poco como uno calculado con un método paramétrico. 1.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal Una de las fórmulas más conocidas para intervalos de confianza es la siguiente: Si \\(X\\) es \\(N(\\mu,\\sigma)\\) y tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y varianza muestral \\(\\widetilde{S}^2_X\\), un IC-95% para \\(\\mu\\) es \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] donde \\(t_{n-1,0.975}\\) denota el 0.975-cuantil de la distribución t de Student \\(t_{n-1}\\). Este intervalo lo escribiremos \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] para recalcar que estamos estimando \\(\\mu\\) por medio de \\(\\overline{X}\\) más menos un cierto error. A algunos de vosotros os habrán explicado en Bachillerato, o encontraréis en libros que consultéis, una fórmula para el IC-95% para \\(\\mu\\) similar a esta, pero cambiando la \\(\\widetilde{S}_X\\) por \\(\\sigma\\) y el \\(t_{n-1,0.975}\\) por \\(z_{0.975}\\), el 0.975-cuantil de la normal estándar. Esta otra fórmula solo se puede usar si se conoce la desviación típica poblacional \\(\\sigma\\), lo que, en la práctica, nunca pasará. Por lo tanto, por favor, olvidadla. Vamos a explicar de dónde sale esta fórmula, puesto que es un paradigma de cómo se obtienen la mayoría de las fórmulas paramétricas para intervalos de confianza. Quien se la quiera tomar como dogma de fe, que pase al Ejemplo 1.2. Supongamos pues que \\(X\\) es \\(N(\\mu,\\sigma)\\) y que tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y varianza muestral \\(\\widetilde{S}^2_X\\). En esta situación, sabemos que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] tiene distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\). Si podemos encontrar \\(A,B\\in \\mathbb{R}\\) tales que \\[ P(A\\leq T\\leq B)=0.95, \\] entonces: \\[ \\begin{array}{rl} 0.95\\!\\!\\!\\! &amp; =P\\Bigg(A\\leq \\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leq B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\overline{X}-\\mu \\leq B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq -\\mu \\leq -\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\mu \\leq \\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Como \\(P(A\\leq T\\leq B)=0.95\\) significa que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) el valor de \\(T\\) está entre \\(A\\) y \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\mu \\leq \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significará que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) la \\(\\mu\\) cae dentro del intervalo \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Por lo tanto, ¡esto será un IC-95% para \\(\\mu\\)! Nos falta encontrar los \\(A,B\\) tales que \\(P(A\\leq T\\leq B)=0.95\\). Para encontrarlos, usaremos cuantiles de la distribución de \\(T\\). Recordemos que, por definición de cuantil, \\[ P(T\\leq t_{n-1,0.975})=0.975 \\] y por la simetría de la \\(t\\) de Student, \\[ P(T\\leq -t_{n-1,0.975})=P(T\\geq t_{n-1,0.975})=0.025 \\] Por tanto: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leq T\\leq t_{n-1,0.975})\\\\ \\quad =P(T\\leq t_{n-1,0.975})-P(T\\leq -t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Así pues, podemos tomar \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] y obtenemos el IC-95% para \\(\\mu\\) anunciado: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Ejemplo 1.2 Hagamos un experimento para ver que, efectivamente, esta fórmula “acierta”, en el sentido de que el intervalo que produce contiene la \\(\\mu\\), alrededor del 95% de las veces. En el bloque de código de R siguiente: Generamos al azar una Población de 107 “individuos” que siguen una ley normal estándar y calculamos la media mu de esta población. Definimos una función IC que calcula el IC-95% para la media \\(\\mu\\) con la fórmula anterior. Tomamos, al azar, 200 muestras aleatorias simples de tamaño 50 de nuestra población y les aplicamos esta función. Obtenemos una matriz M de 200 columnas formadas por los dos extremos de los intervalos (el inferior en la primera fila y el superior en la segunda fila). Dibujamos los intervalos en un gráfico, donde aparecerán en gris los que aciertan y en rojo los que fallan. La recta vertical marca la media poblacional \\(\\mu\\). Población=rnorm(10^7) mu=mean(Población) IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Población,50,replace=TRUE))) plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valores&quot;,ylab=&quot;Repeticiones&quot;, main=&quot;200 IC-95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Si contáis los intervalos rojos, veréis que hemos fallado 11 veces y por lo tanto hemos acertado 189 veces, es decir, en un 94.5% de los intervalos. Es aproximadamente lo que esperábamos. Si lo probáis en casa, ejecutando el código de R que hemos dado, obtendréis otros resultados, a veces mejores, a veces peores. Es lo que tiene la aleatoriedad. ¡Atención! De media, un IC-Q% NO contiene el valor real del parámetro en un (100-Q)% de las ocasiones. Por ejemplo, de media, un 5% de las veces que calculemos un IC-95%, el parámetro poblacional no pertenecerá al intervalo obtenido. En nuestro experimento, de los 200 IC-95% que hemos calculado, 11 no han contenido el valor real de \\(\\mu\\). Por lo tanto, si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, el número de veces que el intervalo resultante no contendrá el parámetro poblacional seguirá una distribución binomial \\(B(n,0.05)\\). El gráfico siguiente representa el valor de \\(P(X\\geq 1)\\) para una variable aleatoria \\(X\\) de tipo \\(B(n,0.05)\\), para \\(n=0,...,100\\), y por tanto la probabilidad de que si calculamos \\(n\\) IC-95% sobre muestras aleatorias simples independientes, al menos uno de ellos no contenga el parámetro poblacional deseado. Esto es un problema grave en artículos científicos donde se calculen intervalos de confianza para muchos parámetros. De media, de cada 20 IC-95% que se calculan, 1 es erróneo. Y no se puede hacer nada al respecto, forma parte de la definición. Ejemplo 1.3 Volvamos al experimento en el que medimos el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. La media y la desviación típica muestral de estos porcentajes de incremento fueron \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1 \\] Para calcular un IC-95% para el porcentaje medio de aumento, \\(\\mu\\), supondremos que la variable aleatoria de interés (de la que queremos estimar la media) \\(X\\), que es “Tomamos una persona y le medimos el porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza”, es normal y que la muestra que hemos tomado de esta variable es aleatoria simple. Entonces, como \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC-95% para \\(\\mu\\) es \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Por lo tanto, estimamos con un 95% de confianza que el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza está entre el 40.5% y el 41.9%. Para calcular el intervalo anterior hemos supuesto que la variable poblacional “Porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza” sigue una distribución normal. ¿Y si no fuera normal? En este caso, como el tamaño de la muestra \\(n=40\\) es lo bastante grande como para poder invocar el Teorema Central del Límite, el Teorema 1.2 de la próxima sección nos dice que el intervalo obtenido sigue siendo (aproximadamente) un intervalo de confianza del 95% para \\(\\mu\\). Si \\(n\\) fuera pequeño y \\(X\\) muy diferente de una normal, no se puede usar esta fórmula y hay que buscarse la vida (por ejemplo, usar el método bootstrap). También hemos supuesto que era una muestra aleatoria simple. ¿Y si no lo es? Si es aleatoria, como la población sobre la que tenemos definida nuestra variable aleatoria, las personas que pueden tomar 4 cañas de cerveza, es muy grande, a efectos prácticos la podemos considerar simple. Pero seguro que no es aleatoria, sino oportunista. En este caso, no hemos sacado 40 personas por sorteo de la lista de toda la población mundial, ni siquiera de la de Mallorca, sino que hemos buscado voluntarios. Entonces, no podemos hacer nada para salvar la fórmula, y su validez depende de si la muestra de personas usada puede pasar por aleatoria o no. 1.3 Intervalo de confianza para la media basado en la t de Student A partir de ahora, para evitar ambigüedades, en las fórmulas expresaremos el nivel de confianza de los intervalos en tanto por uno, no en tanto por ciento; es decir, como una proporción en vez de como un porcentaje. Por lo tanto, hablaremos de intervalos de confianza de nivel de confianza \\(q\\) (IC-\\(q\\)), con \\(q\\) entre 0 y 1, en vez de intervalos de confianza del Q% con Q=100q. Con estas notaciones, por ejemplo, los intervalos de confianza del 95% serán intervalos de confianza de nivel de confianza 0.95. El mismo argumento de la sección anterior, cambiando 0.95 por \\(q\\), da: Teorema 1.1 Si \\(X\\) es \\(N(\\mu,\\sigma)\\) y tomamos una muestra aleatoria simple de tamaño \\(n\\), un IC-\\(q\\) para \\(\\mu\\) es \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La fórmula de la sección anterior es un caso particular de esta, porque en los IC-0.95, \\(q=0.95\\) y por lo tanto \\((1+q)/2=1.95/2=0.975\\). Usando el Teorema Central del Límite y algunas aproximaciones, tenemos el siguiente resultado: Teorema 1.2 Si \\(X\\) es una variable aleatoria cualquiera de media poblacional \\(\\mu\\) y tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande (digamos, de 40 o más elementos), entonces, un IC-\\(q\\) para \\(\\mu\\) es aproximadamente \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] La aproximación del teorema anterior es mejor cuanto mayor sea \\(n\\) o cuanto más próxima a una normal sea la variable poblacional \\(X\\). En resumen: Podemos usar la fórmula para el IC-\\(q\\) para la media poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] si la variable poblacional es normal o si la muestra aleatoria simple es grande. Observad que la estructura del IC-\\(q\\) para \\(\\mu\\) dado por esta fórmula es estimador \\(\\pm\\) (\\(\\frac{1+q}{2}\\)-cuantil de la distr. muestral)\\(\\times\\)(error típico de la muestra) Esta estructura es muy típica (pero no universal: no creáis que todos los intervalos de confianza paramétricos tienen esta forma) y cumple que: El intervalo de confianza está centrado en la estimación puntual. La “probabilidad de equivocarnos” se reparte por igual a los dos lados del intervalo: en una fracción \\(q/2\\) de las veces que aplicamos la fórmula, el valor real del parámetro estará a la izquierda del extremo inferior y en otra fracción \\(q/2\\) de estas ocasiones estará a la derecha del extremo superior. Para una misma muestra y una misma fórmula (paramétrica) para calcular el intervalo de confianza, si el nivel de confianza crece, el intervalo se ensancha. Esto es general, para todos los intervalos de confianza paramétricos. La idea intuitiva es que, para estar más seguros de que un intervalo contiene un valor, el intervalo tiene que ser más ancho. En un intervalo de confianza con la estructura descrita hace un momento, el motivo matemático es que a mayor \\(q\\), mayor \\((1+q)/2\\)-cuantil de la distribución muestral. Por ejemplo, en el Ejemplo 1.3, teníamos \\(n=40\\), \\(\\overline{x}=41.2\\) y \\(\\widetilde{s}=2.1\\): El IC-95% tiene \\(q=0.95\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), y daba \\[ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] El IC-99% tiene \\(q=0.99\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), y da \\[ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] más ancho Pero si cambiamos de muestra (o de fórmula, si hay más de una) para calcular el intervalo de confianza, puede pasar cualquier cosa. 1.4 Intervalos de confianza para proporciones Supongamos que tenemos una variable Bernoulli \\(X\\) con probabilidad poblacional de éxito \\(p_X\\) desconocida. Queremos calcular un intervalo de confianza para \\(p_X\\). Para hacerlo, tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\), con número de éxitos \\(S\\) y por tanto proporción muestral de éxitos \\(\\widehat{p}_{X}=S/n\\) Explicaremos tres métodos para calcular este intervalo de confianza: el método de Clopper-Pearson, el de Wilson y el de Laplace. Método “exacto” de Clopper-Pearson Este método se basa en que el número de éxitos \\(S\\) en muestras aleatorias simples de tamaño \\(n\\) de \\(X\\) tiene una distribución conocida: es binomial \\(B(n,p_X)\\). Razonando de manera similar a cómo obteníamos el intervalo para \\(\\mu\\) basado en la t de Student se llega a una fórmula que os vamos a ahorrar, ya que nunca la vais a aplicar “a mano”. Este método tiene la ventaja de que se puede aplicar siempre, independientemente del tamaño de la muestra, y es “exacto” porque se basa en la distribución exacta de \\(S\\). Pero tiene algunos inconvenientes: Como las proporciones muestrales en muestras de tamaño fijo avanzan a saltos (0, \\(1/n\\), \\(2/n\\), \\(3/n\\)…), suele dar intervalos de confianza más anchos de lo necesario. Los intervalos que produce no son de la forma “probabilidad muestral \\(\\pm\\) algo”. Se necesita un ordenador para calcularlo, no se puede calcular a mano. Método aproximado de Wilson Supongamos ahora que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande digamos, \\(n\\geq 40\\), y proporción muestral de éxitos \\(\\widehat{p}_{X}\\). En estas condiciones, por el Teorema Central del Límite, sabemos que \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\approx N(0,1) \\] Por lo tanto \\[ P\\Big(-z_{(1+q)/2}\\leq \\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leq z_{(1+q)/2}\\Big)=q \\] Despejando \\(p_X\\) como en el cálculo del IC-95% para la \\(\\mu\\) usando la t de Student, obtenemos el resultado siguiente (que no hay que saber, tranquilos): Teorema 1.3 Si \\(n\\geq 40\\), un IC-\\(q\\) para \\(p_X\\) es aproximadamente: \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}}\\pm \\frac{z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Fijaos en que: Este método no se puede usar con muestras de cualquier tamaño, han de ser lo bastante grandes como para poder invocar el Teorema Central del Límite. El centro del intervalo no es \\(\\widehat{p}_X\\). Se basa en la aproximación a la normal dada por el Teorema Central del Límite, y por lo tanto el intervalo resultante es un intervalo de confianza “aproximado”, no exacto como el de Clopper-Pearson. Esto no es un gran problema, porque total, la muestra usada seguramente tampoco será aleatoria simple. Fórmula de Laplace Supongamos finalmente que tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) todavía más grande y que el valor de \\(\\widehat{p}_{X}\\) no es muy próximo ni a 0 ni a 1. Para fijar unas condiciones que suelen ser suficientes, supongamos que: \\(n\\geq 100\\). Tanto el número de éxitos como el número de fracasos en la muestra son \\(\\geq 10\\). En este caso, en la fórmula del intervalo de Wilson los términos \\(z_{(1+q)/{2}}^2/n\\) son despreciablemente pequeños comparados con los otros. Si los igualamos a 0, obtenemos la fórmula siguiente: Teorema 1.4 En las condiciones explicadas, un IC-\\(q\\) para \\(p_X\\) es (aproximadamente): \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Esta fórmula es la más popular, hasta el punto que forma parte de la “cultura general” de un científico. De hecho, tiene más de 200 años y precede en más de 100 años a la de Wilson. Además, tiene la forma familiar “estimador \\(\\pm\\) cuantil\\(\\times\\)error típico”. Os tenéis que saber la fórmula de Laplace, no hay que saber las fórmulas de los otros dos intervalos. Pero sí cuándo se pueden usar y cuándo no. Cuando podemos calcular más de un intervalo para \\(p_X\\), ¿cuál calculamos? De entrada hay que decir que si podemos calcular más de un intervalo, seguramente los que podamos calcular darán resultados muy parecidos. Además, recordad que las tres fórmulas solo nos dan “un nivel de confianza \\(q\\)” si se aplican a muestras aleatorias simples, y nuestras muestras casi siempre serán oportunistas, en cuyo caso, si nos ponemos tiquismiquis, no podemos aplicar ninguno. Solo un consejo: Si podéis usar la fórmula de Laplace, usadla. Todo el mundo lo conoce, forma parte de la cultura general del científico, y da un intervalo centrado en la proporción muestral. Ejemplo 1.4 En una muestra de 20 pacientes operados de cáncer de próstata con una nueva técnica, ninguno desarrolló complicaciones importantes en las 24 horas siguientes a la operación. ¿Cuál sería un IC-95% para la proporción de pacientes operados con esta técnica nueva que desarrollan complicaciones importantes en las 24 horas siguientes a la operación? Para calcularlo solo podemos usar el método de Clopper-Pearson, y este es uno de los pocos casos en que este intervalo tiene una expresión analítica sencilla: Si en una muestra aleatoria simple de tamaño \\(n\\) de una variable \\(Be(p_X)\\) obtenemos 0 éxitos, el IC-\\(q\\) de Clopper-Pearson para \\(p_X\\) es \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] En nuestro caso, \\(n=20\\), da el intervalo [0,0.1684]. Por lo tanto, estimamos con un 95% de confianza que menos del 16.84% de los pacientes operados con esta técnica nueva desarrollan complicaciones importantes en las 24 horas siguientes. Cuando se tiene que calcular “a ojo” un intervalo de confianza del 95% para una probabilidad \\(p_X\\) a partir de una muestra aleatoria simple donde no ha habido ningún éxito, a menudo se usa la regla siguiente: Regla del 3: Cuando en una muestra aleatoria simple de tamaño \\(n\\) de una variable aleatoria de Bernoulli de parámetro \\(p_X\\) no encontramos ningún éxito, un IC-95% para \\(p_X\\) va, aproximadamente, de 0 a \\(3/n\\). Con esta regla, en nuestro ejemplo con \\(n=20\\) obtendríamos el intervalo [0,3/20]=[0,0.15], no muy lejos del [0,0.1684] que hemos obtenido. Para ver como la regla del 3 aproxima el intervalo de Clopper-Pearson, el gráfico siguiente muestra los valores \\(3/n\\) y el extremo superior del IC-95% de Clopper-Pearson a partir de una muestra de tamaño \\(n\\) con 0 éxitos: Si la muestra hubiera sido mayor, pongamos de 50 pacientes y de nuevo 0 complicaciones graves, hubiéramos podido usar el método de Wilson. Podéis comprobar con algo de paciencia que da [0,0.0713]. El método de Clopper-Pearson da en este caso [0,0.0711] y la regla del 3 [0,0.06]. El gráfico siguiente muestra los valores \\(3/n\\) y los extremos superiores de los IC-95% de Clopper-Pearson y de Wilson a partir de una muestra de tamaño \\(n\\) (\\(n\\geq 40\\) para los intervalos de confianza de Wilson) con 0 éxitos: Los extremos superiores de los intervalos de Clopper-Pearson y Wilson se superponen en este último gráfico. Aunque la muestra de pacientes hubiera sido enorme, yo qué sé, de 30000 pacientes, con 0 casos de complicaciones graves no se puede usar la fórmula de Laplace. De hecho, si la aplicáis con 0 éxitos obtenéis el interval [0,0]. Ejemplo 1.5 En un ensayo de un tratamiento de quimioterapia, en una muestra de 100 pacientes tratados, 25 desarrollaron cáncer testicular secundario. ¿Cuál es un IC-95% para la proporción de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular. En este caso podemos usar los tres métodos. Clopper-Pearson, porque se puede usar siempre Wilson, porque \\(n=100\\geq 40\\) Laplace, porque \\(n\\geq 100\\) y hay más de 10 éxitos y más de 10 fracasos. Vamos a aplicar la fórmula de Laplace, que es la única que es sensato calcular a mano (y es la que os recomendamos usar si podéis). Tenemos que \\(\\widehat{p}_{X}=25/100=0.25\\) y \\(z_{0.975}=1.96\\). Da: \\[ 0.25\\pm 1.96\\sqrt{\\frac{0.25\\cdot 0.75}{100}}=0.25\\pm 0.085\\Rightarrow [0.165, 0.335] \\] Concluimos, con un nivel de confianza del 95%, que entre aproximadamente un 16.5% y un 33.5% de los pacientes tratados con esta quimioterapia desarrollan cáncer testicular. Por si os interesan: El intervalo de Clopper-Pearson da [0.169, 0.347] El intervalo de Wilson da [0.175, 0.343] Como podéis ver, los tres dan muy parecidos, con diferencias en los extremos de un punto porcentual. Cálculo del tamaño de la muestra para fijar el error Llamaremos margen de error (o error, precisión…) del intervalo de confianza de Laplace a la mitad de su amplitud, es decir, a \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Fijaos en que el intervalo de confianza de Laplace es \\(\\widehat{p}_X\\pm M\\) y por lo tanto, si contiene el valor real de \\(p_X\\), el error \\(|\\widehat{p}_X-p_X|\\) que cometemos cuando decimos que el valor de \\(p_X\\) es \\(\\widehat{p}_X\\) es como máximo este \\(M\\). Una típica pregunta al diseñar un estudio es ¿de qué tamaño he de tomar la muestra para garantizar que el margen de error en la estimación sea como máximo un valor concreto \\(M_{max}\\)? En el caso del intervalo de Laplace para una proporción, podemos dar un tamaño \\(n\\) que garantice un error máximo dado valga lo que valga \\(\\widehat{p}_{X}\\in [0,1]\\). Fijaos que la función \\(y=p(1-p)\\), con \\(p\\in [0,1]\\), es una parábola cóncava con vértice en su punto \\(p=0.5\\) Por lo tanto, toma su valor máximo en \\(p=0.5\\). Así, pues \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leq 0.5(1-0.5)=0.5^2 \\] y por lo tanto \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leq z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] De este modo, si tomamos \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leq M_{max} \\] entonces seguro que \\(M\\leq M_{max}\\), valga lo que valga \\(\\widehat{p}_{X}\\). Por consiguiente, lo que haremos será calcular la \\(n\\) para obtener un error como máximo \\(M_{max}\\) en el caso más desfavorable (o en el peor de los casos): cuando el intervalo es lo más ancho posible, es decir , suponiendo que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geq \\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Rightarrow n\\geq \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}} \\right)^2 \\] En resumen: Teorema 1.5 Si \\[ n\\geq \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] el error del intervalo de Laplace calculado con una muestra de tamaño \\(n\\) siempre será \\(\\leq M_{max}\\). Ejemplo 1.6 ¿Cuál es el menor tamaño de una muestra que nos garantice un error de como máximo 0.05 al estimar una proporción \\(p_X\\) usando un intervalo de confianza de Laplace del 95%? Por el teorema anterior, para garantizar un error de 0.05 al calcular un IC-95% para una proporción \\(p_X\\) usando la fórmula de Laplace, tenemos que usar una muestra de tamaño \\(n\\) tal que \\[ n\\geq \\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] El menor tamaño que satisface esta condición es \\(n=385\\). La respuesta correcta no es 384, por mucho que 384.16 se redondee a 384. Fijaos en que 384 no es más grande que 384.16. Observad tres cosas: El valor de \\(n\\) solo depende del error y del nivel de confianza, no de la naturaleza del estudio. Tal y como hemos encontrado la \\(n\\), estamos seguros de que si tomamos una muestra como mínimo de este tamaño, el margen de error del intervalo de confianza de Laplace será como máximo \\(M_{max}\\), sea cual sea la muestra. ¡Es de las pocas veces que podemos estar seguros de algo en estadística! El teorema anterior es para el intervalo de Laplace, pero la \\(n\\) seguramente os saldrá muy grande y en este caso el intervalo de Laplace aproxima muy bien los otros dos intervalos, si la proporción muestral luego no os sale muy extrema. “Poblaciones finitas” En esta sección hasta ahora hemos usado muestras aleatorias simples. Ya sabemos que si tomamos muestras aleatorias sin reposición y la población es mucho más grande que el tamaño \\(n\\) de las muestras, las fórmulas que hemos dado siguen funcionando (aproximadamente) bien. Pero, ¿qué pasa si tomamos muestras aleatorias sin reposición y la población no es mucho más grande que el tamaño \\(n\\) de las muestras? Por un lado, hay métodos tipo el de Clopper-Pearson que usan que el número de éxitos en muestras aleatorias sin reposición sigue una distribución hipergeométrica, pero son aun más complicados que el de Clopper-Pearson. Lo que se hace cuando se puede es usar la fórmula de Laplace teniendo en cuenta el factor de población finita: Si \\(X\\) una variable aleatoria de Bernoulli \\(Be(p_X)\\) definida sobre una población de tamaño \\(N\\) y tomamos una muestra aleatoria sin reposición de \\(X\\), con \\(n\\geq 100\\) y números de éxitos y fracasos \\(\\geq 10\\), un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) es, aproximadamente, \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En las condiciones del punto anterior, para obtener un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) con un margen de error \\(M_{max}\\) en el caso más desfavorable (\\(\\widehat{p}_X=0.5\\)) habrá que tomar una muestra de tamaño \\[ n\\geq \\frac{Nz_{(q+1)/2}^2}{4(N-1)M_{max}^2+z_{(q+1)/2}^2} \\] Ejemplo 1.7 En una muestra aleatoria de 727 estudiantes diferentes de la UIB (\\(N=12000\\)), 557 afirmaron haber cometido plagio en algún trabajo durante sus estudios. ¿Cuál sería un intervalo de confianza del 95% para la proporción \\(p_X\\) de estudiantes de la UIB que han cometido plagio en algún trabajo? Una muestra de 727 estudiantes diferentes es muy grande respecto del total de estudiantes de la UIB, por lo cual conviene usar la fórmula de Laplace con el factor de población finita \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] donde \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) y \\(N=12000\\): da \\[ 0.766\\pm \\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.751,0.781] \\] Estimamos con un nivel de confianza del 95% que entre un 75.1% y un 78.1% de los estudiantes de la UIB han cometido plagio en algún trabajo. Figura 1.1: https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf 1.5 Intervalos de confianza para diferencias de medias Sean \\(X_1\\) y \\(X_2\\) dos variables de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de medias \\(\\mu_1-\\mu_2\\). Para ello, tomamos: Una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de media muestral \\(\\overline{X}_1\\). Una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de media muestral \\(\\overline{X}_2\\). Si \\(X_1\\) y \\(X_2\\) son aproximadamente normales o si las muestras aleatorias simples usadas son grandes (de nuevo, digamos, ambas de tamaño como mínimo 40), entonces podemos usar un método paramétrico basado en una distribución t de Student, que da un intervalo de la forma \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\times\\text{error típico} \\] Pero el número de grados de libertad \\(\\nu\\) a usar en el cuantil y el error típico van a depender de dos factores. Por un lado, de que las muestras sean independientes (hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras obtenidas de manera independiente la una de la otra) o emparejadas (hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra o hay un emparejamiento natural entre los sujetos de las dos muestras; en particular, si las muestras son emparejadas ha de pasar que \\(n_1=n_2\\)). Y si las muestras son independientes, la fórmula a usar depende de si las varianzas de \\(X_1\\) y \\(X_2\\) son iguales o diferentes. (¿Y cómo podemos saber si son iguales o diferentes? No os perdáis la próxima lección.) Os damos las fórmulas, aunque no hace falta saberlas, solo recordar que la fórmula concreta a usar depende de estas condiciones. Supongamos, pues, que \\(X_1\\) y \\(X_2\\) son aproximadamente normales o que \\(n_1,n_2\\geq 40\\). En estas condiciones: Si las muestras son emparejadas y \\(n_1=n_2=n\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{n-1,(q+1)/2}\\cdot \\frac{\\widetilde{S}_D}{\\sqrt{n}} \\] donde \\(\\widetilde{S}_D\\) es la desviación típica muestral de las diferencias \\(X_1-X_2\\) sobre las parejas de la muestra. Si las muestras son independientes y \\(\\sigma_{X_1}^2=\\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{n_1+n_2-2,(q+1)/2} \\sqrt{\\Big(\\frac{1}{n_1}+\\frac{1}{n_2}\\Big)\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2} {n_1+n_2-2}} \\] donde \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente. Si las muestras son independientes y \\(\\sigma_{X_1}^2=\\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[ \\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\cdot\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}} \\] donde, de nuevo, \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente, y \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2}{\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} \\] 1.6 Un intervalo de confianza para la diferencia de proporciones Sean \\(X_1\\) y \\(X_2\\) dos variables Bernoulli de probabilidades poblacionales de éxito \\(p_1\\) y \\(p_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de estas probabilidades, \\(p_1-p_2\\). Para ello, tomamos dos muestras independientes, una de cada variable: Una muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de proporción muestral \\(\\widehat{p}_1\\). Una muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de proporción muestral \\(\\widehat{p}_2\\). Si las dos muestras son grandes, pongamos cada una de 50 o más sujetos, y las proporciones muestrales no son muy cercanas a 0 o a 1 (para fijar ideas, que en cada muestra haya como mínimo 5 éxitos y 5 fracasos), un IC-\\(q\\) para la diferencia \\(p_1-p_2\\) es, aproximadamente, \\[ \\widehat{p}_1-\\widehat{p}_2 \\pm z_{(q+1)/2}\\cdot \\sqrt{\\frac{n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2}{n_1 +n_2}\\cdot \\Big(\\frac{n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)}{n_1 +n_2}\\Big)\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)} \\] Notad que \\(n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) es el número total de éxitos y \\(n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)\\) el número total de fracasos en las dos muestras. 1.7 Test (1) Un intervalo de confianza del 99% para la concentración de un determinado metabolito en sangre es [10,12]. De acuerdo con esto, esperamos encontrar fuera de este intervalo: Un 1% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de las concentraciones medias de las muestras grandes (con \\(n\\geq 40\\)) Un 99% de las concentraciones medias de todas las muestras de cualquier tamaño Un 1% de todas las concentraciones en la población Un 99% de todas las concentraciones en la población Ninguna de las anteriores respuestas es correcta. (2) Para estimar una cierta media poblacional con un nivel de confianza 0.95, hemos usado una muestra de 100 individuos y un método paramétrico y hemos obtenido un IC-95% con un margen de error de 0.02. Si usamos una muestra de 200 individuos y la misma fórmula para calcular el IC, estamos seguros de que (marcad todas las afirmaciones correctas): El IC-95% obtenido tendrá un margen de error \\(&lt;0.02\\) El IC-95% obtenido tendrá un margen de error \\(&gt;0.02\\) Si calculamos un IC-99%, su margen de error será \\(&gt;0.02\\) Si calculamos un IC-90%, su margen de error será \\(&gt;0.02\\) Ninguna de las otras afirmaciones es correcta (3) Para calcular un IC-95% para la media poblacional \\(\\mu\\) de un cierto parámetro con la fórmula basada en la t de Student, hemos tomado una muestra aleatoria simple de 100 individuos con \\(\\overline{x}=2\\) y \\(\\widetilde{s}_X^2=0.8\\). Si ahora usamos otra muestra aleatoria simple de 100 individuos y obtenemos \\(\\overline{x}=3\\) y \\(\\widetilde{s}_X^2=0.6\\), ¿como será el IC-95% que obtengamos? Igual de ancho que el anterior. Más estrecho que el anterior. Más ancho que el anterior. No podemos saber si el nuevo IC será más ancho, más estrecho o igual de ancho que el anterior. (4) Un artículo de una revista científica informa de que el intervalo de confianza del 95% del nivel medio de colesterolemia en los adultos atendidos en un Centro de Salud es 192-208. Se aceptó que la variable tenía una distribución normal y el número de pacientes estudiados fue de 100. ¿Cuáles de las siguientes afirmaciones son verdaderas? Es muy probable que el nivel medio poblacional esté comprendido entre 192 y 208. Si se repitiera el estudio muchas veces, en un 95% de ellas se obtendría una media muestral comprendida entre 192 y 208. El 95% de los adultos de la población tiene un nivel de colesterolemia comprendido entre 192 y 208. La media muestral encontrada en el estudio es de 200. La desviación típica muestral encontrada en el estudio ha sido aproximadamente 40 o 41. Ninguna de las anteriores respuestas es correcta. (5) Un intervalo de confianza del 95% para la media estimado a partir de una muestra (marcad las afirmaciones correctas): Es un intervalo en el cual, a largo plazo, caen el 95% de las observaciones. Es una manera de expresar la precisión de la estimación de la media. Es un intervalo que se ha calculado con una fórmula para que incluya la media muestral en el 95% de las ocasiones que la apliquemos a muestras. Es un intervalo que se ha calculado con una fórmula para que incluya la media de la población en el 95% de las ocasiones que la apliquemos a muestras. Es una manera de expresar la variabilidad de un conjunto de observaciones. "]
]
